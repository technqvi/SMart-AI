{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e0f92d-885a-42f9-806a-3b38b4e70876",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy import stats\n",
    "from dython.nominal import associations\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot  as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef765238-7818-4d10-b19a-0bf9ab232a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_name='train_incident'\n",
    "validation_name='validation_incident'\n",
    "test_name='test_incident'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5b965f-2406-481f-91f1-84f045f7f1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "projectId='pongthorn'\n",
    "client = bigquery.Client(project=projectId)\n",
    "\n",
    "# projectId='smart-data-ml'\n",
    "# credentials = service_account.Credentials.from_service_account_file(r'C:\\Windows\\smart-data-ml-91b6f6204773.json')\n",
    "# client = bigquery.Client(credentials=credentials, project=projectId)\n",
    "\n",
    "dataset_dw_id='SMartDW'\n",
    "dataset_id='SMartML'\n",
    "\n",
    "dw_table_id = f\"{projectId}.{dataset_dw_id}.incident\"\n",
    "\n",
    "train_table_id=f\"{projectId}.{dataset_id}.{train_name}\"\n",
    "val_tabel_id=f\"{projectId}.{dataset_id}.{validation_name}\"\n",
    "test_tabel_id=f\"{projectId}.{dataset_id}.{test_name}\"\n",
    "\n",
    "file_name=\"ML_Incident.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a034146f-e44c-4bd5-811d-6d2a62477250",
   "metadata": {},
   "outputs": [],
   "source": [
    "isLastUpdate=True\n",
    "\n",
    "IsNewData=False\n",
    "\n",
    "label='severity_id'\n",
    "labelName='severity_name'\n",
    "\n",
    "threshold_x_sd = 3  # 2.5/3/3.5\n",
    "\n",
    "\n",
    "removeCols=['id','updated_at','imported_at']\n",
    "\n",
    "dateCols=['open_datetime','close_datetime','response_datetime','resolved_datetime']\n",
    "\n",
    "numbericCols=['count_detail','open_to_close_hour','open_to_response_hour','response_to_resolved_hour']\n",
    "#numbericCols=['count_detail','open_to_close_hour']\n",
    "\n",
    "cateCols=['sla','product_type','brand','service_type','incident_type']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e5a81d-bb30-40ac-9ead-dfe21e96e9d2",
   "metadata": {},
   "source": [
    "# Explore and Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb79121-2ec3-4c14-a314-56464938bf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_bq(sql:str):\n",
    "\n",
    " query_result=client.query(sql)\n",
    " df_all=query_result.to_dataframe()\n",
    " return df_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0375bba-02df-43c2-bc2e-66dfab84589a",
   "metadata": {},
   "outputs": [],
   "source": [
    "imported_to='2023-11-01'  # for test  date+1 of the day that you perform\n",
    "#imported_to='2023-03-13' For production\n",
    "#updated_to='2023-03-13' # For test\n",
    "\n",
    "sql_all=f\"\"\"\n",
    "SELECT  id,severity_id,severity_name\n",
    ",count_detail\n",
    ",sla,product_type,brand,service_type,incident_type\n",
    ",open_datetime,  close_datetime, response_datetime,resolved_datetime\n",
    ",updated_at,imported_at\n",
    "\n",
    "FROM `{dw_table_id}`    \n",
    "\n",
    "WHERE imported_at< '{imported_to}'\n",
    "\n",
    "order  by imported_at\n",
    "\"\"\"\n",
    "#WHERE updated_at< '{updated_to}'\n",
    "#WHERE imported_at< '{imported_to}'\n",
    "\n",
    "# copy sql statement to check whether to be valid or not\n",
    "print(sql_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b2ba6f-79e9-4f63-bdea-2848c383a309",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Load data from Bigquery\")\n",
    "df_all=load_data_bq(sql_all)\n",
    "if len(df_all)==0:\n",
    " print(\"No records from bigquery\")  \n",
    " quit()\n",
    "else:\n",
    " print(df_all.shape)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03886d3-4ac0-48df-81d9-6f3eb62279eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all=df_all.drop_duplicates(subset=['id'],keep='last')\n",
    "\n",
    "no_original_rows=len(df_all)\n",
    "\n",
    "df_all.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e511da8d-67bb-4352-856c-9c12a4ddc3ca",
   "metadata": {},
   "source": [
    "# Manage Numberic Cols\n",
    "Converting the data of these columns to hourly time period., it is more informative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7459c270-e68f-46f7-b27a-08bf2c44d3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_end_list=[ ['open_datetime','close_datetime'],['open_datetime','response_datetime'],['response_datetime','resolved_datetime']]\n",
    "listDiffDateDeltaCols=[]\n",
    "listDiffHourCols=[]\n",
    "for item  in  start_end_list:\n",
    "   diff_str=f\"{item[0]}_to_{item[1]}\" \n",
    "   diff_str=diff_str.replace('_datetime','')  \n",
    "   listDiffDateDeltaCols.append(diff_str)\n",
    "   df_all[diff_str]=df_all[item[1]]-df_all[item[0]]\n",
    "    \n",
    "   diff_hour=f'{diff_str}_hour'\n",
    "   listDiffHourCols.append(diff_hour)\n",
    "   df_all[diff_hour] = df_all[diff_str].apply(lambda x:  x.total_seconds() / (60*60) if x is not np.nan else np.nan  )\n",
    "\n",
    "\n",
    "#df_all[listDiffHourCols].describe()\n",
    "df_all[listDiffHourCols].describe(percentiles=[.95,.75,.50,.25,.05])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d02b867-d9e6-4a43-90fd-b75fb98f534e",
   "metadata": {},
   "source": [
    "# Remove outlier on Time Interval to service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7b1d06-0794-4248-b406-359c959d1ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.geeksforgeeks.org/z-score-for-outlier-detection-python/\n",
    "xScoreDiffHourCols=[]\n",
    "for col in listDiffHourCols:\n",
    "  z_col=f\"zscore_{col}\"   \n",
    "  df_all[z_col] = np.abs(stats.zscore(df_all[col]))   \n",
    "  xScoreDiffHourCols.append(z_col)  \n",
    "#remove oulier\n",
    "\n",
    "for col in  xScoreDiffHourCols:\n",
    "  df_all=df_all.query(f\"{col}<@threshold_x_sd\")\n",
    "\n",
    "\n",
    "no_rows_after_removing_outlier=len(df_all)\n",
    "pct_row_decrease=round( (no_original_rows-no_rows_after_removing_outlier)/no_original_rows*100 ,0)\n",
    "\n",
    "print(f\"% remove data {pct_row_decrease}\")\n",
    "\n",
    "print(df_all.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6724d7cb-0903-4681-9439-bdc3e27cce0e",
   "metadata": {},
   "source": [
    "# Find any rows  contain zero time period\n",
    "## it doesn't make any sense on real world "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28a3052-cf5f-489b-90b6-02296d28406c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if>5%  remove column, else judge to remove 0 value \n",
    "# remove coundetail because mostly, there are few value 1,2 items\n",
    "allRows=df_all.shape[0]\n",
    "for col in numbericCols:\n",
    "    zeroRows=len(df_all.query(f\"{col}==0\"))\n",
    "    pctZeroHour=round(zeroRows/allRows*100,1)\n",
    "    print(f\"No. 0-hour row on {col} = {zeroRows}({pctZeroHour} %)\")\n",
    "    \n",
    "  # open_to_response_hour =o is not realistic  ==> move columns  \n",
    "# No. 0-hour row on open_to_response_hour = 456(19.2 %) , it is relevant to site manage's behaviod\n",
    "# They get incident call from customer  and provide engineer to response completely\n",
    "# afte that they will enter the application to record case "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b93a24d-ed5f-4a63-80be-923250b5949a",
   "metadata": {},
   "source": [
    "# Bining Range\n",
    "\n",
    "function is used to separate the array elements into many different ranges . \n",
    "The cut function is mainly used to perform statistical analysis on scalar data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82892e02-14e5-4789-82ab-e6855e7dbe47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.geeksforgeeks.org/pandas-cut-method-in-python/\n",
    "\n",
    "\n",
    "def explore_ranges_numberic_val(col,rangeList):\n",
    "    print(col)\n",
    "    rangeList.sort()\n",
    "    return pd.cut(df_all[col],rangeList, right=True).value_counts()\n",
    "range1= [0,24, 168, 360, 720,math.floor(df_all['open_to_close_hour'].max())]\n",
    "print(explore_ranges_numberic_val('open_to_close_hour',range1))\n",
    "print(\"=======================================================\")\n",
    "\n",
    "range2= [0,24, 168, 360, 720,math.floor(df_all['response_to_resolved_hour'].max())]\n",
    "print(explore_ranges_numberic_val('response_to_resolved_hour',range2))\n",
    "print(\"=======================================================\")\n",
    "\n",
    "# range3= [0,4, 8, 12, 24,math.floor(df_all['open_to_response_hour'].max())]\n",
    "# print(explore_ranges_numberic_val('open_to_response_hour',range3))\n",
    "# print(\"=======================================================\")\n",
    "\n",
    "range4= [0,2, 4,math.floor(df_all['count_detail'].max())]\n",
    "print(explore_ranges_numberic_val('count_detail',range4))\n",
    "print(\"=======================================================\")\n",
    "\n",
    "# we can convert hour to range   \n",
    "# (0, 24] =by 1 day =best\n",
    "# (24, 168] =  1day -1 week  =good\n",
    "# (168, 360]=  1week- 15 days(half a month) =fair\n",
    "# (360, 720]= 15 dasy-1 month =bad\n",
    "# (720, 2349]=1 month-1 Q =worst\n",
    "\n",
    "# open_to_close_hour ,response_to_resolved_hour , mostly  we can complate by 1 day (0, 24]\n",
    "# there are few cased that take long to close incident (360, 720]   15 day to  1month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d1d32d-8037-4b71-a322-4eee67215d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Anyway , We will have 2 columns left \n",
    "print(\"remove some cate featurs that have undeisred data\")\n",
    "\n",
    "# open_to_response_hour :No. 0-hour row on open_to_response_hour = 456(19.2 %)\n",
    "# ount_detail  : 80%  (0, 2] =1790 You'll notice that most of the data is clustered in (0, 2] detail  only\n",
    "numColsRemove=['open_to_response_hour','count_detail'] \n",
    "numbericCols=[x for x in numbericCols if x not in numColsRemove]   \n",
    "numbericCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abd839a-145f-4364-8731-6ed661e75762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove response_to_resolved_hour ,it doesn't make any sense\n",
    "# No. 0-hour row on response_to_resolved_hour = 99(4.2 %)\n",
    "df_all=df_all.query('response_to_resolved_hour!=0')\n",
    "df_all.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab576892-126a-4ea4-ab6c-a8de32e80bb6",
   "metadata": {},
   "source": [
    "# Drop unnessay columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8ad9c1-a0a3-4bd3-a0f3-cb1e61008d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "removeCols=removeCols+dateCols+xScoreDiffHourCols+listDiffDateDeltaCols+numColsRemove\n",
    "df_all=df_all.drop(columns=removeCols)\n",
    "df_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b39c6f9-32b6-4373-828e-3fcfa0c67f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[numbericCols].describe(percentiles=[.95,.75,.50,.25,.05])\n",
    "# 95% vs max"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de4dc52-7540-493d-9ef1-0554b445e15d",
   "metadata": {},
   "source": [
    "# Plot Numeric  columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baae5996-3ac2-43a3-9fe3-c19b61937e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[numbericCols].plot(kind='box',subplots=True,layout=(1,len(numbericCols)),sharex=False, sharey=False,figsize=(10,5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afbb497-21b2-4277-b868-1b921f83811f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.scatter_matrix(df_all[numbericCols], alpha=0.2,figsize=(10,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e7f71a-6096-4535-a70a-174cd602d50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = df_all[numbericCols].corr ()  \n",
    "corr_df = corr_df .round(2)\n",
    "\n",
    "fig = plt.figure(figsize = (10, 6))\n",
    "heatmap = sns. heatmap(corr_df, annot = True) \n",
    "plt. show ()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd2166f-c6be-4e46-b2e1-6c5b617f2c3f",
   "metadata": {},
   "source": [
    "# Plot Categorical Cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59cc8ff-1f30-435a-aa5b-5f47d5cbab73",
   "metadata": {},
   "outputs": [],
   "source": [
    "VBar=['brand','incident_type']\n",
    "HBar=[ x for x in cateCols if x not in VBar]\n",
    "HBar.insert(0,'severity_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7844dd-2b0e-4597-8858-bc0d37d8409f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in HBar:\n",
    "    fig , ax = plt.subplots(figsize=(15,5))\n",
    "    ax =sns.countplot(x=col, data=df_all,)\n",
    "    for p in ax.patches:\n",
    "       ax.annotate('{:.1f}'.format(p.get_height()), (p.get_x()+0.25, p.get_height()+0.01))\n",
    "    plt.title(col.title())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34017110-73c2-4d1c-b28d-32027145592f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in VBar:\n",
    "    fig , ax = plt.subplots(figsize=(10,20))\n",
    "    ax =sns.countplot(y=col, data=df_all)\n",
    "    plt.title(col.title())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132aaf81-5b06-43bc-9460-323fe19fbfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all of them are not hardly relevant, it is hight variance\n",
    "complete_correlation= associations(df_all[ cateCols ], figsize=(15,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b02902-c184-4589-afa4-24ddcccb52b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_all.info())\n",
    "df_all.to_csv(f\"data/{file_name}\",index=False)\n",
    "#bucket_name=\"gs://smart-ml-pongthorn\"\n",
    "# df_all.to_csv(f\"{bucket_name}/{file_name}\",index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c95b90d-adb7-4e88-8081-04fcc949a620",
   "metadata": {},
   "source": [
    "# Build Training DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b82357-cce8-4301-ab51-47624a65a861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create label\n",
    "map_severity_to_class={'Cosmetic':0,'Minor': 1, \"Major\": 2, \"Critical\": 3}\n",
    "print(f\"Map severity Name to LabelCode: {str(map_severity_to_class)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a785398d-9ccf-473e-9255-7eb9dde7f222",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['label_multi_severity'] =df_all['severity_name'].map(map_severity_to_class) \n",
    "def map_4to2_serverity(severity_id):\n",
    "    if severity_id==1 or severity_id==2:\n",
    "       return 1\n",
    "    else:\n",
    "       return 0 \n",
    "df_all['label_binary_severity'] =df_all['severity_id'].apply(map_4to2_serverity)\n",
    "\n",
    "print( list(df_all['label_multi_severity'].unique()))\n",
    "print(df_all['label_binary_severity'].unique())\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3abd14c-18b0-46c6-aadb-5ed60a51545a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into 3 dataset to BQ\n",
    "len_all=len(df_all)\n",
    "print(f\"All Data = {len_all}\")\n",
    "\n",
    "# Split the 80% of total as train\n",
    "# The remaining  will be splited equally 50% for valuation and the rest of later part is test\n",
    "\n",
    "train, val = train_test_split(df_all,test_size=0.2,random_state=1000,shuffle=True)\n",
    "val,test = train_test_split(val, test_size=0.5,random_state=1000,shuffle=True)\n",
    "\n",
    "len_all=len(df_all)\n",
    "len_train=len(train)\n",
    "len_val=len(val)\n",
    "len_test=len(test)\n",
    "print(f'{len_train} =train examples ({round(len_train/len_all*100,1)}%)')\n",
    "print(f'{len_val} =val examples ({round(len_val/len_all*100,1)}%)')\n",
    "print(f'{len_test} =test examples ({round(len_test/len_all*100,1)}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a9847f-58f6-4613-a00f-2e464a751e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"pct removed data ={(no_original_rows-len(df_all))/no_original_rows*100}\")\n",
    "#it is pretty close to 5%   , at most 10% is removable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7914720-e035-4ff4-a663-3a174ec39de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataFrameToBQ(table_id,dfx):\n",
    "    try:\n",
    "        job_config = bigquery.LoadJobConfig(\n",
    "            write_disposition=\"WRITE_TRUNCATE\",\n",
    "        )\n",
    "\n",
    "        job = client.load_table_from_dataframe(\n",
    "            dfx, table_id, job_config=job_config\n",
    "        )\n",
    "        job.result()  # Wait for the job to complete.\n",
    "        print(f\"{len(dfx)} rows imported to {table_id} successfully\")\n",
    "\n",
    "    except BadRequest as e:\n",
    "        print(\"Bigquery Error\\n\")\n",
    "        for e in job.errors:\n",
    "            print('ERROR: {}'.format(e['message']))\n",
    "            \n",
    "# save to csv file to load faster than bigquery\n",
    "train.to_csv(f\"data/{train_name}.csv\",index=False)\n",
    "val.to_csv(f\"data/{validation_name}.csv\",index=False)\n",
    "test.to_csv(f\"data/{test_name}.csv\",index=False)\n",
    "\n",
    "#write_disposition=\"WRITE_TRUNCATE\"\n",
    "#google will create table and load data into them automaticall \n",
    "loadDataFrameToBQ(f\"{train_table_id}\",train)\n",
    "loadDataFrameToBQ(f\"{val_tabel_id}\",val)\n",
    "loadDataFrameToBQ(f\"{test_tabel_id}\",test)   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dffecb0-2790-4d35-bae6-2da2c2871aec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
