{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9df47983-136a-4ae5-99cb-114efcecc044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n",
      "1.4.0\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import aiplatform\n",
    "from google.cloud import bigquery\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date,datetime,timedelta\n",
    "\n",
    "import math\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_decision_forests as tfdf  # constantly registered to load model \n",
    "print(tf.__version__)\n",
    "print(tfdf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b7633548-9dc9-406c-a8ec-080e7c5562f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import functions_framework\n",
    "# @functions_framework.http\n",
    "# def xgb_tf_predict_incident_severity(request):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b9604a8d-66ee-41f8-bca5-4ced39eadd0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://demo-tuned-tf-incident-pongthorn/model_xgb_tf\n"
     ]
    }
   ],
   "source": [
    "model_tree_type=1 # 1= xgboost  2-random forest\n",
    "option=1\n",
    "\n",
    "if model_tree_type==1:\n",
    "    _model='model_xgb_tf'\n",
    "else:\n",
    "     _model='model_rf_tf'\n",
    "\n",
    "model_gs_path=f\"gs://demo-tuned-tf-incident-pongthorn/{_model}\"\n",
    "print(model_gs_path)\n",
    "\n",
    "projectId=\"pongthorn\"\n",
    "dataset_id=\"SMartML\"\n",
    "\n",
    "map_severity_to_class={0:4,1: 3, 2: 2, 3: 1}\n",
    "\n",
    "if option==1:\n",
    "    unusedCols_unseen=['id','severity_name','open_to_close_hour']\n",
    "else:\n",
    "    unusedCols_unseen=['id','severity_name','range_open_to_close_hour']\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6feef88-a349-497c-9845-731e4fad788c",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "83c3e87a-46fb-4294-8ad9-45cd14f2e21c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 23-07-07 15:42:36.6887 UTC kernel.cc:1243] Loading model from path gs://demo-tuned-tf-incident-pongthorn/model_xgb_tf/assets/ with prefix 3ac63f3679524a2a\n",
      "[INFO 23-07-07 15:42:37.1656 UTC decision_forest.cc:660] Model loaded with 148 root(s), 7318 node(s), and 6 input feature(s).\n",
      "[INFO 23-07-07 15:42:37.1665 UTC abstract_model.cc:1311] Engine \"GradientBoostedTreesGeneric\" built\n",
      "[INFO 23-07-07 15:42:37.1670 UTC kernel.cc:1075] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"gradient_boosted_trees_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      "=================================================================\n",
      "Total params: 1\n",
      "Trainable params: 0\n",
      "Non-trainable params: 1\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "abc_model = tf.keras.models.load_model(model_gs_path)  \n",
    "print(abc_model.summary())\n",
    "# abc_model = tf.keras.models.load_model(model_local_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaffc009-d504-4345-8af0-75ea4100d667",
   "metadata": {},
   "source": [
    "# Make Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c849ad7a-10f4-43b8-8421-1f907fc42b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17 entries, 0 to 16\n",
      "Data columns (total 7 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   severity_id               17 non-null     Int64 \n",
      " 1   sla                       17 non-null     object\n",
      " 2   product_type              17 non-null     object\n",
      " 3   brand                     17 non-null     object\n",
      " 4   service_type              17 non-null     object\n",
      " 5   incident_type             17 non-null     object\n",
      " 6   range_open_to_close_hour  17 non-null     object\n",
      "dtypes: Int64(1), object(6)\n",
      "memory usage: 1.1+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>severity_id</th>\n",
       "      <th>sla</th>\n",
       "      <th>product_type</th>\n",
       "      <th>brand</th>\n",
       "      <th>service_type</th>\n",
       "      <th>incident_type</th>\n",
       "      <th>range_open_to_close_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>24x7 4Hrs Response Time</td>\n",
       "      <td>Storage</td>\n",
       "      <td>NetApp</td>\n",
       "      <td>Incident</td>\n",
       "      <td>Controller/Node Failure</td>\n",
       "      <td>soon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>24x7 4Hrs Resolution Time</td>\n",
       "      <td>Storage</td>\n",
       "      <td>NetApp</td>\n",
       "      <td>Incident</td>\n",
       "      <td>Controller/Node Failure</td>\n",
       "      <td>soon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>24x7 4Hrs Resolution Time</td>\n",
       "      <td>Storage</td>\n",
       "      <td>NetApp</td>\n",
       "      <td>Incident</td>\n",
       "      <td>Hard Disk Drive Failure</td>\n",
       "      <td>latest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>24x7 4Hrs Response Time</td>\n",
       "      <td>Storage</td>\n",
       "      <td>NetApp</td>\n",
       "      <td>Incident</td>\n",
       "      <td>Hard Disk Drive Failure</td>\n",
       "      <td>soon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>24x7 4Hrs Response Time</td>\n",
       "      <td>Storage</td>\n",
       "      <td>NetApp</td>\n",
       "      <td>Incident</td>\n",
       "      <td>General Incident</td>\n",
       "      <td>soon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>24x7 4Hrs Response Time</td>\n",
       "      <td>Security</td>\n",
       "      <td>Trend Micro</td>\n",
       "      <td>Incident</td>\n",
       "      <td>Upgrade Software</td>\n",
       "      <td>soon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>24x7 4Hrs Response Time</td>\n",
       "      <td>Software</td>\n",
       "      <td>VMWare</td>\n",
       "      <td>Incident</td>\n",
       "      <td>General Incident</td>\n",
       "      <td>soonest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>24x7 4Hrs Response Time</td>\n",
       "      <td>Software</td>\n",
       "      <td>VMWare</td>\n",
       "      <td>Incident</td>\n",
       "      <td>General Incident</td>\n",
       "      <td>soonest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>24x7 6Hrs Resolution Time</td>\n",
       "      <td>Software</td>\n",
       "      <td>eUnite</td>\n",
       "      <td>Incident</td>\n",
       "      <td>Software</td>\n",
       "      <td>soonest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>24x7 6Hrs Resolution Time</td>\n",
       "      <td>Software</td>\n",
       "      <td>eUnite</td>\n",
       "      <td>Incident</td>\n",
       "      <td>Software</td>\n",
       "      <td>soonest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    severity_id                        sla product_type        brand  \\\n",
       "7             3    24x7 4Hrs Response Time      Storage       NetApp   \n",
       "8             3  24x7 4Hrs Resolution Time      Storage       NetApp   \n",
       "9             3  24x7 4Hrs Resolution Time      Storage       NetApp   \n",
       "10            3    24x7 4Hrs Response Time      Storage       NetApp   \n",
       "11            4    24x7 4Hrs Response Time      Storage       NetApp   \n",
       "12            3    24x7 4Hrs Response Time     Security  Trend Micro   \n",
       "13            3    24x7 4Hrs Response Time     Software       VMWare   \n",
       "14            3    24x7 4Hrs Response Time     Software       VMWare   \n",
       "15            3  24x7 6Hrs Resolution Time     Software       eUnite   \n",
       "16            2  24x7 6Hrs Resolution Time     Software       eUnite   \n",
       "\n",
       "   service_type            incident_type range_open_to_close_hour  \n",
       "7      Incident  Controller/Node Failure                     soon  \n",
       "8      Incident  Controller/Node Failure                     soon  \n",
       "9      Incident  Hard Disk Drive Failure                   latest  \n",
       "10     Incident  Hard Disk Drive Failure                     soon  \n",
       "11     Incident         General Incident                     soon  \n",
       "12     Incident         Upgrade Software                     soon  \n",
       "13     Incident         General Incident                  soonest  \n",
       "14     Incident         General Incident                  soonest  \n",
       "15     Incident                 Software                  soonest  \n",
       "16     Incident                 Software                  soonest  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = bigquery.Client(project=projectId)\n",
    "new_data_table_id=f\"{projectId}.{dataset_id}.new2_incident\"\n",
    "\n",
    "query_result=client.query(f\"SELECT * FROM {new_data_table_id}\")\n",
    "df=query_result.to_dataframe()\n",
    "\n",
    "unseen =df.drop(columns=unusedCols_unseen)\n",
    "print(unseen.info())\n",
    "unseen.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a4b709a5-91c0-4e40-abd7-7fc4bc49c5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_PrefetchDataset element_spec={'sla': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'product_type': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'brand': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'service_type': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'incident_type': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'range_open_to_close_hour': TensorSpec(shape=(None,), dtype=tf.string, name=None)}>\n"
     ]
    }
   ],
   "source": [
    "unseen_ds= tfdf.keras.pd_dataframe_to_tf_dataset(unseen.drop(columns=['severity_id']))\n",
    "print(unseen_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "31d90302-f84b-4266-9407-a03f1689026f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 74ms/step\n",
      "[0.94347364 0.0481788  0.00486785 0.00347972] : 0 as severity#4\n",
      "[0.01779265 0.08065245 0.8698259  0.03172899] : 2 as severity#2\n",
      "[0.02062506 0.12977083 0.8195875  0.03001656] : 2 as severity#2\n",
      "[0.00982261 0.04917946 0.9345066  0.0064913 ] : 2 as severity#2\n",
      "[0.02177456 0.06510144 0.8986616  0.01446236] : 2 as severity#2\n",
      "[0.01796301 0.07064571 0.8959037  0.0154876 ] : 2 as severity#2\n",
      "[0.0202044  0.33375847 0.6294168  0.0166203 ] : 2 as severity#2\n",
      "[0.0084537  0.5115585  0.3211109  0.15887694] : 1 as severity#3\n",
      "[0.01782154 0.24195981 0.26666096 0.47355765] : 3 as severity#1\n",
      "[0.01380757 0.7401283  0.21320215 0.03286188] : 1 as severity#3\n",
      "[0.01318795 0.4098764  0.5532594  0.02367628] : 2 as severity#2\n",
      "[0.01558995 0.7628804  0.208927   0.01260272] : 1 as severity#3\n",
      "[0.01177808 0.9077274  0.07633034 0.00416415] : 1 as severity#3\n",
      "[0.0132471  0.5037367  0.46594632 0.01706991] : 1 as severity#3\n",
      "[0.0132471  0.5037367  0.46594632 0.01706991] : 1 as severity#3\n",
      "[0.00540476 0.9591863  0.03236104 0.00304785] : 1 as severity#3\n",
      "[0.00540476 0.9591863  0.03236104 0.00304785] : 1 as severity#3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-07 15:43:00.623529: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [17]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    }
   ],
   "source": [
    "predResultList=abc_model.predict(unseen_ds)\n",
    "predServerityIDList=[]\n",
    "for predResult in predResultList:\n",
    "    _class=tf.argmax(predResult,-1).numpy()\n",
    "    pred_seveirty_id=map_severity_to_class[_class]\n",
    "    predServerityIDList.append(pred_seveirty_id)\n",
    "    print(f\"{predResult} : {_class} as severity#{pred_seveirty_id}\")\n",
    "    \n",
    "dfPred=pd.DataFrame(data=predServerityIDList,columns=[\"pred_severity_id\"])   \n",
    "df=pd.concat([dfPred,df],axis=1)\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767ac965-914f-4ca8-99f4-33f25079bed1",
   "metadata": {},
   "source": [
    "# Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "06828323-74af-44fb-b261-aade71784b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix,classification_report\n",
    "# className=list(set().union(list(df['pred_severity_id'].unique()),list(df['severity_id'].unique())))\n",
    "# className\n",
    "# actualClass=[  f'actual-{x}' for x in  className]\n",
    "# predictedlClass=[  f'pred-{x}' for x in className]\n",
    "# y_true=list(df['severity_id'])\n",
    "# y_pred=list(df['pred_severity_id'])\n",
    "# cnf_matrix = confusion_matrix(y_true,y_pred)\n",
    "# cnf_matrix\n",
    "\n",
    "# # #index=actual , column=prediction\n",
    "# cm_df = pd.DataFrame(cnf_matrix,\n",
    "#                      index = actualClass, \n",
    "#                      columns = predictedlClass)\n",
    "# print(cm_df)\n",
    "# print(classification_report(y_true, y_pred, labels=className))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98ac483-bdf4-4060-b394-95ae66b01286",
   "metadata": {},
   "source": [
    "# Write Prediction Result to BQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b18455cc-545f-424b-9640-37eb84b4dad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id  severity_id  pred_severity_id        prediction_datetime\n",
      "0   2790            4                 4 2023-07-07 15:43:07.472917\n",
      "1   3027            2                 2 2023-07-07 15:43:07.472917\n",
      "2   2832            2                 2 2023-07-07 15:43:07.472917\n",
      "3   3026            2                 2 2023-07-07 15:43:07.472917\n",
      "4   3025            2                 2 2023-07-07 15:43:07.472917\n",
      "5   3021            3                 2 2023-07-07 15:43:07.472917\n",
      "6   3029            4                 2 2023-07-07 15:43:07.472917\n",
      "7   3034            3                 3 2023-07-07 15:43:07.472917\n",
      "8   3035            3                 1 2023-07-07 15:43:07.472917\n",
      "9   3032            3                 3 2023-07-07 15:43:07.472917\n",
      "10  3030            3                 2 2023-07-07 15:43:07.472917\n",
      "11  2957            4                 3 2023-07-07 15:43:07.472917\n",
      "12  3031            3                 3 2023-07-07 15:43:07.472917\n",
      "13  3033            3                 3 2023-07-07 15:43:07.472917\n",
      "14  3022            3                 3 2023-07-07 15:43:07.472917\n",
      "15  3018            3                 3 2023-07-07 15:43:07.472917\n",
      "16  3006            2                 3 2023-07-07 15:43:07.472917\n"
     ]
    }
   ],
   "source": [
    "df=df[['id','severity_id','pred_severity_id']]\n",
    "df['prediction_datetime']=datetime.now()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a466acd-b50a-44c0-85fe-4a4d07afd09c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d6d6b712-df15-4cc4-8fa5-fef554725ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict Result Table pongthorn.SMartML.new2_result_prediction_incident already exists.\n"
     ]
    }
   ],
   "source": [
    "predictResult_table_id=f\"{projectId}.{dataset_id}.new2_result_prediction_incident\"\n",
    "\n",
    "try:\n",
    "    client.get_table(predictResult_table_id)  # Make an API request.\n",
    "    print(\"Predict Result Table {} already exists.\".format(predictResult_table_id))\n",
    "except Exception as ex:\n",
    "    schema = [\n",
    "    bigquery.SchemaField(\"id\", \"INTEGER\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"severity_id\", \"INTEGER\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"pred_severity_id\", \"INTEGER\", mode=\"REQUIRED\"),       \n",
    "    bigquery.SchemaField(\"prediction_datetime\", \"DATETIME\", mode=\"REQUIRED\") \n",
    "    ]\n",
    "\n",
    "    table = bigquery.Table(predictResult_table_id,schema=schema)\n",
    "    # table.time_partitioning = bigquery.TimePartitioning(\n",
    "    # type_=bigquery.TimePartitioningType.DAY,field=\"prediction_item_date\")\n",
    "    \n",
    "    table = client.create_table(table)  # Make an API request.\n",
    "    \n",
    "    print(\n",
    "        \"Created table {}.{}.{}\".format(table.project, table.dataset_id, table.table_id)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "690bc079-2458-42b7-8343-30114abb4435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Prediction ML  17 Imported bigquery successfully\n"
     ]
    }
   ],
   "source": [
    "def loadDataFrameToBQ():\n",
    "    try:\n",
    "        job_config = bigquery.LoadJobConfig(\n",
    "            write_disposition=\"WRITE_APPEND\",\n",
    "        )\n",
    "\n",
    "        job = client.load_table_from_dataframe(\n",
    "            df, predictResult_table_id, job_config=job_config\n",
    "        )\n",
    "        job.result()  # Wait for the job to complete.\n",
    "        print(\"Total Prediction ML \", len(df), \"Imported bigquery successfully\")\n",
    "\n",
    "    except BadRequest as e:\n",
    "        print(\"Bigquery Error\\n\")\n",
    "        for e in job.errors:\n",
    "            print('ERROR: {}'.format(e['message']))\n",
    "\n",
    "try:\n",
    "    loadDataFrameToBQ()\n",
    "except Exception as ex:\n",
    "    raise ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293e9a0a-85c3-46c3-8298-2271d8b462f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return 'All incidents has been predicted completely.'"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-12.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-12:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
