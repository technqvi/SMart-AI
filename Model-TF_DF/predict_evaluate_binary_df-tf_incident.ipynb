{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9df47983-136a-4ae5-99cb-114efcecc044",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-12 06:30:32.953657: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n",
      "1.4.0\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date,datetime,timedelta,timezone\n",
    "\n",
    "import math\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_decision_forests as tfdf  # constantly registered to load model \n",
    "print(tf.__version__)\n",
    "print(tfdf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7633548-9dc9-406c-a8ec-080e7c5562f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import functions_framework\n",
    "# @functions_framework.http\n",
    "# def xgb_tf_predict_incident_severity(request):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166aefd0-bb63-428a-a29e-9f1548e1b354",
   "metadata": {},
   "source": [
    "# Load Configuration Data and Constant Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9604a8d-66ee-41f8-bca5-4ced39eadd0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction at 2023-11-12 06:33:20.169436+00:00 for 2023-11-12 (2023-11-12 00:00:00)\n",
      "gs://demo2-tf-incident-pongthorn/demo2_binary_rf_tf_model/\n",
      "Data: new2_incident and Prediction: new2_result_binary_prediction_incident\n"
     ]
    }
   ],
   "source": [
    "projectId=\"pongthorn\"\n",
    "#_model='binary_xgb_tf_model'   # the is resonable because unsseen and tune 70%\n",
    "all_prediction=True\n",
    "is_evaluation=True\n",
    "\n",
    "\n",
    "\n",
    "_model=\"demo2_binary_rf_tf_model/\"  # best 75% on unseen test\n",
    "model_version=f'{_model}_demo_tNov23'\n",
    "\n",
    "model_gs_path=f\"gs://demo2-tf-incident-pongthorn/{_model}\"\n",
    "\n",
    "\n",
    "dataset_id=\"SMartML\"\n",
    "\n",
    "data_table=\"new2_incident\"\n",
    "prediction_table=\"new2_result_binary_prediction_incident\"\n",
    "\n",
    "\n",
    "# unusedCols_unseen=['id','severity_name','imported_at','open_to_close_hour']\n",
    "\n",
    "unusedCols_unseen=['id','severity_name','imported_at','range_open_to_close_hour']\n",
    "\n",
    "\n",
    "# Get today's date\n",
    "prediction_datetime=datetime.now(timezone.utc)\n",
    "today_str=prediction_datetime.strftime(\"%Y-%m-%d\")\n",
    "today=datetime.strptime(today_str,\"%Y-%m-%d\")\n",
    "print(f\"Prediction at {prediction_datetime} for {today_str} ({today})\")\n",
    "\n",
    "print(model_gs_path)\n",
    "\n",
    "print(f\"Data: {data_table} and Prediction: {prediction_table}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6feef88-a349-497c-9845-731e4fad788c",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83c3e87a-46fb-4294-8ad9-45cd14f2e21c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 23-11-12 06:33:23.9313 UTC kernel.cc:1243] Loading model from path gs://demo2-tf-incident-pongthorn/demo2_binary_rf_tf_model/assets/ with prefix 898a63dcc5b24f14\n",
      "[INFO 23-11-12 06:33:24.7024 UTC decision_forest.cc:660] Model loaded with 300 root(s), 135716 node(s), and 6 input feature(s).\n",
      "[INFO 23-11-12 06:33:24.7033 UTC abstract_model.cc:1311] Engine \"RandomForestOptPred\" built\n",
      "[INFO 23-11-12 06:33:24.7038 UTC kernel.cc:1075] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"random_forest_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      "=================================================================\n",
      "Total params: 1\n",
      "Trainable params: 0\n",
      "Non-trainable params: 1\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "abc_model = tf.keras.models.load_model(model_gs_path)  \n",
    "print(abc_model.summary())\n",
    "# abc_model = tf.keras.models.load_model(model_local_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff853c6f-9db7-4e35-8e29-5ad37e3cfef2",
   "metadata": {},
   "source": [
    "# BigQuery Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bc0a0cc-321a-47a3-9712-d428a838533c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pongthorn.SMartML.new2_incident\n",
      "pongthorn.SMartML.new2_result_binary_prediction_incident\n"
     ]
    }
   ],
   "source": [
    "client = bigquery.Client(project=projectId)\n",
    "new_data_table_id=f\"{projectId}.{dataset_id}.{data_table}\"\n",
    "predictResult_table_id=f\"{projectId}.{dataset_id}.{prediction_table}\"\n",
    "print(new_data_table_id)\n",
    "print(predictResult_table_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5939dbb1-3319-4953-b238-40d5109dee90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict Result Table pongthorn.SMartML.new2_result_binary_prediction_incident already exists.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    client.get_table(predictResult_table_id)  # Make an API request.\n",
    "    print(\"Predict Result Table {} already exists.\".format(predictResult_table_id))\n",
    "    \n",
    "except Exception as ex:\n",
    "    schema = [\n",
    "    bigquery.SchemaField(\"id\", \"INTEGER\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"prediction_item_date\", \"DATE\", mode=\"REQUIRED\"),    \n",
    "    bigquery.SchemaField(\"label_binary_severity\", \"INTEGER\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"pred_binary_severity\", \"INTEGER\", mode=\"REQUIRED\"),       \n",
    "    bigquery.SchemaField(\"prediction_datetime\", \"DATETIME\", mode=\"REQUIRED\") ,\n",
    "    bigquery.SchemaField(\"model_version\", \"STRING\", mode=\"REQUIRED\")     \n",
    "    ]\n",
    "\n",
    "    table = bigquery.Table(predictResult_table_id,schema=schema)\n",
    "    table.time_partitioning = bigquery.TimePartitioning(\n",
    "    type_=bigquery.TimePartitioningType.DAY,field=\"prediction_item_date\")\n",
    "    \n",
    "    table = client.create_table(table)  # Make an API request.\n",
    "    \n",
    "    print(\n",
    "        \"Created table {}.{}.{}\".format(table.project, table.dataset_id, table.table_id)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaffc009-d504-4345-8af0-75ea4100d667",
   "metadata": {},
   "source": [
    "# Load data to Make Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c849ad7a-10f4-43b8-8421-1f907fc42b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    SELECT *  FROM `pongthorn.SMartML.new2_incident` \n",
      "     order by imported_at\n",
      "    \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 67 entries, 0 to 66\n",
      "Data columns (total 11 columns):\n",
      " #   Column                    Non-Null Count  Dtype         \n",
      "---  ------                    --------------  -----         \n",
      " 0   id                        67 non-null     Int64         \n",
      " 1   severity_id               67 non-null     Int64         \n",
      " 2   severity_name             67 non-null     object        \n",
      " 3   sla                       67 non-null     object        \n",
      " 4   product_type              67 non-null     object        \n",
      " 5   brand                     67 non-null     object        \n",
      " 6   service_type              67 non-null     object        \n",
      " 7   incident_type             67 non-null     object        \n",
      " 8   open_to_close_hour        67 non-null     float64       \n",
      " 9   range_open_to_close_hour  67 non-null     object        \n",
      " 10  imported_at               67 non-null     datetime64[ns]\n",
      "dtypes: Int64(2), datetime64[ns](1), float64(1), object(7)\n",
      "memory usage: 6.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "if int(all_prediction)==0:\n",
    "    sql=f\"\"\"\n",
    "    SELECT *  FROM `{new_data_table_id}` \n",
    "     WHERE DATE(imported_at) = '{today_str}'\n",
    "     order by imported_at\n",
    "    \"\"\"\n",
    "else:\n",
    "    sql=f\"\"\"\n",
    "    SELECT *  FROM `{new_data_table_id}` \n",
    "     order by imported_at\n",
    "    \"\"\"\n",
    "\n",
    "print(sql)\n",
    "\n",
    "\n",
    "query_result=client.query(sql)\n",
    "df=query_result.to_dataframe()\n",
    "if df.empty==True:\n",
    "  print(\"no data to make prediction\")  \n",
    "  # return \"no data to make prediction\"\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3afe76-1f85-4b6c-9079-6c00b98edd0d",
   "metadata": {},
   "source": [
    "# Build Unseen data by removing label and others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fdd59584-42b3-4ca4-83f4-4656a1d71baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 67 entries, 0 to 66\n",
      "Data columns (total 7 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   severity_id         67 non-null     Int64  \n",
      " 1   sla                 67 non-null     object \n",
      " 2   product_type        67 non-null     object \n",
      " 3   brand               67 non-null     object \n",
      " 4   service_type        67 non-null     object \n",
      " 5   incident_type       67 non-null     object \n",
      " 6   open_to_close_hour  67 non-null     float64\n",
      "dtypes: Int64(1), float64(1), object(5)\n",
      "memory usage: 3.9+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>severity_id</th>\n",
       "      <th>sla</th>\n",
       "      <th>product_type</th>\n",
       "      <th>brand</th>\n",
       "      <th>service_type</th>\n",
       "      <th>incident_type</th>\n",
       "      <th>open_to_close_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>2</td>\n",
       "      <td>24x7 4Hrs Resolution Time</td>\n",
       "      <td>Server</td>\n",
       "      <td>HPE</td>\n",
       "      <td>Incident</td>\n",
       "      <td>Hard Disk Drive Failure</td>\n",
       "      <td>5.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2</td>\n",
       "      <td>24x7 4Hrs Resolution Time</td>\n",
       "      <td>Server</td>\n",
       "      <td>HPE</td>\n",
       "      <td>Incident</td>\n",
       "      <td>Hard Disk Drive Failure</td>\n",
       "      <td>5.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2</td>\n",
       "      <td>24x7 6Hrs Response Time</td>\n",
       "      <td>Server</td>\n",
       "      <td>HPE</td>\n",
       "      <td>Incident</td>\n",
       "      <td>Hard Disk Drive Failure</td>\n",
       "      <td>21.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>3</td>\n",
       "      <td>24x7 4Hrs Response Time</td>\n",
       "      <td>Storage</td>\n",
       "      <td>NetApp</td>\n",
       "      <td>Incident</td>\n",
       "      <td>Hard Disk Drive Failure</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>3</td>\n",
       "      <td>24x7 4Hrs Response Time</td>\n",
       "      <td>Storage</td>\n",
       "      <td>NetApp</td>\n",
       "      <td>Incident</td>\n",
       "      <td>Hard Disk Drive Failure</td>\n",
       "      <td>7.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>4</td>\n",
       "      <td>24x7 4Hrs Resolution Time</td>\n",
       "      <td>Storage</td>\n",
       "      <td>Oracle</td>\n",
       "      <td>Incident</td>\n",
       "      <td>Hard Disk Drive Failure</td>\n",
       "      <td>2.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>4</td>\n",
       "      <td>24x7 4Hrs Resolution Time</td>\n",
       "      <td>Storage</td>\n",
       "      <td>Oracle</td>\n",
       "      <td>Incident</td>\n",
       "      <td>Hard Disk Drive Failure</td>\n",
       "      <td>2.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>2</td>\n",
       "      <td>8x5 4Hrs Response Time</td>\n",
       "      <td>Switch</td>\n",
       "      <td>HPE</td>\n",
       "      <td>Incident</td>\n",
       "      <td>Network Adapter Failure</td>\n",
       "      <td>4.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>2</td>\n",
       "      <td>8x5 NBD Response Time</td>\n",
       "      <td>Server</td>\n",
       "      <td>HPE</td>\n",
       "      <td>Incident</td>\n",
       "      <td>Network Adapter Failure</td>\n",
       "      <td>109.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>3</td>\n",
       "      <td>24x7 4Hrs Resolution Time</td>\n",
       "      <td>Server</td>\n",
       "      <td>Oracle</td>\n",
       "      <td>Incident</td>\n",
       "      <td>Network Adapter Failure</td>\n",
       "      <td>479.716667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    severity_id                        sla product_type   brand service_type  \\\n",
       "57            2  24x7 4Hrs Resolution Time       Server     HPE     Incident   \n",
       "58            2  24x7 4Hrs Resolution Time       Server     HPE     Incident   \n",
       "59            2    24x7 6Hrs Response Time       Server     HPE     Incident   \n",
       "60            3    24x7 4Hrs Response Time      Storage  NetApp     Incident   \n",
       "61            3    24x7 4Hrs Response Time      Storage  NetApp     Incident   \n",
       "62            4  24x7 4Hrs Resolution Time      Storage  Oracle     Incident   \n",
       "63            4  24x7 4Hrs Resolution Time      Storage  Oracle     Incident   \n",
       "64            2     8x5 4Hrs Response Time       Switch     HPE     Incident   \n",
       "65            2      8x5 NBD Response Time       Server     HPE     Incident   \n",
       "66            3  24x7 4Hrs Resolution Time       Server  Oracle     Incident   \n",
       "\n",
       "              incident_type  open_to_close_hour  \n",
       "57  Hard Disk Drive Failure            5.750000  \n",
       "58  Hard Disk Drive Failure            5.750000  \n",
       "59  Hard Disk Drive Failure           21.066667  \n",
       "60  Hard Disk Drive Failure           35.000000  \n",
       "61  Hard Disk Drive Failure            7.633333  \n",
       "62  Hard Disk Drive Failure            2.066667  \n",
       "63  Hard Disk Drive Failure            2.266667  \n",
       "64  Network Adapter Failure            4.350000  \n",
       "65  Network Adapter Failure          109.333333  \n",
       "66  Network Adapter Failure          479.716667  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unseen =df.drop(columns=unusedCols_unseen)\n",
    "print(unseen.info())\n",
    "unseen.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2629f7e6-c179-436e-8a8c-09b902c76938",
   "metadata": {},
   "source": [
    "# Convert dataframe to tensorflow dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4b709a5-91c0-4e40-abd7-7fc4bc49c5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_PrefetchDataset element_spec={'sla': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'product_type': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'brand': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'service_type': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'incident_type': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'open_to_close_hour': TensorSpec(shape=(None,), dtype=tf.float64, name=None)}>\n"
     ]
    }
   ],
   "source": [
    "unseen_ds= tfdf.keras.pd_dataframe_to_tf_dataset(unseen.drop(columns=['severity_id']))\n",
    "print(unseen_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31d90302-f84b-4266-9407-a03f1689026f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 78ms/step\n",
      "[0.5933329] : 1\n",
      "[0.61333287] : 1\n",
      "[0.23999985] : 0\n",
      "[0.8733326] : 1\n",
      "[0.6733328] : 1\n",
      "[0.7033328] : 1\n",
      "[0.4766663] : 0\n",
      "[0.84333265] : 1\n",
      "[0.83333266] : 1\n",
      "[0.5599996] : 1\n",
      "[0.443333] : 0\n",
      "[0.99666584] : 1\n",
      "[0.3866664] : 0\n",
      "[0.3866664] : 0\n",
      "[0.99999917] : 1\n",
      "[0.99999917] : 1\n",
      "[0.40666637] : 0\n",
      "[0.5733329] : 1\n",
      "[0.95333254] : 1\n",
      "[0.16333325] : 0\n",
      "[0.5733329] : 1\n",
      "[0.99999917] : 1\n",
      "[0.99999917] : 1\n",
      "[0.7699994] : 1\n",
      "[0.47999963] : 0\n",
      "[0.19999988] : 0\n",
      "[0.34999976] : 0\n",
      "[0.38333306] : 0\n",
      "[0.01333333] : 0\n",
      "[0.38999972] : 0\n",
      "[0.] : 0\n",
      "[0.48999962] : 0\n",
      "[0.00666667] : 0\n",
      "[0.] : 0\n",
      "[0.] : 0\n",
      "[0.00333333] : 0\n",
      "[0.] : 0\n",
      "[0.00333333] : 0\n",
      "[0.5733329] : 1\n",
      "[0.6066662] : 1\n",
      "[0.31999978] : 0\n",
      "[0.] : 0\n",
      "[0.] : 0\n",
      "[0.] : 0\n",
      "[0.00666667] : 0\n",
      "[0.] : 0\n",
      "[0.] : 0\n",
      "[0.] : 0\n",
      "[0.00666667] : 0\n",
      "[0.02] : 0\n",
      "[0.02] : 0\n",
      "[0.02] : 0\n",
      "[0.5199996] : 1\n",
      "[0.8633326] : 1\n",
      "[0.03333334] : 0\n",
      "[0.06333334] : 0\n",
      "[0.9033326] : 1\n",
      "[0.99999917] : 1\n",
      "[0.99999917] : 1\n",
      "[0.9466659] : 1\n",
      "[0.26333317] : 0\n",
      "[0.5599996] : 1\n",
      "[0.17333324] : 0\n",
      "[0.16666658] : 0\n",
      "[0.9233326] : 1\n",
      "[0.6199995] : 1\n",
      "[0.6833328] : 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-12 06:33:36.275465: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype double and shape [67]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    }
   ],
   "source": [
    "predResultList=abc_model.predict(unseen_ds)\n",
    "predServerityIDList=[]\n",
    "for predResult in predResultList:\n",
    "    # prob = tf.nn.sigmoid(predResult) # no need to convert to Signmoid\n",
    "    # print(prob)\n",
    "    # pred_seveirty_id= \"critical\" if _class==1 else \"normal\"\n",
    "    _class= 1 if predResult[0]>=0.5 else 0  \n",
    "    predServerityIDList.append(_class) #0=normal , 1=critical\n",
    "    print(f\"{predResult} : {_class}\")\n",
    "\n",
    "dfPred=pd.DataFrame(data=predServerityIDList,columns=[\"pred_binary_severity\"])   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ecdf4a-3e80-43d5-a02f-ad8a7f620658",
   "metadata": {},
   "source": [
    "# Map severity_id to label for actual value.\n",
    "# Merge predicted value to main dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66ada838-3f00-45b6-9cbe-7b84f701348e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_4to2_serverity(severity_id):\n",
    "    if severity_id==1 or severity_id==2:\n",
    "       return 1\n",
    "    else:\n",
    "       return 0 \n",
    "df['label_binary_severity'] =df['severity_id'].apply(map_4to2_serverity)\n",
    "\n",
    "dfPred\n",
    "df=pd.concat([df,dfPred],axis=1)\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767ac965-914f-4ca8-99f4-33f25079bed1",
   "metadata": {},
   "source": [
    "# Evaluate model and Show Metric Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06828323-74af-44fb-b261-aade71784b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n",
      "          pred-0  pred-1\n",
      "actual-0      28       6\n",
      "actual-1      10      23\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.82      0.78        34\n",
      "           1       0.79      0.70      0.74        33\n",
      "\n",
      "    accuracy                           0.76        67\n",
      "   macro avg       0.76      0.76      0.76        67\n",
      "weighted avg       0.76      0.76      0.76        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if is_evaluation:\n",
    "    from sklearn.metrics import confusion_matrix,classification_report\n",
    "    className=list(set().union(list(df['pred_binary_severity'].unique()),list(df['label_binary_severity'].unique())))\n",
    "    print(className)\n",
    "    actualClass=[  f'actual-{x}' for x in  className]\n",
    "    predictedlClass=[  f'pred-{x}' for x in className]\n",
    "    y_true=list(df['label_binary_severity'])\n",
    "    y_pred=list(df['pred_binary_severity'])\n",
    "    cnf_matrix = confusion_matrix(y_true,y_pred)\n",
    "    cnf_matrix\n",
    "\n",
    "    # #index=actual , column=prediction\n",
    "    cm_df = pd.DataFrame(cnf_matrix,\n",
    "                         index = actualClass, \n",
    "                         columns = predictedlClass)\n",
    "    print(cm_df)\n",
    "    print(classification_report(y_true, y_pred, labels=className))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98ac483-bdf4-4060-b394-95ae66b01286",
   "metadata": {},
   "source": [
    "# Transform data for Writing Prediction Result to BQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b18455cc-545f-424b-9640-37eb84b4dad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label_binary_severity</th>\n",
       "      <th>pred_binary_severity</th>\n",
       "      <th>prediction_item_date</th>\n",
       "      <th>prediction_datetime</th>\n",
       "      <th>model_version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3951</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-11-12</td>\n",
       "      <td>2023-11-12 06:33:59.190116</td>\n",
       "      <td>demo2_binary_rf_tf_model/_demo_tNov23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3941</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-11-12</td>\n",
       "      <td>2023-11-12 06:33:59.190116</td>\n",
       "      <td>demo2_binary_rf_tf_model/_demo_tNov23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3891</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-11-12</td>\n",
       "      <td>2023-11-12 06:33:59.190116</td>\n",
       "      <td>demo2_binary_rf_tf_model/_demo_tNov23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3889</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-11-12</td>\n",
       "      <td>2023-11-12 06:33:59.190116</td>\n",
       "      <td>demo2_binary_rf_tf_model/_demo_tNov23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3851</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-11-12</td>\n",
       "      <td>2023-11-12 06:33:59.190116</td>\n",
       "      <td>demo2_binary_rf_tf_model/_demo_tNov23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>3933</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-11-12</td>\n",
       "      <td>2023-11-12 06:33:59.190116</td>\n",
       "      <td>demo2_binary_rf_tf_model/_demo_tNov23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>3931</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-11-12</td>\n",
       "      <td>2023-11-12 06:33:59.190116</td>\n",
       "      <td>demo2_binary_rf_tf_model/_demo_tNov23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>3946</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-11-12</td>\n",
       "      <td>2023-11-12 06:33:59.190116</td>\n",
       "      <td>demo2_binary_rf_tf_model/_demo_tNov23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>3938</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-11-12</td>\n",
       "      <td>2023-11-12 06:33:59.190116</td>\n",
       "      <td>demo2_binary_rf_tf_model/_demo_tNov23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>3760</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-11-12</td>\n",
       "      <td>2023-11-12 06:33:59.190116</td>\n",
       "      <td>demo2_binary_rf_tf_model/_demo_tNov23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  label_binary_severity  pred_binary_severity prediction_item_date  \\\n",
       "0   3951                      1                     1           2023-11-12   \n",
       "1   3941                      1                     1           2023-11-12   \n",
       "2   3891                      1                     0           2023-11-12   \n",
       "3   3889                      1                     1           2023-11-12   \n",
       "4   3851                      0                     1           2023-11-12   \n",
       "..   ...                    ...                   ...                  ...   \n",
       "62  3933                      0                     0           2023-11-12   \n",
       "63  3931                      0                     0           2023-11-12   \n",
       "64  3946                      1                     1           2023-11-12   \n",
       "65  3938                      1                     1           2023-11-12   \n",
       "66  3760                      0                     1           2023-11-12   \n",
       "\n",
       "          prediction_datetime                          model_version  \n",
       "0  2023-11-12 06:33:59.190116  demo2_binary_rf_tf_model/_demo_tNov23  \n",
       "1  2023-11-12 06:33:59.190116  demo2_binary_rf_tf_model/_demo_tNov23  \n",
       "2  2023-11-12 06:33:59.190116  demo2_binary_rf_tf_model/_demo_tNov23  \n",
       "3  2023-11-12 06:33:59.190116  demo2_binary_rf_tf_model/_demo_tNov23  \n",
       "4  2023-11-12 06:33:59.190116  demo2_binary_rf_tf_model/_demo_tNov23  \n",
       "..                        ...                                    ...  \n",
       "62 2023-11-12 06:33:59.190116  demo2_binary_rf_tf_model/_demo_tNov23  \n",
       "63 2023-11-12 06:33:59.190116  demo2_binary_rf_tf_model/_demo_tNov23  \n",
       "64 2023-11-12 06:33:59.190116  demo2_binary_rf_tf_model/_demo_tNov23  \n",
       "65 2023-11-12 06:33:59.190116  demo2_binary_rf_tf_model/_demo_tNov23  \n",
       "66 2023-11-12 06:33:59.190116  demo2_binary_rf_tf_model/_demo_tNov23  \n",
       "\n",
       "[67 rows x 6 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df[['id','label_binary_severity','pred_binary_severity']]\n",
    "df['prediction_item_date']=today\n",
    "df['prediction_datetime']=datetime.now()\n",
    "df['model_version']=model_version\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a466acd-b50a-44c0-85fe-4a4d07afd09c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c973c88-9133-4fbb-adcd-fcc7981702f1",
   "metadata": {},
   "source": [
    "# Load ata to BQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "690bc079-2458-42b7-8343-30114abb4435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Prediction ML  67 Imported bigquery successfully\n"
     ]
    }
   ],
   "source": [
    "def loadDataFrameToBQ():\n",
    "    # WRITE_TRUNCATE , WRITE_APPEND\n",
    "    try:\n",
    "        if all_prediction==1: \n",
    "            job_config = bigquery.LoadJobConfig(write_disposition=\"WRITE_TRUNCATE\")\n",
    "        else:\n",
    "            job_config = bigquery.LoadJobConfig(write_disposition=\"WRITE_APPEND\")\n",
    "\n",
    "        job = client.load_table_from_dataframe(\n",
    "            df, predictResult_table_id, job_config=job_config\n",
    "        )\n",
    "        job.result()  # Wait for the job to complete.\n",
    "        print(\"Total Prediction ML \", len(df), \"Imported bigquery successfully\")\n",
    "\n",
    "    except BadRequest as e:\n",
    "        print(\"Bigquery Error\\n\")\n",
    "        for e in job.errors:\n",
    "            print('ERROR: {}'.format(e['message']))\n",
    "\n",
    "try:\n",
    "    loadDataFrameToBQ()\n",
    "except Exception as ex:\n",
    "    raise ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293e9a0a-85c3-46c3-8298-2271d8b462f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return 'All incidents has been predicted completely.'"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-12.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-12:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
