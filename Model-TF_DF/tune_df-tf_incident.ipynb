{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6920b3d-e127-4d00-b7ae-0779e6ef5803",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-17 08:20:10.951591: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "#https://www.tensorflow.org/decision_forests/tutorials/automatic_tuning_colab\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from datetime import date, timedelta, datetime \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5eb2a0e9-ddd0-4a05-86e9-e2ed32435331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n"
     ]
    }
   ],
   "source": [
    "#pip install tensorflow_decision_forests --upgrade --user\n",
    "import tensorflow_decision_forests as tfdf\n",
    "print(tfdf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6748e1-f46a-4d3d-9ade-3e91150f3391",
   "metadata": {},
   "source": [
    "# Variable to Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f42f6351-3e31-40ce-88a9-81d531ea3530",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tree_type=1# 1= xgboost  2-random forest\n",
    "option_cate_feature=1\n",
    "\n",
    "#labelCol='label_multi_severity'\n",
    "labelCol='label_binary_severity'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08b48f64-eb5b-4f0e-8e27-acb7ee210d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train-ds = pongthorn.SMartML.train2_incident\n",
      "test-ds = pongthorn.SMartML.test2_incident\n"
     ]
    }
   ],
   "source": [
    "projectId='pongthorn'\n",
    "dataset_id='SMartML'\n",
    "\n",
    "train_name='train2_incident'\n",
    "test_name='test2_incident'\n",
    "\n",
    "train_table_id=f\"{projectId}.{dataset_id}.{train_name}\"\n",
    "test_tabel_id=f\"{projectId}.{dataset_id}.{test_name}\"\n",
    "print(f\"train-ds = {train_table_id}\")\n",
    "print(f\"test-ds = {test_tabel_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86703035-9e51-439c-ad30-fcb8131ae83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://demo-tuned-tf-incident-pongthorn/tuned_binary_xgb_tf_model\n"
     ]
    }
   ],
   "source": [
    "metric=\"accuracy\"\n",
    "if  labelCol=='label_multi_severity':\n",
    "    if model_tree_type==1:\n",
    "        _model='tuned_xgb_tf_model'\n",
    "    else:\n",
    "         _model='tuned_rf_tf_model'\n",
    "else:\n",
    "    if model_tree_type==1:\n",
    "        _model='tuned_binary_xgb_tf_model'\n",
    "    else:\n",
    "         _model='tuned_binary__rf_tf_model'\n",
    "\n",
    "model_gs_path=f\"gs://demo-tuned-tf-incident-pongthorn/{_model}\"\n",
    "print(model_gs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ed72e3f-b0a4-4712-a1f8-c2c7156eb03a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CateCols : ['sla', 'product_type', 'brand', 'service_type', 'incident_type', 'range_open_to_close_hour']\n",
      "NumbericCols : []\n",
      "UnusedCols : ['id', 'severity_id', 'severity_name', 'open_to_close_hour', 'label_multi_severity']\n"
     ]
    }
   ],
   "source": [
    "if option_cate_feature==1:\n",
    "    # cateCols=['sla','product_type','brand','service_type','incident_type','range_open_to_close_hour','range_response_to_resolved_hour']\n",
    "    cateCols=['sla','product_type','brand','service_type','incident_type','range_open_to_close_hour']\n",
    "    numbericCols=[]\n",
    "    #unusedCols=['id','severity_id','severity_name','label_binary_severity','open_to_close_hour','response_to_resolved_hour']\n",
    "    if labelCol=='label_multi_severity':\n",
    "     unusedCols=['id','severity_id','severity_name','open_to_close_hour','label_binary_severity']\n",
    "    else:\n",
    "     unusedCols=['id','severity_id','severity_name','open_to_close_hour','label_multi_severity']   \n",
    "else:\n",
    "    cateCols=['sla','product_type','brand','service_type','incident_type']\n",
    "    numbericCols=['open_to_close_hour']\n",
    "    if labelCol=='label_multi_severity':\n",
    "     unusedCols=['id','severity_id','severity_name','range_open_to_close_hour','label_binary_severity']\n",
    "    else:\n",
    "      unusedCols=['id','severity_id','severity_name','range_open_to_close_hour','label_multi_severity']  \n",
    "\n",
    "\n",
    "print(f\"CateCols : {cateCols}\")\n",
    "print(f\"NumbericCols : {numbericCols}\")\n",
    "print(f\"UnusedCols : {unusedCols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd9f87b-86b1-4869-a88e-28f63279a9aa",
   "metadata": {},
   "source": [
    "# Load & Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b54d4427-4ded-438a-9910-9531e0dc651e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ml_data(data_path):\n",
    " df=pd.read_csv(data_path)\n",
    " df =df.drop(columns=unusedCols)\n",
    " \n",
    " return df\n",
    "\n",
    "def load_data_bq(sql:str):\n",
    " \n",
    " query_result=client.query(sql)\n",
    " df=query_result.to_dataframe()\n",
    " df =df.drop(columns=unusedCols)\n",
    " df[labelCol]=df[labelCol].astype('int64') \n",
    " df=df[[labelCol]+cateCols+numbericCols]   \n",
    "  \n",
    " return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "93a32924-01b9-44f0-9c95-3dc335daaf96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2241 entries, 0 to 2240\n",
      "Data columns (total 7 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   label_multi_severity      2241 non-null   int64 \n",
      " 1   sla                       2241 non-null   object\n",
      " 2   product_type              2241 non-null   object\n",
      " 3   brand                     2241 non-null   object\n",
      " 4   service_type              2241 non-null   object\n",
      " 5   incident_type             2241 non-null   object\n",
      " 6   range_open_to_close_hour  2241 non-null   object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 122.7+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 561 entries, 0 to 560\n",
      "Data columns (total 7 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   label_multi_severity      561 non-null    int64 \n",
      " 1   sla                       561 non-null    object\n",
      " 2   product_type              561 non-null    object\n",
      " 3   brand                     561 non-null    object\n",
      " 4   service_type              561 non-null    object\n",
      " 5   incident_type             561 non-null    object\n",
      " 6   range_open_to_close_hour  561 non-null    object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 30.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "client = bigquery.Client(project=projectId)\n",
    "\n",
    "train=load_data_bq(f\"SELECT * FROM {train_table_id}\")\n",
    "test=load_data_bq(f\"SELECT * FROM {test_tabel_id}\")\n",
    "\n",
    "print(train.info())\n",
    "\n",
    "print(test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "db86f9b2-8cab-44c7-a9f4-a1d7617ea969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_train = list(train[labelCol].unique())\n",
    "classes_test = list(test[labelCol].unique())\n",
    "\n",
    "set_classes=set(classes_train) & set(classes_test)\n",
    "classes=list(set_classes)\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "33b553e0-a511-489a-9d16-e68535cec436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_multi_severity</th>\n",
       "      <th>sla</th>\n",
       "      <th>product_type</th>\n",
       "      <th>brand</th>\n",
       "      <th>service_type</th>\n",
       "      <th>incident_type</th>\n",
       "      <th>range_open_to_close_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2236</th>\n",
       "      <td>0</td>\n",
       "      <td>24x7 4Hrs Response Time</td>\n",
       "      <td>Software</td>\n",
       "      <td>Trend Micro</td>\n",
       "      <td>Request</td>\n",
       "      <td>Configuration Change</td>\n",
       "      <td>soonest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2237</th>\n",
       "      <td>0</td>\n",
       "      <td>24x7 4Hrs Response Time</td>\n",
       "      <td>Software</td>\n",
       "      <td>Trend Micro</td>\n",
       "      <td>Request</td>\n",
       "      <td>OS / Firmware</td>\n",
       "      <td>latest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2238</th>\n",
       "      <td>0</td>\n",
       "      <td>24x7 6Hrs Resolution Time</td>\n",
       "      <td>Software</td>\n",
       "      <td>Trend Micro</td>\n",
       "      <td>Request</td>\n",
       "      <td>General Incident</td>\n",
       "      <td>soonest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2239</th>\n",
       "      <td>0</td>\n",
       "      <td>24x7 4Hrs Response Time</td>\n",
       "      <td>Security</td>\n",
       "      <td>Trend Micro</td>\n",
       "      <td>Request</td>\n",
       "      <td>Upgrade Software</td>\n",
       "      <td>fair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2240</th>\n",
       "      <td>0</td>\n",
       "      <td>24x7 4Hrs Response Time</td>\n",
       "      <td>Software</td>\n",
       "      <td>Trend Micro</td>\n",
       "      <td>Request</td>\n",
       "      <td>General Incident</td>\n",
       "      <td>soonest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label_multi_severity                        sla product_type  \\\n",
       "2236                     0    24x7 4Hrs Response Time     Software   \n",
       "2237                     0    24x7 4Hrs Response Time     Software   \n",
       "2238                     0  24x7 6Hrs Resolution Time     Software   \n",
       "2239                     0    24x7 4Hrs Response Time     Security   \n",
       "2240                     0    24x7 4Hrs Response Time     Software   \n",
       "\n",
       "            brand service_type         incident_type range_open_to_close_hour  \n",
       "2236  Trend Micro      Request  Configuration Change                  soonest  \n",
       "2237  Trend Micro      Request         OS / Firmware                   latest  \n",
       "2238  Trend Micro      Request      General Incident                  soonest  \n",
       "2239  Trend Micro      Request      Upgrade Software                     fair  \n",
       "2240  Trend Micro      Request      General Incident                  soonest  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e37f9812-69ab-4672-9641-0e9c1873396a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_multi_severity</th>\n",
       "      <th>sla</th>\n",
       "      <th>product_type</th>\n",
       "      <th>brand</th>\n",
       "      <th>service_type</th>\n",
       "      <th>incident_type</th>\n",
       "      <th>range_open_to_close_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>0</td>\n",
       "      <td>24x7 4Hrs Resolution Time</td>\n",
       "      <td>Firewall</td>\n",
       "      <td>Palo Alto</td>\n",
       "      <td>Request</td>\n",
       "      <td>Software</td>\n",
       "      <td>late</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>3</td>\n",
       "      <td>24x7 6Hrs Resolution Time</td>\n",
       "      <td>Software</td>\n",
       "      <td>Trend Micro</td>\n",
       "      <td>Incident</td>\n",
       "      <td>General Incident</td>\n",
       "      <td>soonest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>1</td>\n",
       "      <td>24x7 4Hrs Response Time</td>\n",
       "      <td>Software</td>\n",
       "      <td>Trend Micro</td>\n",
       "      <td>Request</td>\n",
       "      <td>Software</td>\n",
       "      <td>late</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>0</td>\n",
       "      <td>24x7 4Hrs Response Time</td>\n",
       "      <td>Software</td>\n",
       "      <td>Trend Micro</td>\n",
       "      <td>Request</td>\n",
       "      <td>General Incident</td>\n",
       "      <td>soon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>0</td>\n",
       "      <td>24x7 4Hrs Response Time</td>\n",
       "      <td>Software</td>\n",
       "      <td>Trend Micro</td>\n",
       "      <td>Request</td>\n",
       "      <td>General Incident</td>\n",
       "      <td>soon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label_multi_severity                        sla product_type  \\\n",
       "556                     0  24x7 4Hrs Resolution Time     Firewall   \n",
       "557                     3  24x7 6Hrs Resolution Time     Software   \n",
       "558                     1    24x7 4Hrs Response Time     Software   \n",
       "559                     0    24x7 4Hrs Response Time     Software   \n",
       "560                     0    24x7 4Hrs Response Time     Software   \n",
       "\n",
       "           brand service_type     incident_type range_open_to_close_hour  \n",
       "556    Palo Alto      Request          Software                     late  \n",
       "557  Trend Micro     Incident  General Incident                  soonest  \n",
       "558  Trend Micro      Request          Software                     late  \n",
       "559  Trend Micro      Request  General Incident                     soon  \n",
       "560  Trend Micro      Request  General Incident                     soon  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa72159d-066d-4e7c-be00-3e74b60a4062",
   "metadata": {},
   "source": [
    "# Tune Model\n",
    "\n",
    "## Training a model with automated hyper-parameter tuning and automatic definition of the hyper-parameters (recommended approach)\n",
    "\n",
    "As before, hyper-parameter tuning is enabled by specifying the tuner constructor argument of the model. Set use_predefined_hps=True to automatically configure the search space for the hyper-parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1c895353-d33e-44b8-91eb-75a4322db7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train, label=labelCol)\n",
    "test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test, label=labelCol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8d64afab-6272-4df2-9d7b-cfa7b6c2107c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start tund at 2023-07-12 17:06:52.834719\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "t_Start=time.time()\n",
    "\n",
    "print(f\"Start tund at {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "da1f2012-412a-4c3a-aaeb-9b98dd11fec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostedTreesModel\n",
      "Use /var/tmp/tmpw5cok1sa as temporary training directory\n",
      "Reading training dataset...\n",
      "Training tensor examples:\n",
      "Features: {'sla': <tf.Tensor 'data:0' shape=(None,) dtype=string>, 'product_type': <tf.Tensor 'data_1:0' shape=(None,) dtype=string>, 'brand': <tf.Tensor 'data_2:0' shape=(None,) dtype=string>, 'service_type': <tf.Tensor 'data_3:0' shape=(None,) dtype=string>, 'incident_type': <tf.Tensor 'data_4:0' shape=(None,) dtype=string>, 'range_open_to_close_hour': <tf.Tensor 'data_5:0' shape=(None,) dtype=string>}\n",
      "Label: Tensor(\"data_6:0\", shape=(None,), dtype=int64)\n",
      "Weights: None\n",
      "Normalized tensor features:\n",
      " {'sla': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'data:0' shape=(None,) dtype=string>), 'product_type': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'data_1:0' shape=(None,) dtype=string>), 'brand': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'data_2:0' shape=(None,) dtype=string>), 'service_type': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'data_3:0' shape=(None,) dtype=string>), 'incident_type': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'data_4:0' shape=(None,) dtype=string>), 'range_open_to_close_hour': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'data_5:0' shape=(None,) dtype=string>)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING 23-07-12 17:06:53.4441 UTC gradient_boosted_trees.cc:1818] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 23-07-12 17:06:53.4452 UTC gradient_boosted_trees.cc:1829] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 23-07-12 17:06:53.4457 UTC gradient_boosted_trees.cc:1843] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n",
      "2023-07-12 17:06:53.465584: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [2241]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset read in 0:00:00.238232. Found 2241 examples.\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 23-07-12 17:06:53.7081 UTC kernel.cc:773] Start Yggdrasil model training\n",
      "[INFO 23-07-12 17:06:53.7081 UTC kernel.cc:774] Collect training examples\n",
      "[INFO 23-07-12 17:06:53.7081 UTC kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "[INFO 23-07-12 17:06:53.7083 UTC kernel.cc:393] Number of batches: 3\n",
      "[INFO 23-07-12 17:06:53.7083 UTC kernel.cc:394] Number of examples: 2241\n",
      "[INFO 23-07-12 17:06:53.7088 UTC data_spec_inference.cc:305] 9 item(s) have been pruned (i.e. they are considered out of dictionary) for the column brand (17 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "[INFO 23-07-12 17:06:53.7089 UTC data_spec_inference.cc:305] 1 item(s) have been pruned (i.e. they are considered out of dictionary) for the column incident_type (20 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "[INFO 23-07-12 17:06:53.7089 UTC data_spec_inference.cc:305] 1 item(s) have been pruned (i.e. they are considered out of dictionary) for the column product_type (10 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "[INFO 23-07-12 17:06:53.7089 UTC data_spec_inference.cc:305] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column sla (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "[INFO 23-07-12 17:06:53.7094 UTC kernel.cc:794] Training dataset:\n",
      "Number of records: 2241\n",
      "Number of columns: 7\n",
      "\n",
      "Number of columns by type:\n",
      "\tCATEGORICAL: 7 (100%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "CATEGORICAL: 7 (100%)\n",
      "\t0: \"__LABEL\" CATEGORICAL integerized vocab-size:5 no-ood-item\n",
      "\t1: \"brand\" CATEGORICAL has-dict vocab-size:18 num-oods:9 (0.401606%) most-frequent:\"HPE\" 717 (31.9946%)\n",
      "\t2: \"incident_type\" CATEGORICAL has-dict vocab-size:21 num-oods:1 (0.0446229%) most-frequent:\"General Incident\" 1135 (50.647%)\n",
      "\t3: \"product_type\" CATEGORICAL has-dict vocab-size:11 num-oods:1 (0.0446229%) most-frequent:\"Storage\" 652 (29.0942%)\n",
      "\t4: \"range_open_to_close_hour\" CATEGORICAL has-dict vocab-size:6 zero-ood-items most-frequent:\"soonest\" 1443 (64.3909%)\n",
      "\t5: \"service_type\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"Incident\" 1679 (74.9219%)\n",
      "\t6: \"sla\" CATEGORICAL has-dict vocab-size:7 num-oods:2 (0.0892459%) most-frequent:\"24x7 4Hrs Resolution Time\" 1056 (47.1218%)\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "[INFO 23-07-12 17:06:53.7095 UTC kernel.cc:810] Configure learner\n",
      "[WARNING 23-07-12 17:06:53.7098 UTC gradient_boosted_trees.cc:1818] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 23-07-12 17:06:53.7098 UTC gradient_boosted_trees.cc:1829] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 23-07-12 17:06:53.7098 UTC gradient_boosted_trees.cc:1843] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n",
      "[INFO 23-07-12 17:06:53.7098 UTC kernel.cc:824] Training config:\n",
      "learner: \"HYPERPARAMETER_OPTIMIZER\"\n",
      "features: \"^brand$\"\n",
      "features: \"^incident_type$\"\n",
      "features: \"^product_type$\"\n",
      "features: \"^range_open_to_close_hour$\"\n",
      "features: \"^service_type$\"\n",
      "features: \"^sla$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "[yggdrasil_decision_forests.model.hyperparameters_optimizer_v2.proto.hyperparameters_optimizer_config] {\n",
      "  base_learner {\n",
      "    learner: \"GRADIENT_BOOSTED_TREES\"\n",
      "    features: \"^brand$\"\n",
      "    features: \"^incident_type$\"\n",
      "    features: \"^product_type$\"\n",
      "    features: \"^range_open_to_close_hour$\"\n",
      "    features: \"^service_type$\"\n",
      "    features: \"^sla$\"\n",
      "    label: \"^__LABEL$\"\n",
      "    task: CLASSIFICATION\n",
      "    random_seed: 123456\n",
      "    pure_serving_model: false\n",
      "    [yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
      "      num_trees: 300\n",
      "      decision_tree {\n",
      "        max_depth: 6\n",
      "        min_examples: 5\n",
      "        in_split_min_examples_check: true\n",
      "        keep_non_leaf_label_distribution: true\n",
      "        num_candidate_attributes: -1\n",
      "        missing_value_policy: GLOBAL_IMPUTATION\n",
      "        allow_na_conditions: false\n",
      "        categorical_set_greedy_forward {\n",
      "          sampling: 0.1\n",
      "          max_num_items: -1\n",
      "          min_item_frequency: 1\n",
      "        }\n",
      "        growing_strategy_local {\n",
      "        }\n",
      "        categorical {\n",
      "          cart {\n",
      "          }\n",
      "        }\n",
      "        axis_aligned_split {\n",
      "        }\n",
      "        internal {\n",
      "          sorting_strategy: PRESORTED\n",
      "        }\n",
      "        uplift {\n",
      "          min_examples_in_treatment: 5\n",
      "          split_score: KULLBACK_LEIBLER\n",
      "        }\n",
      "      }\n",
      "      shrinkage: 0.1\n",
      "      loss: DEFAULT\n",
      "      validation_set_ratio: 0.1\n",
      "      validation_interval_in_trees: 1\n",
      "      early_stopping: VALIDATION_LOSS_INCREASE\n",
      "      early_stopping_num_trees_look_ahead: 30\n",
      "      l2_regularization: 0\n",
      "      lambda_loss: 1\n",
      "      mart {\n",
      "      }\n",
      "      adapt_subsample_for_maximum_training_duration: false\n",
      "      l1_regularization: 0\n",
      "      use_hessian_gain: false\n",
      "      l2_regularization_categorical: 1\n",
      "      stochastic_gradient_boosting {\n",
      "        ratio: 1\n",
      "      }\n",
      "      apply_link_function: true\n",
      "      compute_permutation_variable_importance: false\n",
      "      binary_focal_loss_options {\n",
      "        misprediction_exponent: 2\n",
      "        positive_sample_coefficient: 0.5\n",
      "      }\n",
      "      early_stopping_initial_iteration: 10\n",
      "    }\n",
      "  }\n",
      "  optimizer {\n",
      "    optimizer_key: \"RANDOM\"\n",
      "    [yggdrasil_decision_forests.model.hyperparameters_optimizer_v2.proto.random] {\n",
      "      num_trials: 100\n",
      "    }\n",
      "  }\n",
      "  base_learner_deployment {\n",
      "    num_threads: 1\n",
      "  }\n",
      "  predefined_search_space {\n",
      "  }\n",
      "}\n",
      "\n",
      "[INFO 23-07-12 17:06:53.7100 UTC kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/tmp/tmpw5cok1sa/working_cache\"\n",
      "num_threads: 1\n",
      "try_resume_training: true\n",
      "\n",
      "[INFO 23-07-12 17:06:53.7200 UTC kernel.cc:889] Train model\n",
      "[INFO 23-07-12 17:06:53.7242 UTC hyperparameters_optimizer.cc:209] Hyperparameter search space:\n",
      "fields {\n",
      "  name: \"split_axis\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      categorical: \"AXIS_ALIGNED\"\n",
      "    }\n",
      "    possible_values {\n",
      "      categorical: \"SPARSE_OBLIQUE\"\n",
      "    }\n",
      "  }\n",
      "  children {\n",
      "    name: \"sparse_oblique_projection_density_factor\"\n",
      "    discrete_candidates {\n",
      "      possible_values {\n",
      "        real: 1\n",
      "      }\n",
      "      possible_values {\n",
      "        real: 2\n",
      "      }\n",
      "      possible_values {\n",
      "        real: 3\n",
      "      }\n",
      "      possible_values {\n",
      "        real: 4\n",
      "      }\n",
      "      possible_values {\n",
      "        real: 5\n",
      "      }\n",
      "    }\n",
      "    parent_discrete_values {\n",
      "      possible_values {\n",
      "        categorical: \"SPARSE_OBLIQUE\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  children {\n",
      "    name: \"sparse_oblique_normalization\"\n",
      "    discrete_candidates {\n",
      "      possible_values {\n",
      "        categorical: \"NONE\"\n",
      "      }\n",
      "      possible_values {\n",
      "        categorical: \"STANDARD_DEVIATION\"\n",
      "      }\n",
      "      possible_values {\n",
      "        categorical: \"MIN_MAX\"\n",
      "      }\n",
      "    }\n",
      "    parent_discrete_values {\n",
      "      possible_values {\n",
      "        categorical: \"SPARSE_OBLIQUE\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  children {\n",
      "    name: \"sparse_oblique_weights\"\n",
      "    discrete_candidates {\n",
      "      possible_values {\n",
      "        categorical: \"BINARY\"\n",
      "      }\n",
      "      possible_values {\n",
      "        categorical: \"CONTINUOUS\"\n",
      "      }\n",
      "    }\n",
      "    parent_discrete_values {\n",
      "      possible_values {\n",
      "        categorical: \"SPARSE_OBLIQUE\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"categorical_algorithm\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      categorical: \"CART\"\n",
      "    }\n",
      "    possible_values {\n",
      "      categorical: \"RANDOM\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"growing_strategy\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      categorical: \"LOCAL\"\n",
      "    }\n",
      "    possible_values {\n",
      "      categorical: \"BEST_FIRST_GLOBAL\"\n",
      "    }\n",
      "  }\n",
      "  children {\n",
      "    name: \"max_num_nodes\"\n",
      "    discrete_candidates {\n",
      "      possible_values {\n",
      "        integer: 16\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 32\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 64\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 128\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 256\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 512\n",
      "      }\n",
      "    }\n",
      "    parent_discrete_values {\n",
      "      possible_values {\n",
      "        categorical: \"BEST_FIRST_GLOBAL\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  children {\n",
      "    name: \"max_depth\"\n",
      "    discrete_candidates {\n",
      "      possible_values {\n",
      "        integer: 3\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 4\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 6\n",
      "      }\n",
      "      possible_values {\n",
      "        integer: 8\n",
      "      }\n",
      "    }\n",
      "    parent_discrete_values {\n",
      "      possible_values {\n",
      "        categorical: \"LOCAL\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"sampling_method\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      categorical: \"RANDOM\"\n",
      "    }\n",
      "  }\n",
      "  children {\n",
      "    name: \"subsample\"\n",
      "    discrete_candidates {\n",
      "      possible_values {\n",
      "        real: 0.6\n",
      "      }\n",
      "      possible_values {\n",
      "        real: 0.8\n",
      "      }\n",
      "      possible_values {\n",
      "        real: 0.9\n",
      "      }\n",
      "      possible_values {\n",
      "        real: 1\n",
      "      }\n",
      "    }\n",
      "    parent_discrete_values {\n",
      "      possible_values {\n",
      "        categorical: \"RANDOM\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"shrinkage\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      real: 0.02\n",
      "    }\n",
      "    possible_values {\n",
      "      real: 0.05\n",
      "    }\n",
      "    possible_values {\n",
      "      real: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"min_examples\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      integer: 5\n",
      "    }\n",
      "    possible_values {\n",
      "      integer: 7\n",
      "    }\n",
      "    possible_values {\n",
      "      integer: 10\n",
      "    }\n",
      "    possible_values {\n",
      "      integer: 20\n",
      "    }\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"use_hessian_gain\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      categorical: \"true\"\n",
      "    }\n",
      "    possible_values {\n",
      "      categorical: \"false\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"num_candidate_attributes_ratio\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      real: 0.2\n",
      "    }\n",
      "    possible_values {\n",
      "      real: 0.5\n",
      "    }\n",
      "    possible_values {\n",
      "      real: 0.9\n",
      "    }\n",
      "    possible_values {\n",
      "      real: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "[INFO 23-07-12 17:06:53.7245 UTC hyperparameters_optimizer.cc:500] Start local tuner with 1 thread(s)\n",
      "[INFO 23-07-12 17:06:53.7324 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:06:53.7343 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:06:53.7382 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:06:53.7546 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.236219 train-accuracy:0.755371 valid-loss:1.255190 valid-accuracy:0.720207\n",
      "[INFO 23-07-12 17:06:53.7727 UTC gradient_boosted_trees.cc:1544] \tnum-trees:2 train-loss:1.122101 train-accuracy:0.766113 valid-loss:1.151607 valid-accuracy:0.715026\n",
      "[INFO 23-07-12 17:06:53.9430 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.680938\n",
      "[INFO 23-07-12 17:06:53.9451 UTC gradient_boosted_trees.cc:247] Truncates the model to 152 tree(s) i.e. 38  iteration(s).\n",
      "[INFO 23-07-12 17:06:53.9456 UTC gradient_boosted_trees.cc:310] Final model num-trees:38 valid-loss:0.680938 valid-accuracy:0.715026\n",
      "[INFO 23-07-12 17:06:53.9516 UTC hyperparameters_optimizer.cc:582] [1/100] Score: -0.680938 / -0.680938 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 23-07-12 17:06:53.9590 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:06:53.9590 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:06:53.9594 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:06:53.9921 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.355547 train-accuracy:0.746582 valid-loss:1.357221 valid-accuracy:0.709845\n",
      "[INFO 23-07-12 17:06:56.0498 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.683798\n",
      "[INFO 23-07-12 17:06:56.0535 UTC gradient_boosted_trees.cc:247] Truncates the model to 564 tree(s) i.e. 141  iteration(s).\n",
      "[INFO 23-07-12 17:06:56.0542 UTC gradient_boosted_trees.cc:310] Final model num-trees:141 valid-loss:0.683798 valid-accuracy:0.751295\n",
      "[INFO 23-07-12 17:06:56.0685 UTC hyperparameters_optimizer.cc:582] [2/100] Score: -0.683798 / -0.680938 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 23-07-12 17:06:56.0893 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:06:56.0894 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:06:56.0897 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:06:56.1260 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.226845 train-accuracy:0.771484 valid-loss:1.245192 valid-accuracy:0.694301\n",
      "[INFO 23-07-12 17:06:56.6554 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.693557\n",
      "[INFO 23-07-12 17:06:56.6582 UTC gradient_boosted_trees.cc:247] Truncates the model to 96 tree(s) i.e. 24  iteration(s).\n",
      "[INFO 23-07-12 17:06:56.6626 UTC gradient_boosted_trees.cc:310] Final model num-trees:24 valid-loss:0.693557 valid-accuracy:0.740933\n",
      "[INFO 23-07-12 17:06:56.6651 UTC hyperparameters_optimizer.cc:582] [3/100] Score: -0.693557 / -0.680938 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 23-07-12 17:06:56.6757 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:06:56.6757 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:06:56.6760 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:06:56.6905 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.243906 train-accuracy:0.735352 valid-loss:1.253726 valid-accuracy:0.689119\n",
      "[INFO 23-07-12 17:06:56.8328 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.680185\n",
      "[INFO 23-07-12 17:06:56.8359 UTC gradient_boosted_trees.cc:247] Truncates the model to 116 tree(s) i.e. 29  iteration(s).\n",
      "[INFO 23-07-12 17:06:56.8376 UTC gradient_boosted_trees.cc:310] Final model num-trees:29 valid-loss:0.680185 valid-accuracy:0.756477\n",
      "[INFO 23-07-12 17:06:56.8428 UTC hyperparameters_optimizer.cc:582] [4/100] Score: -0.680185 / -0.680185 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 23-07-12 17:06:56.8485 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:06:56.8486 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:06:56.8489 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:06:56.8858 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.242452 train-accuracy:0.749512 valid-loss:1.252965 valid-accuracy:0.709845\n",
      "[INFO 23-07-12 17:06:57.4173 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.682491\n",
      "[INFO 23-07-12 17:06:57.4204 UTC gradient_boosted_trees.cc:247] Truncates the model to 144 tree(s) i.e. 36  iteration(s).\n",
      "[INFO 23-07-12 17:06:57.4210 UTC gradient_boosted_trees.cc:310] Final model num-trees:36 valid-loss:0.682491 valid-accuracy:0.751295\n",
      "[INFO 23-07-12 17:06:57.4252 UTC hyperparameters_optimizer.cc:582] [5/100] Score: -0.682491 / -0.680185 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 23-07-12 17:06:57.4316 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:06:57.4316 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:06:57.4319 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:06:57.4702 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.356457 train-accuracy:0.723145 valid-loss:1.358970 valid-accuracy:0.663212\n",
      "[INFO 23-07-12 17:06:59.5366 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.683169\n",
      "[INFO 23-07-12 17:06:59.5394 UTC gradient_boosted_trees.cc:247] Truncates the model to 636 tree(s) i.e. 159  iteration(s).\n",
      "[INFO 23-07-12 17:06:59.5415 UTC gradient_boosted_trees.cc:310] Final model num-trees:159 valid-loss:0.683169 valid-accuracy:0.746114\n",
      "[INFO 23-07-12 17:06:59.5639 UTC hyperparameters_optimizer.cc:582] [6/100] Score: -0.683169 / -0.680185 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 23-07-12 17:06:59.5828 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:06:59.5829 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:06:59.5839 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:06:59.6127 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.307977 train-accuracy:0.757324 valid-loss:1.315425 valid-accuracy:0.725389\n",
      "[INFO 23-07-12 17:07:00.4246 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.683146\n",
      "[INFO 23-07-12 17:07:00.4273 UTC gradient_boosted_trees.cc:247] Truncates the model to 228 tree(s) i.e. 57  iteration(s).\n",
      "[INFO 23-07-12 17:07:00.4281 UTC gradient_boosted_trees.cc:310] Final model num-trees:57 valid-loss:0.683146 valid-accuracy:0.740933\n",
      "[INFO 23-07-12 17:07:00.4423 UTC hyperparameters_optimizer.cc:582] [7/100] Score: -0.683146 / -0.680185 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 23-07-12 17:07:00.4547 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:00.4548 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:00.4550 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:00.4614 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.262715 train-accuracy:0.693359 valid-loss:1.266620 valid-accuracy:0.652850\n",
      "[INFO 23-07-12 17:07:00.5651 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.679135\n",
      "[INFO 23-07-12 17:07:00.5678 UTC gradient_boosted_trees.cc:247] Truncates the model to 164 tree(s) i.e. 41  iteration(s).\n",
      "[INFO 23-07-12 17:07:00.5682 UTC gradient_boosted_trees.cc:310] Final model num-trees:41 valid-loss:0.679135 valid-accuracy:0.720207\n",
      "[INFO 23-07-12 17:07:00.5728 UTC hyperparameters_optimizer.cc:582] [8/100] Score: -0.679135 / -0.679135 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 23-07-12 17:07:00.5763 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:00.5763 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:00.5766 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:00.6214 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.310623 train-accuracy:0.749023 valid-loss:1.317656 valid-accuracy:0.694301\n",
      "[INFO 23-07-12 17:07:02.1329 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.684664\n",
      "[INFO 23-07-12 17:07:02.1400 UTC gradient_boosted_trees.cc:247] Truncates the model to 240 tree(s) i.e. 60  iteration(s).\n",
      "[INFO 23-07-12 17:07:02.1404 UTC gradient_boosted_trees.cc:310] Final model num-trees:60 valid-loss:0.684664 valid-accuracy:0.746114\n",
      "[INFO 23-07-12 17:07:02.1603 UTC hyperparameters_optimizer.cc:582] [9/100] Score: -0.684664 / -0.679135 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 23-07-12 17:07:02.1791 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:02.1791 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:02.1794 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:02.2584 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.311347 train-accuracy:0.750000 valid-loss:1.318870 valid-accuracy:0.720207\n",
      "[INFO 23-07-12 17:07:04.3923 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.68042\n",
      "[INFO 23-07-12 17:07:04.3998 UTC gradient_boosted_trees.cc:247] Truncates the model to 244 tree(s) i.e. 61  iteration(s).\n",
      "[INFO 23-07-12 17:07:04.4008 UTC gradient_boosted_trees.cc:310] Final model num-trees:61 valid-loss:0.680420 valid-accuracy:0.751295\n",
      "[INFO 23-07-12 17:07:04.4230 UTC hyperparameters_optimizer.cc:582] [10/100] Score: -0.68042 / -0.679135 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 23-07-12 17:07:04.4383 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:04.4383 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:04.4386 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:04.4467 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.260947 train-accuracy:0.699219 valid-loss:1.265441 valid-accuracy:0.694301\n",
      "[INFO 23-07-12 17:07:04.7421 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.678819\n",
      "[INFO 23-07-12 17:07:04.7502 UTC gradient_boosted_trees.cc:247] Truncates the model to 208 tree(s) i.e. 52  iteration(s).\n",
      "[INFO 23-07-12 17:07:04.7508 UTC gradient_boosted_trees.cc:310] Final model num-trees:52 valid-loss:0.678819 valid-accuracy:0.720207\n",
      "[INFO 23-07-12 17:07:04.7613 UTC hyperparameters_optimizer.cc:582] [11/100] Score: -0.678819 / -0.678819 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 23-07-12 17:07:04.7683 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:04.7683 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:04.7686 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:04.7913 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.356684 train-accuracy:0.742676 valid-loss:1.358451 valid-accuracy:0.694301\n",
      "[INFO 23-07-12 17:07:05.8123 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.705104\n",
      "[INFO 23-07-12 17:07:05.8183 UTC gradient_boosted_trees.cc:247] Truncates the model to 580 tree(s) i.e. 145  iteration(s).\n",
      "[INFO 23-07-12 17:07:05.8246 UTC gradient_boosted_trees.cc:310] Final model num-trees:145 valid-loss:0.705104 valid-accuracy:0.720207\n",
      "[INFO 23-07-12 17:07:05.8679 UTC hyperparameters_optimizer.cc:582] [12/100] Score: -0.705104 / -0.678819 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 23-07-12 17:07:05.8983 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:05.8985 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:05.9203 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:05.9899 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.324181 train-accuracy:0.688965 valid-loss:1.327198 valid-accuracy:0.673575\n",
      "[INFO 23-07-12 17:07:07.0575 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.677428\n",
      "[INFO 23-07-12 17:07:07.0603 UTC gradient_boosted_trees.cc:247] Truncates the model to 540 tree(s) i.e. 135  iteration(s).\n",
      "[INFO 23-07-12 17:07:07.0604 UTC gradient_boosted_trees.cc:310] Final model num-trees:135 valid-loss:0.677428 valid-accuracy:0.709845\n",
      "[INFO 23-07-12 17:07:07.0678 UTC hyperparameters_optimizer.cc:582] [13/100] Score: -0.677428 / -0.677428 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 23-07-12 17:07:07.0711 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:07.0712 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:07.0715 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:07.0845 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.309118 train-accuracy:0.748047 valid-loss:1.314497 valid-accuracy:0.709845\n",
      "[INFO 23-07-12 17:07:07.2939 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.684867\n",
      "[INFO 23-07-12 17:07:07.2966 UTC gradient_boosted_trees.cc:247] Truncates the model to 220 tree(s) i.e. 55  iteration(s).\n",
      "[INFO 23-07-12 17:07:07.2972 UTC gradient_boosted_trees.cc:310] Final model num-trees:55 valid-loss:0.684867 valid-accuracy:0.709845\n",
      "[INFO 23-07-12 17:07:07.3094 UTC hyperparameters_optimizer.cc:582] [14/100] Score: -0.684867 / -0.677428 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 23-07-12 17:07:07.3219 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:07.3219 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:07.3222 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:07.3247 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.358230 train-accuracy:0.716797 valid-loss:1.359945 valid-accuracy:0.678756\n",
      "[INFO 23-07-12 17:07:07.8119 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.703658\n",
      "[INFO 23-07-12 17:07:07.8146 UTC gradient_boosted_trees.cc:247] Truncates the model to 716 tree(s) i.e. 179  iteration(s).\n",
      "[INFO 23-07-12 17:07:07.8151 UTC gradient_boosted_trees.cc:310] Final model num-trees:179 valid-loss:0.703658 valid-accuracy:0.720207\n",
      "[INFO 23-07-12 17:07:07.8370 UTC hyperparameters_optimizer.cc:582] [15/100] Score: -0.703658 / -0.677428 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 23-07-12 17:07:07.8567 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:07.8587 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:07.8590 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:07.8901 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.248128 train-accuracy:0.732422 valid-loss:1.255253 valid-accuracy:0.709845\n",
      "[INFO 23-07-12 17:07:08.4027 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.681927\n",
      "[INFO 23-07-12 17:07:08.4054 UTC gradient_boosted_trees.cc:247] Truncates the model to 156 tree(s) i.e. 39  iteration(s).\n",
      "[INFO 23-07-12 17:07:08.4056 UTC gradient_boosted_trees.cc:310] Final model num-trees:39 valid-loss:0.681927 valid-accuracy:0.704663\n",
      "[INFO 23-07-12 17:07:08.4095 UTC hyperparameters_optimizer.cc:582] [16/100] Score: -0.681927 / -0.677428 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 23-07-12 17:07:08.4167 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:08.4169 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:08.4188 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:08.4539 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.358266 train-accuracy:0.717285 valid-loss:1.360672 valid-accuracy:0.668394\n",
      "[INFO 23-07-12 17:07:09.9799 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.695789\n",
      "[INFO 23-07-12 17:07:09.9828 UTC gradient_boosted_trees.cc:247] Truncates the model to 676 tree(s) i.e. 169  iteration(s).\n",
      "[INFO 23-07-12 17:07:09.9834 UTC gradient_boosted_trees.cc:310] Final model num-trees:169 valid-loss:0.695789 valid-accuracy:0.751295\n",
      "[INFO 23-07-12 17:07:10.0025 UTC hyperparameters_optimizer.cc:582] [17/100] Score: -0.695789 / -0.677428 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 23-07-12 17:07:10.0263 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:10.0263 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:10.0267 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:10.0374 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.308026 train-accuracy:0.751465 valid-loss:1.312519 valid-accuracy:0.704663\n",
      "[INFO 23-07-12 17:07:10.2686 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.672943\n",
      "[INFO 23-07-12 17:07:10.2717 UTC gradient_boosted_trees.cc:247] Truncates the model to 260 tree(s) i.e. 65  iteration(s).\n",
      "[INFO 23-07-12 17:07:10.2740 UTC gradient_boosted_trees.cc:310] Final model num-trees:65 valid-loss:0.672943 valid-accuracy:0.761658\n",
      "[INFO 23-07-12 17:07:10.2811 UTC hyperparameters_optimizer.cc:582] [18/100] Score: -0.672943 / -0.672943 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 23-07-12 17:07:10.2923 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:10.2924 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:10.2927 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:10.3395 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.353507 train-accuracy:0.778809 valid-loss:1.356976 valid-accuracy:0.740933\n",
      "[INFO 23-07-12 17:07:12.4929 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.690812\n",
      "[INFO 23-07-12 17:07:12.4959 UTC gradient_boosted_trees.cc:247] Truncates the model to 576 tree(s) i.e. 144  iteration(s).\n",
      "[INFO 23-07-12 17:07:12.4967 UTC gradient_boosted_trees.cc:310] Final model num-trees:144 valid-loss:0.690812 valid-accuracy:0.746114\n",
      "[INFO 23-07-12 17:07:12.5202 UTC hyperparameters_optimizer.cc:582] [19/100] Score: -0.690812 / -0.672943 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 23-07-12 17:07:12.5513 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:12.5541 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:12.5545 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:12.5625 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.362392 train-accuracy:0.657227 valid-loss:1.362989 valid-accuracy:0.652850\n",
      "[INFO 23-07-12 17:07:12.9569 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.71422\n",
      "[INFO 23-07-12 17:07:12.9598 UTC gradient_boosted_trees.cc:247] Truncates the model to 1088 tree(s) i.e. 272  iteration(s).\n",
      "[INFO 23-07-12 17:07:12.9610 UTC gradient_boosted_trees.cc:310] Final model num-trees:272 valid-loss:0.714220 valid-accuracy:0.699482\n",
      "[INFO 23-07-12 17:07:12.9674 UTC hyperparameters_optimizer.cc:582] [20/100] Score: -0.71422 / -0.672943 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 23-07-12 17:07:12.9766 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:12.9766 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:12.9771 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:12.9879 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.364018 train-accuracy:0.662598 valid-loss:1.364436 valid-accuracy:0.668394\n",
      "[INFO 23-07-12 17:07:13.8867 UTC gradient_boosted_trees.cc:1542] \tnum-trees:300 train-loss:0.663944 train-accuracy:0.712402 valid-loss:0.703365 valid-accuracy:0.683938\n",
      "[INFO 23-07-12 17:07:13.8894 UTC gradient_boosted_trees.cc:247] Truncates the model to 1200 tree(s) i.e. 300  iteration(s).\n",
      "[INFO 23-07-12 17:07:13.8900 UTC gradient_boosted_trees.cc:310] Final model num-trees:300 valid-loss:0.703365 valid-accuracy:0.683938\n",
      "[INFO 23-07-12 17:07:13.8946 UTC hyperparameters_optimizer.cc:582] [21/100] Score: -0.703365 / -0.672943 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 23-07-12 17:07:13.9024 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:13.9026 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:13.9031 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:13.9485 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.355811 train-accuracy:0.753418 valid-loss:1.358583 valid-accuracy:0.704663\n",
      "[INFO 23-07-12 17:07:16.1087 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.678821\n",
      "[INFO 23-07-12 17:07:16.1112 UTC gradient_boosted_trees.cc:247] Truncates the model to 652 tree(s) i.e. 163  iteration(s).\n",
      "[INFO 23-07-12 17:07:16.1115 UTC gradient_boosted_trees.cc:310] Final model num-trees:163 valid-loss:0.678821 valid-accuracy:0.709845\n",
      "[INFO 23-07-12 17:07:16.1285 UTC hyperparameters_optimizer.cc:582] [22/100] Score: -0.678821 / -0.672943 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 23-07-12 17:07:16.1535 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:16.1563 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:16.1584 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:16.1710 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.244175 train-accuracy:0.741699 valid-loss:1.250900 valid-accuracy:0.699482\n",
      "[INFO 23-07-12 17:07:16.3187 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.67907\n",
      "[INFO 23-07-12 17:07:16.3215 UTC gradient_boosted_trees.cc:247] Truncates the model to 156 tree(s) i.e. 39  iteration(s).\n",
      "[INFO 23-07-12 17:07:16.3218 UTC gradient_boosted_trees.cc:310] Final model num-trees:39 valid-loss:0.679070 valid-accuracy:0.751295\n",
      "[INFO 23-07-12 17:07:16.3260 UTC hyperparameters_optimizer.cc:582] [23/100] Score: -0.67907 / -0.672943 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 23-07-12 17:07:16.3319 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:16.3320 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:16.3323 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:16.3676 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.238260 train-accuracy:0.742676 valid-loss:1.250403 valid-accuracy:0.694301\n",
      "[INFO 23-07-12 17:07:16.8414 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.681634\n",
      "[INFO 23-07-12 17:07:16.8442 UTC gradient_boosted_trees.cc:247] Truncates the model to 116 tree(s) i.e. 29  iteration(s).\n",
      "[INFO 23-07-12 17:07:16.8447 UTC gradient_boosted_trees.cc:310] Final model num-trees:29 valid-loss:0.681634 valid-accuracy:0.751295\n",
      "[INFO 23-07-12 17:07:16.8459 UTC hyperparameters_optimizer.cc:582] [24/100] Score: -0.681634 / -0.672943 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 23-07-12 17:07:16.8525 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:16.8527 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:16.8533 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:16.8662 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.313590 train-accuracy:0.743164 valid-loss:1.317692 valid-accuracy:0.699482\n",
      "[INFO 23-07-12 17:07:17.1122 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.695826\n",
      "[INFO 23-07-12 17:07:17.1151 UTC gradient_boosted_trees.cc:247] Truncates the model to 280 tree(s) i.e. 70  iteration(s).\n",
      "[INFO 23-07-12 17:07:17.1173 UTC gradient_boosted_trees.cc:310] Final model num-trees:70 valid-loss:0.695826 valid-accuracy:0.720207\n",
      "[INFO 23-07-12 17:07:17.1268 UTC hyperparameters_optimizer.cc:582] [25/100] Score: -0.695826 / -0.672943 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 23-07-12 17:07:17.1389 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:17.1389 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:17.1392 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:17.1761 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.354881 train-accuracy:0.763184 valid-loss:1.356731 valid-accuracy:0.715026\n",
      "[INFO 23-07-12 17:07:20.0932 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.688005\n",
      "[INFO 23-07-12 17:07:20.0987 UTC gradient_boosted_trees.cc:247] Truncates the model to 528 tree(s) i.e. 132  iteration(s).\n",
      "[INFO 23-07-12 17:07:20.0991 UTC gradient_boosted_trees.cc:310] Final model num-trees:132 valid-loss:0.688005 valid-accuracy:0.740933\n",
      "[INFO 23-07-12 17:07:20.1353 UTC hyperparameters_optimizer.cc:582] [26/100] Score: -0.688005 / -0.672943 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 23-07-12 17:07:20.1780 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:20.1784 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:20.1788 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:20.2647 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.354170 train-accuracy:0.762695 valid-loss:1.357391 valid-accuracy:0.709845\n",
      "[INFO 23-07-12 17:07:22.7588 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.682131\n",
      "[INFO 23-07-12 17:07:22.7616 UTC gradient_boosted_trees.cc:247] Truncates the model to 556 tree(s) i.e. 139  iteration(s).\n",
      "[INFO 23-07-12 17:07:22.7626 UTC gradient_boosted_trees.cc:310] Final model num-trees:139 valid-loss:0.682131 valid-accuracy:0.746114\n",
      "[INFO 23-07-12 17:07:22.7923 UTC hyperparameters_optimizer.cc:582] [27/100] Score: -0.682131 / -0.672943 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 23-07-12 17:07:22.8073 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:22.8073 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:22.8076 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:22.8339 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.356305 train-accuracy:0.748047 valid-loss:1.359015 valid-accuracy:0.683938\n",
      "[INFO 23-07-12 17:07:23.3535 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.689384\n",
      "[INFO 23-07-12 17:07:23.3564 UTC gradient_boosted_trees.cc:247] Truncates the model to 672 tree(s) i.e. 168  iteration(s).\n",
      "[INFO 23-07-12 17:07:23.3593 UTC gradient_boosted_trees.cc:310] Final model num-trees:168 valid-loss:0.689384 valid-accuracy:0.720207\n",
      "[INFO 23-07-12 17:07:23.3951 UTC hyperparameters_optimizer.cc:582] [28/100] Score: -0.689384 / -0.672943 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 23-07-12 17:07:23.4220 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:23.4264 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:23.4359 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:23.4459 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.277474 train-accuracy:0.660645 valid-loss:1.281116 valid-accuracy:0.652850\n",
      "[INFO 23-07-12 17:07:23.5824 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.689062\n",
      "[INFO 23-07-12 17:07:23.5848 UTC gradient_boosted_trees.cc:247] Truncates the model to 384 tree(s) i.e. 96  iteration(s).\n",
      "[INFO 23-07-12 17:07:23.5849 UTC gradient_boosted_trees.cc:310] Final model num-trees:96 valid-loss:0.689062 valid-accuracy:0.694301\n",
      "[INFO 23-07-12 17:07:23.5865 UTC hyperparameters_optimizer.cc:582] [29/100] Score: -0.689062 / -0.672943 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 23-07-12 17:07:23.5929 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:23.5932 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:23.5960 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:23.6123 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.232321 train-accuracy:0.768555 valid-loss:1.246879 valid-accuracy:0.699482\n",
      "[INFO 23-07-12 17:07:23.7818 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.683321\n",
      "[INFO 23-07-12 17:07:23.7845 UTC gradient_boosted_trees.cc:247] Truncates the model to 124 tree(s) i.e. 31  iteration(s).\n",
      "[INFO 23-07-12 17:07:23.7874 UTC gradient_boosted_trees.cc:310] Final model num-trees:31 valid-loss:0.683321 valid-accuracy:0.715026\n",
      "[INFO 23-07-12 17:07:23.7916 UTC hyperparameters_optimizer.cc:582] [30/100] Score: -0.683321 / -0.672943 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 23-07-12 17:07:23.8030 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:23.8031 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:23.8034 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:23.8448 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.305530 train-accuracy:0.758301 valid-loss:1.314551 valid-accuracy:0.678756\n",
      "[INFO 23-07-12 17:07:23.8855 UTC gradient_boosted_trees.cc:1544] \tnum-trees:2 train-loss:1.236782 train-accuracy:0.772949 valid-loss:1.252040 valid-accuracy:0.740933\n",
      "[INFO 23-07-12 17:07:24.9039 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.687312\n",
      "[INFO 23-07-12 17:07:24.9068 UTC gradient_boosted_trees.cc:247] Truncates the model to 204 tree(s) i.e. 51  iteration(s).\n",
      "[INFO 23-07-12 17:07:24.9096 UTC gradient_boosted_trees.cc:310] Final model num-trees:51 valid-loss:0.687312 valid-accuracy:0.761658\n",
      "[INFO 23-07-12 17:07:24.9239 UTC hyperparameters_optimizer.cc:582] [31/100] Score: -0.687312 / -0.672943 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 23-07-12 17:07:24.9460 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:24.9461 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:24.9464 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:24.9669 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.326154 train-accuracy:0.691406 valid-loss:1.328681 valid-accuracy:0.652850\n",
      "[INFO 23-07-12 17:07:25.5246 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.682706\n",
      "[INFO 23-07-12 17:07:25.5274 UTC gradient_boosted_trees.cc:247] Truncates the model to 356 tree(s) i.e. 89  iteration(s).\n",
      "[INFO 23-07-12 17:07:25.5285 UTC gradient_boosted_trees.cc:310] Final model num-trees:89 valid-loss:0.682706 valid-accuracy:0.694301\n",
      "[INFO 23-07-12 17:07:25.5295 UTC hyperparameters_optimizer.cc:582] [32/100] Score: -0.682706 / -0.672943 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 23-07-12 17:07:25.5353 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:25.5355 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:25.5364 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:25.5447 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.359863 train-accuracy:0.715332 valid-loss:1.360971 valid-accuracy:0.699482\n",
      "[INFO 23-07-12 17:07:26.0504 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.699585\n",
      "[INFO 23-07-12 17:07:26.0530 UTC gradient_boosted_trees.cc:247] Truncates the model to 828 tree(s) i.e. 207  iteration(s).\n",
      "[INFO 23-07-12 17:07:26.0532 UTC gradient_boosted_trees.cc:310] Final model num-trees:207 valid-loss:0.699585 valid-accuracy:0.709845\n",
      "[INFO 23-07-12 17:07:26.0696 UTC hyperparameters_optimizer.cc:582] [33/100] Score: -0.699585 / -0.672943 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 23-07-12 17:07:26.0808 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:26.0810 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:26.0893 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:26.1267 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.311478 train-accuracy:0.736328 valid-loss:1.317924 valid-accuracy:0.694301\n",
      "[INFO 23-07-12 17:07:27.2214 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.675679\n",
      "[INFO 23-07-12 17:07:27.2244 UTC gradient_boosted_trees.cc:247] Truncates the model to 268 tree(s) i.e. 67  iteration(s).\n",
      "[INFO 23-07-12 17:07:27.2272 UTC gradient_boosted_trees.cc:310] Final model num-trees:67 valid-loss:0.675679 valid-accuracy:0.751295\n",
      "[INFO 23-07-12 17:07:27.2387 UTC hyperparameters_optimizer.cc:582] [34/100] Score: -0.675679 / -0.672943 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 23-07-12 17:07:27.2589 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:27.2591 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:27.2595 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:27.2880 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.356892 train-accuracy:0.752441 valid-loss:1.358632 valid-accuracy:0.709845\n",
      "[INFO 23-07-12 17:07:29.1220 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.676167\n",
      "[INFO 23-07-12 17:07:29.1250 UTC gradient_boosted_trees.cc:247] Truncates the model to 700 tree(s) i.e. 175  iteration(s).\n",
      "[INFO 23-07-12 17:07:29.1255 UTC gradient_boosted_trees.cc:310] Final model num-trees:175 valid-loss:0.676167 valid-accuracy:0.715026\n",
      "[INFO 23-07-12 17:07:29.1479 UTC hyperparameters_optimizer.cc:582] [35/100] Score: -0.676167 / -0.672943 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 23-07-12 17:07:29.1642 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:29.1642 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:29.1645 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:29.1952 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.233624 train-accuracy:0.760254 valid-loss:1.249740 valid-accuracy:0.704663\n",
      "[INFO 23-07-12 17:07:29.8302 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.684074\n",
      "[INFO 23-07-12 17:07:29.8329 UTC gradient_boosted_trees.cc:247] Truncates the model to 128 tree(s) i.e. 32  iteration(s).\n",
      "[INFO 23-07-12 17:07:29.8335 UTC gradient_boosted_trees.cc:310] Final model num-trees:32 valid-loss:0.684074 valid-accuracy:0.740933\n",
      "[INFO 23-07-12 17:07:29.8395 UTC hyperparameters_optimizer.cc:582] [36/100] Score: -0.684074 / -0.672943 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 23-07-12 17:07:29.8479 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:29.8479 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:29.8482 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:29.8815 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.247405 train-accuracy:0.737793 valid-loss:1.258816 valid-accuracy:0.673575\n",
      "[INFO 23-07-12 17:07:30.4217 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.678721\n",
      "[INFO 23-07-12 17:07:30.4241 UTC gradient_boosted_trees.cc:247] Truncates the model to 140 tree(s) i.e. 35  iteration(s).\n",
      "[INFO 23-07-12 17:07:30.4244 UTC gradient_boosted_trees.cc:310] Final model num-trees:35 valid-loss:0.678721 valid-accuracy:0.746114\n",
      "[INFO 23-07-12 17:07:30.4253 UTC hyperparameters_optimizer.cc:582] [37/100] Score: -0.678721 / -0.672943 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 23-07-12 17:07:30.4329 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:30.4330 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:30.4333 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:30.4686 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.355656 train-accuracy:0.753418 valid-loss:1.357315 valid-accuracy:0.740933\n",
      "[INFO 23-07-12 17:07:32.6168 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.679326\n",
      "[INFO 23-07-12 17:07:32.6191 UTC gradient_boosted_trees.cc:247] Truncates the model to 668 tree(s) i.e. 167  iteration(s).\n",
      "[INFO 23-07-12 17:07:32.6195 UTC gradient_boosted_trees.cc:310] Final model num-trees:167 valid-loss:0.679326 valid-accuracy:0.715026\n",
      "[INFO 23-07-12 17:07:32.6297 UTC hyperparameters_optimizer.cc:582] [38/100] Score: -0.679326 / -0.672943 HParams: fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 23-07-12 17:07:32.6727 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:32.6756 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:32.6762 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:32.6775 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.275577 train-accuracy:0.669434 valid-loss:1.277177 valid-accuracy:0.668394\n",
      "[INFO 23-07-12 17:07:32.7923 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.680261\n",
      "[INFO 23-07-12 17:07:32.7950 UTC gradient_boosted_trees.cc:247] Truncates the model to 304 tree(s) i.e. 76  iteration(s).\n",
      "[INFO 23-07-12 17:07:32.7951 UTC gradient_boosted_trees.cc:310] Final model num-trees:76 valid-loss:0.680261 valid-accuracy:0.699482\n",
      "[INFO 23-07-12 17:07:32.7956 UTC hyperparameters_optimizer.cc:582] [39/100] Score: -0.680261 / -0.672943 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 23-07-12 17:07:32.7996 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:32.7998 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:32.8001 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:32.8355 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.356360 train-accuracy:0.734863 valid-loss:1.358813 valid-accuracy:0.683938\n",
      "[INFO 23-07-12 17:07:35.3466 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.677445\n",
      "[INFO 23-07-12 17:07:35.3493 UTC gradient_boosted_trees.cc:247] Truncates the model to 696 tree(s) i.e. 174  iteration(s).\n",
      "[INFO 23-07-12 17:07:35.3496 UTC gradient_boosted_trees.cc:310] Final model num-trees:174 valid-loss:0.677445 valid-accuracy:0.751295\n",
      "[INFO 23-07-12 17:07:35.3734 UTC hyperparameters_optimizer.cc:582] [40/100] Score: -0.677445 / -0.672943 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 23-07-12 17:07:35.3831 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:35.3831 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:35.3834 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:35.4127 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.275111 train-accuracy:0.672363 valid-loss:1.276007 valid-accuracy:0.652850\n",
      "[INFO 23-07-12 17:07:35.8725 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.689318\n",
      "[INFO 23-07-12 17:07:35.8748 UTC gradient_boosted_trees.cc:247] Truncates the model to 360 tree(s) i.e. 90  iteration(s).\n",
      "[INFO 23-07-12 17:07:35.8749 UTC gradient_boosted_trees.cc:310] Final model num-trees:90 valid-loss:0.689318 valid-accuracy:0.699482\n",
      "[INFO 23-07-12 17:07:35.8777 UTC hyperparameters_optimizer.cc:582] [41/100] Score: -0.689318 / -0.672943 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 23-07-12 17:07:35.8816 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:35.8817 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:35.8820 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:35.9197 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.310328 train-accuracy:0.740723 valid-loss:1.317931 valid-accuracy:0.683938\n",
      "[INFO 23-07-12 17:07:36.8877 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.681224\n",
      "[INFO 23-07-12 17:07:36.8904 UTC gradient_boosted_trees.cc:247] Truncates the model to 256 tree(s) i.e. 64  iteration(s).\n",
      "[INFO 23-07-12 17:07:36.8921 UTC gradient_boosted_trees.cc:310] Final model num-trees:64 valid-loss:0.681224 valid-accuracy:0.756477\n",
      "[INFO 23-07-12 17:07:36.9026 UTC hyperparameters_optimizer.cc:582] [42/100] Score: -0.681224 / -0.672943 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 23-07-12 17:07:36.9145 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:36.9146 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:36.9149 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:36.9256 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.236006 train-accuracy:0.760254 valid-loss:1.250479 valid-accuracy:0.709845\n",
      "[INFO 23-07-12 17:07:37.0736 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.683532\n",
      "[INFO 23-07-12 17:07:37.0761 UTC gradient_boosted_trees.cc:247] Truncates the model to 124 tree(s) i.e. 31  iteration(s).\n",
      "[INFO 23-07-12 17:07:37.0790 UTC gradient_boosted_trees.cc:310] Final model num-trees:31 valid-loss:0.683532 valid-accuracy:0.751295\n",
      "[INFO 23-07-12 17:07:37.0810 UTC hyperparameters_optimizer.cc:582] [43/100] Score: -0.683532 / -0.672943 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 23-07-12 17:07:37.0875 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:37.0875 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:37.0878 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:37.1037 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.230803 train-accuracy:0.767090 valid-loss:1.245970 valid-accuracy:0.715026\n",
      "[INFO 23-07-12 17:07:37.2824 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.674863\n",
      "[INFO 23-07-12 17:07:37.2847 UTC gradient_boosted_trees.cc:247] Truncates the model to 120 tree(s) i.e. 30  iteration(s).\n",
      "[INFO 23-07-12 17:07:37.2879 UTC gradient_boosted_trees.cc:310] Final model num-trees:30 valid-loss:0.674863 valid-accuracy:0.735751\n",
      "[INFO 23-07-12 17:07:37.2896 UTC hyperparameters_optimizer.cc:582] [44/100] Score: -0.674863 / -0.672943 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 23-07-12 17:07:37.2990 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:37.2991 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:37.2994 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:37.3384 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.309187 train-accuracy:0.754883 valid-loss:1.316990 valid-accuracy:0.678756\n",
      "[INFO 23-07-12 17:07:38.5263 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.695964\n",
      "[INFO 23-07-12 17:07:38.5294 UTC gradient_boosted_trees.cc:247] Truncates the model to 276 tree(s) i.e. 69  iteration(s).\n",
      "[INFO 23-07-12 17:07:38.5298 UTC gradient_boosted_trees.cc:310] Final model num-trees:69 valid-loss:0.695964 valid-accuracy:0.735751\n",
      "[INFO 23-07-12 17:07:38.5356 UTC hyperparameters_optimizer.cc:582] [45/100] Score: -0.695964 / -0.672943 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 23-07-12 17:07:38.5498 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:38.5498 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:38.5501 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:38.5529 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.310945 train-accuracy:0.531738 valid-loss:1.310362 valid-accuracy:0.554404\n",
      "[INFO 23-07-12 17:07:38.8909 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.692976\n",
      "[INFO 23-07-12 17:07:38.8937 UTC gradient_boosted_trees.cc:247] Truncates the model to 1164 tree(s) i.e. 291  iteration(s).\n",
      "[INFO 23-07-12 17:07:38.8939 UTC gradient_boosted_trees.cc:310] Final model num-trees:291 valid-loss:0.692976 valid-accuracy:0.694301\n",
      "[INFO 23-07-12 17:07:38.8994 UTC hyperparameters_optimizer.cc:582] [46/100] Score: -0.692976 / -0.672943 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 23-07-12 17:07:38.9032 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:38.9033 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:38.9035 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:38.9070 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.370612 train-accuracy:0.531738 valid-loss:1.370493 valid-accuracy:0.554404\n",
      "[INFO 23-07-12 17:07:39.2591 UTC gradient_boosted_trees.cc:1542] \tnum-trees:300 train-loss:0.718118 train-accuracy:0.691406 valid-loss:0.737444 valid-accuracy:0.694301\n",
      "[INFO 23-07-12 17:07:39.2623 UTC gradient_boosted_trees.cc:247] Truncates the model to 1200 tree(s) i.e. 300  iteration(s).\n",
      "[INFO 23-07-12 17:07:39.2623 UTC gradient_boosted_trees.cc:310] Final model num-trees:300 valid-loss:0.737444 valid-accuracy:0.694301\n",
      "[INFO 23-07-12 17:07:39.2653 UTC hyperparameters_optimizer.cc:582] [47/100] Score: -0.737444 / -0.672943 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 23-07-12 17:07:39.2725 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:39.2725 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:39.2728 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:39.2763 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.353621 train-accuracy:0.749023 valid-loss:1.356838 valid-accuracy:0.694301\n",
      "[INFO 23-07-12 17:07:39.8216 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.681391\n",
      "[INFO 23-07-12 17:07:39.8243 UTC gradient_boosted_trees.cc:247] Truncates the model to 540 tree(s) i.e. 135  iteration(s).\n",
      "[INFO 23-07-12 17:07:39.8248 UTC gradient_boosted_trees.cc:310] Final model num-trees:135 valid-loss:0.681391 valid-accuracy:0.751295\n",
      "[INFO 23-07-12 17:07:39.8509 UTC hyperparameters_optimizer.cc:582] [48/100] Score: -0.681391 / -0.672943 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 23-07-12 17:07:39.8882 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:39.8918 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:39.8924 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:39.9066 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.319472 train-accuracy:0.721191 valid-loss:1.323888 valid-accuracy:0.678756\n",
      "[INFO 23-07-12 17:07:40.2522 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.706328\n",
      "[INFO 23-07-12 17:07:40.2550 UTC gradient_boosted_trees.cc:247] Truncates the model to 452 tree(s) i.e. 113  iteration(s).\n",
      "[INFO 23-07-12 17:07:40.2552 UTC gradient_boosted_trees.cc:310] Final model num-trees:113 valid-loss:0.706328 valid-accuracy:0.709845\n",
      "[INFO 23-07-12 17:07:40.2597 UTC hyperparameters_optimizer.cc:582] [49/100] Score: -0.706328 / -0.672943 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 23-07-12 17:07:40.2704 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:40.2704 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:40.2708 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:40.2730 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.319742 train-accuracy:0.710938 valid-loss:1.323434 valid-accuracy:0.673575\n",
      "[INFO 23-07-12 17:07:40.5868 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.692933\n",
      "[INFO 23-07-12 17:07:40.5899 UTC gradient_boosted_trees.cc:247] Truncates the model to 444 tree(s) i.e. 111  iteration(s).\n",
      "[INFO 23-07-12 17:07:40.5914 UTC gradient_boosted_trees.cc:310] Final model num-trees:111 valid-loss:0.692933 valid-accuracy:0.709845\n",
      "[INFO 23-07-12 17:07:40.5980 UTC hyperparameters_optimizer.cc:582] [50/100] Score: -0.692933 / -0.672943 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 23-07-12 17:07:40.6103 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:40.6106 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:40.6125 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:40.6609 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.239399 train-accuracy:0.753906 valid-loss:1.252109 valid-accuracy:0.704663\n",
      "[INFO 23-07-12 17:07:41.1570 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.689254\n",
      "[INFO 23-07-12 17:07:41.1598 UTC gradient_boosted_trees.cc:247] Truncates the model to 108 tree(s) i.e. 27  iteration(s).\n",
      "[INFO 23-07-12 17:07:41.1619 UTC gradient_boosted_trees.cc:310] Final model num-trees:27 valid-loss:0.689254 valid-accuracy:0.746114\n",
      "[INFO 23-07-12 17:07:41.1634 UTC hyperparameters_optimizer.cc:582] [51/100] Score: -0.689254 / -0.672943 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 23-07-12 17:07:41.1686 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:41.1687 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:41.1689 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:41.1827 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.240524 train-accuracy:0.741211 valid-loss:1.257775 valid-accuracy:0.673575\n",
      "[INFO 23-07-12 17:07:41.3408 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.672501\n",
      "[INFO 23-07-12 17:07:41.3436 UTC gradient_boosted_trees.cc:247] Truncates the model to 156 tree(s) i.e. 39  iteration(s).\n",
      "[INFO 23-07-12 17:07:41.3457 UTC gradient_boosted_trees.cc:310] Final model num-trees:39 valid-loss:0.672501 valid-accuracy:0.756477\n",
      "[INFO 23-07-12 17:07:41.3542 UTC hyperparameters_optimizer.cc:582] [52/100] Score: -0.672501 / -0.672501 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 23-07-12 17:07:41.3641 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:41.3641 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:41.3644 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:41.3658 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.324043 train-accuracy:0.674805 valid-loss:1.324265 valid-accuracy:0.683938\n",
      "[INFO 23-07-12 17:07:41.5686 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.680162\n",
      "[INFO 23-07-12 17:07:41.5718 UTC gradient_boosted_trees.cc:247] Truncates the model to 460 tree(s) i.e. 115  iteration(s).\n",
      "[INFO 23-07-12 17:07:41.5719 UTC gradient_boosted_trees.cc:310] Final model num-trees:115 valid-loss:0.680162 valid-accuracy:0.715026\n",
      "[INFO 23-07-12 17:07:41.5740 UTC hyperparameters_optimizer.cc:582] [53/100] Score: -0.680162 / -0.672501 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 23-07-12 17:07:41.5820 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:41.5822 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:41.5827 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:41.5887 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.370099 train-accuracy:0.545898 valid-loss:1.369949 valid-accuracy:0.564767\n",
      "[INFO 23-07-12 17:07:41.9236 UTC gradient_boosted_trees.cc:1542] \tnum-trees:300 train-loss:0.722739 train-accuracy:0.694824 valid-loss:0.736366 valid-accuracy:0.689119\n",
      "[INFO 23-07-12 17:07:41.9263 UTC gradient_boosted_trees.cc:247] Truncates the model to 1200 tree(s) i.e. 300  iteration(s).\n",
      "[INFO 23-07-12 17:07:41.9266 UTC gradient_boosted_trees.cc:310] Final model num-trees:300 valid-loss:0.736366 valid-accuracy:0.689119\n",
      "[INFO 23-07-12 17:07:41.9280 UTC hyperparameters_optimizer.cc:582] [54/100] Score: -0.736366 / -0.672501 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 23-07-12 17:07:41.9362 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:41.9370 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:41.9379 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:41.9463 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.263646 train-accuracy:0.690918 valid-loss:1.265731 valid-accuracy:0.699482\n",
      "[INFO 23-07-12 17:07:42.1069 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.694605\n",
      "[INFO 23-07-12 17:07:42.1097 UTC gradient_boosted_trees.cc:247] Truncates the model to 212 tree(s) i.e. 53  iteration(s).\n",
      "[INFO 23-07-12 17:07:42.1106 UTC gradient_boosted_trees.cc:310] Final model num-trees:53 valid-loss:0.694605 valid-accuracy:0.709845\n",
      "[INFO 23-07-12 17:07:42.1145 UTC hyperparameters_optimizer.cc:582] [55/100] Score: -0.694605 / -0.672501 HParams: fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 23-07-12 17:07:42.1313 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:42.1313 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:42.1317 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:42.1335 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.360517 train-accuracy:0.693359 valid-loss:1.361311 valid-accuracy:0.652850\n",
      "[INFO 23-07-12 17:07:42.5180 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.678572\n",
      "[INFO 23-07-12 17:07:42.5207 UTC gradient_boosted_trees.cc:247] Truncates the model to 864 tree(s) i.e. 216  iteration(s).\n",
      "[INFO 23-07-12 17:07:42.5208 UTC gradient_boosted_trees.cc:310] Final model num-trees:216 valid-loss:0.678572 valid-accuracy:0.725389\n",
      "[INFO 23-07-12 17:07:42.5265 UTC hyperparameters_optimizer.cc:582] [56/100] Score: -0.678572 / -0.672501 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 23-07-12 17:07:42.5379 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:42.5379 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:42.5386 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:42.5614 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.360712 train-accuracy:0.689941 valid-loss:1.361743 valid-accuracy:0.647668\n",
      "[INFO 23-07-12 17:07:44.2014 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.68787\n",
      "[INFO 23-07-12 17:07:44.2042 UTC gradient_boosted_trees.cc:247] Truncates the model to 864 tree(s) i.e. 216  iteration(s).\n",
      "[INFO 23-07-12 17:07:44.2046 UTC gradient_boosted_trees.cc:310] Final model num-trees:216 valid-loss:0.687870 valid-accuracy:0.709845\n",
      "[INFO 23-07-12 17:07:44.2118 UTC hyperparameters_optimizer.cc:582] [57/100] Score: -0.68787 / -0.672501 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 23-07-12 17:07:44.2199 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:44.2199 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:44.2202 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:44.2405 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.275111 train-accuracy:0.672363 valid-loss:1.276007 valid-accuracy:0.652850\n",
      "[INFO 23-07-12 17:07:44.6364 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.682734\n",
      "[INFO 23-07-12 17:07:44.6396 UTC gradient_boosted_trees.cc:247] Truncates the model to 312 tree(s) i.e. 78  iteration(s).\n",
      "[INFO 23-07-12 17:07:44.6398 UTC gradient_boosted_trees.cc:310] Final model num-trees:78 valid-loss:0.682734 valid-accuracy:0.715026\n",
      "[INFO 23-07-12 17:07:44.6404 UTC hyperparameters_optimizer.cc:582] [58/100] Score: -0.682734 / -0.672501 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 23-07-12 17:07:44.6438 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:44.6438 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:44.6441 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:44.6816 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.316093 train-accuracy:0.724121 valid-loss:1.318890 valid-accuracy:0.663212\n",
      "[INFO 23-07-12 17:07:45.5302 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.679442\n",
      "[INFO 23-07-12 17:07:45.5333 UTC gradient_boosted_trees.cc:247] Truncates the model to 252 tree(s) i.e. 63  iteration(s).\n",
      "[INFO 23-07-12 17:07:45.5350 UTC gradient_boosted_trees.cc:310] Final model num-trees:63 valid-loss:0.679442 valid-accuracy:0.720207\n",
      "[INFO 23-07-12 17:07:45.5368 UTC hyperparameters_optimizer.cc:582] [59/100] Score: -0.679442 / -0.672501 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 23-07-12 17:07:45.5445 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:45.5445 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:45.5448 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:45.5797 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.313359 train-accuracy:0.743164 valid-loss:1.318207 valid-accuracy:0.709845\n",
      "[INFO 23-07-12 17:07:46.3053 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.673659\n",
      "[INFO 23-07-12 17:07:46.3081 UTC gradient_boosted_trees.cc:247] Truncates the model to 260 tree(s) i.e. 65  iteration(s).\n",
      "[INFO 23-07-12 17:07:46.3098 UTC gradient_boosted_trees.cc:310] Final model num-trees:65 valid-loss:0.673659 valid-accuracy:0.704663\n",
      "[INFO 23-07-12 17:07:46.3123 UTC hyperparameters_optimizer.cc:582] [60/100] Score: -0.673659 / -0.672501 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 23-07-12 17:07:46.3235 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:46.3235 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:46.3238 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:46.3584 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.308560 train-accuracy:0.766602 valid-loss:1.312561 valid-accuracy:0.715026\n",
      "[INFO 23-07-12 17:07:47.0990 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.680078\n",
      "[INFO 23-07-12 17:07:47.1021 UTC gradient_boosted_trees.cc:247] Truncates the model to 224 tree(s) i.e. 56  iteration(s).\n",
      "[INFO 23-07-12 17:07:47.1025 UTC gradient_boosted_trees.cc:310] Final model num-trees:56 valid-loss:0.680078 valid-accuracy:0.746114\n",
      "[INFO 23-07-12 17:07:47.1092 UTC hyperparameters_optimizer.cc:582] [61/100] Score: -0.680078 / -0.672501 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 23-07-12 17:07:47.1242 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:47.1242 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:47.1245 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:47.1565 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.355911 train-accuracy:0.735840 valid-loss:1.358767 valid-accuracy:0.673575\n",
      "[INFO 23-07-12 17:07:49.0947 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.68083\n",
      "[INFO 23-07-12 17:07:49.0975 UTC gradient_boosted_trees.cc:247] Truncates the model to 600 tree(s) i.e. 150  iteration(s).\n",
      "[INFO 23-07-12 17:07:49.0993 UTC gradient_boosted_trees.cc:310] Final model num-trees:150 valid-loss:0.680830 valid-accuracy:0.751295\n",
      "[INFO 23-07-12 17:07:49.1180 UTC hyperparameters_optimizer.cc:582] [62/100] Score: -0.68083 / -0.672501 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 23-07-12 17:07:49.1418 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:49.1419 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:49.1421 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:49.1741 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.236310 train-accuracy:0.755371 valid-loss:1.249322 valid-accuracy:0.715026\n",
      "[INFO 23-07-12 17:07:49.6704 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.683163\n",
      "[INFO 23-07-12 17:07:49.6732 UTC gradient_boosted_trees.cc:247] Truncates the model to 116 tree(s) i.e. 29  iteration(s).\n",
      "[INFO 23-07-12 17:07:49.6738 UTC gradient_boosted_trees.cc:310] Final model num-trees:29 valid-loss:0.683163 valid-accuracy:0.746114\n",
      "[INFO 23-07-12 17:07:49.6806 UTC hyperparameters_optimizer.cc:582] [63/100] Score: -0.683163 / -0.672501 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 23-07-12 17:07:49.6887 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:49.6887 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:49.6890 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:49.7287 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.352729 train-accuracy:0.770996 valid-loss:1.356627 valid-accuracy:0.683938\n",
      "[INFO 23-07-12 17:07:52.3936 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.693304\n",
      "[INFO 23-07-12 17:07:52.3964 UTC gradient_boosted_trees.cc:247] Truncates the model to 540 tree(s) i.e. 135  iteration(s).\n",
      "[INFO 23-07-12 17:07:52.3995 UTC gradient_boosted_trees.cc:310] Final model num-trees:135 valid-loss:0.693304 valid-accuracy:0.746114\n",
      "[INFO 23-07-12 17:07:52.4381 UTC hyperparameters_optimizer.cc:582] [64/100] Score: -0.693304 / -0.672501 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 23-07-12 17:07:52.4838 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:52.4840 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:52.4843 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:52.4996 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.327850 train-accuracy:0.661133 valid-loss:1.328154 valid-accuracy:0.658031\n",
      "[INFO 23-07-12 17:07:52.9948 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.697627\n",
      "[INFO 23-07-12 17:07:52.9975 UTC gradient_boosted_trees.cc:247] Truncates the model to 416 tree(s) i.e. 104  iteration(s).\n",
      "[INFO 23-07-12 17:07:52.9977 UTC gradient_boosted_trees.cc:310] Final model num-trees:104 valid-loss:0.697627 valid-accuracy:0.704663\n",
      "[INFO 23-07-12 17:07:52.9985 UTC hyperparameters_optimizer.cc:582] [65/100] Score: -0.697627 / -0.672501 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 23-07-12 17:07:53.0037 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:53.0038 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:53.0041 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:53.0238 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.361506 train-accuracy:0.673340 valid-loss:1.362451 valid-accuracy:0.658031\n",
      "[INFO 23-07-12 17:07:53.8880 UTC gradient_boosted_trees.cc:1544] \tnum-trees:157 train-loss:0.643858 train-accuracy:0.750000 valid-loss:0.702405 valid-accuracy:0.709845\n",
      "[INFO 23-07-12 17:07:54.5842 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.681913\n",
      "[INFO 23-07-12 17:07:54.5869 UTC gradient_boosted_trees.cc:247] Truncates the model to 1116 tree(s) i.e. 279  iteration(s).\n",
      "[INFO 23-07-12 17:07:54.5871 UTC gradient_boosted_trees.cc:310] Final model num-trees:279 valid-loss:0.681913 valid-accuracy:0.709845\n",
      "[INFO 23-07-12 17:07:54.5941 UTC hyperparameters_optimizer.cc:582] [66/100] Score: -0.681913 / -0.672501 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 23-07-12 17:07:54.6093 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:54.6093 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:54.6096 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:54.6230 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.240512 train-accuracy:0.740723 valid-loss:1.257154 valid-accuracy:0.678756\n",
      "[INFO 23-07-12 17:07:54.7911 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.678502\n",
      "[INFO 23-07-12 17:07:54.7933 UTC gradient_boosted_trees.cc:247] Truncates the model to 148 tree(s) i.e. 37  iteration(s).\n",
      "[INFO 23-07-12 17:07:54.7937 UTC gradient_boosted_trees.cc:310] Final model num-trees:37 valid-loss:0.678502 valid-accuracy:0.751295\n",
      "[INFO 23-07-12 17:07:54.8000 UTC hyperparameters_optimizer.cc:582] [67/100] Score: -0.678502 / -0.672501 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 23-07-12 17:07:54.8054 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:54.8055 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:54.8058 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:54.8198 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.275347 train-accuracy:0.635742 valid-loss:1.279247 valid-accuracy:0.611399\n",
      "[INFO 23-07-12 17:07:55.1096 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.689215\n",
      "[INFO 23-07-12 17:07:55.1122 UTC gradient_boosted_trees.cc:247] Truncates the model to 288 tree(s) i.e. 72  iteration(s).\n",
      "[INFO 23-07-12 17:07:55.1126 UTC gradient_boosted_trees.cc:310] Final model num-trees:72 valid-loss:0.689215 valid-accuracy:0.704663\n",
      "[INFO 23-07-12 17:07:55.1130 UTC hyperparameters_optimizer.cc:582] [68/100] Score: -0.689215 / -0.672501 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 23-07-12 17:07:55.1158 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:55.1165 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:55.1169 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:55.1252 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.360128 train-accuracy:0.699219 valid-loss:1.361002 valid-accuracy:0.694301\n",
      "[INFO 23-07-12 17:07:55.5835 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.694469\n",
      "[INFO 23-07-12 17:07:55.5863 UTC gradient_boosted_trees.cc:247] Truncates the model to 884 tree(s) i.e. 221  iteration(s).\n",
      "[INFO 23-07-12 17:07:55.5879 UTC gradient_boosted_trees.cc:310] Final model num-trees:221 valid-loss:0.694469 valid-accuracy:0.715026\n",
      "[INFO 23-07-12 17:07:55.6104 UTC hyperparameters_optimizer.cc:582] [69/100] Score: -0.694469 / -0.672501 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 16 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 23-07-12 17:07:55.6263 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:55.6263 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:55.6267 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:55.6517 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.312340 train-accuracy:0.744629 valid-loss:1.317806 valid-accuracy:0.699482\n",
      "[INFO 23-07-12 17:07:56.4412 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.677198\n",
      "[INFO 23-07-12 17:07:56.4443 UTC gradient_boosted_trees.cc:247] Truncates the model to 284 tree(s) i.e. 71  iteration(s).\n",
      "[INFO 23-07-12 17:07:56.4459 UTC gradient_boosted_trees.cc:310] Final model num-trees:71 valid-loss:0.677198 valid-accuracy:0.751295\n",
      "[INFO 23-07-12 17:07:56.4498 UTC hyperparameters_optimizer.cc:582] [70/100] Score: -0.677198 / -0.672501 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 23-07-12 17:07:56.4599 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:56.4601 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:56.4609 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:56.5066 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.355332 train-accuracy:0.753418 valid-loss:1.357831 valid-accuracy:0.694301\n",
      "[INFO 23-07-12 17:07:58.5438 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.675644\n",
      "[INFO 23-07-12 17:07:58.5471 UTC gradient_boosted_trees.cc:247] Truncates the model to 608 tree(s) i.e. 152  iteration(s).\n",
      "[INFO 23-07-12 17:07:58.5498 UTC gradient_boosted_trees.cc:310] Final model num-trees:152 valid-loss:0.675644 valid-accuracy:0.756477\n",
      "[INFO 23-07-12 17:07:58.5808 UTC hyperparameters_optimizer.cc:582] [71/100] Score: -0.675644 / -0.672501 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 23-07-12 17:07:58.6075 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:58.6107 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:58.6122 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:58.6511 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.312833 train-accuracy:0.742188 valid-loss:1.317370 valid-accuracy:0.735751\n",
      "[INFO 23-07-12 17:07:59.6079 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.682358\n",
      "[INFO 23-07-12 17:07:59.6109 UTC gradient_boosted_trees.cc:247] Truncates the model to 268 tree(s) i.e. 67  iteration(s).\n",
      "[INFO 23-07-12 17:07:59.6113 UTC gradient_boosted_trees.cc:310] Final model num-trees:67 valid-loss:0.682358 valid-accuracy:0.746114\n",
      "[INFO 23-07-12 17:07:59.6195 UTC hyperparameters_optimizer.cc:582] [72/100] Score: -0.682358 / -0.672501 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 23-07-12 17:07:59.6363 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:07:59.6375 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:07:59.6423 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:07:59.6849 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.307729 train-accuracy:0.745117 valid-loss:1.317825 valid-accuracy:0.689119\n",
      "[INFO 23-07-12 17:08:00.8670 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.67649\n",
      "[INFO 23-07-12 17:08:00.8698 UTC gradient_boosted_trees.cc:247] Truncates the model to 308 tree(s) i.e. 77  iteration(s).\n",
      "[INFO 23-07-12 17:08:00.8733 UTC gradient_boosted_trees.cc:310] Final model num-trees:77 valid-loss:0.676490 valid-accuracy:0.761658\n",
      "[INFO 23-07-12 17:08:00.8938 UTC hyperparameters_optimizer.cc:582] [73/100] Score: -0.67649 / -0.672501 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 23-07-12 17:08:00.9116 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:08:00.9116 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:08:00.9120 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:08:00.9212 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.251509 train-accuracy:0.732910 valid-loss:1.257351 valid-accuracy:0.715026\n",
      "[INFO 23-07-12 17:08:01.0508 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.680756\n",
      "[INFO 23-07-12 17:08:01.0532 UTC gradient_boosted_trees.cc:247] Truncates the model to 144 tree(s) i.e. 36  iteration(s).\n",
      "[INFO 23-07-12 17:08:01.0536 UTC gradient_boosted_trees.cc:310] Final model num-trees:36 valid-loss:0.680756 valid-accuracy:0.715026\n",
      "[INFO 23-07-12 17:08:01.0587 UTC hyperparameters_optimizer.cc:582] [74/100] Score: -0.680756 / -0.672501 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 23-07-12 17:08:01.0658 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:08:01.0661 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:08:01.0664 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:08:01.0680 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.362529 train-accuracy:0.675781 valid-loss:1.362901 valid-accuracy:0.673575\n",
      "[INFO 23-07-12 17:08:01.7955 UTC gradient_boosted_trees.cc:1542] \tnum-trees:300 train-loss:0.641257 train-accuracy:0.733887 valid-loss:0.714711 valid-accuracy:0.699482\n",
      "[INFO 23-07-12 17:08:01.8029 UTC gradient_boosted_trees.cc:247] Truncates the model to 1184 tree(s) i.e. 296  iteration(s).\n",
      "[INFO 23-07-12 17:08:01.8033 UTC gradient_boosted_trees.cc:310] Final model num-trees:296 valid-loss:0.714607 valid-accuracy:0.699482\n",
      "[INFO 23-07-12 17:08:01.8099 UTC hyperparameters_optimizer.cc:582] [75/100] Score: -0.714607 / -0.672501 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 23-07-12 17:08:01.8346 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:08:01.8347 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:08:01.8350 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:08:01.9145 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.235971 train-accuracy:0.737305 valid-loss:1.252512 valid-accuracy:0.683938\n",
      "[INFO 23-07-12 17:08:02.7998 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.679678\n",
      "[INFO 23-07-12 17:08:02.8014 UTC gradient_boosted_trees.cc:247] Truncates the model to 116 tree(s) i.e. 29  iteration(s).\n",
      "[INFO 23-07-12 17:08:02.8083 UTC gradient_boosted_trees.cc:310] Final model num-trees:29 valid-loss:0.679678 valid-accuracy:0.740933\n",
      "[INFO 23-07-12 17:08:02.8198 UTC hyperparameters_optimizer.cc:582] [76/100] Score: -0.679678 / -0.672501 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 23-07-12 17:08:02.8362 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:08:02.8363 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:08:02.8376 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:08:02.9232 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.239333 train-accuracy:0.751465 valid-loss:1.250307 valid-accuracy:0.709845\n",
      "[INFO 23-07-12 17:08:03.8534 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.675159\n",
      "[INFO 23-07-12 17:08:03.8595 UTC gradient_boosted_trees.cc:247] Truncates the model to 144 tree(s) i.e. 36  iteration(s).\n",
      "[INFO 23-07-12 17:08:03.8665 UTC gradient_boosted_trees.cc:310] Final model num-trees:36 valid-loss:0.675159 valid-accuracy:0.751295\n",
      "[INFO 23-07-12 17:08:03.8682 UTC hyperparameters_optimizer.cc:582] [77/100] Score: -0.675159 / -0.672501 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 23-07-12 17:08:03.8834 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:08:03.8836 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:08:03.8842 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:08:03.9727 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.309890 train-accuracy:0.753906 valid-loss:1.316296 valid-accuracy:0.689119\n",
      "[INFO 23-07-12 17:08:05.8343 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.686276\n",
      "[INFO 23-07-12 17:08:05.8399 UTC gradient_boosted_trees.cc:247] Truncates the model to 256 tree(s) i.e. 64  iteration(s).\n",
      "[INFO 23-07-12 17:08:05.8471 UTC gradient_boosted_trees.cc:310] Final model num-trees:64 valid-loss:0.686276 valid-accuracy:0.756477\n",
      "[INFO 23-07-12 17:08:05.8573 UTC hyperparameters_optimizer.cc:582] [78/100] Score: -0.686276 / -0.672501 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 23-07-12 17:08:05.8969 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:08:05.8969 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:08:05.8977 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:08:05.8996 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.319554 train-accuracy:0.710938 valid-loss:1.323691 valid-accuracy:0.652850\n",
      "[INFO 23-07-12 17:08:06.2943 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.705211\n",
      "[INFO 23-07-12 17:08:06.2989 UTC gradient_boosted_trees.cc:247] Truncates the model to 284 tree(s) i.e. 71  iteration(s).\n",
      "[INFO 23-07-12 17:08:06.2992 UTC gradient_boosted_trees.cc:310] Final model num-trees:71 valid-loss:0.705211 valid-accuracy:0.709845\n",
      "[INFO 23-07-12 17:08:06.3143 UTC hyperparameters_optimizer.cc:582] [79/100] Score: -0.705211 / -0.672501 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 23-07-12 17:08:06.3306 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:08:06.3306 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:08:06.3309 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:08:06.3463 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.362659 train-accuracy:0.674805 valid-loss:1.362912 valid-accuracy:0.673575\n",
      "[INFO 23-07-12 17:08:06.9519 UTC gradient_boosted_trees.cc:1542] \tnum-trees:300 train-loss:0.654960 train-accuracy:0.713867 valid-loss:0.712526 valid-accuracy:0.704663\n",
      "[INFO 23-07-12 17:08:06.9544 UTC gradient_boosted_trees.cc:247] Truncates the model to 1200 tree(s) i.e. 300  iteration(s).\n",
      "[INFO 23-07-12 17:08:06.9544 UTC gradient_boosted_trees.cc:310] Final model num-trees:300 valid-loss:0.712526 valid-accuracy:0.704663\n",
      "[INFO 23-07-12 17:08:06.9646 UTC hyperparameters_optimizer.cc:582] [80/100] Score: -0.712526 / -0.672501 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 23-07-12 17:08:06.9738 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:08:06.9746 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:08:06.9762 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:08:07.0249 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.354428 train-accuracy:0.753906 valid-loss:1.357079 valid-accuracy:0.694301\n",
      "[INFO 23-07-12 17:08:08.9399 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.682207\n",
      "[INFO 23-07-12 17:08:08.9422 UTC gradient_boosted_trees.cc:247] Truncates the model to 552 tree(s) i.e. 138  iteration(s).\n",
      "[INFO 23-07-12 17:08:08.9427 UTC gradient_boosted_trees.cc:310] Final model num-trees:138 valid-loss:0.682207 valid-accuracy:0.740933\n",
      "[INFO 23-07-12 17:08:08.9687 UTC hyperparameters_optimizer.cc:582] [81/100] Score: -0.682207 / -0.672501 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 23-07-12 17:08:08.9860 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:08:08.9860 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:08:08.9863 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:08:09.0194 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.244019 train-accuracy:0.737793 valid-loss:1.256539 valid-accuracy:0.683938\n",
      "[INFO 23-07-12 17:08:09.4796 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.679106\n",
      "[INFO 23-07-12 17:08:09.4822 UTC gradient_boosted_trees.cc:247] Truncates the model to 144 tree(s) i.e. 36  iteration(s).\n",
      "[INFO 23-07-12 17:08:09.4825 UTC gradient_boosted_trees.cc:310] Final model num-trees:36 valid-loss:0.679106 valid-accuracy:0.751295\n",
      "[INFO 23-07-12 17:08:09.4868 UTC hyperparameters_optimizer.cc:582] [82/100] Score: -0.679106 / -0.672501 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 23-07-12 17:08:09.4950 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:08:09.4950 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:08:09.4954 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:08:09.5077 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.356409 train-accuracy:0.743164 valid-loss:1.358234 valid-accuracy:0.683938\n",
      "[INFO 23-07-12 17:08:10.0404 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.687856\n",
      "[INFO 23-07-12 17:08:10.0432 UTC gradient_boosted_trees.cc:247] Truncates the model to 700 tree(s) i.e. 175  iteration(s).\n",
      "[INFO 23-07-12 17:08:10.0460 UTC gradient_boosted_trees.cc:310] Final model num-trees:175 valid-loss:0.687856 valid-accuracy:0.720207\n",
      "[INFO 23-07-12 17:08:10.0792 UTC hyperparameters_optimizer.cc:582] [83/100] Score: -0.687856 / -0.672501 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 23-07-12 17:08:10.1123 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:08:10.1123 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:08:10.1126 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:08:10.1408 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.242977 train-accuracy:0.734863 valid-loss:1.255333 valid-accuracy:0.683938\n",
      "[INFO 23-07-12 17:08:10.7034 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.680091\n",
      "[INFO 23-07-12 17:08:10.7061 UTC gradient_boosted_trees.cc:247] Truncates the model to 132 tree(s) i.e. 33  iteration(s).\n",
      "[INFO 23-07-12 17:08:10.7065 UTC gradient_boosted_trees.cc:310] Final model num-trees:33 valid-loss:0.680091 valid-accuracy:0.751295\n",
      "[INFO 23-07-12 17:08:10.7109 UTC hyperparameters_optimizer.cc:582] [84/100] Score: -0.680091 / -0.672501 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 32 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 23-07-12 17:08:10.7182 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:08:10.7182 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:08:10.7185 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:08:10.7537 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.310623 train-accuracy:0.749023 valid-loss:1.317656 valid-accuracy:0.694301\n",
      "[INFO 23-07-12 17:08:11.7535 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.684664\n",
      "[INFO 23-07-12 17:08:11.7564 UTC gradient_boosted_trees.cc:247] Truncates the model to 240 tree(s) i.e. 60  iteration(s).\n",
      "[INFO 23-07-12 17:08:11.7567 UTC gradient_boosted_trees.cc:310] Final model num-trees:60 valid-loss:0.684664 valid-accuracy:0.746114\n",
      "[INFO 23-07-12 17:08:11.7693 UTC hyperparameters_optimizer.cc:582] [85/100] Score: -0.684664 / -0.672501 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 23-07-12 17:08:11.7759 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:08:11.7761 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:08:11.7764 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:08:11.7872 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.354909 train-accuracy:0.735352 valid-loss:1.357465 valid-accuracy:0.689119\n",
      "[INFO 23-07-12 17:08:12.2793 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.682561\n",
      "[INFO 23-07-12 17:08:12.2821 UTC gradient_boosted_trees.cc:247] Truncates the model to 516 tree(s) i.e. 129  iteration(s).\n",
      "[INFO 23-07-12 17:08:12.2831 UTC gradient_boosted_trees.cc:310] Final model num-trees:129 valid-loss:0.682561 valid-accuracy:0.740933\n",
      "[INFO 23-07-12 17:08:12.3067 UTC hyperparameters_optimizer.cc:582] [86/100] Score: -0.682561 / -0.672501 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 23-07-12 17:08:12.3294 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:08:12.3294 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:08:12.3298 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:08:12.3591 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.236040 train-accuracy:0.756348 valid-loss:1.246806 valid-accuracy:0.730570\n",
      "[INFO 23-07-12 17:08:12.8312 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.681925\n",
      "[INFO 23-07-12 17:08:12.8340 UTC gradient_boosted_trees.cc:247] Truncates the model to 116 tree(s) i.e. 29  iteration(s).\n",
      "[INFO 23-07-12 17:08:12.8381 UTC gradient_boosted_trees.cc:310] Final model num-trees:29 valid-loss:0.681925 valid-accuracy:0.756477\n",
      "[INFO 23-07-12 17:08:12.8404 UTC hyperparameters_optimizer.cc:582] [87/100] Score: -0.681925 / -0.672501 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 23-07-12 17:08:12.8529 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:08:12.8530 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:08:12.8533 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:08:12.8961 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.354681 train-accuracy:0.767578 valid-loss:1.357051 valid-accuracy:0.694301\n",
      "[INFO 23-07-12 17:08:15.2941 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.686341\n",
      "[INFO 23-07-12 17:08:15.2970 UTC gradient_boosted_trees.cc:247] Truncates the model to 560 tree(s) i.e. 140  iteration(s).\n",
      "[INFO 23-07-12 17:08:15.2990 UTC gradient_boosted_trees.cc:310] Final model num-trees:140 valid-loss:0.686341 valid-accuracy:0.735751\n",
      "[INFO 23-07-12 17:08:15.3248 UTC hyperparameters_optimizer.cc:582] [88/100] Score: -0.686341 / -0.672501 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 23-07-12 17:08:15.3469 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:08:15.3470 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:08:15.3473 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:08:15.3836 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.309376 train-accuracy:0.743652 valid-loss:1.316147 valid-accuracy:0.694301\n",
      "[INFO 23-07-12 17:08:16.4718 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.685598\n",
      "[INFO 23-07-12 17:08:16.4746 UTC gradient_boosted_trees.cc:247] Truncates the model to 264 tree(s) i.e. 66  iteration(s).\n",
      "[INFO 23-07-12 17:08:16.4773 UTC gradient_boosted_trees.cc:310] Final model num-trees:66 valid-loss:0.685598 valid-accuracy:0.746114\n",
      "[INFO 23-07-12 17:08:16.4938 UTC hyperparameters_optimizer.cc:582] [89/100] Score: -0.685598 / -0.672501 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 23-07-12 17:08:16.5135 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:08:16.5137 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:08:16.5152 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:08:16.5246 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.359303 train-accuracy:0.703613 valid-loss:1.360766 valid-accuracy:0.658031\n",
      "[INFO 23-07-12 17:08:17.0402 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.698139\n",
      "[INFO 23-07-12 17:08:17.0425 UTC gradient_boosted_trees.cc:247] Truncates the model to 872 tree(s) i.e. 218  iteration(s).\n",
      "[INFO 23-07-12 17:08:17.0446 UTC gradient_boosted_trees.cc:310] Final model num-trees:218 valid-loss:0.698139 valid-accuracy:0.720207\n",
      "[INFO 23-07-12 17:08:17.0584 UTC hyperparameters_optimizer.cc:582] [90/100] Score: -0.698139 / -0.672501 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 23-07-12 17:08:17.0760 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:08:17.0762 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:08:17.0771 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:08:17.0863 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.362392 train-accuracy:0.657227 valid-loss:1.362989 valid-accuracy:0.652850\n",
      "[INFO 23-07-12 17:08:17.4859 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.71422\n",
      "[INFO 23-07-12 17:08:17.4887 UTC gradient_boosted_trees.cc:247] Truncates the model to 1088 tree(s) i.e. 272  iteration(s).\n",
      "[INFO 23-07-12 17:08:17.4891 UTC gradient_boosted_trees.cc:310] Final model num-trees:272 valid-loss:0.714220 valid-accuracy:0.699482\n",
      "[INFO 23-07-12 17:08:17.5004 UTC hyperparameters_optimizer.cc:582] [91/100] Score: -0.71422 / -0.672501 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 23-07-12 17:08:17.5104 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:08:17.5104 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:08:17.5107 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:08:17.5411 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.356315 train-accuracy:0.740234 valid-loss:1.358245 valid-accuracy:0.709845\n",
      "[INFO 23-07-12 17:08:19.2347 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.685409\n",
      "[INFO 23-07-12 17:08:19.2378 UTC gradient_boosted_trees.cc:247] Truncates the model to 568 tree(s) i.e. 142  iteration(s).\n",
      "[INFO 23-07-12 17:08:19.2382 UTC gradient_boosted_trees.cc:310] Final model num-trees:142 valid-loss:0.685409 valid-accuracy:0.751295\n",
      "[INFO 23-07-12 17:08:19.2615 UTC hyperparameters_optimizer.cc:582] [92/100] Score: -0.685409 / -0.672501 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 23-07-12 17:08:19.2774 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:08:19.2774 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:08:19.2777 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:08:19.2951 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.354017 train-accuracy:0.763672 valid-loss:1.357299 valid-accuracy:0.704663\n",
      "[INFO 23-07-12 17:08:20.0165 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.682036\n",
      "[INFO 23-07-12 17:08:20.0189 UTC gradient_boosted_trees.cc:247] Truncates the model to 684 tree(s) i.e. 171  iteration(s).\n",
      "[INFO 23-07-12 17:08:20.0216 UTC gradient_boosted_trees.cc:310] Final model num-trees:171 valid-loss:0.682036 valid-accuracy:0.751295\n",
      "[INFO 23-07-12 17:08:20.0461 UTC hyperparameters_optimizer.cc:582] [93/100] Score: -0.682036 / -0.672501 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 23-07-12 17:08:20.0774 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:08:20.0803 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:08:20.0807 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:08:20.0973 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.353825 train-accuracy:0.767090 valid-loss:1.356847 valid-accuracy:0.715026\n",
      "[INFO 23-07-12 17:08:20.7125 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.681843\n",
      "[INFO 23-07-12 17:08:20.7153 UTC gradient_boosted_trees.cc:247] Truncates the model to 592 tree(s) i.e. 148  iteration(s).\n",
      "[INFO 23-07-12 17:08:20.7160 UTC gradient_boosted_trees.cc:310] Final model num-trees:148 valid-loss:0.681843 valid-accuracy:0.746114\n",
      "[INFO 23-07-12 17:08:20.7445 UTC hyperparameters_optimizer.cc:582] [94/100] Score: -0.681843 / -0.672501 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 512 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 23-07-12 17:08:20.7648 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:08:20.7649 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:08:20.7652 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:08:20.7783 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.356657 train-accuracy:0.741699 valid-loss:1.358412 valid-accuracy:0.694301\n",
      "[INFO 23-07-12 17:08:21.3222 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.7028\n",
      "[INFO 23-07-12 17:08:21.3248 UTC gradient_boosted_trees.cc:247] Truncates the model to 668 tree(s) i.e. 167  iteration(s).\n",
      "[INFO 23-07-12 17:08:21.3255 UTC gradient_boosted_trees.cc:310] Final model num-trees:167 valid-loss:0.702800 valid-accuracy:0.725389\n",
      "[INFO 23-07-12 17:08:21.3491 UTC hyperparameters_optimizer.cc:582] [95/100] Score: -0.7028 / -0.672501 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 1 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 7 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 23-07-12 17:08:21.3776 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:08:21.3779 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:08:21.3796 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:08:21.4151 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.355911 train-accuracy:0.735840 valid-loss:1.358767 valid-accuracy:0.673575\n",
      "[INFO 23-07-12 17:08:23.8891 UTC gradient_boosted_trees.cc:1544] \tnum-trees:106 train-loss:0.580397 train-accuracy:0.790527 valid-loss:0.695180 valid-accuracy:0.756477\n",
      "[INFO 23-07-12 17:08:24.7519 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.68083\n",
      "[INFO 23-07-12 17:08:24.7546 UTC gradient_boosted_trees.cc:247] Truncates the model to 600 tree(s) i.e. 150  iteration(s).\n",
      "[INFO 23-07-12 17:08:24.7566 UTC gradient_boosted_trees.cc:310] Final model num-trees:150 valid-loss:0.680830 valid-accuracy:0.751295\n",
      "[INFO 23-07-12 17:08:24.7744 UTC hyperparameters_optimizer.cc:582] [96/100] Score: -0.68083 / -0.672501 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 128 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.6 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.9 } }\n",
      "[INFO 23-07-12 17:08:24.7935 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:08:24.7936 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:08:24.7938 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:08:24.7961 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.251623 train-accuracy:0.724121 valid-loss:1.256888 valid-accuracy:0.694301\n",
      "[INFO 23-07-12 17:08:24.9348 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.686407\n",
      "[INFO 23-07-12 17:08:24.9376 UTC gradient_boosted_trees.cc:247] Truncates the model to 168 tree(s) i.e. 42  iteration(s).\n",
      "[INFO 23-07-12 17:08:24.9380 UTC gradient_boosted_trees.cc:310] Final model num-trees:42 valid-loss:0.686407 valid-accuracy:0.709845\n",
      "[INFO 23-07-12 17:08:24.9454 UTC hyperparameters_optimizer.cc:582] [97/100] Score: -0.686407 / -0.672501 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 256 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 23-07-12 17:08:24.9530 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:08:24.9531 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:08:24.9533 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:08:24.9872 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.231208 train-accuracy:0.759277 valid-loss:1.247920 valid-accuracy:0.689119\n",
      "[INFO 23-07-12 17:08:25.4046 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.686833\n",
      "[INFO 23-07-12 17:08:25.4075 UTC gradient_boosted_trees.cc:247] Truncates the model to 100 tree(s) i.e. 25  iteration(s).\n",
      "[INFO 23-07-12 17:08:25.4111 UTC gradient_boosted_trees.cc:310] Final model num-trees:25 valid-loss:0.686833 valid-accuracy:0.751295\n",
      "[INFO 23-07-12 17:08:25.4135 UTC hyperparameters_optimizer.cc:582] [98/100] Score: -0.686833 / -0.672501 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 8 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"min_examples\" value { integer: 5 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.2 } }\n",
      "[INFO 23-07-12 17:08:25.4280 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:08:25.4281 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:08:25.4284 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:08:25.4405 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.309294 train-accuracy:0.749512 valid-loss:1.317549 valid-accuracy:0.694301\n",
      "[INFO 23-07-12 17:08:25.6958 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.67639\n",
      "[INFO 23-07-12 17:08:25.6989 UTC gradient_boosted_trees.cc:247] Truncates the model to 244 tree(s) i.e. 61  iteration(s).\n",
      "[INFO 23-07-12 17:08:25.7009 UTC gradient_boosted_trees.cc:310] Final model num-trees:61 valid-loss:0.676390 valid-accuracy:0.746114\n",
      "[INFO 23-07-12 17:08:25.7037 UTC hyperparameters_optimizer.cc:582] [99/100] Score: -0.67639 / -0.672501 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"BEST_FIRST_GLOBAL\" } } fields { name: \"max_num_nodes\" value { integer: 64 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.8 } } fields { name: \"shrinkage\" value { real: 0.05 } } fields { name: \"min_examples\" value { integer: 10 } } fields { name: \"use_hessian_gain\" value { categorical: \"false\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 0.5 } }\n",
      "[INFO 23-07-12 17:08:25.7150 UTC gradient_boosted_trees.cc:459] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "[INFO 23-07-12 17:08:25.7150 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-12 17:08:25.7162 UTC gradient_boosted_trees.cc:1128] 2048 examples used for training and 193 examples used for validation\n",
      "[INFO 23-07-12 17:08:25.7214 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:1.364620 train-accuracy:0.625977 valid-loss:1.365526 valid-accuracy:0.616580\n",
      "[INFO 23-07-12 17:08:26.0945 UTC gradient_boosted_trees.cc:1542] \tnum-trees:300 train-loss:0.715353 train-accuracy:0.696289 valid-loss:0.734365 valid-accuracy:0.699482\n",
      "[INFO 23-07-12 17:08:26.0972 UTC gradient_boosted_trees.cc:247] Truncates the model to 1200 tree(s) i.e. 300  iteration(s).\n",
      "[INFO 23-07-12 17:08:26.0975 UTC gradient_boosted_trees.cc:310] Final model num-trees:300 valid-loss:0.734365 valid-accuracy:0.699482\n",
      "[INFO 23-07-12 17:08:26.1033 UTC hyperparameters_optimizer.cc:582] [100/100] Score: -0.734365 / -0.672501 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"growing_strategy\" value { categorical: \"LOCAL\" } } fields { name: \"max_depth\" value { integer: 3 } } fields { name: \"sampling_method\" value { categorical: \"RANDOM\" } } fields { name: \"subsample\" value { real: 0.9 } } fields { name: \"shrinkage\" value { real: 0.02 } } fields { name: \"min_examples\" value { integer: 20 } } fields { name: \"use_hessian_gain\" value { categorical: \"true\" } } fields { name: \"num_candidate_attributes_ratio\" value { real: 1 } }\n",
      "[INFO 23-07-12 17:08:26.1096 UTC hyperparameters_optimizer.cc:219] Best hyperparameters:\n",
      "fields {\n",
      "  name: \"split_axis\"\n",
      "  value {\n",
      "    categorical: \"SPARSE_OBLIQUE\"\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"sparse_oblique_projection_density_factor\"\n",
      "  value {\n",
      "    real: 5\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"sparse_oblique_normalization\"\n",
      "  value {\n",
      "    categorical: \"STANDARD_DEVIATION\"\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"sparse_oblique_weights\"\n",
      "  value {\n",
      "    categorical: \"CONTINUOUS\"\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"categorical_algorithm\"\n",
      "  value {\n",
      "    categorical: \"CART\"\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"growing_strategy\"\n",
      "  value {\n",
      "    categorical: \"BEST_FIRST_GLOBAL\"\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"max_num_nodes\"\n",
      "  value {\n",
      "    integer: 64\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"sampling_method\"\n",
      "  value {\n",
      "    categorical: \"RANDOM\"\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"subsample\"\n",
      "  value {\n",
      "    real: 0.8\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"shrinkage\"\n",
      "  value {\n",
      "    real: 0.1\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"min_examples\"\n",
      "  value {\n",
      "    integer: 20\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"use_hessian_gain\"\n",
      "  value {\n",
      "    categorical: \"false\"\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"num_candidate_attributes_ratio\"\n",
      "  value {\n",
      "    real: 0.2\n",
      "  }\n",
      "}\n",
      "\n",
      "[INFO 23-07-12 17:08:26.1104 UTC kernel.cc:926] Export model in log directory: /var/tmp/tmpw5cok1sa with prefix a4b22fad5ae44b9e\n",
      "[INFO 23-07-12 17:08:26.1359 UTC kernel.cc:944] Save model in resources\n",
      "[INFO 23-07-12 17:08:26.1390 UTC abstract_model.cc:849] Model self evaluation:\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "Loss (MULTINOMIAL_LOG_LIKELIHOOD): 0.672501\n",
      "\n",
      "Accuracy: 0.756477  CI95[W][0 1]\n",
      "ErrorRate: : 0.243523\n",
      "\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "   0   1   2   3  4\n",
      "0  0   0   0   0  0\n",
      "1  0  27   5   3  0\n",
      "2  0   4  32  22  0\n",
      "3  0   0   6  86  0\n",
      "4  0   0   0   7  1\n",
      "Total: 193\n",
      "\n",
      "One vs other classes:\n",
      "\n",
      "[INFO 23-07-12 17:08:26.1867 UTC kernel.cc:1243] Loading model from path /var/tmp/tmpw5cok1sa/model/ with prefix a4b22fad5ae44b9e\n",
      "[INFO 23-07-12 17:08:26.2374 UTC decision_forest.cc:660] Model loaded with 156 root(s), 7354 node(s), and 6 input feature(s).\n",
      "[INFO 23-07-12 17:08:26.2399 UTC abstract_model.cc:1311] Engine \"GradientBoostedTreesGeneric\" built\n",
      "[INFO 23-07-12 17:08:26.2399 UTC kernel.cc:1075] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained in 0:01:32.549797\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-12 17:08:26.261951: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_6' with dtype int64 and shape [2241]\n",
      "\t [[{{node Placeholder/_6}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7a3fbca530>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://www.tensorflow.org/decision_forests/api_docs/python/tfdf/tuner/RandomSearch\n",
    "tuner = tfdf.tuner.RandomSearch( use_predefined_hps=True)\n",
    "# Specify the model.\n",
    "if model_tree_type==1:\n",
    "    print(\"GradientBoostedTreesModel\")\n",
    "    tuned_model=tfdf.keras.GradientBoostedTreesModel(tuner=tuner)\n",
    "else:\n",
    "    print(\"RandomForestModel\")\n",
    "    tuned_model = tfdf.keras.RandomForestModel(tuner=tuner)\n",
    "\n",
    "tuned_model.fit(x=train_ds,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c36921b9-d118-4a92-82c2-23ed332defca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total execution :  0.04\n",
      "2023-07-12 17:09:15.604250\n"
     ]
    }
   ],
   "source": [
    "t_End=time.time()\n",
    "t_elapsed=(t_End-t_Start)/60/60\n",
    "print('Total execution : ',round(t_elapsed,2)) \n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b6f489-e628-41c2-bba2-d71ce40392c5",
   "metadata": {},
   "source": [
    "# Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ed1044ae-7da6-4273-acac-363700e7aecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function InferenceCoreModel.make_test_function.<locals>.test_function at 0x7f7a3f835000> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function InferenceCoreModel.make_test_function.<locals>.test_function at 0x7f7a3f835000> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy with the TF-DF hyper-parameter tuner: 0.6970\n"
     ]
    }
   ],
   "source": [
    "tuned_model.compile([\"accuracy\"])\n",
    "tuned_test_accuracy = tuned_model.evaluate(test_ds, return_dict=True, verbose=0)[\"accuracy\"]\n",
    "print(f\"Test accuracy with the TF-DF hyper-parameter tuner: {tuned_test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba6e508-1298-4916-a8f1-af00990c0645",
   "metadata": {},
   "source": [
    "# Inspect and debug decision forest models\n",
    "## Model structure and feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "161a5f2c-c349-48ab-abb6-1a484eb2fb4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>evaluation_time</th>\n",
       "      <th>best</th>\n",
       "      <th>split_axis</th>\n",
       "      <th>sparse_oblique_projection_density_factor</th>\n",
       "      <th>sparse_oblique_normalization</th>\n",
       "      <th>sparse_oblique_weights</th>\n",
       "      <th>categorical_algorithm</th>\n",
       "      <th>growing_strategy</th>\n",
       "      <th>max_num_nodes</th>\n",
       "      <th>sampling_method</th>\n",
       "      <th>subsample</th>\n",
       "      <th>shrinkage</th>\n",
       "      <th>min_examples</th>\n",
       "      <th>use_hessian_gain</th>\n",
       "      <th>num_candidate_attributes_ratio</th>\n",
       "      <th>max_depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.680938</td>\n",
       "      <td>0.227219</td>\n",
       "      <td>False</td>\n",
       "      <td>SPARSE_OBLIQUE</td>\n",
       "      <td>5.0</td>\n",
       "      <td>MIN_MAX</td>\n",
       "      <td>BINARY</td>\n",
       "      <td>CART</td>\n",
       "      <td>BEST_FIRST_GLOBAL</td>\n",
       "      <td>32.0</td>\n",
       "      <td>RANDOM</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>10</td>\n",
       "      <td>false</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.683798</td>\n",
       "      <td>2.344076</td>\n",
       "      <td>False</td>\n",
       "      <td>SPARSE_OBLIQUE</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NONE</td>\n",
       "      <td>BINARY</td>\n",
       "      <td>RANDOM</td>\n",
       "      <td>BEST_FIRST_GLOBAL</td>\n",
       "      <td>128.0</td>\n",
       "      <td>RANDOM</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.02</td>\n",
       "      <td>10</td>\n",
       "      <td>true</td>\n",
       "      <td>0.9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.693557</td>\n",
       "      <td>2.940731</td>\n",
       "      <td>False</td>\n",
       "      <td>SPARSE_OBLIQUE</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NONE</td>\n",
       "      <td>BINARY</td>\n",
       "      <td>RANDOM</td>\n",
       "      <td>LOCAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RANDOM</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>5</td>\n",
       "      <td>false</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.680185</td>\n",
       "      <td>3.114767</td>\n",
       "      <td>False</td>\n",
       "      <td>SPARSE_OBLIQUE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NONE</td>\n",
       "      <td>BINARY</td>\n",
       "      <td>CART</td>\n",
       "      <td>BEST_FIRST_GLOBAL</td>\n",
       "      <td>64.0</td>\n",
       "      <td>RANDOM</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>20</td>\n",
       "      <td>false</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.682491</td>\n",
       "      <td>3.700840</td>\n",
       "      <td>False</td>\n",
       "      <td>SPARSE_OBLIQUE</td>\n",
       "      <td>4.0</td>\n",
       "      <td>STANDARD_DEVIATION</td>\n",
       "      <td>CONTINUOUS</td>\n",
       "      <td>RANDOM</td>\n",
       "      <td>BEST_FIRST_GLOBAL</td>\n",
       "      <td>256.0</td>\n",
       "      <td>RANDOM</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>20</td>\n",
       "      <td>true</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score  evaluation_time   best      split_axis  \\\n",
       "0 -0.680938         0.227219  False  SPARSE_OBLIQUE   \n",
       "1 -0.683798         2.344076  False  SPARSE_OBLIQUE   \n",
       "2 -0.693557         2.940731  False  SPARSE_OBLIQUE   \n",
       "3 -0.680185         3.114767  False  SPARSE_OBLIQUE   \n",
       "4 -0.682491         3.700840  False  SPARSE_OBLIQUE   \n",
       "\n",
       "   sparse_oblique_projection_density_factor sparse_oblique_normalization  \\\n",
       "0                                       5.0                      MIN_MAX   \n",
       "1                                       2.0                         NONE   \n",
       "2                                       3.0                         NONE   \n",
       "3                                       1.0                         NONE   \n",
       "4                                       4.0           STANDARD_DEVIATION   \n",
       "\n",
       "  sparse_oblique_weights categorical_algorithm   growing_strategy  \\\n",
       "0                 BINARY                  CART  BEST_FIRST_GLOBAL   \n",
       "1                 BINARY                RANDOM  BEST_FIRST_GLOBAL   \n",
       "2                 BINARY                RANDOM              LOCAL   \n",
       "3                 BINARY                  CART  BEST_FIRST_GLOBAL   \n",
       "4             CONTINUOUS                RANDOM  BEST_FIRST_GLOBAL   \n",
       "\n",
       "   max_num_nodes sampling_method  subsample  shrinkage  min_examples  \\\n",
       "0           32.0          RANDOM        1.0       0.10            10   \n",
       "1          128.0          RANDOM        0.8       0.02            10   \n",
       "2            NaN          RANDOM        1.0       0.10             5   \n",
       "3           64.0          RANDOM        1.0       0.10            20   \n",
       "4          256.0          RANDOM        1.0       0.10            20   \n",
       "\n",
       "  use_hessian_gain  num_candidate_attributes_ratio  max_depth  \n",
       "0            false                             0.2        NaN  \n",
       "1             true                             0.9        NaN  \n",
       "2            false                             0.5        8.0  \n",
       "3            false                             0.2        NaN  \n",
       "4             true                             0.5        NaN  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the tuning logs.\n",
    "tuning_logs = tuned_model.make_inspector().tuning_logs()\n",
    "tuning_logs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bb31ca9d-04c7-45a6-895b-fc8bee1febd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "score                                                -0.672501\n",
       "evaluation_time                                      47.622756\n",
       "best                                                      True\n",
       "split_axis                                      SPARSE_OBLIQUE\n",
       "sparse_oblique_projection_density_factor                   5.0\n",
       "sparse_oblique_normalization                STANDARD_DEVIATION\n",
       "sparse_oblique_weights                              CONTINUOUS\n",
       "categorical_algorithm                                     CART\n",
       "growing_strategy                             BEST_FIRST_GLOBAL\n",
       "max_num_nodes                                             64.0\n",
       "sampling_method                                         RANDOM\n",
       "subsample                                                  0.8\n",
       "shrinkage                                                  0.1\n",
       "min_examples                                                20\n",
       "use_hessian_gain                                         false\n",
       "num_candidate_attributes_ratio                             0.2\n",
       "max_depth                                                  NaN\n",
       "Name: 51, dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best hyper-parameters.\n",
    "tuning_logs[tuning_logs.best].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cadf966-6f4f-417b-8529-2ec2e64759b7",
   "metadata": {},
   "source": [
    "# Plotting the training logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a3292b-f7cc-4f0c-b491-e84206636957",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(tuning_logs[\"score\"], label=\"current trial\")\n",
    "plt.plot(tuning_logs[\"score\"].cummax(), label=\"best trial\")\n",
    "plt.xlabel(\"Tuning step\")\n",
    "plt.ylabel(\"Tuning score\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74420e30-fbb5-4730-bb48-b8a3efce49ce",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b21d1d7-6d34-4c40-b0a2-fac22ca7097e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/distribute/save_and_load.ipynb#scrollTo=jFcuzsI94bNA\n",
    "#save_options = tf.saved_model.SaveOptions(experimental_io_device='/job:localhost')\n",
    "# model.save(model_gs_path,options=save_options)\n",
    "# model.save(model_local_path,options=save_options)\n",
    "tuned_model.save(model_gs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62b65f7-d674-4dd9-8fb2-d7fcb2f7e355",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6e51e5-4f9a-4fe5-a622-30213686d54b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b732c93e-930c-4fbe-9ee7-98fda68a58a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-12.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-12:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
