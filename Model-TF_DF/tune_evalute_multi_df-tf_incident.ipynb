{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "c6920b3d-e127-4d00-b7ae-0779e6ef5803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n"
     ]
    }
   ],
   "source": [
    "#https://www.tensorflow.org/decision_forests/tutorials/automatic_tuning_colab\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from datetime import date, timedelta, datetime \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "5eb2a0e9-ddd0-4a05-86e9-e2ed32435331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n"
     ]
    }
   ],
   "source": [
    "#pip install tensorflow_decision_forests --upgrade --user\n",
    "import tensorflow_decision_forests as tfdf\n",
    "print(tfdf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6748e1-f46a-4d3d-9ade-3e91150f3391",
   "metadata": {},
   "source": [
    "# Variable to Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f42f6351-3e31-40ce-88a9-81d531ea3530",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tree_type=2# 1= xgboost  2-random forest\n",
    "option_cate_feature=1\n",
    "\n",
    "labelCol='label_multi_severity'\n",
    "# labelCol='label_binary_severity'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "08b48f64-eb5b-4f0e-8e27-acb7ee210d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train-ds = pongthorn.SMartML.train2_incident\n",
      "test-ds = pongthorn.SMartML.test2_incident\n"
     ]
    }
   ],
   "source": [
    "projectId='pongthorn'\n",
    "dataset_id='SMartML'\n",
    "\n",
    "train_name='train2_incident'\n",
    "test_name='test2_incident'\n",
    "\n",
    "train_table_id=f\"{projectId}.{dataset_id}.{train_name}\"\n",
    "test_tabel_id=f\"{projectId}.{dataset_id}.{test_name}\"\n",
    "print(f\"train-ds = {train_table_id}\")\n",
    "print(f\"test-ds = {test_tabel_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "86703035-9e51-439c-ad30-fcb8131ae83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://demo-tuned-tf-incident-pongthorn/model_tuned_rf_tf\n"
     ]
    }
   ],
   "source": [
    "metric=\"accuracy\"\n",
    "\n",
    "if model_tree_type==1:\n",
    "    _model='model_tuned_xgb_tf'\n",
    "else:\n",
    "     _model='model_tuned_rf_tf'\n",
    "\n",
    "model_gs_path=f\"gs://demo-tuned-tf-incident-pongthorn/{_model}\"\n",
    "print(model_gs_path)\n",
    "#model_local_path=_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "6ed72e3f-b0a4-4712-a1f8-c2c7156eb03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if option_cate_feature==1:\n",
    "    # cateCols=['sla','product_type','brand','service_type','incident_type','range_open_to_close_hour','range_response_to_resolved_hour']\n",
    "    cateCols=['sla','product_type','brand','service_type','incident_type','range_open_to_close_hour']\n",
    "    numbericCols=[]\n",
    "    #unusedCols=['id','severity_id','severity_name','label_binary_severity','open_to_close_hour','response_to_resolved_hour']\n",
    "    unusedCols=['id','severity_id','severity_name','label_binary_severity','open_to_close_hour']\n",
    "else:\n",
    "    cateCols=['sla','product_type','brand','service_type','incident_type']\n",
    "    numbericCols=['open_to_close_hour']\n",
    "    unusedCols=['id','severity_id','severity_name','label_binary_severity','range_open_to_close_hour']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd9f87b-86b1-4869-a88e-28f63279a9aa",
   "metadata": {},
   "source": [
    "# Load & Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "b54d4427-4ded-438a-9910-9531e0dc651e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ml_data(data_path):\n",
    " df=pd.read_csv(data_path)\n",
    " df =df.drop(columns=unusedCols)\n",
    " \n",
    " return df\n",
    "\n",
    "def load_data_bq(sql:str):\n",
    " \n",
    " query_result=client.query(sql)\n",
    " df=query_result.to_dataframe()\n",
    " df =df.drop(columns=unusedCols)\n",
    " df[labelCol]=df[labelCol].astype('int64') \n",
    " df=df[[labelCol]+cateCols+numbericCols]   \n",
    "  \n",
    " return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "93a32924-01b9-44f0-9c95-3dc335daaf96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2241 entries, 0 to 2240\n",
      "Data columns (total 7 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   label_multi_severity      2241 non-null   int64 \n",
      " 1   sla                       2241 non-null   object\n",
      " 2   product_type              2241 non-null   object\n",
      " 3   brand                     2241 non-null   object\n",
      " 4   service_type              2241 non-null   object\n",
      " 5   incident_type             2241 non-null   object\n",
      " 6   range_open_to_close_hour  2241 non-null   object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 122.7+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 561 entries, 0 to 560\n",
      "Data columns (total 7 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   label_multi_severity      561 non-null    int64 \n",
      " 1   sla                       561 non-null    object\n",
      " 2   product_type              561 non-null    object\n",
      " 3   brand                     561 non-null    object\n",
      " 4   service_type              561 non-null    object\n",
      " 5   incident_type             561 non-null    object\n",
      " 6   range_open_to_close_hour  561 non-null    object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 30.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "client = bigquery.Client(project=projectId)\n",
    "\n",
    "train=load_data_bq(f\"SELECT * FROM {train_table_id}\")\n",
    "test=load_data_bq(f\"SELECT * FROM {test_tabel_id}\")\n",
    "\n",
    "print(train.info())\n",
    "\n",
    "print(test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "db86f9b2-8cab-44c7-a9f4-a1d7617ea969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_train = list(train[labelCol].unique())\n",
    "classes_test = list(test[labelCol].unique())\n",
    "\n",
    "set_classes=set(classes_train) & set(classes_test)\n",
    "classes=list(set_classes)\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "33b553e0-a511-489a-9d16-e68535cec436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_multi_severity</th>\n",
       "      <th>sla</th>\n",
       "      <th>product_type</th>\n",
       "      <th>brand</th>\n",
       "      <th>service_type</th>\n",
       "      <th>incident_type</th>\n",
       "      <th>range_open_to_close_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2236</th>\n",
       "      <td>0</td>\n",
       "      <td>24x7 4Hrs Response Time</td>\n",
       "      <td>Software</td>\n",
       "      <td>Trend Micro</td>\n",
       "      <td>Request</td>\n",
       "      <td>Configuration Change</td>\n",
       "      <td>soonest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2237</th>\n",
       "      <td>0</td>\n",
       "      <td>24x7 4Hrs Response Time</td>\n",
       "      <td>Software</td>\n",
       "      <td>Trend Micro</td>\n",
       "      <td>Request</td>\n",
       "      <td>OS / Firmware</td>\n",
       "      <td>latest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2238</th>\n",
       "      <td>0</td>\n",
       "      <td>24x7 6Hrs Resolution Time</td>\n",
       "      <td>Software</td>\n",
       "      <td>Trend Micro</td>\n",
       "      <td>Request</td>\n",
       "      <td>General Incident</td>\n",
       "      <td>soonest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2239</th>\n",
       "      <td>0</td>\n",
       "      <td>24x7 4Hrs Response Time</td>\n",
       "      <td>Security</td>\n",
       "      <td>Trend Micro</td>\n",
       "      <td>Request</td>\n",
       "      <td>Upgrade Software</td>\n",
       "      <td>fair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2240</th>\n",
       "      <td>0</td>\n",
       "      <td>24x7 4Hrs Response Time</td>\n",
       "      <td>Software</td>\n",
       "      <td>Trend Micro</td>\n",
       "      <td>Request</td>\n",
       "      <td>General Incident</td>\n",
       "      <td>soonest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label_multi_severity                        sla product_type  \\\n",
       "2236                     0    24x7 4Hrs Response Time     Software   \n",
       "2237                     0    24x7 4Hrs Response Time     Software   \n",
       "2238                     0  24x7 6Hrs Resolution Time     Software   \n",
       "2239                     0    24x7 4Hrs Response Time     Security   \n",
       "2240                     0    24x7 4Hrs Response Time     Software   \n",
       "\n",
       "            brand service_type         incident_type range_open_to_close_hour  \n",
       "2236  Trend Micro      Request  Configuration Change                  soonest  \n",
       "2237  Trend Micro      Request         OS / Firmware                   latest  \n",
       "2238  Trend Micro      Request      General Incident                  soonest  \n",
       "2239  Trend Micro      Request      Upgrade Software                     fair  \n",
       "2240  Trend Micro      Request      General Incident                  soonest  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e37f9812-69ab-4672-9641-0e9c1873396a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_multi_severity</th>\n",
       "      <th>sla</th>\n",
       "      <th>product_type</th>\n",
       "      <th>brand</th>\n",
       "      <th>service_type</th>\n",
       "      <th>incident_type</th>\n",
       "      <th>range_open_to_close_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>0</td>\n",
       "      <td>24x7 4Hrs Resolution Time</td>\n",
       "      <td>Firewall</td>\n",
       "      <td>Palo Alto</td>\n",
       "      <td>Request</td>\n",
       "      <td>Software</td>\n",
       "      <td>late</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>3</td>\n",
       "      <td>24x7 6Hrs Resolution Time</td>\n",
       "      <td>Software</td>\n",
       "      <td>Trend Micro</td>\n",
       "      <td>Incident</td>\n",
       "      <td>General Incident</td>\n",
       "      <td>soonest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>1</td>\n",
       "      <td>24x7 4Hrs Response Time</td>\n",
       "      <td>Software</td>\n",
       "      <td>Trend Micro</td>\n",
       "      <td>Request</td>\n",
       "      <td>Software</td>\n",
       "      <td>late</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>0</td>\n",
       "      <td>24x7 4Hrs Response Time</td>\n",
       "      <td>Software</td>\n",
       "      <td>Trend Micro</td>\n",
       "      <td>Request</td>\n",
       "      <td>General Incident</td>\n",
       "      <td>soon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>0</td>\n",
       "      <td>24x7 4Hrs Response Time</td>\n",
       "      <td>Software</td>\n",
       "      <td>Trend Micro</td>\n",
       "      <td>Request</td>\n",
       "      <td>General Incident</td>\n",
       "      <td>soon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label_multi_severity                        sla product_type  \\\n",
       "556                     0  24x7 4Hrs Resolution Time     Firewall   \n",
       "557                     3  24x7 6Hrs Resolution Time     Software   \n",
       "558                     1    24x7 4Hrs Response Time     Software   \n",
       "559                     0    24x7 4Hrs Response Time     Software   \n",
       "560                     0    24x7 4Hrs Response Time     Software   \n",
       "\n",
       "           brand service_type     incident_type range_open_to_close_hour  \n",
       "556    Palo Alto      Request          Software                     late  \n",
       "557  Trend Micro     Incident  General Incident                  soonest  \n",
       "558  Trend Micro      Request          Software                     late  \n",
       "559  Trend Micro      Request  General Incident                     soon  \n",
       "560  Trend Micro      Request  General Incident                     soon  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa72159d-066d-4e7c-be00-3e74b60a4062",
   "metadata": {},
   "source": [
    "# Tune Model\n",
    "\n",
    "## Training a model with automated hyper-parameter tuning and automatic definition of the hyper-parameters (recommended approach)\n",
    "\n",
    "As before, hyper-parameter tuning is enabled by specifying the tuner constructor argument of the model. Set use_predefined_hps=True to automatically configure the search space for the hyper-parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "1c895353-d33e-44b8-91eb-75a4322db7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train, label=labelCol)\n",
    "test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test, label=labelCol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8d64afab-6272-4df2-9d7b-cfa7b6c2107c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start tund at 2023-07-08 15:51:22.208505\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "t_Start=time.time()\n",
    "\n",
    "print(f\"Start tund at {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "da1f2012-412a-4c3a-aaeb-9b98dd11fec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestModel\n",
      "Use /var/tmp/tmpgxiuwd92 as temporary training directory\n",
      "Reading training dataset...\n",
      "Training tensor examples:\n",
      "Features: {'sla': <tf.Tensor 'data:0' shape=(None,) dtype=string>, 'product_type': <tf.Tensor 'data_1:0' shape=(None,) dtype=string>, 'brand': <tf.Tensor 'data_2:0' shape=(None,) dtype=string>, 'service_type': <tf.Tensor 'data_3:0' shape=(None,) dtype=string>, 'incident_type': <tf.Tensor 'data_4:0' shape=(None,) dtype=string>, 'range_open_to_close_hour': <tf.Tensor 'data_5:0' shape=(None,) dtype=string>}\n",
      "Label: Tensor(\"data_6:0\", shape=(None,), dtype=int64)\n",
      "Weights: None\n",
      "Normalized tensor features:\n",
      " {'sla': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'data:0' shape=(None,) dtype=string>), 'product_type': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'data_1:0' shape=(None,) dtype=string>), 'brand': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'data_2:0' shape=(None,) dtype=string>), 'service_type': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'data_3:0' shape=(None,) dtype=string>), 'incident_type': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'data_4:0' shape=(None,) dtype=string>), 'range_open_to_close_hour': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'data_5:0' shape=(None,) dtype=string>)}\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function CoreModel._consumes_training_examples_until_eof at 0x7f0e44477760> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-08 15:51:22.525739: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_6' with dtype int64 and shape [2241]\n",
      "\t [[{{node Placeholder/_6}}]]\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function CoreModel._consumes_training_examples_until_eof at 0x7f0e44477760> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset read in 0:00:00.188594. Found 2241 examples.\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 23-07-08 15:51:22.7195 UTC kernel.cc:773] Start Yggdrasil model training\n",
      "[INFO 23-07-08 15:51:22.7196 UTC kernel.cc:774] Collect training examples\n",
      "[INFO 23-07-08 15:51:22.7196 UTC kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "[INFO 23-07-08 15:51:22.7197 UTC kernel.cc:393] Number of batches: 3\n",
      "[INFO 23-07-08 15:51:22.7197 UTC kernel.cc:394] Number of examples: 2241\n",
      "[INFO 23-07-08 15:51:22.7205 UTC data_spec_inference.cc:305] 9 item(s) have been pruned (i.e. they are considered out of dictionary) for the column brand (17 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "[INFO 23-07-08 15:51:22.7205 UTC data_spec_inference.cc:305] 1 item(s) have been pruned (i.e. they are considered out of dictionary) for the column incident_type (20 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "[INFO 23-07-08 15:51:22.7205 UTC data_spec_inference.cc:305] 1 item(s) have been pruned (i.e. they are considered out of dictionary) for the column product_type (10 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "[INFO 23-07-08 15:51:22.7205 UTC data_spec_inference.cc:305] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column sla (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "[INFO 23-07-08 15:51:22.7210 UTC kernel.cc:794] Training dataset:\n",
      "Number of records: 2241\n",
      "Number of columns: 7\n",
      "\n",
      "Number of columns by type:\n",
      "\tCATEGORICAL: 7 (100%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "CATEGORICAL: 7 (100%)\n",
      "\t0: \"__LABEL\" CATEGORICAL integerized vocab-size:5 no-ood-item\n",
      "\t1: \"brand\" CATEGORICAL has-dict vocab-size:18 num-oods:9 (0.401606%) most-frequent:\"HPE\" 717 (31.9946%)\n",
      "\t2: \"incident_type\" CATEGORICAL has-dict vocab-size:21 num-oods:1 (0.0446229%) most-frequent:\"General Incident\" 1135 (50.647%)\n",
      "\t3: \"product_type\" CATEGORICAL has-dict vocab-size:11 num-oods:1 (0.0446229%) most-frequent:\"Storage\" 652 (29.0942%)\n",
      "\t4: \"range_open_to_close_hour\" CATEGORICAL has-dict vocab-size:6 zero-ood-items most-frequent:\"soonest\" 1443 (64.3909%)\n",
      "\t5: \"service_type\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"Incident\" 1679 (74.9219%)\n",
      "\t6: \"sla\" CATEGORICAL has-dict vocab-size:7 num-oods:2 (0.0892459%) most-frequent:\"24x7 4Hrs Resolution Time\" 1056 (47.1218%)\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "[INFO 23-07-08 15:51:22.7210 UTC kernel.cc:810] Configure learner\n",
      "[INFO 23-07-08 15:51:22.7213 UTC kernel.cc:824] Training config:\n",
      "learner: \"HYPERPARAMETER_OPTIMIZER\"\n",
      "features: \"^brand$\"\n",
      "features: \"^incident_type$\"\n",
      "features: \"^product_type$\"\n",
      "features: \"^range_open_to_close_hour$\"\n",
      "features: \"^service_type$\"\n",
      "features: \"^sla$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "[yggdrasil_decision_forests.model.hyperparameters_optimizer_v2.proto.hyperparameters_optimizer_config] {\n",
      "  base_learner {\n",
      "    learner: \"RANDOM_FOREST\"\n",
      "    features: \"^brand$\"\n",
      "    features: \"^incident_type$\"\n",
      "    features: \"^product_type$\"\n",
      "    features: \"^range_open_to_close_hour$\"\n",
      "    features: \"^service_type$\"\n",
      "    features: \"^sla$\"\n",
      "    label: \"^__LABEL$\"\n",
      "    task: CLASSIFICATION\n",
      "    random_seed: 123456\n",
      "    pure_serving_model: false\n",
      "    [yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "      num_trees: 300\n",
      "      decision_tree {\n",
      "        max_depth: 16\n",
      "        min_examples: 5\n",
      "        in_split_min_examples_check: true\n",
      "        keep_non_leaf_label_distribution: true\n",
      "        num_candidate_attributes: 0\n",
      "        missing_value_policy: GLOBAL_IMPUTATION\n",
      "        allow_na_conditions: false\n",
      "        categorical_set_greedy_forward {\n",
      "          sampling: 0.1\n",
      "          max_num_items: -1\n",
      "          min_item_frequency: 1\n",
      "        }\n",
      "        growing_strategy_local {\n",
      "        }\n",
      "        categorical {\n",
      "          cart {\n",
      "          }\n",
      "        }\n",
      "        axis_aligned_split {\n",
      "        }\n",
      "        internal {\n",
      "          sorting_strategy: PRESORTED\n",
      "        }\n",
      "        uplift {\n",
      "          min_examples_in_treatment: 5\n",
      "          split_score: KULLBACK_LEIBLER\n",
      "        }\n",
      "      }\n",
      "      winner_take_all_inference: true\n",
      "      compute_oob_performances: true\n",
      "      compute_oob_variable_importances: false\n",
      "      num_oob_variable_importances_permutations: 1\n",
      "      bootstrap_training_dataset: true\n",
      "      bootstrap_size_ratio: 1\n",
      "      adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "      sampling_with_replacement: true\n",
      "    }\n",
      "  }\n",
      "  optimizer {\n",
      "    optimizer_key: \"RANDOM\"\n",
      "    [yggdrasil_decision_forests.model.hyperparameters_optimizer_v2.proto.random] {\n",
      "      num_trials: 50\n",
      "    }\n",
      "  }\n",
      "  base_learner_deployment {\n",
      "    num_threads: 1\n",
      "  }\n",
      "  predefined_search_space {\n",
      "  }\n",
      "}\n",
      "\n",
      "[INFO 23-07-08 15:51:22.7247 UTC kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/tmp/tmpgxiuwd92/working_cache\"\n",
      "num_threads: 1\n",
      "try_resume_training: true\n",
      "\n",
      "[INFO 23-07-08 15:51:22.7298 UTC kernel.cc:889] Train model\n",
      "[INFO 23-07-08 15:51:22.7339 UTC hyperparameters_optimizer.cc:209] Hyperparameter search space:\n",
      "fields {\n",
      "  name: \"split_axis\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      categorical: \"AXIS_ALIGNED\"\n",
      "    }\n",
      "    possible_values {\n",
      "      categorical: \"SPARSE_OBLIQUE\"\n",
      "    }\n",
      "  }\n",
      "  children {\n",
      "    name: \"sparse_oblique_projection_density_factor\"\n",
      "    discrete_candidates {\n",
      "      possible_values {\n",
      "        real: 1\n",
      "      }\n",
      "      possible_values {\n",
      "        real: 2\n",
      "      }\n",
      "      possible_values {\n",
      "        real: 3\n",
      "      }\n",
      "      possible_values {\n",
      "        real: 4\n",
      "      }\n",
      "      possible_values {\n",
      "        real: 5\n",
      "      }\n",
      "    }\n",
      "    parent_discrete_values {\n",
      "      possible_values {\n",
      "        categorical: \"SPARSE_OBLIQUE\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  children {\n",
      "    name: \"sparse_oblique_normalization\"\n",
      "    discrete_candidates {\n",
      "      possible_values {\n",
      "        categorical: \"NONE\"\n",
      "      }\n",
      "      possible_values {\n",
      "        categorical: \"STANDARD_DEVIATION\"\n",
      "      }\n",
      "      possible_values {\n",
      "        categorical: \"MIN_MAX\"\n",
      "      }\n",
      "    }\n",
      "    parent_discrete_values {\n",
      "      possible_values {\n",
      "        categorical: \"SPARSE_OBLIQUE\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  children {\n",
      "    name: \"sparse_oblique_weights\"\n",
      "    discrete_candidates {\n",
      "      possible_values {\n",
      "        categorical: \"BINARY\"\n",
      "      }\n",
      "      possible_values {\n",
      "        categorical: \"CONTINUOUS\"\n",
      "      }\n",
      "    }\n",
      "    parent_discrete_values {\n",
      "      possible_values {\n",
      "        categorical: \"SPARSE_OBLIQUE\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"categorical_algorithm\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      categorical: \"CART\"\n",
      "    }\n",
      "    possible_values {\n",
      "      categorical: \"RANDOM\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"winner_take_all\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      categorical: \"true\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"max_depth\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      integer: 12\n",
      "    }\n",
      "    possible_values {\n",
      "      integer: 16\n",
      "    }\n",
      "    possible_values {\n",
      "      integer: 20\n",
      "    }\n",
      "    possible_values {\n",
      "      integer: 25\n",
      "    }\n",
      "    possible_values {\n",
      "      integer: 30\n",
      "    }\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"min_examples\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      integer: 1\n",
      "    }\n",
      "    possible_values {\n",
      "      integer: 2\n",
      "    }\n",
      "    possible_values {\n",
      "      integer: 5\n",
      "    }\n",
      "    possible_values {\n",
      "      integer: 10\n",
      "    }\n",
      "    possible_values {\n",
      "      integer: 40\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "[INFO 23-07-08 15:51:22.7340 UTC hyperparameters_optimizer.cc:500] Start local tuner with 1 thread(s)\n",
      "[INFO 23-07-08 15:51:22.7412 UTC random_forest.cc:416] Training random forest on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-08 15:51:22.7651 UTC random_forest.cc:802] Training of tree  1/300 (tree index:0) done accuracy:0.68523 logloss:11.3455\n",
      "[INFO 23-07-08 15:51:22.7954 UTC random_forest.cc:802] Training of tree  11/300 (tree index:10) done accuracy:0.70382 logloss:6.05949\n",
      "[INFO 23-07-08 15:51:22.8301 UTC random_forest.cc:802] Training of tree  21/300 (tree index:20) done accuracy:0.714413 logloss:5.01416\n",
      "[INFO 23-07-08 15:51:22.8605 UTC random_forest.cc:802] Training of tree  31/300 (tree index:30) done accuracy:0.717537 logloss:4.58107\n",
      "[INFO 23-07-08 15:51:22.8936 UTC random_forest.cc:802] Training of tree  41/300 (tree index:40) done accuracy:0.711736 logloss:4.34229\n",
      "[INFO 23-07-08 15:51:22.9246 UTC random_forest.cc:802] Training of tree  51/300 (tree index:50) done accuracy:0.713521 logloss:4.16687\n",
      "[INFO 23-07-08 15:51:22.9547 UTC random_forest.cc:802] Training of tree  61/300 (tree index:60) done accuracy:0.713521 logloss:4.09711\n",
      "[INFO 23-07-08 15:51:22.9872 UTC random_forest.cc:802] Training of tree  71/300 (tree index:70) done accuracy:0.71129 logloss:3.94954\n",
      "[INFO 23-07-08 15:51:23.0206 UTC random_forest.cc:802] Training of tree  81/300 (tree index:80) done accuracy:0.71129 logloss:3.92266\n",
      "[INFO 23-07-08 15:51:23.0536 UTC random_forest.cc:802] Training of tree  91/300 (tree index:90) done accuracy:0.71129 logloss:3.89094\n",
      "[INFO 23-07-08 15:51:23.0864 UTC random_forest.cc:802] Training of tree  101/300 (tree index:100) done accuracy:0.709951 logloss:3.84799\n",
      "[INFO 23-07-08 15:51:23.1239 UTC random_forest.cc:802] Training of tree  111/300 (tree index:110) done accuracy:0.707274 logloss:3.73154\n",
      "[INFO 23-07-08 15:51:23.1546 UTC random_forest.cc:802] Training of tree  121/300 (tree index:120) done accuracy:0.709505 logloss:3.68738\n",
      "[INFO 23-07-08 15:51:23.1876 UTC random_forest.cc:802] Training of tree  131/300 (tree index:130) done accuracy:0.709058 logloss:3.66024\n",
      "[INFO 23-07-08 15:51:23.2224 UTC random_forest.cc:802] Training of tree  141/300 (tree index:140) done accuracy:0.710843 logloss:3.64611\n",
      "[INFO 23-07-08 15:51:23.2544 UTC random_forest.cc:802] Training of tree  151/300 (tree index:150) done accuracy:0.711736 logloss:3.63176\n",
      "[INFO 23-07-08 15:51:23.2865 UTC random_forest.cc:802] Training of tree  161/300 (tree index:160) done accuracy:0.711736 logloss:3.63327\n",
      "[INFO 23-07-08 15:51:23.3174 UTC random_forest.cc:802] Training of tree  171/300 (tree index:170) done accuracy:0.712628 logloss:3.63305\n",
      "[INFO 23-07-08 15:51:23.3505 UTC random_forest.cc:802] Training of tree  181/300 (tree index:180) done accuracy:0.71129 logloss:3.60535\n",
      "[INFO 23-07-08 15:51:23.3812 UTC random_forest.cc:802] Training of tree  191/300 (tree index:190) done accuracy:0.710843 logloss:3.56285\n",
      "[INFO 23-07-08 15:51:23.4121 UTC random_forest.cc:802] Training of tree  201/300 (tree index:200) done accuracy:0.709058 logloss:3.53335\n",
      "[INFO 23-07-08 15:51:23.4445 UTC random_forest.cc:802] Training of tree  211/300 (tree index:210) done accuracy:0.708166 logloss:3.53472\n",
      "[INFO 23-07-08 15:51:23.4762 UTC random_forest.cc:802] Training of tree  221/300 (tree index:220) done accuracy:0.708612 logloss:3.50685\n",
      "[INFO 23-07-08 15:51:23.5078 UTC random_forest.cc:802] Training of tree  231/300 (tree index:230) done accuracy:0.705935 logloss:3.49128\n",
      "[INFO 23-07-08 15:51:23.5412 UTC random_forest.cc:802] Training of tree  241/300 (tree index:240) done accuracy:0.70772 logloss:3.35077\n",
      "[INFO 23-07-08 15:51:23.5743 UTC random_forest.cc:802] Training of tree  251/300 (tree index:250) done accuracy:0.708612 logloss:3.33764\n",
      "[INFO 23-07-08 15:51:23.6078 UTC random_forest.cc:802] Training of tree  261/300 (tree index:260) done accuracy:0.707274 logloss:3.32324\n",
      "[INFO 23-07-08 15:51:23.6409 UTC random_forest.cc:802] Training of tree  271/300 (tree index:270) done accuracy:0.707274 logloss:3.26521\n",
      "[INFO 23-07-08 15:51:23.6763 UTC random_forest.cc:802] Training of tree  281/300 (tree index:280) done accuracy:0.705042 logloss:3.25093\n",
      "[INFO 23-07-08 15:51:23.7075 UTC random_forest.cc:802] Training of tree  291/300 (tree index:290) done accuracy:0.704596 logloss:3.2527\n",
      "[INFO 23-07-08 15:51:23.7369 UTC random_forest.cc:802] Training of tree  300/300 (tree index:299) done accuracy:0.705042 logloss:3.25254\n",
      "[INFO 23-07-08 15:51:23.7409 UTC random_forest.cc:882] Final OOB metrics: accuracy:0.705042 logloss:3.25254\n",
      "[INFO 23-07-08 15:51:23.7451 UTC hyperparameters_optimizer.cc:582] [1/50] Score: 0.705042 / 0.705042 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"min_examples\" value { integer: 40 } }\n",
      "[INFO 23-07-08 15:51:23.7493 UTC random_forest.cc:416] Training random forest on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-08 15:51:23.7670 UTC random_forest.cc:802] Training of tree  1/300 (tree index:0) done accuracy:0.725182 logloss:9.90546\n",
      "[INFO 23-07-08 15:51:23.8475 UTC random_forest.cc:802] Training of tree  11/300 (tree index:10) done accuracy:0.71191 logloss:6.70598\n",
      "[INFO 23-07-08 15:51:23.9251 UTC random_forest.cc:802] Training of tree  21/300 (tree index:20) done accuracy:0.715752 logloss:5.89465\n",
      "[INFO 23-07-08 15:51:24.0018 UTC random_forest.cc:802] Training of tree  31/300 (tree index:30) done accuracy:0.715752 logloss:5.31333\n",
      "[INFO 23-07-08 15:51:24.0794 UTC random_forest.cc:802] Training of tree  41/300 (tree index:40) done accuracy:0.715752 logloss:4.95639\n",
      "[INFO 23-07-08 15:51:24.1608 UTC random_forest.cc:802] Training of tree  51/300 (tree index:50) done accuracy:0.71129 logloss:4.81268\n",
      "[INFO 23-07-08 15:51:24.2418 UTC random_forest.cc:802] Training of tree  61/300 (tree index:60) done accuracy:0.714859 logloss:4.5796\n",
      "[INFO 23-07-08 15:51:24.3195 UTC random_forest.cc:802] Training of tree  71/300 (tree index:70) done accuracy:0.715752 logloss:4.31836\n",
      "[INFO 23-07-08 15:51:24.3967 UTC random_forest.cc:802] Training of tree  81/300 (tree index:80) done accuracy:0.719322 logloss:4.14392\n",
      "[INFO 23-07-08 15:51:24.4740 UTC random_forest.cc:802] Training of tree  91/300 (tree index:90) done accuracy:0.720214 logloss:4.04466\n",
      "[INFO 23-07-08 15:51:24.5529 UTC random_forest.cc:802] Training of tree  101/300 (tree index:100) done accuracy:0.720214 logloss:4.0017\n",
      "[INFO 23-07-08 15:51:24.6323 UTC random_forest.cc:802] Training of tree  111/300 (tree index:110) done accuracy:0.719322 logloss:3.93051\n",
      "[INFO 23-07-08 15:51:24.7098 UTC random_forest.cc:802] Training of tree  121/300 (tree index:120) done accuracy:0.717983 logloss:3.83031\n",
      "[INFO 23-07-08 15:51:24.7862 UTC random_forest.cc:802] Training of tree  131/300 (tree index:130) done accuracy:0.718876 logloss:3.75935\n",
      "[INFO 23-07-08 15:51:24.8649 UTC random_forest.cc:802] Training of tree  141/300 (tree index:140) done accuracy:0.717983 logloss:3.73111\n",
      "[INFO 23-07-08 15:51:24.9455 UTC random_forest.cc:802] Training of tree  151/300 (tree index:150) done accuracy:0.719768 logloss:3.69015\n",
      "[INFO 23-07-08 15:51:25.0239 UTC random_forest.cc:802] Training of tree  161/300 (tree index:160) done accuracy:0.72066 logloss:3.60227\n",
      "[INFO 23-07-08 15:51:25.1006 UTC random_forest.cc:802] Training of tree  171/300 (tree index:170) done accuracy:0.719768 logloss:3.56087\n",
      "[INFO 23-07-08 15:51:25.1786 UTC random_forest.cc:802] Training of tree  181/300 (tree index:180) done accuracy:0.721553 logloss:3.51893\n",
      "[INFO 23-07-08 15:51:25.2574 UTC random_forest.cc:802] Training of tree  191/300 (tree index:190) done accuracy:0.718876 logloss:3.46413\n",
      "[INFO 23-07-08 15:51:25.3363 UTC random_forest.cc:802] Training of tree  201/300 (tree index:200) done accuracy:0.718429 logloss:3.41918\n",
      "[INFO 23-07-08 15:51:25.4146 UTC random_forest.cc:802] Training of tree  211/300 (tree index:210) done accuracy:0.718429 logloss:3.4043\n",
      "[INFO 23-07-08 15:51:25.4950 UTC random_forest.cc:802] Training of tree  221/300 (tree index:220) done accuracy:0.718876 logloss:3.3912\n",
      "[INFO 23-07-08 15:51:25.5741 UTC random_forest.cc:802] Training of tree  231/300 (tree index:230) done accuracy:0.719768 logloss:3.37729\n",
      "[INFO 23-07-08 15:51:25.6534 UTC random_forest.cc:802] Training of tree  241/300 (tree index:240) done accuracy:0.721107 logloss:3.3771\n",
      "[INFO 23-07-08 15:51:25.7354 UTC random_forest.cc:802] Training of tree  251/300 (tree index:250) done accuracy:0.719322 logloss:3.37698\n",
      "[INFO 23-07-08 15:51:25.8154 UTC random_forest.cc:802] Training of tree  261/300 (tree index:260) done accuracy:0.718429 logloss:3.36123\n",
      "[INFO 23-07-08 15:51:25.8956 UTC random_forest.cc:802] Training of tree  271/300 (tree index:270) done accuracy:0.718876 logloss:3.34805\n",
      "[INFO 23-07-08 15:51:25.9759 UTC random_forest.cc:802] Training of tree  281/300 (tree index:280) done accuracy:0.720214 logloss:3.34832\n",
      "[INFO 23-07-08 15:51:26.0550 UTC random_forest.cc:802] Training of tree  291/300 (tree index:290) done accuracy:0.721553 logloss:3.3337\n",
      "[INFO 23-07-08 15:51:26.1290 UTC random_forest.cc:802] Training of tree  300/300 (tree index:299) done accuracy:0.720214 logloss:3.33411\n",
      "[INFO 23-07-08 15:51:26.1334 UTC random_forest.cc:882] Final OOB metrics: accuracy:0.720214 logloss:3.33411\n",
      "[[INFO 23-07-08 15:51:26.1945 UTC random_forest.cc:416] Training random forest on 2241 example(s) and 6 feature(s).\n",
      "INFO 23-07-08 15:51:26.2007 UTC hyperparameters_optimizer.cc:582] [2/50] Score: 0.720214 / 0.720214 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 16 } } fields { name: \"min_examples\" value { integer: 1 } }\n",
      "[INFO 23-07-08 15:51:26.2259 UTC random_forest.cc:802] Training of tree  1/300 (tree index:0) done accuracy:0.702179 logloss:10.7345\n",
      "[INFO 23-07-08 15:51:26.3338 UTC random_forest.cc:802] Training of tree  11/300 (tree index:10) done accuracy:0.710562 logloss:6.57439\n",
      "[INFO 23-07-08 15:51:26.4368 UTC random_forest.cc:802] Training of tree  21/300 (tree index:20) done accuracy:0.723784 logloss:5.3979\n",
      "[INFO 23-07-08 15:51:26.5414 UTC random_forest.cc:802] Training of tree  31/300 (tree index:30) done accuracy:0.729585 logloss:4.76787\n",
      "[INFO 23-07-08 15:51:26.6483 UTC random_forest.cc:802] Training of tree  41/300 (tree index:40) done accuracy:0.730924 logloss:4.4903\n",
      "[INFO 23-07-08 15:51:26.7553 UTC random_forest.cc:802] Training of tree  51/300 (tree index:50) done accuracy:0.73137 logloss:4.29551\n",
      "[INFO 23-07-08 15:51:26.8696 UTC random_forest.cc:802] Training of tree  61/300 (tree index:60) done accuracy:0.734494 logloss:4.09206\n",
      "[INFO 23-07-08 15:51:26.9775 UTC random_forest.cc:802] Training of tree  71/300 (tree index:70) done accuracy:0.737617 logloss:3.91753\n",
      "[INFO 23-07-08 15:51:27.0842 UTC random_forest.cc:802] Training of tree  81/300 (tree index:80) done accuracy:0.73494 logloss:3.72881\n",
      "[INFO 23-07-08 15:51:27.1931 UTC random_forest.cc:802] Training of tree  91/300 (tree index:90) done accuracy:0.737617 logloss:3.59751\n",
      "[INFO 23-07-08 15:51:27.3010 UTC random_forest.cc:802] Training of tree  101/300 (tree index:100) done accuracy:0.737617 logloss:3.53982\n",
      "[INFO 23-07-08 15:51:27.4100 UTC random_forest.cc:802] Training of tree  111/300 (tree index:110) done accuracy:0.738063 logloss:3.49579\n",
      "[INFO 23-07-08 15:51:27.5202 UTC random_forest.cc:802] Training of tree  121/300 (tree index:120) done accuracy:0.738956 logloss:3.46867\n",
      "[INFO 23-07-08 15:51:27.6268 UTC random_forest.cc:802] Training of tree  131/300 (tree index:130) done accuracy:0.740295 logloss:3.35256\n",
      "[INFO 23-07-08 15:51:27.7352 UTC random_forest.cc:802] Training of tree  141/300 (tree index:140) done accuracy:0.737617 logloss:3.3095\n",
      "[INFO 23-07-08 15:51:27.8411 UTC random_forest.cc:802] Training of tree  151/300 (tree index:150) done accuracy:0.735832 logloss:3.2809\n",
      "[INFO 23-07-08 15:51:27.9469 UTC random_forest.cc:802] Training of tree  161/300 (tree index:160) done accuracy:0.738956 logloss:3.25228\n",
      "[INFO 23-07-08 15:51:28.0616 UTC random_forest.cc:802] Training of tree  171/300 (tree index:170) done accuracy:0.739402 logloss:3.23951\n",
      "[INFO 23-07-08 15:51:28.1672 UTC random_forest.cc:802] Training of tree  181/300 (tree index:180) done accuracy:0.740295 logloss:3.19706\n",
      "[INFO 23-07-08 15:51:28.2732 UTC random_forest.cc:802] Training of tree  191/300 (tree index:190) done accuracy:0.739848 logloss:3.19739\n",
      "[INFO 23-07-08 15:51:28.3785 UTC random_forest.cc:802] Training of tree  201/300 (tree index:200) done accuracy:0.739848 logloss:3.12638\n",
      "[INFO 23-07-08 15:51:28.4863 UTC random_forest.cc:802] Training of tree  211/300 (tree index:210) done accuracy:0.740295 logloss:3.11136\n",
      "[INFO 23-07-08 15:51:28.5931 UTC random_forest.cc:802] Training of tree  221/300 (tree index:220) done accuracy:0.738956 logloss:3.11184\n",
      "[INFO 23-07-08 15:51:28.7023 UTC random_forest.cc:802] Training of tree  231/300 (tree index:230) done accuracy:0.737617 logloss:3.01426\n",
      "[INFO 23-07-08 15:51:28.8089 UTC random_forest.cc:802] Training of tree  241/300 (tree index:240) done accuracy:0.739848 logloss:2.88752\n",
      "[INFO 23-07-08 15:51:28.9188 UTC random_forest.cc:802] Training of tree  251/300 (tree index:250) done accuracy:0.740741 logloss:2.87447\n",
      "[INFO 23-07-08 15:51:29.0284 UTC random_forest.cc:802] Training of tree  261/300 (tree index:260) done accuracy:0.742079 logloss:2.85942\n",
      "[INFO 23-07-08 15:51:29.1364 UTC random_forest.cc:802] Training of tree  271/300 (tree index:270) done accuracy:0.741187 logloss:2.85894\n",
      "[INFO 23-07-08 15:51:29.2430 UTC random_forest.cc:802] Training of tree  281/300 (tree index:280) done accuracy:0.741633 logloss:2.84439\n",
      "[INFO 23-07-08 15:51:29.3498 UTC random_forest.cc:802] Training of tree  291/300 (tree index:290) done accuracy:0.739848 logloss:2.83029\n",
      "[INFO 23-07-08 15:51:29.4477 UTC random_forest.cc:802] Training of tree  300/300 (tree index:299) done accuracy:0.740741 logloss:2.83056\n",
      "[INFO 23-07-08 15:51:29.4511 UTC random_forest.cc:882] Final OOB metrics: accuracy:0.740741 logloss:2.83056\n",
      "[INFO 23-07-08 15:51:29.4848 UTC random_forest.cc:416] Training random forest on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-08 15:51:29.5113 UTC random_forest.cc:802] Training of tree  1/300 (tree index:0) done accuracy:0.717918 logloss:10.1673\n",
      "[INFO 23-07-08 15:51:29.5864 UTC hyperparameters_optimizer.cc:582] [3/50] Score: 0.740741 / 0.740741 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 16 } } fields { name: \"min_examples\" value { integer: 10 } }\n",
      "[INFO 23-07-08 15:51:29.6270 UTC random_forest.cc:802] Training of tree  11/300 (tree index:10) done accuracy:0.715056 logloss:6.84692\n",
      "[INFO 23-07-08 15:51:29.6968 UTC random_forest.cc:802] Training of tree  21/300 (tree index:20) done accuracy:0.725569 logloss:5.78337\n",
      "[INFO 23-07-08 15:51:29.7668 UTC random_forest.cc:802] Training of tree  31/300 (tree index:30) done accuracy:0.721107 logloss:5.20285\n",
      "[INFO 23-07-08 15:51:29.8349 UTC random_forest.cc:802] Training of tree  41/300 (tree index:40) done accuracy:0.721553 logloss:4.8477\n",
      "[INFO 23-07-08 15:51:29.9045 UTC random_forest.cc:802] Training of tree  51/300 (tree index:50) done accuracy:0.719768 logloss:4.62821\n",
      "[INFO 23-07-08 15:51:29.9762 UTC random_forest.cc:802] Training of tree  61/300 (tree index:60) done accuracy:0.72066 logloss:4.39727\n",
      "[INFO 23-07-08 15:51:30.0473 UTC random_forest.cc:802] Training of tree  71/300 (tree index:70) done accuracy:0.721553 logloss:4.19513\n",
      "[INFO 23-07-08 15:51:30.1177 UTC random_forest.cc:802] Training of tree  81/300 (tree index:80) done accuracy:0.72066 logloss:4.05009\n",
      "[INFO 23-07-08 15:51:30.1892 UTC random_forest.cc:802] Training of tree  91/300 (tree index:90) done accuracy:0.721999 logloss:3.97999\n",
      "[INFO 23-07-08 15:51:30.2605 UTC random_forest.cc:802] Training of tree  101/300 (tree index:100) done accuracy:0.723784 logloss:3.89406\n",
      "[INFO 23-07-08 15:51:30.3346 UTC random_forest.cc:802] Training of tree  111/300 (tree index:110) done accuracy:0.726015 logloss:3.82151\n",
      "[INFO 23-07-08 15:51:30.4029 UTC random_forest.cc:802] Training of tree  121/300 (tree index:120) done accuracy:0.726908 logloss:3.76412\n",
      "[INFO 23-07-08 15:51:30.4743 UTC random_forest.cc:802] Training of tree  131/300 (tree index:130) done accuracy:0.728693 logloss:3.64933\n",
      "[INFO 23-07-08 15:51:30.5439 UTC random_forest.cc:802] Training of tree  141/300 (tree index:140) done accuracy:0.726908 logloss:3.59232\n",
      "[INFO 23-07-08 15:51:30.6159 UTC random_forest.cc:802] Training of tree  151/300 (tree index:150) done accuracy:0.7278 logloss:3.56497\n",
      "[INFO 23-07-08 15:51:30.6901 UTC random_forest.cc:802] Training of tree  161/300 (tree index:160) done accuracy:0.72423 logloss:3.50868\n",
      "[INFO 23-07-08 15:51:30.7627 UTC random_forest.cc:802] Training of tree  171/300 (tree index:170) done accuracy:0.725569 logloss:3.48071\n",
      "[INFO 23-07-08 15:51:30.8360 UTC random_forest.cc:802] Training of tree  181/300 (tree index:180) done accuracy:0.72423 logloss:3.46627\n",
      "[INFO 23-07-08 15:51:30.9083 UTC random_forest.cc:802] Training of tree  191/300 (tree index:190) done accuracy:0.723338 logloss:3.40967\n",
      "[INFO 23-07-08 15:51:30.9839 UTC random_forest.cc:802] Training of tree  201/300 (tree index:200) done accuracy:0.722892 logloss:3.34993\n",
      "[INFO 23-07-08 15:51:31.0569 UTC random_forest.cc:802] Training of tree  211/300 (tree index:210) done accuracy:0.722892 logloss:3.33466\n",
      "[INFO 23-07-08 15:51:31.1303 UTC random_forest.cc:802] Training of tree  221/300 (tree index:220) done accuracy:0.723784 logloss:3.32185\n",
      "[INFO 23-07-08 15:51:31.2040 UTC random_forest.cc:802] Training of tree  231/300 (tree index:230) done accuracy:0.724676 logloss:3.29354\n",
      "[INFO 23-07-08 15:51:31.2782 UTC random_forest.cc:802] Training of tree  241/300 (tree index:240) done accuracy:0.725569 logloss:3.27943\n",
      "[INFO 23-07-08 15:51:31.3519 UTC random_forest.cc:802] Training of tree  251/300 (tree index:250) done accuracy:0.724676 logloss:3.28036\n",
      "[INFO 23-07-08 15:51:31.4257 UTC random_forest.cc:802] Training of tree  261/300 (tree index:260) done accuracy:0.72423 logloss:3.25036\n",
      "[INFO 23-07-08 15:51:31.5003 UTC random_forest.cc:802] Training of tree  271/300 (tree index:270) done accuracy:0.72423 logloss:3.25105\n",
      "[INFO 23-07-08 15:51:31.5747 UTC random_forest.cc:802] Training of tree  281/300 (tree index:280) done accuracy:0.726015 logloss:3.25095\n",
      "[INFO 23-07-08 15:51:31.6458 UTC random_forest.cc:802] Training of tree  291/300 (tree index:290) done accuracy:0.726015 logloss:3.25048\n",
      "[INFO 23-07-08 15:51:31.7139 UTC random_forest.cc:802] Training of tree  300/300 (tree index:299) done accuracy:0.72423 logloss:3.22165\n",
      "[INFO 23-07-08 15:51:31.7173 UTC random_forest.cc:882] Final OOB metrics: accuracy:0.72423 logloss:3.22165\n",
      "[INFO 23-07-08 15:51:31.7605 UTC hyperparameters_optimizer.cc:582] [4/50] Score: 0.72423 / 0.740741 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 25 } } fields { name: \"min_examples\" value { integer: 2 } }\n",
      "[INFO 23-07-08 15:51:31.7720 UTC random_forest.cc:416] Training random forest on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-08 15:51:31.7960 UTC random_forest.cc:802] Training of tree  1/300 (tree index:0) done accuracy:0.716707 logloss:10.2109\n",
      "[INFO 23-07-08 15:51:31.8644 UTC random_forest.cc:802] Training of tree  11/300 (tree index:10) done accuracy:0.710112 logloss:6.63275\n",
      "[INFO 23-07-08 15:51:31.9141 UTC random_forest.cc:802] Training of tree  21/300 (tree index:20) done accuracy:0.728693 logloss:5.46481\n",
      "[INFO 23-07-08 15:51:31.9624 UTC random_forest.cc:802] Training of tree  31/300 (tree index:30) done accuracy:0.728246 logloss:4.99131\n",
      "[INFO 23-07-08 15:51:32.0115 UTC random_forest.cc:802] Training of tree  41/300 (tree index:40) done accuracy:0.729585 logloss:4.56309\n",
      "[INFO 23-07-08 15:51:32.0621 UTC random_forest.cc:802] Training of tree  51/300 (tree index:50) done accuracy:0.728246 logloss:4.34453\n",
      "[INFO 23-07-08 15:51:32.1165 UTC random_forest.cc:802] Training of tree  61/300 (tree index:60) done accuracy:0.733601 logloss:4.18214\n",
      "[INFO 23-07-08 15:51:32.1647 UTC random_forest.cc:802] Training of tree  71/300 (tree index:70) done accuracy:0.733601 logloss:3.99388\n",
      "[INFO 23-07-08 15:51:32.2147 UTC random_forest.cc:802] Training of tree  81/300 (tree index:80) done accuracy:0.732262 logloss:3.89545\n",
      "[INFO 23-07-08 15:51:32.2638 UTC random_forest.cc:802] Training of tree  91/300 (tree index:90) done accuracy:0.73494 logloss:3.8672\n",
      "[INFO 23-07-08 15:51:32.3121 UTC random_forest.cc:802] Training of tree  101/300 (tree index:100) done accuracy:0.73494 logloss:3.75001\n",
      "[INFO 23-07-08 15:51:32.3609 UTC random_forest.cc:802] Training of tree  111/300 (tree index:110) done accuracy:0.734047 logloss:3.67642\n",
      "[INFO 23-07-08 15:51:32.4101 UTC random_forest.cc:802] Training of tree  121/300 (tree index:120) done accuracy:0.733601 logloss:3.64851\n",
      "[INFO 23-07-08 15:51:32.4601 UTC random_forest.cc:802] Training of tree  131/300 (tree index:130) done accuracy:0.736278 logloss:3.54679\n",
      "[INFO 23-07-08 15:51:32.5100 UTC random_forest.cc:802] Training of tree  141/300 (tree index:140) done accuracy:0.736725 logloss:3.44668\n",
      "[INFO 23-07-08 15:51:32.5612 UTC random_forest.cc:802] Training of tree  151/300 (tree index:150) done accuracy:0.738956 logloss:3.40438\n",
      "[INFO 23-07-08 15:51:32.6103 UTC random_forest.cc:802] Training of tree  161/300 (tree index:160) done accuracy:0.737171 logloss:3.33383\n",
      "[INFO 23-07-08 15:51:32.6596 UTC random_forest.cc:802] Training of tree  171/300 (tree index:170) done accuracy:0.736725 logloss:3.30592\n",
      "[INFO 23-07-08 15:51:32.7091 UTC random_forest.cc:802] Training of tree  181/300 (tree index:180) done accuracy:0.736725 logloss:3.29276\n",
      "[INFO 23-07-08 15:51:32.7594 UTC random_forest.cc:802] Training of tree  191/300 (tree index:190) done accuracy:0.736725 logloss:3.26406\n",
      "[INFO 23-07-08 15:51:32.8079 UTC random_forest.cc:802] Training of tree  201/300 (tree index:200) done accuracy:0.736278 logloss:3.21833\n",
      "[INFO 23-07-08 15:51:32.8590 UTC random_forest.cc:802] Training of tree  211/300 (tree index:210) done accuracy:0.737617 logloss:3.18965\n",
      "[INFO 23-07-08 15:51:32.9090 UTC random_forest.cc:802] Training of tree  221/300 (tree index:220) done accuracy:0.736725 logloss:3.1477\n",
      "[INFO 23-07-08 15:51:32.9616 UTC random_forest.cc:802] Training of tree  231/300 (tree index:230) done accuracy:0.736278 logloss:3.13392\n",
      "[INFO 23-07-08 15:51:33.0108 UTC random_forest.cc:802] Training of tree  241/300 (tree index:240) done accuracy:0.735386 logloss:3.11915\n",
      "[INFO 23-07-08 15:51:33.0598 UTC random_forest.cc:802] Training of tree  251/300 (tree index:250) done accuracy:0.735386 logloss:3.11919\n",
      "[INFO 23-07-08 15:51:33.1088 UTC random_forest.cc:802] Training of tree  261/300 (tree index:260) done accuracy:0.735386 logloss:3.09101\n",
      "[INFO 23-07-08 15:51:33.1597 UTC random_forest.cc:802] Training of tree  271/300 (tree index:270) done accuracy:0.73494 logloss:3.06321\n",
      "[INFO 23-07-08 15:51:33.2078 UTC random_forest.cc:802] Training of tree  281/300 (tree index:280) done accuracy:0.736725 logloss:3.0483\n",
      "[INFO 23-07-08 15:51:33.2566 UTC random_forest.cc:802] Training of tree  291/300 (tree index:290) done accuracy:0.736278 logloss:3.03378\n",
      "[INFO 23-07-08 15:51:33.3025 UTC random_forest.cc:802] Training of tree  300/300 (tree index:299) done accuracy:0.736725 logloss:3.03436\n",
      "[INFO 23-07-08 15:51:33.3063 UTC random_forest.cc:882] Final OOB metrics: accuracy:0.736725 logloss:3.03436\n",
      "[INFO 23-07-08 15:51:33.3272 UTC hyperparameters_optimizer.cc:582] [5/50] Score: 0.736725 / 0.740741 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 20 } } fields { name: \"min_examples\" value { integer: 10 } }\n",
      "[INFO 23-07-08 15:51:33.3383 UTC random_forest.cc:416] Training random forest on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-08 15:51:33.3597 UTC random_forest.cc:802] Training of tree  1/300 (tree index:0) done accuracy:0.716707 logloss:10.2109\n",
      "[INFO 23-07-08 15:51:33.4181 UTC random_forest.cc:802] Training of tree  11/300 (tree index:10) done accuracy:0.710112 logloss:6.63275\n",
      "[INFO 23-07-08 15:51:33.4680 UTC random_forest.cc:802] Training of tree  21/300 (tree index:20) done accuracy:0.728693 logloss:5.46481\n",
      "[INFO 23-07-08 15:51:33.5167 UTC random_forest.cc:802] Training of tree  31/300 (tree index:30) done accuracy:0.728246 logloss:4.99131\n",
      "[INFO 23-07-08 15:51:33.5675 UTC random_forest.cc:802] Training of tree  41/300 (tree index:40) done accuracy:0.729585 logloss:4.56309\n",
      "[INFO 23-07-08 15:51:33.6173 UTC random_forest.cc:802] Training of tree  51/300 (tree index:50) done accuracy:0.728246 logloss:4.34453\n",
      "[INFO 23-07-08 15:51:33.6674 UTC random_forest.cc:802] Training of tree  61/300 (tree index:60) done accuracy:0.733601 logloss:4.18214\n",
      "[INFO 23-07-08 15:51:33.7172 UTC random_forest.cc:802] Training of tree  71/300 (tree index:70) done accuracy:0.733601 logloss:3.99388\n",
      "[INFO 23-07-08 15:51:33.7657 UTC random_forest.cc:802] Training of tree  81/300 (tree index:80) done accuracy:0.732262 logloss:3.89545\n",
      "[INFO 23-07-08 15:51:33.8182 UTC random_forest.cc:802] Training of tree  91/300 (tree index:90) done accuracy:0.73494 logloss:3.8672\n",
      "[INFO 23-07-08 15:51:33.8672 UTC random_forest.cc:802] Training of tree  101/300 (tree index:100) done accuracy:0.73494 logloss:3.75001\n",
      "[INFO 23-07-08 15:51:33.9158 UTC random_forest.cc:802] Training of tree  111/300 (tree index:110) done accuracy:0.734047 logloss:3.67642\n",
      "[INFO 23-07-08 15:51:33.9654 UTC random_forest.cc:802] Training of tree  121/300 (tree index:120) done accuracy:0.733601 logloss:3.64851\n",
      "[INFO 23-07-08 15:51:34.0140 UTC random_forest.cc:802] Training of tree  131/300 (tree index:130) done accuracy:0.736278 logloss:3.54679\n",
      "[INFO 23-07-08 15:51:34.0616 UTC random_forest.cc:802] Training of tree  141/300 (tree index:140) done accuracy:0.736725 logloss:3.44668\n",
      "[INFO 23-07-08 15:51:34.1110 UTC random_forest.cc:802] Training of tree  151/300 (tree index:150) done accuracy:0.738956 logloss:3.40438\n",
      "[INFO 23-07-08 15:51:34.1601 UTC random_forest.cc:802] Training of tree  161/300 (tree index:160) done accuracy:0.737171 logloss:3.33383\n",
      "[INFO 23-07-08 15:51:34.2096 UTC random_forest.cc:802] Training of tree  171/300 (tree index:170) done accuracy:0.736725 logloss:3.30592\n",
      "[INFO 23-07-08 15:51:34.2620 UTC random_forest.cc:802] Training of tree  181/300 (tree index:180) done accuracy:0.736725 logloss:3.29276\n",
      "[INFO 23-07-08 15:51:34.3159 UTC random_forest.cc:802] Training of tree  191/300 (tree index:190) done accuracy:0.736725 logloss:3.26406\n",
      "[INFO 23-07-08 15:51:34.3635 UTC random_forest.cc:802] Training of tree  201/300 (tree index:200) done accuracy:0.736278 logloss:3.21833\n",
      "[INFO 23-07-08 15:51:34.4126 UTC random_forest.cc:802] Training of tree  211/300 (tree index:210) done accuracy:0.737617 logloss:3.18965\n",
      "[INFO 23-07-08 15:51:34.4621 UTC random_forest.cc:802] Training of tree  221/300 (tree index:220) done accuracy:0.736725 logloss:3.1477\n",
      "[INFO 23-07-08 15:51:34.5094 UTC random_forest.cc:802] Training of tree  231/300 (tree index:230) done accuracy:0.736278 logloss:3.13392\n",
      "[INFO 23-07-08 15:51:34.5577 UTC random_forest.cc:802] Training of tree  241/300 (tree index:240) done accuracy:0.735386 logloss:3.11915\n",
      "[INFO 23-07-08 15:51:34.6068 UTC random_forest.cc:802] Training of tree  251/300 (tree index:250) done accuracy:0.735386 logloss:3.11919\n",
      "[INFO 23-07-08 15:51:34.6550 UTC random_forest.cc:802] Training of tree  261/300 (tree index:260) done accuracy:0.735386 logloss:3.09101\n",
      "[INFO 23-07-08 15:51:34.7084 UTC random_forest.cc:802] Training of tree  271/300 (tree index:270) done accuracy:0.73494 logloss:3.06321\n",
      "[INFO 23-07-08 15:51:34.7577 UTC random_forest.cc:802] Training of tree  281/300 (tree index:280) done accuracy:0.736725 logloss:3.0483\n",
      "[INFO 23-07-08 15:51:34.8071 UTC random_forest.cc:802] Training of tree  291/300 (tree index:290) done accuracy:0.736278 logloss:3.03378\n",
      "[INFO 23-07-08 15:51:34.8526 UTC random_forest.cc:802] Training of tree  300/300 (tree index:299) done accuracy:0.736725 logloss:3.03436\n",
      "[INFO 23-07-08 15:51:34.8575 UTC random_forest.cc:882] Final OOB metrics: accuracy:0.736725 logloss:3.03436\n",
      "[INFO 23-07-08 15:51:34.8772 UTC hyperparameters_optimizer.cc:582] [6/50] Score: 0.736725 / 0.740741 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 20 } } fields { name: \"min_examples\" value { integer: 10 } }\n",
      "[INFO 23-07-08 15:51:34.8937 UTC random_forest.cc:416] Training random forest on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-08 15:51:34.9215 UTC random_forest.cc:802] Training of tree  1/300 (tree index:0) done accuracy:0.702179 logloss:10.7345\n",
      "[INFO 23-07-08 15:51:35.0314 UTC random_forest.cc:802] Training of tree  11/300 (tree index:10) done accuracy:0.710562 logloss:6.57439\n",
      "[INFO 23-07-08 15:51:35.1371 UTC random_forest.cc:802] Training of tree  21/300 (tree index:20) done accuracy:0.723784 logloss:5.3979\n",
      "[INFO 23-07-08 15:51:35.2447 UTC random_forest.cc:802] Training of tree  31/300 (tree index:30) done accuracy:0.729585 logloss:4.76787\n",
      "[INFO 23-07-08 15:51:35.3561 UTC random_forest.cc:802] Training of tree  41/300 (tree index:40) done accuracy:0.730924 logloss:4.4903\n",
      "[INFO 23-07-08 15:51:35.4660 UTC random_forest.cc:802] Training of tree  51/300 (tree index:50) done accuracy:0.73137 logloss:4.29551\n",
      "[INFO 23-07-08 15:51:35.5792 UTC random_forest.cc:802] Training of tree  61/300 (tree index:60) done accuracy:0.734494 logloss:4.09206\n",
      "[INFO 23-07-08 15:51:35.6866 UTC random_forest.cc:802] Training of tree  71/300 (tree index:70) done accuracy:0.737617 logloss:3.91753\n",
      "[INFO 23-07-08 15:51:35.7956 UTC random_forest.cc:802] Training of tree  81/300 (tree index:80) done accuracy:0.73494 logloss:3.72881\n",
      "[INFO 23-07-08 15:51:35.9051 UTC random_forest.cc:802] Training of tree  91/300 (tree index:90) done accuracy:0.737617 logloss:3.59751\n",
      "[INFO 23-07-08 15:51:36.0138 UTC random_forest.cc:802] Training of tree  101/300 (tree index:100) done accuracy:0.737617 logloss:3.53982\n",
      "[INFO 23-07-08 15:51:36.1243 UTC random_forest.cc:802] Training of tree  111/300 (tree index:110) done accuracy:0.738063 logloss:3.49579\n",
      "[INFO 23-07-08 15:51:36.2322 UTC random_forest.cc:802] Training of tree  121/300 (tree index:120) done accuracy:0.738956 logloss:3.46867\n",
      "[INFO 23-07-08 15:51:36.3450 UTC random_forest.cc:802] Training of tree  131/300 (tree index:130) done accuracy:0.740295 logloss:3.35234\n",
      "[INFO 23-07-08 15:51:36.4544 UTC random_forest.cc:802] Training of tree  141/300 (tree index:140) done accuracy:0.737617 logloss:3.30928\n",
      "[INFO 23-07-08 15:51:36.5648 UTC random_forest.cc:802] Training of tree  151/300 (tree index:150) done accuracy:0.736278 logloss:3.28073\n",
      "[INFO 23-07-08 15:51:36.6725 UTC random_forest.cc:802] Training of tree  161/300 (tree index:160) done accuracy:0.738956 logloss:3.25215\n",
      "[INFO 23-07-08 15:51:36.7795 UTC random_forest.cc:802] Training of tree  171/300 (tree index:170) done accuracy:0.739402 logloss:3.23938\n",
      "[INFO 23-07-08 15:51:36.8856 UTC random_forest.cc:802] Training of tree  181/300 (tree index:180) done accuracy:0.740295 logloss:3.19694\n",
      "[INFO 23-07-08 15:51:36.9911 UTC random_forest.cc:802] Training of tree  191/300 (tree index:190) done accuracy:0.739848 logloss:3.19727\n",
      "[INFO 23-07-08 15:51:37.0964 UTC random_forest.cc:802] Training of tree  201/300 (tree index:200) done accuracy:0.739848 logloss:3.12628\n",
      "[INFO 23-07-08 15:51:37.2052 UTC random_forest.cc:802] Training of tree  211/300 (tree index:210) done accuracy:0.740295 logloss:3.11127\n",
      "[INFO 23-07-08 15:51:37.3112 UTC random_forest.cc:802] Training of tree  221/300 (tree index:220) done accuracy:0.738956 logloss:3.11175\n",
      "[INFO 23-07-08 15:51:37.4196 UTC random_forest.cc:802] Training of tree  231/300 (tree index:230) done accuracy:0.737617 logloss:3.01417\n",
      "[INFO 23-07-08 15:51:37.5256 UTC random_forest.cc:802] Training of tree  241/300 (tree index:240) done accuracy:0.739848 logloss:2.88744\n",
      "[INFO 23-07-08 15:51:37.6316 UTC random_forest.cc:802] Training of tree  251/300 (tree index:250) done accuracy:0.740741 logloss:2.87439\n",
      "[INFO 23-07-08 15:51:37.7405 UTC random_forest.cc:802] Training of tree  261/300 (tree index:260) done accuracy:0.742079 logloss:2.85934\n",
      "[INFO 23-07-08 15:51:37.8499 UTC random_forest.cc:802] Training of tree  271/300 (tree index:270) done accuracy:0.741187 logloss:2.85886\n",
      "[INFO 23-07-08 15:51:37.9583 UTC random_forest.cc:802] Training of tree  281/300 (tree index:280) done accuracy:0.741633 logloss:2.84431\n",
      "[INFO 23-07-08 15:51:38.0662 UTC random_forest.cc:802] Training of tree  291/300 (tree index:290) done accuracy:0.739848 logloss:2.83022\n",
      "[INFO 23-07-08 15:51:38.1686 UTC random_forest.cc:802] Training of tree  300/300 (tree index:299) done accuracy:0.740741 logloss:2.83054\n",
      "[INFO 23-07-08 15:51:38.1725 UTC random_forest.cc:882] Final OOB metrics: accuracy:0.740741 logloss:2.83054\n",
      "[INFO 23-07-08 15:51:38.1915 UTC hyperparameters_optimizer.cc:582] [7/50] Score: 0.740741 / 0.740741 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 20 } } fields { name: \"min_examples\" value { integer: 10 } }\n",
      "[INFO 23-07-08 15:51:38.2004 UTC random_forest.cc:416] Training random forest on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-08 15:51:38.2351 UTC random_forest.cc:802] Training of tree  1/300 (tree index:0) done accuracy:0.716707 logloss:10.2109\n",
      "[INFO 23-07-08 15:51:38.3502 UTC random_forest.cc:802] Training of tree  11/300 (tree index:10) done accuracy:0.717303 logloss:6.53681\n",
      "[INFO 23-07-08 15:51:38.4721 UTC random_forest.cc:802] Training of tree  21/300 (tree index:20) done accuracy:0.730477 logloss:5.48935\n",
      "[INFO 23-07-08 15:51:38.5937 UTC random_forest.cc:802] Training of tree  31/300 (tree index:30) done accuracy:0.728246 logloss:4.88399\n",
      "[INFO 23-07-08 15:51:38.7125 UTC random_forest.cc:802] Training of tree  41/300 (tree index:40) done accuracy:0.73494 logloss:4.54454\n",
      "[INFO 23-07-08 15:51:38.8330 UTC random_forest.cc:802] Training of tree  51/300 (tree index:50) done accuracy:0.73137 logloss:4.35551\n",
      "[INFO 23-07-08 15:51:38.9575 UTC random_forest.cc:802] Training of tree  61/300 (tree index:60) done accuracy:0.73494 logloss:4.1666\n",
      "[INFO 23-07-08 15:51:39.0793 UTC random_forest.cc:802] Training of tree  71/300 (tree index:70) done accuracy:0.736725 logloss:3.89251\n",
      "[INFO 23-07-08 15:51:39.2018 UTC random_forest.cc:802] Training of tree  81/300 (tree index:80) done accuracy:0.733155 logloss:3.7622\n",
      "[INFO 23-07-08 15:51:39.3230 UTC random_forest.cc:802] Training of tree  91/300 (tree index:90) done accuracy:0.736278 logloss:3.67715\n",
      "[INFO 23-07-08 15:51:39.4495 UTC random_forest.cc:802] Training of tree  101/300 (tree index:100) done accuracy:0.736278 logloss:3.63581\n",
      "[INFO 23-07-08 15:51:39.5757 UTC random_forest.cc:802] Training of tree  111/300 (tree index:110) done accuracy:0.736278 logloss:3.54806\n",
      "[INFO 23-07-08 15:51:39.7006 UTC random_forest.cc:802] Training of tree  121/300 (tree index:120) done accuracy:0.738063 logloss:3.47819\n",
      "[INFO 23-07-08 15:51:39.8223 UTC random_forest.cc:802] Training of tree  131/300 (tree index:130) done accuracy:0.738956 logloss:3.38984\n",
      "[INFO 23-07-08 15:51:39.9413 UTC random_forest.cc:802] Training of tree  141/300 (tree index:140) done accuracy:0.739402 logloss:3.33103\n",
      "[INFO 23-07-08 15:51:40.0632 UTC random_forest.cc:802] Training of tree  151/300 (tree index:150) done accuracy:0.73851 logloss:3.28876\n",
      "[INFO 23-07-08 15:51:40.1862 UTC random_forest.cc:802] Training of tree  161/300 (tree index:160) done accuracy:0.738063 logloss:3.26062\n",
      "[INFO 23-07-08 15:51:40.3074 UTC random_forest.cc:802] Training of tree  171/300 (tree index:170) done accuracy:0.737171 logloss:3.20131\n",
      "[INFO 23-07-08 15:51:40.4279 UTC random_forest.cc:802] Training of tree  181/300 (tree index:180) done accuracy:0.739848 logloss:3.18617\n",
      "[INFO 23-07-08 15:51:40.5515 UTC random_forest.cc:802] Training of tree  191/300 (tree index:190) done accuracy:0.738956 logloss:3.17221\n",
      "[INFO 23-07-08 15:51:40.6756 UTC random_forest.cc:802] Training of tree  201/300 (tree index:200) done accuracy:0.739402 logloss:3.12874\n",
      "[INFO 23-07-08 15:51:40.8001 UTC random_forest.cc:802] Training of tree  211/300 (tree index:210) done accuracy:0.739848 logloss:3.12767\n",
      "[INFO 23-07-08 15:51:40.9228 UTC random_forest.cc:802] Training of tree  221/300 (tree index:220) done accuracy:0.739402 logloss:3.1293\n",
      "[INFO 23-07-08 15:51:41.0433 UTC random_forest.cc:802] Training of tree  231/300 (tree index:230) done accuracy:0.739848 logloss:3.03213\n",
      "[INFO 23-07-08 15:51:41.1641 UTC random_forest.cc:802] Training of tree  241/300 (tree index:240) done accuracy:0.741633 logloss:3.003\n",
      "[INFO 23-07-08 15:51:41.2857 UTC random_forest.cc:802] Training of tree  251/300 (tree index:250) done accuracy:0.741187 logloss:3.0034\n",
      "[INFO 23-07-08 15:51:41.4090 UTC random_forest.cc:802] Training of tree  261/300 (tree index:260) done accuracy:0.741187 logloss:3.00202\n",
      "[INFO 23-07-08 15:51:41.5323 UTC random_forest.cc:802] Training of tree  271/300 (tree index:270) done accuracy:0.740295 logloss:2.97425\n",
      "[INFO 23-07-08 15:51:41.6578 UTC random_forest.cc:802] Training of tree  281/300 (tree index:280) done accuracy:0.739402 logloss:2.96008\n",
      "[INFO 23-07-08 15:51:41.7775 UTC random_forest.cc:802] Training of tree  291/300 (tree index:290) done accuracy:0.741187 logloss:2.93156\n",
      "[INFO 23-07-08 15:51:41.8911 UTC random_forest.cc:802] Training of tree  300/300 (tree index:299) done accuracy:0.739402 logloss:2.91823\n",
      "[INFO 23-07-08 15:51:41.8952 UTC random_forest.cc:882] Final OOB metrics: accuracy:0.739402 logloss:2.91823\n",
      "[INFO 23-07-08 15:51:41.9214 UTC hyperparameters_optimizer.cc:582] [8/50] Score: 0.739402 / 0.740741 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 30 } } fields { name: \"min_examples\" value { integer: 5 } }\n",
      "[INFO 23-07-08 15:51:41.9344 UTC random_forest.cc:416] Training random forest on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-08 15:51:41.9584 UTC random_forest.cc:802] Training of tree  1/300 (tree index:0) done accuracy:0.717918 logloss:10.1673\n",
      "[INFO 23-07-08 15:51:42.0375 UTC random_forest.cc:802] Training of tree  11/300 (tree index:10) done accuracy:0.715056 logloss:6.84692\n",
      "[INFO 23-07-08 15:51:42.1058 UTC random_forest.cc:802] Training of tree  21/300 (tree index:20) done accuracy:0.725569 logloss:5.78337\n",
      "[INFO 23-07-08 15:51:42.1758 UTC random_forest.cc:802] Training of tree  31/300 (tree index:30) done accuracy:0.721107 logloss:5.20285\n",
      "[INFO 23-07-08 15:51:42.2440 UTC random_forest.cc:802] Training of tree  41/300 (tree index:40) done accuracy:0.721553 logloss:4.8477\n",
      "[INFO 23-07-08 15:51:42.3123 UTC random_forest.cc:802] Training of tree  51/300 (tree index:50) done accuracy:0.719768 logloss:4.62821\n",
      "[INFO 23-07-08 15:51:42.3829 UTC random_forest.cc:802] Training of tree  61/300 (tree index:60) done accuracy:0.72066 logloss:4.39727\n",
      "[INFO 23-07-08 15:51:42.4526 UTC random_forest.cc:802] Training of tree  71/300 (tree index:70) done accuracy:0.721553 logloss:4.19513\n",
      "[INFO 23-07-08 15:51:42.5258 UTC random_forest.cc:802] Training of tree  81/300 (tree index:80) done accuracy:0.72066 logloss:4.05009\n",
      "[INFO 23-07-08 15:51:42.5952 UTC random_forest.cc:802] Training of tree  91/300 (tree index:90) done accuracy:0.721999 logloss:3.97999\n",
      "[INFO 23-07-08 15:51:42.6672 UTC random_forest.cc:802] Training of tree  101/300 (tree index:100) done accuracy:0.723784 logloss:3.89406\n",
      "[INFO 23-07-08 15:51:42.7416 UTC random_forest.cc:802] Training of tree  111/300 (tree index:110) done accuracy:0.726015 logloss:3.82151\n",
      "[INFO 23-07-08 15:51:42.8149 UTC random_forest.cc:802] Training of tree  121/300 (tree index:120) done accuracy:0.726908 logloss:3.76412\n",
      "[INFO 23-07-08 15:51:42.8873 UTC random_forest.cc:802] Training of tree  131/300 (tree index:130) done accuracy:0.728693 logloss:3.64933\n",
      "[INFO 23-07-08 15:51:42.9613 UTC random_forest.cc:802] Training of tree  141/300 (tree index:140) done accuracy:0.726908 logloss:3.59232\n",
      "[INFO 23-07-08 15:51:43.0378 UTC random_forest.cc:802] Training of tree  151/300 (tree index:150) done accuracy:0.7278 logloss:3.56497\n",
      "[INFO 23-07-08 15:51:43.1123 UTC random_forest.cc:802] Training of tree  161/300 (tree index:160) done accuracy:0.72423 logloss:3.50868\n",
      "[INFO 23-07-08 15:51:43.1872 UTC random_forest.cc:802] Training of tree  171/300 (tree index:170) done accuracy:0.725569 logloss:3.48071\n",
      "[INFO 23-07-08 15:51:43.2663 UTC random_forest.cc:802] Training of tree  181/300 (tree index:180) done accuracy:0.72423 logloss:3.46627\n",
      "[INFO 23-07-08 15:51:43.3409 UTC random_forest.cc:802] Training of tree  191/300 (tree index:190) done accuracy:0.723338 logloss:3.40967\n",
      "[INFO 23-07-08 15:51:43.4169 UTC random_forest.cc:802] Training of tree  201/300 (tree index:200) done accuracy:0.722892 logloss:3.34993\n",
      "[INFO 23-07-08 15:51:43.4928 UTC random_forest.cc:802] Training of tree  211/300 (tree index:210) done accuracy:0.722892 logloss:3.33466\n",
      "[INFO 23-07-08 15:51:43.5667 UTC random_forest.cc:802] Training of tree  221/300 (tree index:220) done accuracy:0.723784 logloss:3.32185\n",
      "[INFO 23-07-08 15:51:43.6401 UTC random_forest.cc:802] Training of tree  231/300 (tree index:230) done accuracy:0.724676 logloss:3.29354\n",
      "[INFO 23-07-08 15:51:43.7133 UTC random_forest.cc:802] Training of tree  241/300 (tree index:240) done accuracy:0.725569 logloss:3.27943\n",
      "[INFO 23-07-08 15:51:43.7903 UTC random_forest.cc:802] Training of tree  251/300 (tree index:250) done accuracy:0.724676 logloss:3.28036\n",
      "[INFO 23-07-08 15:51:43.8649 UTC random_forest.cc:802] Training of tree  261/300 (tree index:260) done accuracy:0.72423 logloss:3.25036\n",
      "[INFO 23-07-08 15:51:43.9421 UTC random_forest.cc:802] Training of tree  271/300 (tree index:270) done accuracy:0.72423 logloss:3.25105\n",
      "[INFO 23-07-08 15:51:44.0181 UTC random_forest.cc:802] Training of tree  281/300 (tree index:280) done accuracy:0.726015 logloss:3.25095\n",
      "[INFO 23-07-08 15:51:44.0927 UTC random_forest.cc:802] Training of tree  291/300 (tree index:290) done accuracy:0.726015 logloss:3.25048\n",
      "[INFO 23-07-08 15:51:44.1618 UTC random_forest.cc:802] Training of tree  300/300 (tree index:299) done accuracy:0.72423 logloss:3.22165\n",
      "[INFO 23-07-08 15:51:44.1666 UTC random_forest.cc:882] Final OOB metrics: accuracy:0.72423 logloss:3.22165\n",
      "[INFO 23-07-08 15:51:44.2075 UTC hyperparameters_optimizer.cc:582] [9/50] Score: 0.72423 / 0.740741 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 30 } } fields { name: \"min_examples\" value { integer: 2 } }\n",
      "[INFO 23-07-08 15:51:44.2830 UTC random_forest.cc:416] Training random forest on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-08 15:51:44.3107 UTC random_forest.cc:802] Training of tree  1/300 (tree index:0) done accuracy:0.700969 logloss:10.7782\n",
      "[INFO 23-07-08 15:51:44.3892 UTC random_forest.cc:802] Training of tree  11/300 (tree index:10) done accuracy:0.713708 logloss:6.87245\n",
      "[INFO 23-07-08 15:51:44.4687 UTC random_forest.cc:802] Training of tree  21/300 (tree index:20) done accuracy:0.709058 logloss:5.37269\n",
      "[INFO 23-07-08 15:51:44.5477 UTC random_forest.cc:802] Training of tree  31/300 (tree index:30) done accuracy:0.709951 logloss:4.64262\n",
      "[INFO 23-07-08 15:51:44.6260 UTC random_forest.cc:802] Training of tree  41/300 (tree index:40) done accuracy:0.709951 logloss:4.43462\n",
      "[INFO 23-07-08 15:51:44.7108 UTC random_forest.cc:802] Training of tree  51/300 (tree index:50) done accuracy:0.712182 logloss:4.27208\n",
      "[INFO 23-07-08 15:51:44.7910 UTC random_forest.cc:802] Training of tree  61/300 (tree index:60) done accuracy:0.711736 logloss:4.14287\n",
      "[INFO 23-07-08 15:51:44.8691 UTC random_forest.cc:802] Training of tree  71/300 (tree index:70) done accuracy:0.711736 logloss:4.02476\n",
      "[INFO 23-07-08 15:51:44.9475 UTC random_forest.cc:802] Training of tree  81/300 (tree index:80) done accuracy:0.714413 logloss:3.95278\n",
      "[INFO 23-07-08 15:51:45.0272 UTC random_forest.cc:802] Training of tree  91/300 (tree index:90) done accuracy:0.713075 logloss:3.89522\n",
      "[INFO 23-07-08 15:51:45.1049 UTC random_forest.cc:802] Training of tree  101/300 (tree index:100) done accuracy:0.710397 logloss:3.80827\n",
      "[INFO 23-07-08 15:51:45.1853 UTC random_forest.cc:802] Training of tree  111/300 (tree index:110) done accuracy:0.713967 logloss:3.77754\n",
      "[INFO 23-07-08 15:51:45.2638 UTC random_forest.cc:802] Training of tree  121/300 (tree index:120) done accuracy:0.710843 logloss:3.7642\n",
      "[INFO 23-07-08 15:51:45.3430 UTC random_forest.cc:802] Training of tree  131/300 (tree index:130) done accuracy:0.712182 logloss:3.7625\n",
      "[INFO 23-07-08 15:51:45.4235 UTC random_forest.cc:802] Training of tree  141/300 (tree index:140) done accuracy:0.709505 logloss:3.7581\n",
      "[INFO 23-07-08 15:51:45.5003 UTC random_forest.cc:802] Training of tree  151/300 (tree index:150) done accuracy:0.712182 logloss:3.7159\n",
      "[INFO 23-07-08 15:51:45.5775 UTC random_forest.cc:802] Training of tree  161/300 (tree index:160) done accuracy:0.711736 logloss:3.65916\n",
      "[INFO 23-07-08 15:51:45.6530 UTC random_forest.cc:802] Training of tree  171/300 (tree index:170) done accuracy:0.712182 logloss:3.60123\n",
      "[INFO 23-07-08 15:51:45.7310 UTC random_forest.cc:802] Training of tree  181/300 (tree index:180) done accuracy:0.712628 logloss:3.58838\n",
      "[INFO 23-07-08 15:51:45.8082 UTC random_forest.cc:802] Training of tree  191/300 (tree index:190) done accuracy:0.709058 logloss:3.5469\n",
      "[INFO 23-07-08 15:51:45.8878 UTC random_forest.cc:802] Training of tree  201/300 (tree index:200) done accuracy:0.709505 logloss:3.50423\n",
      "[INFO 23-07-08 15:51:45.9682 UTC random_forest.cc:802] Training of tree  211/300 (tree index:210) done accuracy:0.709951 logloss:3.49142\n",
      "[INFO 23-07-08 15:51:46.0481 UTC random_forest.cc:802] Training of tree  221/300 (tree index:220) done accuracy:0.710397 logloss:3.44971\n",
      "[INFO 23-07-08 15:51:46.1250 UTC random_forest.cc:802] Training of tree  231/300 (tree index:230) done accuracy:0.709058 logloss:3.42257\n",
      "[INFO 23-07-08 15:51:46.2009 UTC random_forest.cc:802] Training of tree  241/300 (tree index:240) done accuracy:0.70772 logloss:3.38068\n",
      "[INFO 23-07-08 15:51:46.2810 UTC random_forest.cc:802] Training of tree  251/300 (tree index:250) done accuracy:0.709951 logloss:3.36667\n",
      "[INFO 23-07-08 15:51:46.3604 UTC random_forest.cc:802] Training of tree  261/300 (tree index:260) done accuracy:0.708612 logloss:3.36688\n",
      "[INFO 23-07-08 15:51:46.4390 UTC random_forest.cc:802] Training of tree  271/300 (tree index:270) done accuracy:0.708166 logloss:3.36725\n",
      "[INFO 23-07-08 15:51:46.5178 UTC random_forest.cc:802] Training of tree  281/300 (tree index:280) done accuracy:0.70772 logloss:3.36833\n",
      "[INFO 23-07-08 15:51:46.5962 UTC random_forest.cc:802] Training of tree  291/300 (tree index:290) done accuracy:0.709951 logloss:3.3399\n",
      "[INFO 23-07-08 15:51:46.6707 UTC random_forest.cc:802] Training of tree  300/300 (tree index:299) done accuracy:0.709951 logloss:3.34036\n",
      "[INFO 23-07-08 15:51:46.6748 UTC random_forest.cc:882] Final OOB metrics: accuracy:0.709951 logloss:3.34036\n",
      "[INFO 23-07-08 15:51:46.6797 UTC hyperparameters_optimizer.cc:582] [10/50] Score: 0.709951 / 0.740741 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 25 } } fields { name: \"min_examples\" value { integer: 40 } }\n",
      "[INFO 23-07-08 15:51:46.6886 UTC random_forest.cc:416] Training random forest on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-08 15:51:46.7611 UTC random_forest.cc:802] Training of tree  1/300 (tree index:0) done accuracy:0.716707 logloss:10.2109\n",
      "[INFO 23-07-08 15:51:46.8830 UTC random_forest.cc:802] Training of tree  11/300 (tree index:10) done accuracy:0.717303 logloss:6.53681\n",
      "[INFO 23-07-08 15:51:47.0041 UTC random_forest.cc:802] Training of tree  21/300 (tree index:20) done accuracy:0.730477 logloss:5.48966\n",
      "[INFO 23-07-08 15:51:47.1277 UTC random_forest.cc:802] Training of tree  31/300 (tree index:30) done accuracy:0.728246 logloss:4.88417\n",
      "[INFO 23-07-08 15:51:47.2448 UTC random_forest.cc:802] Training of tree  41/300 (tree index:40) done accuracy:0.736278 logloss:4.5435\n",
      "[INFO 23-07-08 15:51:47.3634 UTC random_forest.cc:802] Training of tree  51/300 (tree index:50) done accuracy:0.732262 logloss:4.35447\n",
      "[INFO 23-07-08 15:51:47.4854 UTC random_forest.cc:802] Training of tree  61/300 (tree index:60) done accuracy:0.734494 logloss:4.1657\n",
      "[INFO 23-07-08 15:51:47.6078 UTC random_forest.cc:802] Training of tree  71/300 (tree index:70) done accuracy:0.737171 logloss:3.892\n",
      "[INFO 23-07-08 15:51:47.7292 UTC random_forest.cc:802] Training of tree  81/300 (tree index:80) done accuracy:0.73494 logloss:3.76169\n",
      "[INFO 23-07-08 15:51:47.8487 UTC random_forest.cc:802] Training of tree  91/300 (tree index:90) done accuracy:0.735386 logloss:3.67665\n",
      "[INFO 23-07-08 15:51:47.9694 UTC random_forest.cc:802] Training of tree  101/300 (tree index:100) done accuracy:0.737617 logloss:3.63528\n",
      "[INFO 23-07-08 15:51:48.0901 UTC random_forest.cc:802] Training of tree  111/300 (tree index:110) done accuracy:0.737617 logloss:3.54737\n",
      "[INFO 23-07-08 15:51:48.2103 UTC random_forest.cc:802] Training of tree  121/300 (tree index:120) done accuracy:0.73851 logloss:3.46324\n",
      "[INFO 23-07-08 15:51:48.3389 UTC random_forest.cc:802] Training of tree  131/300 (tree index:130) done accuracy:0.738063 logloss:3.38873\n",
      "[INFO 23-07-08 15:51:48.4574 UTC random_forest.cc:802] Training of tree  141/300 (tree index:140) done accuracy:0.738063 logloss:3.33019\n",
      "[INFO 23-07-08 15:51:48.5778 UTC random_forest.cc:802] Training of tree  151/300 (tree index:150) done accuracy:0.740741 logloss:3.28794\n",
      "[INFO 23-07-08 15:51:48.6988 UTC random_forest.cc:802] Training of tree  161/300 (tree index:160) done accuracy:0.739402 logloss:3.24359\n",
      "[INFO 23-07-08 15:51:48.8177 UTC random_forest.cc:802] Training of tree  171/300 (tree index:170) done accuracy:0.739402 logloss:3.19868\n",
      "[INFO 23-07-08 15:51:48.9385 UTC random_forest.cc:802] Training of tree  181/300 (tree index:180) done accuracy:0.741187 logloss:3.18378\n",
      "[INFO 23-07-08 15:51:49.0577 UTC random_forest.cc:802] Training of tree  191/300 (tree index:190) done accuracy:0.738063 logloss:3.17006\n",
      "[INFO 23-07-08 15:51:49.1793 UTC random_forest.cc:802] Training of tree  201/300 (tree index:200) done accuracy:0.73851 logloss:3.12701\n",
      "[INFO 23-07-08 15:51:49.3044 UTC random_forest.cc:802] Training of tree  211/300 (tree index:210) done accuracy:0.739402 logloss:3.12615\n",
      "[INFO 23-07-08 15:51:49.4278 UTC random_forest.cc:802] Training of tree  221/300 (tree index:220) done accuracy:0.738063 logloss:3.12792\n",
      "[INFO 23-07-08 15:51:49.5503 UTC random_forest.cc:802] Training of tree  231/300 (tree index:230) done accuracy:0.739402 logloss:3.03081\n",
      "[INFO 23-07-08 15:51:49.6748 UTC random_forest.cc:802] Training of tree  241/300 (tree index:240) done accuracy:0.73851 logloss:3.00172\n",
      "[INFO 23-07-08 15:51:49.7989 UTC random_forest.cc:802] Training of tree  251/300 (tree index:250) done accuracy:0.739402 logloss:3.0021\n",
      "[INFO 23-07-08 15:51:49.9243 UTC random_forest.cc:802] Training of tree  261/300 (tree index:260) done accuracy:0.740295 logloss:3.00067\n",
      "[INFO 23-07-08 15:51:50.0483 UTC random_forest.cc:802] Training of tree  271/300 (tree index:270) done accuracy:0.740295 logloss:2.9729\n",
      "[INFO 23-07-08 15:51:50.1723 UTC random_forest.cc:802] Training of tree  281/300 (tree index:280) done accuracy:0.739848 logloss:2.95883\n",
      "[INFO 23-07-08 15:51:50.2951 UTC random_forest.cc:802] Training of tree  291/300 (tree index:290) done accuracy:0.740741 logloss:2.93028\n",
      "[INFO 23-07-08 15:51:50.4068 UTC random_forest.cc:802] Training of tree  300/300 (tree index:299) done accuracy:0.741187 logloss:2.91689\n",
      "[INFO 23-07-08 15:51:50.4111 UTC random_forest.cc:882] Final OOB metrics: accuracy:0.741187 logloss:2.91689\n",
      "[INFO 23-07-08 15:51:50.4499 UTC random_forest.cc:416] Training random forest on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-08 15:51:50.4869 UTC hyperparameters_optimizer.cc:582] [11/50] Score: 0.741187 / 0.741187 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 16 } } fields { name: \"min_examples\" value { integer: 5 } }\n",
      "[INFO 23-07-08 15:51:50.5254 UTC random_forest.cc:802] Training of tree  1/300 (tree index:0) done accuracy:0.717918 logloss:10.1673\n",
      "[INFO 23-07-08 15:51:50.8651 UTC random_forest.cc:802] Training of tree  11/300 (tree index:10) done accuracy:0.719551 logloss:6.71844\n",
      "[INFO 23-07-08 15:51:51.1499 UTC random_forest.cc:802] Training of tree  21/300 (tree index:20) done accuracy:0.724676 logloss:5.74322\n",
      "[INFO 23-07-08 15:51:51.4330 UTC random_forest.cc:802] Training of tree  31/300 (tree index:30) done accuracy:0.719768 logloss:5.16457\n",
      "[INFO 23-07-08 15:51:51.7130 UTC random_forest.cc:802] Training of tree  41/300 (tree index:40) done accuracy:0.722445 logloss:4.86701\n",
      "[INFO 23-07-08 15:51:51.9996 UTC random_forest.cc:802] Training of tree  51/300 (tree index:50) done accuracy:0.718429 logloss:4.76865\n",
      "[INFO 23-07-08 15:51:52.3201 UTC random_forest.cc:802] Training of tree  61/300 (tree index:60) done accuracy:0.720214 logloss:4.53644\n",
      "[INFO 23-07-08 15:51:52.6051 UTC random_forest.cc:802] Training of tree  71/300 (tree index:70) done accuracy:0.718429 logloss:4.31984\n",
      "[INFO 23-07-08 15:51:52.8175 UTC random_forest.cc:802] Training of tree  81/300 (tree index:80) done accuracy:0.721107 logloss:4.1595\n",
      "[INFO 23-07-08 15:51:52.9591 UTC random_forest.cc:802] Training of tree  91/300 (tree index:90) done accuracy:0.721553 logloss:4.10379\n",
      "[INFO 23-07-08 15:51:53.1034 UTC random_forest.cc:802] Training of tree  101/300 (tree index:100) done accuracy:0.721999 logloss:4.03224\n",
      "[INFO 23-07-08 15:51:53.2491 UTC random_forest.cc:802] Training of tree  111/300 (tree index:110) done accuracy:0.721107 logloss:3.97416\n",
      "[INFO 23-07-08 15:51:53.3949 UTC random_forest.cc:802] Training of tree  121/300 (tree index:120) done accuracy:0.720214 logloss:3.90236\n",
      "[INFO 23-07-08 15:51:53.5425 UTC random_forest.cc:802] Training of tree  131/300 (tree index:130) done accuracy:0.719768 logloss:3.80166\n",
      "[INFO 23-07-08 15:51:53.6876 UTC random_forest.cc:802] Training of tree  141/300 (tree index:140) done accuracy:0.719322 logloss:3.74506\n",
      "[INFO 23-07-08 15:51:53.8357 UTC random_forest.cc:802] Training of tree  151/300 (tree index:150) done accuracy:0.721999 logloss:3.71658\n",
      "[INFO 23-07-08 15:51:53.9842 UTC random_forest.cc:802] Training of tree  161/300 (tree index:160) done accuracy:0.720214 logloss:3.64652\n",
      "[INFO 23-07-08 15:51:54.1257 UTC random_forest.cc:802] Training of tree  171/300 (tree index:170) done accuracy:0.718876 logloss:3.60469\n",
      "[INFO 23-07-08 15:51:54.2712 UTC random_forest.cc:802] Training of tree  181/300 (tree index:180) done accuracy:0.720214 logloss:3.56322\n",
      "[INFO 23-07-08 15:51:54.4111 UTC random_forest.cc:802] Training of tree  191/300 (tree index:190) done accuracy:0.721107 logloss:3.54877\n",
      "[INFO 23-07-08 15:51:54.5543 UTC random_forest.cc:802] Training of tree  201/300 (tree index:200) done accuracy:0.719768 logloss:3.50304\n",
      "[INFO 23-07-08 15:51:54.7020 UTC random_forest.cc:802] Training of tree  211/300 (tree index:210) done accuracy:0.718876 logloss:3.47443\n",
      "[INFO 23-07-08 15:51:54.8463 UTC random_forest.cc:802] Training of tree  221/300 (tree index:220) done accuracy:0.719322 logloss:3.47561\n",
      "[INFO 23-07-08 15:51:54.9920 UTC random_forest.cc:802] Training of tree  231/300 (tree index:230) done accuracy:0.719322 logloss:3.46114\n",
      "[INFO 23-07-08 15:51:55.1385 UTC random_forest.cc:802] Training of tree  241/300 (tree index:240) done accuracy:0.719322 logloss:3.46086\n",
      "[INFO 23-07-08 15:51:55.2816 UTC random_forest.cc:802] Training of tree  251/300 (tree index:250) done accuracy:0.718429 logloss:3.46087\n",
      "[INFO 23-07-08 15:51:55.4265 UTC random_forest.cc:802] Training of tree  261/300 (tree index:260) done accuracy:0.718876 logloss:3.44454\n",
      "[INFO 23-07-08 15:51:55.5734 UTC random_forest.cc:802] Training of tree  271/300 (tree index:270) done accuracy:0.717537 logloss:3.41778\n",
      "[INFO 23-07-08 15:51:55.7226 UTC random_forest.cc:802] Training of tree  281/300 (tree index:280) done accuracy:0.718429 logloss:3.40366\n",
      "[INFO 23-07-08 15:51:55.8677 UTC random_forest.cc:802] Training of tree  291/300 (tree index:290) done accuracy:0.719768 logloss:3.40292\n",
      "[INFO 23-07-08 15:51:55.9982 UTC random_forest.cc:802] Training of tree  300/300 (tree index:299) done accuracy:0.718876 logloss:3.36162\n",
      "[INFO 23-07-08 15:51:56.0016 UTC random_forest.cc:882] Final OOB metrics: accuracy:0.718876 logloss:3.36162\n",
      "[INFO 23-07-08 15:51:56.0509 UTC hyperparameters_optimizer.cc:582] [12/50] Score: 0.718876 / 0.741187 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 30 } } fields { name: \"min_examples\" value { integer: 1 } }\n",
      "[INFO 23-07-08 15:51:56.0636 UTC random_forest.cc:416] Training random forest on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-08 15:51:56.1624 UTC random_forest.cc:802] Training of tree  1/300 (tree index:0) done accuracy:0.702179 logloss:10.7345\n",
      "[INFO 23-07-08 15:51:56.2686 UTC random_forest.cc:802] Training of tree  11/300 (tree index:10) done accuracy:0.710562 logloss:6.57439\n",
      "[INFO 23-07-08 15:51:56.3735 UTC random_forest.cc:802] Training of tree  21/300 (tree index:20) done accuracy:0.723784 logloss:5.3979\n",
      "[INFO 23-07-08 15:51:56.4783 UTC random_forest.cc:802] Training of tree  31/300 (tree index:30) done accuracy:0.729585 logloss:4.76787\n",
      "[INFO 23-07-08 15:51:56.5836 UTC random_forest.cc:802] Training of tree  41/300 (tree index:40) done accuracy:0.730924 logloss:4.4903\n",
      "[INFO 23-07-08 15:51:56.6899 UTC random_forest.cc:802] Training of tree  51/300 (tree index:50) done accuracy:0.73137 logloss:4.29551\n",
      "[INFO 23-07-08 15:51:56.8037 UTC random_forest.cc:802] Training of tree  61/300 (tree index:60) done accuracy:0.734494 logloss:4.09206\n",
      "[INFO 23-07-08 15:51:56.9140 UTC random_forest.cc:802] Training of tree  71/300 (tree index:70) done accuracy:0.737617 logloss:3.91753\n",
      "[INFO 23-07-08 15:51:57.0218 UTC random_forest.cc:802] Training of tree  81/300 (tree index:80) done accuracy:0.73494 logloss:3.72881\n",
      "[INFO 23-07-08 15:51:57.1304 UTC random_forest.cc:802] Training of tree  91/300 (tree index:90) done accuracy:0.737617 logloss:3.59751\n",
      "[INFO 23-07-08 15:51:57.2391 UTC random_forest.cc:802] Training of tree  101/300 (tree index:100) done accuracy:0.737617 logloss:3.53982\n",
      "[INFO 23-07-08 15:51:57.3488 UTC random_forest.cc:802] Training of tree  111/300 (tree index:110) done accuracy:0.738063 logloss:3.49579\n",
      "[INFO 23-07-08 15:51:57.4550 UTC random_forest.cc:802] Training of tree  121/300 (tree index:120) done accuracy:0.738956 logloss:3.46867\n",
      "[INFO 23-07-08 15:51:57.5632 UTC random_forest.cc:802] Training of tree  131/300 (tree index:130) done accuracy:0.740295 logloss:3.35234\n",
      "[INFO 23-07-08 15:51:57.6703 UTC random_forest.cc:802] Training of tree  141/300 (tree index:140) done accuracy:0.737617 logloss:3.30928\n",
      "[INFO 23-07-08 15:51:57.7794 UTC random_forest.cc:802] Training of tree  151/300 (tree index:150) done accuracy:0.736278 logloss:3.28073\n",
      "[INFO 23-07-08 15:51:57.8869 UTC random_forest.cc:802] Training of tree  161/300 (tree index:160) done accuracy:0.738956 logloss:3.25215\n",
      "[INFO 23-07-08 15:51:57.9935 UTC random_forest.cc:802] Training of tree  171/300 (tree index:170) done accuracy:0.739402 logloss:3.23938\n",
      "[INFO 23-07-08 15:51:58.1023 UTC random_forest.cc:802] Training of tree  181/300 (tree index:180) done accuracy:0.740295 logloss:3.19694\n",
      "[INFO 23-07-08 15:51:58.2081 UTC random_forest.cc:802] Training of tree  191/300 (tree index:190) done accuracy:0.739848 logloss:3.19727\n",
      "[INFO 23-07-08 15:51:58.3150 UTC random_forest.cc:802] Training of tree  201/300 (tree index:200) done accuracy:0.739848 logloss:3.12628\n",
      "[INFO 23-07-08 15:51:58.4206 UTC random_forest.cc:802] Training of tree  211/300 (tree index:210) done accuracy:0.740295 logloss:3.11127\n",
      "[INFO 23-07-08 15:51:58.5263 UTC random_forest.cc:802] Training of tree  221/300 (tree index:220) done accuracy:0.738956 logloss:3.11175\n",
      "[INFO 23-07-08 15:51:58.6409 UTC random_forest.cc:802] Training of tree  231/300 (tree index:230) done accuracy:0.737617 logloss:3.01417\n",
      "[INFO 23-07-08 15:51:58.7489 UTC random_forest.cc:802] Training of tree  241/300 (tree index:240) done accuracy:0.739848 logloss:2.88744\n",
      "[INFO 23-07-08 15:51:58.8563 UTC random_forest.cc:802] Training of tree  251/300 (tree index:250) done accuracy:0.740741 logloss:2.87439\n",
      "[INFO 23-07-08 15:51:58.9668 UTC random_forest.cc:802] Training of tree  261/300 (tree index:260) done accuracy:0.742079 logloss:2.85934\n",
      "[INFO 23-07-08 15:51:59.0775 UTC random_forest.cc:802] Training of tree  271/300 (tree index:270) done accuracy:0.741187 logloss:2.85886\n",
      "[INFO 23-07-08 15:51:59.1860 UTC random_forest.cc:802] Training of tree  281/300 (tree index:280) done accuracy:0.741633 logloss:2.84431\n",
      "[INFO 23-07-08 15:51:59.2940 UTC random_forest.cc:802] Training of tree  291/300 (tree index:290) done accuracy:0.739848 logloss:2.83022\n",
      "[INFO 23-07-08 15:51:59.3926 UTC random_forest.cc:802] Training of tree  300/300 (tree index:299) done accuracy:0.740741 logloss:2.83054\n",
      "[INFO 23-07-08 15:51:59.3972 UTC random_forest.cc:882] Final OOB metrics: accuracy:0.740741 logloss:2.83054\n",
      "[INFO 23-07-08 15:51:59.4164 UTC hyperparameters_optimizer.cc:582] [13/50] Score: 0.740741 / 0.741187 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 30 } } fields { name: \"min_examples\" value { integer: 10 } }\n",
      "[INFO 23-07-08 15:51:59.4290 UTC random_forest.cc:416] Training random forest on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-08 15:51:59.4809 UTC random_forest.cc:802] Training of tree  1/300 (tree index:0) done accuracy:0.700969 logloss:10.7782\n",
      "[INFO 23-07-08 15:51:59.5558 UTC random_forest.cc:802] Training of tree  11/300 (tree index:10) done accuracy:0.713708 logloss:6.87245\n",
      "[INFO 23-07-08 15:51:59.6355 UTC random_forest.cc:802] Training of tree  21/300 (tree index:20) done accuracy:0.709058 logloss:5.37269\n",
      "[INFO 23-07-08 15:51:59.7127 UTC random_forest.cc:802] Training of tree  31/300 (tree index:30) done accuracy:0.709951 logloss:4.64262\n",
      "[INFO 23-07-08 15:51:59.7909 UTC random_forest.cc:802] Training of tree  41/300 (tree index:40) done accuracy:0.709951 logloss:4.43462\n",
      "[INFO 23-07-08 15:51:59.8672 UTC random_forest.cc:802] Training of tree  51/300 (tree index:50) done accuracy:0.712182 logloss:4.27208\n",
      "[INFO 23-07-08 15:51:59.9437 UTC random_forest.cc:802] Training of tree  61/300 (tree index:60) done accuracy:0.711736 logloss:4.14287\n",
      "[INFO 23-07-08 15:52:00.0195 UTC random_forest.cc:802] Training of tree  71/300 (tree index:70) done accuracy:0.711736 logloss:4.02476\n",
      "[INFO 23-07-08 15:52:00.0984 UTC random_forest.cc:802] Training of tree  81/300 (tree index:80) done accuracy:0.714413 logloss:3.95278\n",
      "[INFO 23-07-08 15:52:00.1762 UTC random_forest.cc:802] Training of tree  91/300 (tree index:90) done accuracy:0.713075 logloss:3.89522\n",
      "[INFO 23-07-08 15:52:00.2562 UTC random_forest.cc:802] Training of tree  101/300 (tree index:100) done accuracy:0.710397 logloss:3.80827\n",
      "[INFO 23-07-08 15:52:00.3340 UTC random_forest.cc:802] Training of tree  111/300 (tree index:110) done accuracy:0.713967 logloss:3.77754\n",
      "[INFO 23-07-08 15:52:00.4098 UTC random_forest.cc:802] Training of tree  121/300 (tree index:120) done accuracy:0.710843 logloss:3.7642\n",
      "[INFO 23-07-08 15:52:00.4893 UTC random_forest.cc:802] Training of tree  131/300 (tree index:130) done accuracy:0.712182 logloss:3.7625\n",
      "[INFO 23-07-08 15:52:00.5634 UTC random_forest.cc:802] Training of tree  141/300 (tree index:140) done accuracy:0.709505 logloss:3.7581\n",
      "[INFO 23-07-08 15:52:00.6419 UTC random_forest.cc:802] Training of tree  151/300 (tree index:150) done accuracy:0.712182 logloss:3.7159\n",
      "[INFO 23-07-08 15:52:00.7202 UTC random_forest.cc:802] Training of tree  161/300 (tree index:160) done accuracy:0.711736 logloss:3.65916\n",
      "[INFO 23-07-08 15:52:00.7971 UTC random_forest.cc:802] Training of tree  171/300 (tree index:170) done accuracy:0.712182 logloss:3.60123\n",
      "[INFO 23-07-08 15:52:00.8764 UTC random_forest.cc:802] Training of tree  181/300 (tree index:180) done accuracy:0.712628 logloss:3.58838\n",
      "[INFO 23-07-08 15:52:00.9535 UTC random_forest.cc:802] Training of tree  191/300 (tree index:190) done accuracy:0.709058 logloss:3.5469\n",
      "[INFO 23-07-08 15:52:01.0341 UTC random_forest.cc:802] Training of tree  201/300 (tree index:200) done accuracy:0.709505 logloss:3.50423\n",
      "[INFO 23-07-08 15:52:01.1141 UTC random_forest.cc:802] Training of tree  211/300 (tree index:210) done accuracy:0.709951 logloss:3.49142\n",
      "[INFO 23-07-08 15:52:01.1918 UTC random_forest.cc:802] Training of tree  221/300 (tree index:220) done accuracy:0.710397 logloss:3.44971\n",
      "[INFO 23-07-08 15:52:01.2695 UTC random_forest.cc:802] Training of tree  231/300 (tree index:230) done accuracy:0.709058 logloss:3.42257\n",
      "[INFO 23-07-08 15:52:01.3498 UTC random_forest.cc:802] Training of tree  241/300 (tree index:240) done accuracy:0.70772 logloss:3.38068\n",
      "[INFO 23-07-08 15:52:01.4266 UTC random_forest.cc:802] Training of tree  251/300 (tree index:250) done accuracy:0.709951 logloss:3.36667\n",
      "[INFO 23-07-08 15:52:01.5041 UTC random_forest.cc:802] Training of tree  261/300 (tree index:260) done accuracy:0.708612 logloss:3.36688\n",
      "[INFO 23-07-08 15:52:01.5833 UTC random_forest.cc:802] Training of tree  271/300 (tree index:270) done accuracy:0.708166 logloss:3.36725\n",
      "[INFO 23-07-08 15:52:01.6620 UTC random_forest.cc:802] Training of tree  281/300 (tree index:280) done accuracy:0.70772 logloss:3.36833\n",
      "[INFO 23-07-08 15:52:01.7396 UTC random_forest.cc:802] Training of tree  291/300 (tree index:290) done accuracy:0.709951 logloss:3.3399\n",
      "[INFO 23-07-08 15:52:01.8466 UTC random_forest.cc:802] Training of tree  300/300 (tree index:299) done accuracy:0.709951 logloss:3.34036\n",
      "[INFO 23-07-08 15:52:01.8551 UTC random_forest.cc:882] Final OOB metrics: accuracy:0.709951 logloss:3.34036\n",
      "[INFO 23-07-08 15:52:01.8641 UTC hyperparameters_optimizer.cc:582] [14/50] Score: 0.709951 / 0.741187 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 25 } } fields { name: \"min_examples\" value { integer: 40 } }\n",
      "[INFO 23-07-08 15:52:01.8838 UTC random_forest.cc:416] Training random forest on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-08 15:52:01.9680 UTC random_forest.cc:802] Training of tree  1/300 (tree index:0) done accuracy:0.702179 logloss:10.7345\n",
      "[INFO 23-07-08 15:52:02.1854 UTC random_forest.cc:802] Training of tree  11/300 (tree index:10) done accuracy:0.710562 logloss:6.57439\n",
      "[INFO 23-07-08 15:52:02.3944 UTC random_forest.cc:802] Training of tree  21/300 (tree index:20) done accuracy:0.723784 logloss:5.3979\n",
      "[INFO 23-07-08 15:52:02.5983 UTC random_forest.cc:802] Training of tree  31/300 (tree index:30) done accuracy:0.729585 logloss:4.76787\n",
      "[INFO 23-07-08 15:52:02.8136 UTC random_forest.cc:802] Training of tree  41/300 (tree index:40) done accuracy:0.730924 logloss:4.4903\n",
      "[INFO 23-07-08 15:52:03.0343 UTC random_forest.cc:802] Training of tree  51/300 (tree index:50) done accuracy:0.73137 logloss:4.29551\n",
      "[INFO 23-07-08 15:52:03.2605 UTC random_forest.cc:802] Training of tree  61/300 (tree index:60) done accuracy:0.734494 logloss:4.09206\n",
      "[INFO 23-07-08 15:52:03.4810 UTC random_forest.cc:802] Training of tree  71/300 (tree index:70) done accuracy:0.737617 logloss:3.91753\n",
      "[INFO 23-07-08 15:52:03.7004 UTC random_forest.cc:802] Training of tree  81/300 (tree index:80) done accuracy:0.73494 logloss:3.72881\n",
      "[INFO 23-07-08 15:52:03.9170 UTC random_forest.cc:802] Training of tree  91/300 (tree index:90) done accuracy:0.737617 logloss:3.59751\n",
      "[INFO 23-07-08 15:52:04.1291 UTC random_forest.cc:802] Training of tree  101/300 (tree index:100) done accuracy:0.737617 logloss:3.53982\n",
      "[INFO 23-07-08 15:52:04.3683 UTC random_forest.cc:802] Training of tree  111/300 (tree index:110) done accuracy:0.738063 logloss:3.49579\n",
      "[INFO 23-07-08 15:52:04.5848 UTC random_forest.cc:802] Training of tree  121/300 (tree index:120) done accuracy:0.738956 logloss:3.46867\n",
      "[INFO 23-07-08 15:52:04.8043 UTC random_forest.cc:802] Training of tree  131/300 (tree index:130) done accuracy:0.740295 logloss:3.35234\n",
      "[INFO 23-07-08 15:52:05.0194 UTC random_forest.cc:802] Training of tree  141/300 (tree index:140) done accuracy:0.737617 logloss:3.30928\n",
      "[INFO 23-07-08 15:52:05.2332 UTC random_forest.cc:802] Training of tree  151/300 (tree index:150) done accuracy:0.736278 logloss:3.28073\n",
      "[INFO 23-07-08 15:52:05.4541 UTC random_forest.cc:802] Training of tree  161/300 (tree index:160) done accuracy:0.738956 logloss:3.25215\n",
      "[INFO 23-07-08 15:52:05.6641 UTC random_forest.cc:802] Training of tree  171/300 (tree index:170) done accuracy:0.739402 logloss:3.23938\n",
      "[INFO 23-07-08 15:52:05.8847 UTC random_forest.cc:802] Training of tree  181/300 (tree index:180) done accuracy:0.740295 logloss:3.19694\n",
      "[INFO 23-07-08 15:52:06.0646 UTC random_forest.cc:802] Training of tree  191/300 (tree index:190) done accuracy:0.739848 logloss:3.19727\n",
      "[INFO 23-07-08 15:52:06.2235 UTC random_forest.cc:802] Training of tree  201/300 (tree index:200) done accuracy:0.739848 logloss:3.12628\n",
      "[INFO 23-07-08 15:52:06.3315 UTC random_forest.cc:802] Training of tree  211/300 (tree index:210) done accuracy:0.740295 logloss:3.11127\n",
      "[INFO 23-07-08 15:52:06.4395 UTC random_forest.cc:802] Training of tree  221/300 (tree index:220) done accuracy:0.738956 logloss:3.11175\n",
      "[INFO 23-07-08 15:52:06.5486 UTC random_forest.cc:802] Training of tree  231/300 (tree index:230) done accuracy:0.737617 logloss:3.01417\n",
      "[INFO 23-07-08 15:52:06.6574 UTC random_forest.cc:802] Training of tree  241/300 (tree index:240) done accuracy:0.739848 logloss:2.88744\n",
      "[INFO 23-07-08 15:52:06.7641 UTC random_forest.cc:802] Training of tree  251/300 (tree index:250) done accuracy:0.740741 logloss:2.87439\n",
      "[INFO 23-07-08 15:52:06.8742 UTC random_forest.cc:802] Training of tree  261/300 (tree index:260) done accuracy:0.742079 logloss:2.85934\n",
      "[INFO 23-07-08 15:52:06.9832 UTC random_forest.cc:802] Training of tree  271/300 (tree index:270) done accuracy:0.741187 logloss:2.85886\n",
      "[INFO 23-07-08 15:52:07.0886 UTC random_forest.cc:802] Training of tree  281/300 (tree index:280) done accuracy:0.741633 logloss:2.84431\n",
      "[INFO 23-07-08 15:52:07.1980 UTC random_forest.cc:802] Training of tree  291/300 (tree index:290) done accuracy:0.739848 logloss:2.83022\n",
      "[INFO 23-07-08 15:52:07.2954 UTC random_forest.cc:802] Training of tree  300/300 (tree index:299) done accuracy:0.740741 logloss:2.83054\n",
      "[INFO 23-07-08 15:52:07.2985 UTC random_forest.cc:882] Final OOB metrics: accuracy:0.740741 logloss:2.83054\n",
      "[INFO 23-07-08 15:52:07.3193 UTC hyperparameters_optimizer.cc:582] [15/50] Score: 0.740741 / 0.741187 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 30 } } fields { name: \"min_examples\" value { integer: 10 } }\n",
      "[INFO 23-07-08 15:52:07.3320 UTC random_forest.cc:416] Training random forest on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-08 15:52:07.3472 UTC random_forest.cc:802] Training of tree  1/300 (tree index:0) done accuracy:0.68523 logloss:11.3455\n",
      "[INFO 23-07-08 15:52:07.3843 UTC random_forest.cc:802] Training of tree  11/300 (tree index:10) done accuracy:0.70382 logloss:6.05949\n",
      "[INFO 23-07-08 15:52:07.4178 UTC random_forest.cc:802] Training of tree  21/300 (tree index:20) done accuracy:0.714413 logloss:5.01416\n",
      "[INFO 23-07-08 15:52:07.4491 UTC random_forest.cc:802] Training of tree  31/300 (tree index:30) done accuracy:0.717537 logloss:4.58107\n",
      "[INFO 23-07-08 15:52:07.4813 UTC random_forest.cc:802] Training of tree  41/300 (tree index:40) done accuracy:0.711736 logloss:4.34229\n",
      "[INFO 23-07-08 15:52:07.5125 UTC random_forest.cc:802] Training of tree  51/300 (tree index:50) done accuracy:0.713521 logloss:4.16687\n",
      "[INFO 23-07-08 15:52:07.5459 UTC random_forest.cc:802] Training of tree  61/300 (tree index:60) done accuracy:0.713521 logloss:4.09711\n",
      "[INFO 23-07-08 15:52:07.5776 UTC random_forest.cc:802] Training of tree  71/300 (tree index:70) done accuracy:0.71129 logloss:3.94954\n",
      "[INFO 23-07-08 15:52:07.6099 UTC random_forest.cc:802] Training of tree  81/300 (tree index:80) done accuracy:0.71129 logloss:3.92266\n",
      "[INFO 23-07-08 15:52:07.6466 UTC random_forest.cc:802] Training of tree  91/300 (tree index:90) done accuracy:0.71129 logloss:3.89094\n",
      "[INFO 23-07-08 15:52:07.6783 UTC random_forest.cc:802] Training of tree  101/300 (tree index:100) done accuracy:0.709951 logloss:3.84799\n",
      "[INFO 23-07-08 15:52:07.7095 UTC random_forest.cc:802] Training of tree  111/300 (tree index:110) done accuracy:0.707274 logloss:3.73154\n",
      "[INFO 23-07-08 15:52:07.7405 UTC random_forest.cc:802] Training of tree  121/300 (tree index:120) done accuracy:0.709505 logloss:3.68738\n",
      "[INFO 23-07-08 15:52:07.7724 UTC random_forest.cc:802] Training of tree  131/300 (tree index:130) done accuracy:0.709058 logloss:3.66024\n",
      "[INFO 23-07-08 15:52:07.8042 UTC random_forest.cc:802] Training of tree  141/300 (tree index:140) done accuracy:0.710843 logloss:3.64611\n",
      "[INFO 23-07-08 15:52:07.8353 UTC random_forest.cc:802] Training of tree  151/300 (tree index:150) done accuracy:0.711736 logloss:3.63176\n",
      "[INFO 23-07-08 15:52:07.8684 UTC random_forest.cc:802] Training of tree  161/300 (tree index:160) done accuracy:0.711736 logloss:3.63327\n",
      "[INFO 23-07-08 15:52:07.9020 UTC random_forest.cc:802] Training of tree  171/300 (tree index:170) done accuracy:0.712628 logloss:3.63305\n",
      "[INFO 23-07-08 15:52:07.9335 UTC random_forest.cc:802] Training of tree  181/300 (tree index:180) done accuracy:0.71129 logloss:3.60535\n",
      "[INFO 23-07-08 15:52:07.9668 UTC random_forest.cc:802] Training of tree  191/300 (tree index:190) done accuracy:0.710843 logloss:3.56285\n",
      "[INFO 23-07-08 15:52:08.0002 UTC random_forest.cc:802] Training of tree  201/300 (tree index:200) done accuracy:0.709058 logloss:3.53335\n",
      "[INFO 23-07-08 15:52:08.0319 UTC random_forest.cc:802] Training of tree  211/300 (tree index:210) done accuracy:0.708166 logloss:3.53472\n",
      "[INFO 23-07-08 15:52:08.0670 UTC random_forest.cc:802] Training of tree  221/300 (tree index:220) done accuracy:0.708612 logloss:3.50685\n",
      "[INFO 23-07-08 15:52:08.0988 UTC random_forest.cc:802] Training of tree  231/300 (tree index:230) done accuracy:0.705935 logloss:3.49128\n",
      "[INFO 23-07-08 15:52:08.1303 UTC random_forest.cc:802] Training of tree  241/300 (tree index:240) done accuracy:0.70772 logloss:3.35077\n",
      "[INFO 23-07-08 15:52:08.1618 UTC random_forest.cc:802] Training of tree  251/300 (tree index:250) done accuracy:0.708612 logloss:3.33764\n",
      "[INFO 23-07-08 15:52:08.1934 UTC random_forest.cc:802] Training of tree  261/300 (tree index:260) done accuracy:0.707274 logloss:3.32324\n",
      "[INFO 23-07-08 15:52:08.2267 UTC random_forest.cc:802] Training of tree  271/300 (tree index:270) done accuracy:0.707274 logloss:3.26521\n",
      "[INFO 23-07-08 15:52:08.2586 UTC random_forest.cc:802] Training of tree  281/300 (tree index:280) done accuracy:0.705042 logloss:3.25093\n",
      "[INFO 23-07-08 15:52:08.2912 UTC random_forest.cc:802] Training of tree  291/300 (tree index:290) done accuracy:0.704596 logloss:3.2527\n",
      "[INFO 23-07-08 15:52:08.3207 UTC random_forest.cc:802] Training of tree  300/300 (tree index:299) done accuracy:0.705042 logloss:3.25254\n",
      "[INFO 23-07-08 15:52:08.3253 UTC random_forest.cc:882] Final OOB metrics: accuracy:0.705042 logloss:3.25254\n",
      "[INFO 23-07-08 15:52:08.3303 UTC hyperparameters_optimizer.cc:582] [16/50] Score: 0.705042 / 0.741187 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 16 } } fields { name: \"min_examples\" value { integer: 40 } }\n",
      "[INFO 23-07-08 15:52:08.3417 UTC random_forest.cc:416] Training random forest on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-08 15:52:08.3890 UTC random_forest.cc:802] Training of tree  1/300 (tree index:0) done accuracy:0.700969 logloss:10.7782\n",
      "[INFO 23-07-08 15:52:08.4700 UTC random_forest.cc:802] Training of tree  11/300 (tree index:10) done accuracy:0.713708 logloss:6.87245\n",
      "[INFO 23-07-08 15:52:08.5483 UTC random_forest.cc:802] Training of tree  21/300 (tree index:20) done accuracy:0.709058 logloss:5.37269\n",
      "[INFO 23-07-08 15:52:08.6257 UTC random_forest.cc:802] Training of tree  31/300 (tree index:30) done accuracy:0.709951 logloss:4.64262\n",
      "[INFO 23-07-08 15:52:08.7015 UTC random_forest.cc:802] Training of tree  41/300 (tree index:40) done accuracy:0.709951 logloss:4.43462\n",
      "[INFO 23-07-08 15:52:08.7783 UTC random_forest.cc:802] Training of tree  51/300 (tree index:50) done accuracy:0.712182 logloss:4.27208\n",
      "[INFO 23-07-08 15:52:08.8554 UTC random_forest.cc:802] Training of tree  61/300 (tree index:60) done accuracy:0.711736 logloss:4.14287\n",
      "[INFO 23-07-08 15:52:08.9330 UTC random_forest.cc:802] Training of tree  71/300 (tree index:70) done accuracy:0.711736 logloss:4.02476\n",
      "[INFO 23-07-08 15:52:09.0115 UTC random_forest.cc:802] Training of tree  81/300 (tree index:80) done accuracy:0.714413 logloss:3.95278\n",
      "[INFO 23-07-08 15:52:09.0892 UTC random_forest.cc:802] Training of tree  91/300 (tree index:90) done accuracy:0.713075 logloss:3.89522\n",
      "[INFO 23-07-08 15:52:09.1694 UTC random_forest.cc:802] Training of tree  101/300 (tree index:100) done accuracy:0.710397 logloss:3.80827\n",
      "[INFO 23-07-08 15:52:09.2519 UTC random_forest.cc:802] Training of tree  111/300 (tree index:110) done accuracy:0.713967 logloss:3.77754\n",
      "[INFO 23-07-08 15:52:09.3307 UTC random_forest.cc:802] Training of tree  121/300 (tree index:120) done accuracy:0.710843 logloss:3.7642\n",
      "[INFO 23-07-08 15:52:09.4094 UTC random_forest.cc:802] Training of tree  131/300 (tree index:130) done accuracy:0.712182 logloss:3.7625\n",
      "[INFO 23-07-08 15:52:09.4877 UTC random_forest.cc:802] Training of tree  141/300 (tree index:140) done accuracy:0.709505 logloss:3.7581\n",
      "[INFO 23-07-08 15:52:09.5666 UTC random_forest.cc:802] Training of tree  151/300 (tree index:150) done accuracy:0.712182 logloss:3.7159\n",
      "[INFO 23-07-08 15:52:09.6418 UTC random_forest.cc:802] Training of tree  161/300 (tree index:160) done accuracy:0.711736 logloss:3.65916\n",
      "[INFO 23-07-08 15:52:09.7181 UTC random_forest.cc:802] Training of tree  171/300 (tree index:170) done accuracy:0.712182 logloss:3.60123\n",
      "[INFO 23-07-08 15:52:09.7952 UTC random_forest.cc:802] Training of tree  181/300 (tree index:180) done accuracy:0.712628 logloss:3.58838\n",
      "[INFO 23-07-08 15:52:09.8720 UTC random_forest.cc:802] Training of tree  191/300 (tree index:190) done accuracy:0.709058 logloss:3.5469\n",
      "[INFO 23-07-08 15:52:09.9486 UTC random_forest.cc:802] Training of tree  201/300 (tree index:200) done accuracy:0.709505 logloss:3.50423\n",
      "[INFO 23-07-08 15:52:10.0290 UTC random_forest.cc:802] Training of tree  211/300 (tree index:210) done accuracy:0.709951 logloss:3.49142\n",
      "[INFO 23-07-08 15:52:10.1069 UTC random_forest.cc:802] Training of tree  221/300 (tree index:220) done accuracy:0.710397 logloss:3.44971\n",
      "[INFO 23-07-08 15:52:10.1847 UTC random_forest.cc:802] Training of tree  231/300 (tree index:230) done accuracy:0.709058 logloss:3.42257\n",
      "[INFO 23-07-08 15:52:10.2639 UTC random_forest.cc:802] Training of tree  241/300 (tree index:240) done accuracy:0.70772 logloss:3.38068\n",
      "[INFO 23-07-08 15:52:10.3422 UTC random_forest.cc:802] Training of tree  251/300 (tree index:250) done accuracy:0.709951 logloss:3.36667\n",
      "[INFO 23-07-08 15:52:10.4200 UTC random_forest.cc:802] Training of tree  261/300 (tree index:260) done accuracy:0.708612 logloss:3.36688\n",
      "[INFO 23-07-08 15:52:10.4995 UTC random_forest.cc:802] Training of tree  271/300 (tree index:270) done accuracy:0.708166 logloss:3.36725\n",
      "[INFO 23-07-08 15:52:10.5792 UTC random_forest.cc:802] Training of tree  281/300 (tree index:280) done accuracy:0.70772 logloss:3.36833\n",
      "[INFO 23-07-08 15:52:10.6567 UTC random_forest.cc:802] Training of tree  291/300 (tree index:290) done accuracy:0.709951 logloss:3.3399\n",
      "[INFO 23-07-08 15:52:10.7327 UTC random_forest.cc:802] Training of tree  300/300 (tree index:299) done accuracy:0.709951 logloss:3.34036\n",
      "[INFO 23-07-08 15:52:10.7368 UTC random_forest.cc:882] Final OOB metrics: accuracy:0.709951 logloss:3.34036\n",
      "[INFO 23-07-08 15:52:10.7436 UTC hyperparameters_optimizer.cc:582] [17/50] Score: 0.709951 / 0.741187 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 16 } } fields { name: \"min_examples\" value { integer: 40 } }\n",
      "[INFO 23-07-08 15:52:10.7516 UTC random_forest.cc:416] Training random forest on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-08 15:52:10.7779 UTC random_forest.cc:802] Training of tree  1/300 (tree index:0) done accuracy:0.713075 logloss:10.3418\n",
      "[INFO 23-07-08 15:52:10.9072 UTC random_forest.cc:802] Training of tree  11/300 (tree index:10) done accuracy:0.714607 logloss:6.74303\n",
      "[INFO 23-07-08 15:52:11.0404 UTC random_forest.cc:802] Training of tree  21/300 (tree index:20) done accuracy:0.72066 logloss:5.56335\n",
      "[INFO 23-07-08 15:52:11.1692 UTC random_forest.cc:802] Training of tree  31/300 (tree index:30) done accuracy:0.723784 logloss:4.87851\n",
      "[INFO 23-07-08 15:52:11.2960 UTC random_forest.cc:802] Training of tree  41/300 (tree index:40) done accuracy:0.7278 logloss:4.39333\n",
      "[INFO 23-07-08 15:52:11.4260 UTC random_forest.cc:802] Training of tree  51/300 (tree index:50) done accuracy:0.721999 logloss:4.17283\n",
      "[INFO 23-07-08 15:52:11.5604 UTC random_forest.cc:802] Training of tree  61/300 (tree index:60) done accuracy:0.727354 logloss:4.04402\n",
      "[INFO 23-07-08 15:52:11.6938 UTC random_forest.cc:802] Training of tree  71/300 (tree index:70) done accuracy:0.726015 logloss:3.74782\n",
      "[INFO 23-07-08 15:52:11.8285 UTC random_forest.cc:802] Training of tree  81/300 (tree index:80) done accuracy:0.724676 logloss:3.63183\n",
      "[INFO 23-07-08 15:52:11.9612 UTC random_forest.cc:802] Training of tree  91/300 (tree index:90) done accuracy:0.724676 logloss:3.57476\n",
      "[INFO 23-07-08 15:52:12.0922 UTC random_forest.cc:802] Training of tree  101/300 (tree index:100) done accuracy:0.725569 logloss:3.49022\n",
      "[INFO 23-07-08 15:52:12.2249 UTC random_forest.cc:802] Training of tree  111/300 (tree index:110) done accuracy:0.723338 logloss:3.47744\n",
      "[INFO 23-07-08 15:52:12.3551 UTC random_forest.cc:802] Training of tree  121/300 (tree index:120) done accuracy:0.726908 logloss:3.40611\n",
      "[INFO 23-07-08 15:52:12.4845 UTC random_forest.cc:802] Training of tree  131/300 (tree index:130) done accuracy:0.725569 logloss:3.33283\n",
      "[INFO 23-07-08 15:52:12.6182 UTC random_forest.cc:802] Training of tree  141/300 (tree index:140) done accuracy:0.725123 logloss:3.24663\n",
      "[INFO 23-07-08 15:52:12.7505 UTC random_forest.cc:802] Training of tree  151/300 (tree index:150) done accuracy:0.729585 logloss:3.18765\n",
      "[INFO 23-07-08 15:52:12.8840 UTC random_forest.cc:802] Training of tree  161/300 (tree index:160) done accuracy:0.726461 logloss:3.13219\n",
      "[INFO 23-07-08 15:52:13.0192 UTC random_forest.cc:802] Training of tree  171/300 (tree index:170) done accuracy:0.729139 logloss:3.11656\n",
      "[INFO 23-07-08 15:52:13.1500 UTC random_forest.cc:802] Training of tree  181/300 (tree index:180) done accuracy:0.730924 logloss:3.11717\n",
      "[INFO 23-07-08 15:52:13.2817 UTC random_forest.cc:802] Training of tree  191/300 (tree index:190) done accuracy:0.730477 logloss:3.1043\n",
      "[INFO 23-07-08 15:52:13.4136 UTC random_forest.cc:802] Training of tree  201/300 (tree index:200) done accuracy:0.730031 logloss:3.08768\n",
      "[INFO 23-07-08 15:52:13.5444 UTC random_forest.cc:802] Training of tree  211/300 (tree index:210) done accuracy:0.730477 logloss:3.07353\n",
      "[INFO 23-07-08 15:52:13.6800 UTC random_forest.cc:802] Training of tree  221/300 (tree index:220) done accuracy:0.730031 logloss:3.04655\n",
      "[INFO 23-07-08 15:52:13.8118 UTC random_forest.cc:802] Training of tree  231/300 (tree index:230) done accuracy:0.7278 logloss:2.99004\n",
      "[INFO 23-07-08 15:52:13.9468 UTC random_forest.cc:802] Training of tree  241/300 (tree index:240) done accuracy:0.730924 logloss:2.98991\n",
      "[INFO 23-07-08 15:52:14.0805 UTC random_forest.cc:802] Training of tree  251/300 (tree index:250) done accuracy:0.730031 logloss:2.96238\n",
      "[INFO 23-07-08 15:52:14.2181 UTC random_forest.cc:802] Training of tree  261/300 (tree index:260) done accuracy:0.73137 logloss:2.93227\n",
      "[INFO 23-07-08 15:52:14.3549 UTC random_forest.cc:802] Training of tree  271/300 (tree index:270) done accuracy:0.730924 logloss:2.93325\n",
      "[INFO 23-07-08 15:52:14.4892 UTC random_forest.cc:802] Training of tree  281/300 (tree index:280) done accuracy:0.731816 logloss:2.92065\n",
      "[INFO 23-07-08 15:52:14.6224 UTC random_forest.cc:802] Training of tree  291/300 (tree index:290) done accuracy:0.73137 logloss:2.87836\n",
      "[INFO 23-07-08 15:52:14.7443 UTC random_forest.cc:802] Training of tree  300/300 (tree index:299) done accuracy:0.732262 logloss:2.87787\n",
      "[INFO 23-07-08 15:52:14.7477 UTC random_forest.cc:882] Final OOB metrics: accuracy:0.732262 logloss:2.87787\n",
      "[INFO 23-07-08 15:52:14.7880 UTC hyperparameters_optimizer.cc:582] [18/50] Score: 0.732262 / 0.741187 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"min_examples\" value { integer: 1 } }\n",
      "[INFO 23-07-08 15:52:14.8108 UTC random_forest.cc:416] Training random forest on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-08 15:52:14.8748 UTC random_forest.cc:802] Training of tree  1/300 (tree index:0) done accuracy:0.700969 logloss:10.7782\n",
      "[INFO 23-07-08 15:52:14.9707 UTC random_forest.cc:802] Training of tree  11/300 (tree index:10) done accuracy:0.713708 logloss:6.87245\n",
      "[INFO 23-07-08 15:52:15.0519 UTC random_forest.cc:802] Training of tree  21/300 (tree index:20) done accuracy:0.709058 logloss:5.37269\n",
      "[INFO 23-07-08 15:52:15.1282 UTC random_forest.cc:802] Training of tree  31/300 (tree index:30) done accuracy:0.709951 logloss:4.64262\n",
      "[INFO 23-07-08 15:52:15.2058 UTC random_forest.cc:802] Training of tree  41/300 (tree index:40) done accuracy:0.709951 logloss:4.43462\n",
      "[INFO 23-07-08 15:52:15.2840 UTC random_forest.cc:802] Training of tree  51/300 (tree index:50) done accuracy:0.712182 logloss:4.27208\n",
      "[INFO 23-07-08 15:52:15.3621 UTC random_forest.cc:802] Training of tree  61/300 (tree index:60) done accuracy:0.711736 logloss:4.14287\n",
      "[INFO 23-07-08 15:52:15.4391 UTC random_forest.cc:802] Training of tree  71/300 (tree index:70) done accuracy:0.711736 logloss:4.02476\n",
      "[INFO 23-07-08 15:52:15.5178 UTC random_forest.cc:802] Training of tree  81/300 (tree index:80) done accuracy:0.714413 logloss:3.95278\n",
      "[INFO 23-07-08 15:52:15.5952 UTC random_forest.cc:802] Training of tree  91/300 (tree index:90) done accuracy:0.713075 logloss:3.89522\n",
      "[INFO 23-07-08 15:52:15.6759 UTC random_forest.cc:802] Training of tree  101/300 (tree index:100) done accuracy:0.710397 logloss:3.80827\n",
      "[INFO 23-07-08 15:52:15.7582 UTC random_forest.cc:802] Training of tree  111/300 (tree index:110) done accuracy:0.713967 logloss:3.77754\n",
      "[INFO 23-07-08 15:52:15.8372 UTC random_forest.cc:802] Training of tree  121/300 (tree index:120) done accuracy:0.710843 logloss:3.7642\n",
      "[INFO 23-07-08 15:52:15.9155 UTC random_forest.cc:802] Training of tree  131/300 (tree index:130) done accuracy:0.712182 logloss:3.7625\n",
      "[INFO 23-07-08 15:52:15.9930 UTC random_forest.cc:802] Training of tree  141/300 (tree index:140) done accuracy:0.709505 logloss:3.7581\n",
      "[INFO 23-07-08 15:52:16.0723 UTC random_forest.cc:802] Training of tree  151/300 (tree index:150) done accuracy:0.712182 logloss:3.7159\n",
      "[INFO 23-07-08 15:52:16.1517 UTC random_forest.cc:802] Training of tree  161/300 (tree index:160) done accuracy:0.711736 logloss:3.65916\n",
      "[INFO 23-07-08 15:52:16.2284 UTC random_forest.cc:802] Training of tree  171/300 (tree index:170) done accuracy:0.712182 logloss:3.60123\n",
      "[INFO 23-07-08 15:52:16.3075 UTC random_forest.cc:802] Training of tree  181/300 (tree index:180) done accuracy:0.712628 logloss:3.58838\n",
      "[INFO 23-07-08 15:52:16.3853 UTC random_forest.cc:802] Training of tree  191/300 (tree index:190) done accuracy:0.709058 logloss:3.5469\n",
      "[INFO 23-07-08 15:52:16.4647 UTC random_forest.cc:802] Training of tree  201/300 (tree index:200) done accuracy:0.709505 logloss:3.50423\n",
      "[INFO 23-07-08 15:52:16.5486 UTC random_forest.cc:802] Training of tree  211/300 (tree index:210) done accuracy:0.709951 logloss:3.49142\n",
      "[INFO 23-07-08 15:52:16.6294 UTC random_forest.cc:802] Training of tree  221/300 (tree index:220) done accuracy:0.710397 logloss:3.44971\n",
      "[INFO 23-07-08 15:52:16.7074 UTC random_forest.cc:802] Training of tree  231/300 (tree index:230) done accuracy:0.709058 logloss:3.42257\n",
      "[INFO 23-07-08 15:52:16.7867 UTC random_forest.cc:802] Training of tree  241/300 (tree index:240) done accuracy:0.70772 logloss:3.38068\n",
      "[INFO 23-07-08 15:52:16.8644 UTC random_forest.cc:802] Training of tree  251/300 (tree index:250) done accuracy:0.709951 logloss:3.36667\n",
      "[INFO 23-07-08 15:52:16.9429 UTC random_forest.cc:802] Training of tree  261/300 (tree index:260) done accuracy:0.708612 logloss:3.36688\n",
      "[INFO 23-07-08 15:52:17.0212 UTC random_forest.cc:802] Training of tree  271/300 (tree index:270) done accuracy:0.708166 logloss:3.36725\n",
      "[INFO 23-07-08 15:52:17.0997 UTC random_forest.cc:802] Training of tree  281/300 (tree index:280) done accuracy:0.70772 logloss:3.36833\n",
      "[INFO 23-07-08 15:52:17.1758 UTC random_forest.cc:802] Training of tree  291/300 (tree index:290) done accuracy:0.709951 logloss:3.3399\n",
      "[INFO 23-07-08 15:52:17.2533 UTC random_forest.cc:802] Training of tree  300/300 (tree index:299) done accuracy:0.709951 logloss:3.34036\n",
      "[INFO 23-07-08 15:52:17.2572 UTC random_forest.cc:882] Final OOB metrics: accuracy:0.709951 logloss:3.34036\n",
      "[INFO 23-07-08 15:52:17.2623 UTC hyperparameters_optimizer.cc:582] [19/50] Score: 0.709951 / 0.741187 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 30 } } fields { name: \"min_examples\" value { integer: 40 } }\n",
      "[INFO 23-07-08 15:52:17.2724 UTC random_forest.cc:416] Training random forest on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-08 15:52:17.2955 UTC random_forest.cc:802] Training of tree  1/300 (tree index:0) done accuracy:0.713075 logloss:10.3418\n",
      "[INFO 23-07-08 15:52:17.4239 UTC random_forest.cc:802] Training of tree  11/300 (tree index:10) done accuracy:0.714607 logloss:6.74303\n",
      "[INFO 23-07-08 15:52:17.5582 UTC random_forest.cc:802] Training of tree  21/300 (tree index:20) done accuracy:0.72066 logloss:5.56335\n",
      "[INFO 23-07-08 15:52:17.6898 UTC random_forest.cc:802] Training of tree  31/300 (tree index:30) done accuracy:0.723784 logloss:4.87851\n",
      "[INFO 23-07-08 15:52:17.8179 UTC random_forest.cc:802] Training of tree  41/300 (tree index:40) done accuracy:0.7278 logloss:4.39333\n",
      "[INFO 23-07-08 15:52:17.9512 UTC random_forest.cc:802] Training of tree  51/300 (tree index:50) done accuracy:0.721999 logloss:4.17283\n",
      "[INFO 23-07-08 15:52:18.0909 UTC random_forest.cc:802] Training of tree  61/300 (tree index:60) done accuracy:0.727354 logloss:4.04402\n",
      "[INFO 23-07-08 15:52:18.2273 UTC random_forest.cc:802] Training of tree  71/300 (tree index:70) done accuracy:0.726015 logloss:3.74782\n",
      "[INFO 23-07-08 15:52:18.3595 UTC random_forest.cc:802] Training of tree  81/300 (tree index:80) done accuracy:0.724676 logloss:3.63183\n",
      "[INFO 23-07-08 15:52:18.4903 UTC random_forest.cc:802] Training of tree  91/300 (tree index:90) done accuracy:0.724676 logloss:3.57476\n",
      "[INFO 23-07-08 15:52:18.6232 UTC random_forest.cc:802] Training of tree  101/300 (tree index:100) done accuracy:0.725569 logloss:3.49022\n",
      "[INFO 23-07-08 15:52:18.7630 UTC random_forest.cc:802] Training of tree  111/300 (tree index:110) done accuracy:0.723338 logloss:3.47744\n",
      "[INFO 23-07-08 15:52:18.8984 UTC random_forest.cc:802] Training of tree  121/300 (tree index:120) done accuracy:0.726908 logloss:3.40611\n",
      "[INFO 23-07-08 15:52:19.0324 UTC random_forest.cc:802] Training of tree  131/300 (tree index:130) done accuracy:0.725569 logloss:3.33283\n",
      "[INFO 23-07-08 15:52:19.1696 UTC random_forest.cc:802] Training of tree  141/300 (tree index:140) done accuracy:0.725123 logloss:3.24663\n",
      "[INFO 23-07-08 15:52:19.3110 UTC random_forest.cc:802] Training of tree  151/300 (tree index:150) done accuracy:0.729585 logloss:3.18765\n",
      "[INFO 23-07-08 15:52:19.4469 UTC random_forest.cc:802] Training of tree  161/300 (tree index:160) done accuracy:0.726461 logloss:3.13219\n",
      "[INFO 23-07-08 15:52:19.5817 UTC random_forest.cc:802] Training of tree  171/300 (tree index:170) done accuracy:0.729139 logloss:3.11656\n",
      "[INFO 23-07-08 15:52:19.7159 UTC random_forest.cc:802] Training of tree  181/300 (tree index:180) done accuracy:0.730924 logloss:3.11717\n",
      "[INFO 23-07-08 15:52:19.8496 UTC random_forest.cc:802] Training of tree  191/300 (tree index:190) done accuracy:0.730477 logloss:3.1043\n",
      "[INFO 23-07-08 15:52:19.9818 UTC random_forest.cc:802] Training of tree  201/300 (tree index:200) done accuracy:0.730031 logloss:3.08768\n",
      "[INFO 23-07-08 15:52:20.1158 UTC random_forest.cc:802] Training of tree  211/300 (tree index:210) done accuracy:0.730477 logloss:3.07353\n",
      "[INFO 23-07-08 15:52:20.2493 UTC random_forest.cc:802] Training of tree  221/300 (tree index:220) done accuracy:0.730031 logloss:3.04655\n",
      "[INFO 23-07-08 15:52:20.3822 UTC random_forest.cc:802] Training of tree  231/300 (tree index:230) done accuracy:0.7278 logloss:2.99004\n",
      "[INFO 23-07-08 15:52:20.5166 UTC random_forest.cc:802] Training of tree  241/300 (tree index:240) done accuracy:0.730924 logloss:2.98991\n",
      "[INFO 23-07-08 15:52:20.6524 UTC random_forest.cc:802] Training of tree  251/300 (tree index:250) done accuracy:0.730031 logloss:2.96238\n",
      "[INFO 23-07-08 15:52:20.7846 UTC random_forest.cc:802] Training of tree  261/300 (tree index:260) done accuracy:0.73137 logloss:2.93227\n",
      "[INFO 23-07-08 15:52:20.9210 UTC random_forest.cc:802] Training of tree  271/300 (tree index:270) done accuracy:0.730924 logloss:2.93325\n",
      "[INFO 23-07-08 15:52:21.0556 UTC random_forest.cc:802] Training of tree  281/300 (tree index:280) done accuracy:0.731816 logloss:2.92065\n",
      "[INFO 23-07-08 15:52:21.1885 UTC random_forest.cc:802] Training of tree  291/300 (tree index:290) done accuracy:0.73137 logloss:2.87836\n",
      "[INFO 23-07-08 15:52:21.3114 UTC random_forest.cc:802] Training of tree  300/300 (tree index:299) done accuracy:0.732262 logloss:2.87787\n",
      "[INFO 23-07-08 15:52:21.3152 UTC random_forest.cc:882] Final OOB metrics: accuracy:0.732262 logloss:2.87787\n",
      "[INFO 23-07-08 15:52:21.3586 UTC hyperparameters_optimizer.cc:582] [20/50] Score: 0.732262 / 0.741187 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"min_examples\" value { integer: 1 } }\n",
      "[INFO 23-07-08 15:52:21.3717 UTC random_forest.cc:416] Training random forest on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-08 15:52:21.4680 UTC random_forest.cc:802] Training of tree  1/300 (tree index:0) done accuracy:0.716707 logloss:10.2109\n",
      "[INFO 23-07-08 15:52:21.5162 UTC random_forest.cc:802] Training of tree  11/300 (tree index:10) done accuracy:0.710112 logloss:6.63275\n",
      "[INFO 23-07-08 15:52:21.5659 UTC random_forest.cc:802] Training of tree  21/300 (tree index:20) done accuracy:0.728693 logloss:5.46481\n",
      "[INFO 23-07-08 15:52:21.6128 UTC random_forest.cc:802] Training of tree  31/300 (tree index:30) done accuracy:0.728246 logloss:4.99131\n",
      "[INFO 23-07-08 15:52:21.6607 UTC random_forest.cc:802] Training of tree  41/300 (tree index:40) done accuracy:0.729585 logloss:4.56309\n",
      "[INFO 23-07-08 15:52:21.7083 UTC random_forest.cc:802] Training of tree  51/300 (tree index:50) done accuracy:0.728246 logloss:4.34453\n",
      "[INFO 23-07-08 15:52:21.7562 UTC random_forest.cc:802] Training of tree  61/300 (tree index:60) done accuracy:0.733601 logloss:4.18214\n",
      "[INFO 23-07-08 15:52:21.8035 UTC random_forest.cc:802] Training of tree  71/300 (tree index:70) done accuracy:0.733601 logloss:3.99388\n",
      "[INFO 23-07-08 15:52:21.8507 UTC random_forest.cc:802] Training of tree  81/300 (tree index:80) done accuracy:0.732262 logloss:3.89545\n",
      "[INFO 23-07-08 15:52:21.8976 UTC random_forest.cc:802] Training of tree  91/300 (tree index:90) done accuracy:0.73494 logloss:3.8672\n",
      "[INFO 23-07-08 15:52:21.9444 UTC random_forest.cc:802] Training of tree  101/300 (tree index:100) done accuracy:0.73494 logloss:3.75001\n",
      "[INFO 23-07-08 15:52:21.9927 UTC random_forest.cc:802] Training of tree  111/300 (tree index:110) done accuracy:0.734047 logloss:3.67642\n",
      "[INFO 23-07-08 15:52:22.0424 UTC random_forest.cc:802] Training of tree  121/300 (tree index:120) done accuracy:0.733601 logloss:3.64851\n",
      "[INFO 23-07-08 15:52:22.0884 UTC random_forest.cc:802] Training of tree  131/300 (tree index:130) done accuracy:0.736278 logloss:3.54679\n",
      "[INFO 23-07-08 15:52:22.1337 UTC random_forest.cc:802] Training of tree  141/300 (tree index:140) done accuracy:0.736725 logloss:3.44668\n",
      "[INFO 23-07-08 15:52:22.1809 UTC random_forest.cc:802] Training of tree  151/300 (tree index:150) done accuracy:0.738956 logloss:3.40438\n",
      "[INFO 23-07-08 15:52:22.2385 UTC random_forest.cc:802] Training of tree  161/300 (tree index:160) done accuracy:0.737171 logloss:3.33383\n",
      "[INFO 23-07-08 15:52:22.3472 UTC random_forest.cc:802] Training of tree  171/300 (tree index:170) done accuracy:0.736725 logloss:3.30592\n",
      "[INFO 23-07-08 15:52:22.4008 UTC random_forest.cc:802] Training of tree  181/300 (tree index:180) done accuracy:0.736725 logloss:3.29276\n",
      "[INFO 23-07-08 15:52:22.4469 UTC random_forest.cc:802] Training of tree  191/300 (tree index:190) done accuracy:0.736725 logloss:3.26406\n",
      "[INFO 23-07-08 15:52:22.4923 UTC random_forest.cc:802] Training of tree  201/300 (tree index:200) done accuracy:0.736278 logloss:3.21833\n",
      "[INFO 23-07-08 15:52:22.5386 UTC random_forest.cc:802] Training of tree  211/300 (tree index:210) done accuracy:0.737617 logloss:3.18965\n",
      "[INFO 23-07-08 15:52:22.5890 UTC random_forest.cc:802] Training of tree  221/300 (tree index:220) done accuracy:0.736725 logloss:3.1477\n",
      "[INFO 23-07-08 15:52:22.6377 UTC random_forest.cc:802] Training of tree  231/300 (tree index:230) done accuracy:0.736278 logloss:3.13392\n",
      "[INFO 23-07-08 15:52:22.6867 UTC random_forest.cc:802] Training of tree  241/300 (tree index:240) done accuracy:0.735386 logloss:3.11915\n",
      "[INFO 23-07-08 15:52:22.7360 UTC random_forest.cc:802] Training of tree  251/300 (tree index:250) done accuracy:0.735386 logloss:3.11919\n",
      "[INFO 23-07-08 15:52:22.7859 UTC random_forest.cc:802] Training of tree  261/300 (tree index:260) done accuracy:0.735386 logloss:3.09101\n",
      "[INFO 23-07-08 15:52:22.8327 UTC random_forest.cc:802] Training of tree  271/300 (tree index:270) done accuracy:0.73494 logloss:3.06321\n",
      "[INFO 23-07-08 15:52:22.8796 UTC random_forest.cc:802] Training of tree  281/300 (tree index:280) done accuracy:0.736725 logloss:3.0483\n",
      "[INFO 23-07-08 15:52:22.9287 UTC random_forest.cc:802] Training of tree  291/300 (tree index:290) done accuracy:0.736278 logloss:3.03378\n",
      "[INFO 23-07-08 15:52:22.9714 UTC random_forest.cc:802] Training of tree  300/300 (tree index:299) done accuracy:0.736725 logloss:3.03436\n",
      "[INFO 23-07-08 15:52:22.9757 UTC random_forest.cc:882] Final OOB metrics: accuracy:0.736725 logloss:3.03436\n",
      "[INFO 23-07-08 15:52:22.9949 UTC hyperparameters_optimizer.cc:582] [21/50] Score: 0.736725 / 0.741187 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 30 } } fields { name: \"min_examples\" value { integer: 10 } }\n",
      "[INFO 23-07-08 15:52:23.0104 UTC random_forest.cc:416] Training random forest on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-08 15:52:23.0535 UTC random_forest.cc:802] Training of tree  1/300 (tree index:0) done accuracy:0.68523 logloss:11.3455\n",
      "[INFO 23-07-08 15:52:23.0861 UTC random_forest.cc:802] Training of tree  11/300 (tree index:10) done accuracy:0.70382 logloss:6.05949\n",
      "[INFO 23-07-08 15:52:23.1174 UTC random_forest.cc:802] Training of tree  21/300 (tree index:20) done accuracy:0.714413 logloss:5.01416\n",
      "[INFO 23-07-08 15:52:23.1497 UTC random_forest.cc:802] Training of tree  31/300 (tree index:30) done accuracy:0.717537 logloss:4.58107\n",
      "[INFO 23-07-08 15:52:23.1829 UTC random_forest.cc:802] Training of tree  41/300 (tree index:40) done accuracy:0.711736 logloss:4.34229\n",
      "[INFO 23-07-08 15:52:23.2146 UTC random_forest.cc:802] Training of tree  51/300 (tree index:50) done accuracy:0.713521 logloss:4.16687\n",
      "[INFO 23-07-08 15:52:23.2461 UTC random_forest.cc:802] Training of tree  61/300 (tree index:60) done accuracy:0.713521 logloss:4.09711\n",
      "[INFO 23-07-08 15:52:23.2792 UTC random_forest.cc:802] Training of tree  71/300 (tree index:70) done accuracy:0.71129 logloss:3.94954\n",
      "[INFO 23-07-08 15:52:23.3118 UTC random_forest.cc:802] Training of tree  81/300 (tree index:80) done accuracy:0.71129 logloss:3.92266\n",
      "[INFO 23-07-08 15:52:23.3444 UTC random_forest.cc:802] Training of tree  91/300 (tree index:90) done accuracy:0.71129 logloss:3.89094\n",
      "[INFO 23-07-08 15:52:23.3767 UTC random_forest.cc:802] Training of tree  101/300 (tree index:100) done accuracy:0.709951 logloss:3.84799\n",
      "[INFO 23-07-08 15:52:23.4123 UTC random_forest.cc:802] Training of tree  111/300 (tree index:110) done accuracy:0.707274 logloss:3.73154\n",
      "[INFO 23-07-08 15:52:23.4445 UTC random_forest.cc:802] Training of tree  121/300 (tree index:120) done accuracy:0.709505 logloss:3.68738\n",
      "[INFO 23-07-08 15:52:23.4761 UTC random_forest.cc:802] Training of tree  131/300 (tree index:130) done accuracy:0.709058 logloss:3.66024\n",
      "[INFO 23-07-08 15:52:23.5080 UTC random_forest.cc:802] Training of tree  141/300 (tree index:140) done accuracy:0.710843 logloss:3.64611\n",
      "[INFO 23-07-08 15:52:23.5385 UTC random_forest.cc:802] Training of tree  151/300 (tree index:150) done accuracy:0.711736 logloss:3.63176\n",
      "[INFO 23-07-08 15:52:23.5716 UTC random_forest.cc:802] Training of tree  161/300 (tree index:160) done accuracy:0.711736 logloss:3.63327\n",
      "[INFO 23-07-08 15:52:23.6163 UTC random_forest.cc:802] Training of tree  171/300 (tree index:170) done accuracy:0.712628 logloss:3.63305\n",
      "[INFO 23-07-08 15:52:23.6486 UTC random_forest.cc:802] Training of tree  181/300 (tree index:180) done accuracy:0.71129 logloss:3.60535\n",
      "[INFO 23-07-08 15:52:23.6804 UTC random_forest.cc:802] Training of tree  191/300 (tree index:190) done accuracy:0.710843 logloss:3.56285\n",
      "[INFO 23-07-08 15:52:23.7138 UTC random_forest.cc:802] Training of tree  201/300 (tree index:200) done accuracy:0.709058 logloss:3.53335\n",
      "[INFO 23-07-08 15:52:23.7579 UTC random_forest.cc:802] Training of tree  211/300 (tree index:210) done accuracy:0.708166 logloss:3.53472\n",
      "[INFO 23-07-08 15:52:23.7990 UTC random_forest.cc:802] Training of tree  221/300 (tree index:220) done accuracy:0.708612 logloss:3.50685\n",
      "[INFO 23-07-08 15:52:23.8312 UTC random_forest.cc:802] Training of tree  231/300 (tree index:230) done accuracy:0.705935 logloss:3.49128\n",
      "[INFO 23-07-08 15:52:23.8639 UTC random_forest.cc:802] Training of tree  241/300 (tree index:240) done accuracy:0.70772 logloss:3.35077\n",
      "[INFO 23-07-08 15:52:23.8955 UTC random_forest.cc:802] Training of tree  251/300 (tree index:250) done accuracy:0.708612 logloss:3.33764\n",
      "[INFO 23-07-08 15:52:23.9272 UTC random_forest.cc:802] Training of tree  261/300 (tree index:260) done accuracy:0.707274 logloss:3.32324\n",
      "[INFO 23-07-08 15:52:23.9596 UTC random_forest.cc:802] Training of tree  271/300 (tree index:270) done accuracy:0.707274 logloss:3.26521\n",
      "[INFO 23-07-08 15:52:23.9906 UTC random_forest.cc:802] Training of tree  281/300 (tree index:280) done accuracy:0.705042 logloss:3.25093\n",
      "[INFO 23-07-08 15:52:24.0231 UTC random_forest.cc:802] Training of tree  291/300 (tree index:290) done accuracy:0.704596 logloss:3.2527\n",
      "[INFO 23-07-08 15:52:24.0540 UTC random_forest.cc:802] Training of tree  300/300 (tree index:299) done accuracy:0.705042 logloss:3.25254\n",
      "[INFO 23-07-08 15:52:24.0584 UTC random_forest.cc:882] Final OOB metrics: accuracy:0.705042 logloss:3.25254\n",
      "[INFO 23-07-08 15:52:24.0623 UTC hyperparameters_optimizer.cc:582] [22/50] Score: 0.705042 / 0.741187 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 30 } } fields { name: \"min_examples\" value { integer: 40 } }\n",
      "[INFO 23-07-08 15:52:24.0706 UTC random_forest.cc:416] Training random forest on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-08 15:52:24.0973 UTC random_forest.cc:802] Training of tree  1/300 (tree index:0) done accuracy:0.700969 logloss:10.7782\n",
      "[INFO 23-07-08 15:52:24.1747 UTC random_forest.cc:802] Training of tree  11/300 (tree index:10) done accuracy:0.713708 logloss:6.87245\n",
      "[INFO 23-07-08 15:52:24.2567 UTC random_forest.cc:802] Training of tree  21/300 (tree index:20) done accuracy:0.709058 logloss:5.37269\n",
      "[INFO 23-07-08 15:52:24.3324 UTC random_forest.cc:802] Training of tree  31/300 (tree index:30) done accuracy:0.709951 logloss:4.64262\n",
      "[INFO 23-07-08 15:52:24.4100 UTC random_forest.cc:802] Training of tree  41/300 (tree index:40) done accuracy:0.709951 logloss:4.43462\n",
      "[INFO 23-07-08 15:52:24.4861 UTC random_forest.cc:802] Training of tree  51/300 (tree index:50) done accuracy:0.712182 logloss:4.27208\n",
      "[INFO 23-07-08 15:52:24.5627 UTC random_forest.cc:802] Training of tree  61/300 (tree index:60) done accuracy:0.711736 logloss:4.14287\n",
      "[INFO 23-07-08 15:52:24.6423 UTC random_forest.cc:802] Training of tree  71/300 (tree index:70) done accuracy:0.711736 logloss:4.02476\n",
      "[INFO 23-07-08 15:52:24.7214 UTC random_forest.cc:802] Training of tree  81/300 (tree index:80) done accuracy:0.714413 logloss:3.95278\n",
      "[INFO 23-07-08 15:52:24.7983 UTC random_forest.cc:802] Training of tree  91/300 (tree index:90) done accuracy:0.713075 logloss:3.89522\n",
      "[INFO 23-07-08 15:52:24.8755 UTC random_forest.cc:802] Training of tree  101/300 (tree index:100) done accuracy:0.710397 logloss:3.80827\n",
      "[INFO 23-07-08 15:52:24.9551 UTC random_forest.cc:802] Training of tree  111/300 (tree index:110) done accuracy:0.713967 logloss:3.77754\n",
      "[INFO 23-07-08 15:52:25.0355 UTC random_forest.cc:802] Training of tree  121/300 (tree index:120) done accuracy:0.710843 logloss:3.7642\n",
      "[INFO 23-07-08 15:52:25.1128 UTC random_forest.cc:802] Training of tree  131/300 (tree index:130) done accuracy:0.712182 logloss:3.7625\n",
      "[INFO 23-07-08 15:52:25.1888 UTC random_forest.cc:802] Training of tree  141/300 (tree index:140) done accuracy:0.709505 logloss:3.7581\n",
      "[INFO 23-07-08 15:52:25.2677 UTC random_forest.cc:802] Training of tree  151/300 (tree index:150) done accuracy:0.712182 logloss:3.7159\n",
      "[INFO 23-07-08 15:52:25.3427 UTC random_forest.cc:802] Training of tree  161/300 (tree index:160) done accuracy:0.711736 logloss:3.65916\n",
      "[INFO 23-07-08 15:52:25.4180 UTC random_forest.cc:802] Training of tree  171/300 (tree index:170) done accuracy:0.712182 logloss:3.60123\n",
      "[INFO 23-07-08 15:52:25.4950 UTC random_forest.cc:802] Training of tree  181/300 (tree index:180) done accuracy:0.712628 logloss:3.58838\n",
      "[INFO 23-07-08 15:52:25.5727 UTC random_forest.cc:802] Training of tree  191/300 (tree index:190) done accuracy:0.709058 logloss:3.5469\n",
      "[INFO 23-07-08 15:52:25.6511 UTC random_forest.cc:802] Training of tree  201/300 (tree index:200) done accuracy:0.709505 logloss:3.50423\n",
      "[INFO 23-07-08 15:52:25.7347 UTC random_forest.cc:802] Training of tree  211/300 (tree index:210) done accuracy:0.709951 logloss:3.49142\n",
      "[INFO 23-07-08 15:52:25.8135 UTC random_forest.cc:802] Training of tree  221/300 (tree index:220) done accuracy:0.710397 logloss:3.44971\n",
      "[INFO 23-07-08 15:52:25.8912 UTC random_forest.cc:802] Training of tree  231/300 (tree index:230) done accuracy:0.709058 logloss:3.42257\n",
      "[INFO 23-07-08 15:52:25.9703 UTC random_forest.cc:802] Training of tree  241/300 (tree index:240) done accuracy:0.70772 logloss:3.38068\n",
      "[INFO 23-07-08 15:52:26.0478 UTC random_forest.cc:802] Training of tree  251/300 (tree index:250) done accuracy:0.709951 logloss:3.36667\n",
      "[INFO 23-07-08 15:52:26.1259 UTC random_forest.cc:802] Training of tree  261/300 (tree index:260) done accuracy:0.708612 logloss:3.36688\n",
      "[INFO 23-07-08 15:52:26.2044 UTC random_forest.cc:802] Training of tree  271/300 (tree index:270) done accuracy:0.708166 logloss:3.36725\n",
      "[INFO 23-07-08 15:52:26.2841 UTC random_forest.cc:802] Training of tree  281/300 (tree index:280) done accuracy:0.70772 logloss:3.36833\n",
      "[INFO 23-07-08 15:52:26.3597 UTC random_forest.cc:802] Training of tree  291/300 (tree index:290) done accuracy:0.709951 logloss:3.3399\n",
      "[INFO 23-07-08 15:52:26.4344 UTC random_forest.cc:802] Training of tree  300/300 (tree index:299) done accuracy:0.709951 logloss:3.34036\n",
      "[INFO 23-07-08 15:52:26.4385 UTC random_forest.cc:882] Final OOB metrics: accuracy:0.709951 logloss:3.34036\n",
      "[INFO 23-07-08 15:52:26.4431 UTC hyperparameters_optimizer.cc:582] [23/50] Score: 0.709951 / 0.741187 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 25 } } fields { name: \"min_examples\" value { integer: 40 } }\n",
      "[INFO 23-07-08 15:52:26.4521 UTC random_forest.cc:416] Training random forest on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-08 15:52:26.4974 UTC random_forest.cc:802] Training of tree  1/300 (tree index:0) done accuracy:0.700969 logloss:10.7782\n",
      "[INFO 23-07-08 15:52:26.6323 UTC random_forest.cc:802] Training of tree  11/300 (tree index:10) done accuracy:0.709663 logloss:6.86775\n",
      "[INFO 23-07-08 15:52:26.7662 UTC random_forest.cc:802] Training of tree  21/300 (tree index:20) done accuracy:0.729139 logloss:5.79166\n",
      "[INFO 23-07-08 15:52:26.9005 UTC random_forest.cc:802] Training of tree  31/300 (tree index:30) done accuracy:0.728693 logloss:5.16278\n",
      "[INFO 23-07-08 15:52:27.0342 UTC random_forest.cc:802] Training of tree  41/300 (tree index:40) done accuracy:0.726461 logloss:4.74693\n",
      "[INFO 23-07-08 15:52:27.1714 UTC random_forest.cc:802] Training of tree  51/300 (tree index:50) done accuracy:0.722892 logloss:4.55889\n",
      "[INFO 23-07-08 15:52:27.3086 UTC random_forest.cc:802] Training of tree  61/300 (tree index:60) done accuracy:0.72066 logloss:4.38352\n",
      "[INFO 23-07-08 15:52:27.4450 UTC random_forest.cc:802] Training of tree  71/300 (tree index:70) done accuracy:0.718429 logloss:4.13737\n",
      "[INFO 23-07-08 15:52:27.5831 UTC random_forest.cc:802] Training of tree  81/300 (tree index:80) done accuracy:0.723338 logloss:4.00727\n",
      "[INFO 23-07-08 15:52:27.7208 UTC random_forest.cc:802] Training of tree  91/300 (tree index:90) done accuracy:0.726015 logloss:3.89349\n",
      "[INFO 23-07-08 15:52:27.8575 UTC random_forest.cc:802] Training of tree  101/300 (tree index:100) done accuracy:0.72423 logloss:3.82181\n",
      "[INFO 23-07-08 15:52:27.9944 UTC random_forest.cc:802] Training of tree  111/300 (tree index:110) done accuracy:0.72423 logloss:3.73477\n",
      "[INFO 23-07-08 15:52:28.1316 UTC random_forest.cc:802] Training of tree  121/300 (tree index:120) done accuracy:0.72423 logloss:3.67673\n",
      "[INFO 23-07-08 15:52:28.2705 UTC random_forest.cc:802] Training of tree  131/300 (tree index:130) done accuracy:0.726908 logloss:3.58997\n",
      "[INFO 23-07-08 15:52:28.4085 UTC random_forest.cc:802] Training of tree  141/300 (tree index:140) done accuracy:0.725123 logloss:3.56164\n",
      "[INFO 23-07-08 15:52:28.5480 UTC random_forest.cc:802] Training of tree  151/300 (tree index:150) done accuracy:0.728693 logloss:3.54725\n",
      "[INFO 23-07-08 15:52:28.6848 UTC random_forest.cc:802] Training of tree  161/300 (tree index:160) done accuracy:0.728246 logloss:3.52065\n",
      "[INFO 23-07-08 15:52:28.8208 UTC random_forest.cc:802] Training of tree  171/300 (tree index:170) done accuracy:0.729139 logloss:3.47794\n",
      "[INFO 23-07-08 15:52:28.9621 UTC random_forest.cc:802] Training of tree  181/300 (tree index:180) done accuracy:0.730924 logloss:3.46369\n",
      "[INFO 23-07-08 15:52:29.1007 UTC random_forest.cc:802] Training of tree  191/300 (tree index:190) done accuracy:0.729139 logloss:3.39455\n",
      "[INFO 23-07-08 15:52:29.2395 UTC random_forest.cc:802] Training of tree  201/300 (tree index:200) done accuracy:0.729139 logloss:3.34769\n",
      "[INFO 23-07-08 15:52:29.3795 UTC random_forest.cc:802] Training of tree  211/300 (tree index:210) done accuracy:0.727354 logloss:3.33301\n",
      "[INFO 23-07-08 15:52:29.5174 UTC random_forest.cc:802] Training of tree  221/300 (tree index:220) done accuracy:0.729139 logloss:3.31913\n",
      "[INFO 23-07-08 15:52:29.6564 UTC random_forest.cc:802] Training of tree  231/300 (tree index:230) done accuracy:0.728246 logloss:3.30503\n",
      "[INFO 23-07-08 15:52:29.7959 UTC random_forest.cc:802] Training of tree  241/300 (tree index:240) done accuracy:0.729139 logloss:3.30535\n",
      "[INFO 23-07-08 15:52:29.9378 UTC random_forest.cc:802] Training of tree  251/300 (tree index:250) done accuracy:0.727354 logloss:3.30461\n",
      "[INFO 23-07-08 15:52:30.0785 UTC random_forest.cc:802] Training of tree  261/300 (tree index:260) done accuracy:0.728246 logloss:3.24674\n",
      "[INFO 23-07-08 15:52:30.2231 UTC random_forest.cc:802] Training of tree  271/300 (tree index:270) done accuracy:0.7278 logloss:3.24786\n",
      "[INFO 23-07-08 15:52:30.3641 UTC random_forest.cc:802] Training of tree  281/300 (tree index:280) done accuracy:0.729585 logloss:3.24735\n",
      "[INFO 23-07-08 15:52:30.5025 UTC random_forest.cc:802] Training of tree  291/300 (tree index:290) done accuracy:0.730924 logloss:3.20513\n",
      "[INFO 23-07-08 15:52:30.6294 UTC random_forest.cc:802] Training of tree  300/300 (tree index:299) done accuracy:0.730477 logloss:3.19127\n",
      "[INFO 23-07-08 15:52:30.6325 UTC random_forest.cc:882] Final OOB metrics: accuracy:0.730477 logloss:3.19127\n",
      "[INFO 23-07-08 15:52:30.6749 UTC hyperparameters_optimizer.cc:582] [24/50] Score: 0.730477 / 0.741187 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 20 } } fields { name: \"min_examples\" value { integer: 2 } }\n",
      "[INFO 23-07-08 15:52:30.6879 UTC random_forest.cc:416] Training random forest on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-08 15:52:30.7033 UTC random_forest.cc:802] Training of tree  1/300 (tree index:0) done accuracy:0.68523 logloss:11.3455\n",
      "[INFO 23-07-08 15:52:30.7552 UTC random_forest.cc:802] Training of tree  11/300 (tree index:10) done accuracy:0.70382 logloss:6.05949\n",
      "[INFO 23-07-08 15:52:30.7924 UTC random_forest.cc:802] Training of tree  21/300 (tree index:20) done accuracy:0.714413 logloss:5.01416\n",
      "[INFO 23-07-08 15:52:30.8264 UTC random_forest.cc:802] Training of tree  31/300 (tree index:30) done accuracy:0.717537 logloss:4.58107\n",
      "[INFO 23-07-08 15:52:30.8598 UTC random_forest.cc:802] Training of tree  41/300 (tree index:40) done accuracy:0.711736 logloss:4.34229\n",
      "[INFO 23-07-08 15:52:30.8925 UTC random_forest.cc:802] Training of tree  51/300 (tree index:50) done accuracy:0.713521 logloss:4.16687\n",
      "[INFO 23-07-08 15:52:30.9255 UTC random_forest.cc:802] Training of tree  61/300 (tree index:60) done accuracy:0.713521 logloss:4.09711\n",
      "[INFO 23-07-08 15:52:30.9619 UTC random_forest.cc:802] Training of tree  71/300 (tree index:70) done accuracy:0.71129 logloss:3.94954\n",
      "[INFO 23-07-08 15:52:30.9940 UTC random_forest.cc:802] Training of tree  81/300 (tree index:80) done accuracy:0.71129 logloss:3.92266\n",
      "[INFO 23-07-08 15:52:31.0266 UTC random_forest.cc:802] Training of tree  91/300 (tree index:90) done accuracy:0.71129 logloss:3.89094\n",
      "[INFO 23-07-08 15:52:31.0580 UTC random_forest.cc:802] Training of tree  101/300 (tree index:100) done accuracy:0.709951 logloss:3.84799\n",
      "[INFO 23-07-08 15:52:31.0911 UTC random_forest.cc:802] Training of tree  111/300 (tree index:110) done accuracy:0.707274 logloss:3.73154\n",
      "[INFO 23-07-08 15:52:31.1234 UTC random_forest.cc:802] Training of tree  121/300 (tree index:120) done accuracy:0.709505 logloss:3.68738\n",
      "[INFO 23-07-08 15:52:31.1569 UTC random_forest.cc:802] Training of tree  131/300 (tree index:130) done accuracy:0.709058 logloss:3.66024\n",
      "[INFO 23-07-08 15:52:31.1885 UTC random_forest.cc:802] Training of tree  141/300 (tree index:140) done accuracy:0.710843 logloss:3.64611\n",
      "[INFO 23-07-08 15:52:31.2215 UTC random_forest.cc:802] Training of tree  151/300 (tree index:150) done accuracy:0.711736 logloss:3.63176\n",
      "[INFO 23-07-08 15:52:31.2550 UTC random_forest.cc:802] Training of tree  161/300 (tree index:160) done accuracy:0.711736 logloss:3.63327\n",
      "[INFO 23-07-08 15:52:31.2885 UTC random_forest.cc:802] Training of tree  171/300 (tree index:170) done accuracy:0.712628 logloss:3.63305\n",
      "[INFO 23-07-08 15:52:31.3215 UTC random_forest.cc:802] Training of tree  181/300 (tree index:180) done accuracy:0.71129 logloss:3.60535\n",
      "[INFO 23-07-08 15:52:31.3537 UTC random_forest.cc:802] Training of tree  191/300 (tree index:190) done accuracy:0.710843 logloss:3.56285\n",
      "[INFO 23-07-08 15:52:31.3895 UTC random_forest.cc:802] Training of tree  201/300 (tree index:200) done accuracy:0.709058 logloss:3.53335\n",
      "[INFO 23-07-08 15:52:31.4216 UTC random_forest.cc:802] Training of tree  211/300 (tree index:210) done accuracy:0.708166 logloss:3.53472\n",
      "[INFO 23-07-08 15:52:31.4539 UTC random_forest.cc:802] Training of tree  221/300 (tree index:220) done accuracy:0.708612 logloss:3.50685\n",
      "[INFO 23-07-08 15:52:31.4879 UTC random_forest.cc:802] Training of tree  231/300 (tree index:230) done accuracy:0.705935 logloss:3.49128\n",
      "[INFO 23-07-08 15:52:31.5207 UTC random_forest.cc:802] Training of tree  241/300 (tree index:240) done accuracy:0.70772 logloss:3.35077\n",
      "[INFO 23-07-08 15:52:31.5521 UTC random_forest.cc:802] Training of tree  251/300 (tree index:250) done accuracy:0.708612 logloss:3.33764\n",
      "[INFO 23-07-08 15:52:31.5854 UTC random_forest.cc:802] Training of tree  261/300 (tree index:260) done accuracy:0.707274 logloss:3.32324\n",
      "[INFO 23-07-08 15:52:31.6184 UTC random_forest.cc:802] Training of tree  271/300 (tree index:270) done accuracy:0.707274 logloss:3.26521\n",
      "[INFO 23-07-08 15:52:31.6505 UTC random_forest.cc:802] Training of tree  281/300 (tree index:280) done accuracy:0.705042 logloss:3.25093\n",
      "[INFO 23-07-08 15:52:31.6844 UTC random_forest.cc:802] Training of tree  291/300 (tree index:290) done accuracy:0.704596 logloss:3.2527\n",
      "[INFO 23-07-08 15:52:31.7160 UTC random_forest.cc:802] Training of tree  300/300 (tree index:299) done accuracy:0.705042 logloss:3.25254\n",
      "[INFO 23-07-08 15:52:31.7199 UTC random_forest.cc:882] Final OOB metrics: accuracy:0.705042 logloss:3.25254\n",
      "[INFO 23-07-08 15:52:31.7281 UTC hyperparameters_optimizer.cc:582] [25/50] Score: 0.705042 / 0.741187 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 16 } } fields { name: \"min_examples\" value { integer: 40 } }\n",
      "[INFO 23-07-08 15:52:31.7364 UTC random_forest.cc:416] Training random forest on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-08 15:52:31.7680 UTC random_forest.cc:802] Training of tree  1/300 (tree index:0) done accuracy:0.705811 logloss:10.6036\n",
      "[INFO 23-07-08 15:52:31.8988 UTC random_forest.cc:802] Training of tree  11/300 (tree index:10) done accuracy:0.714157 logloss:6.61877\n",
      "[INFO 23-07-08 15:52:32.0268 UTC random_forest.cc:802] Training of tree  21/300 (tree index:20) done accuracy:0.729139 logloss:5.17298\n",
      "[INFO 23-07-08 15:52:32.1541 UTC random_forest.cc:802] Training of tree  31/300 (tree index:30) done accuracy:0.729139 logloss:4.62526\n",
      "[INFO 23-07-08 15:52:32.2813 UTC random_forest.cc:802] Training of tree  41/300 (tree index:40) done accuracy:0.729139 logloss:4.19503\n",
      "[INFO 23-07-08 15:52:32.4105 UTC random_forest.cc:802] Training of tree  51/300 (tree index:50) done accuracy:0.724676 logloss:4.04593\n",
      "[INFO 23-07-08 15:52:32.5408 UTC random_forest.cc:802] Training of tree  61/300 (tree index:60) done accuracy:0.726461 logloss:4.00546\n",
      "[INFO 23-07-08 15:52:32.6688 UTC random_forest.cc:802] Training of tree  71/300 (tree index:70) done accuracy:0.726461 logloss:3.78488\n",
      "[INFO 23-07-08 15:52:32.7952 UTC random_forest.cc:802] Training of tree  81/300 (tree index:80) done accuracy:0.726908 logloss:3.69206\n",
      "[INFO 23-07-08 15:52:32.9216 UTC random_forest.cc:802] Training of tree  91/300 (tree index:90) done accuracy:0.730477 logloss:3.56118\n",
      "[INFO 23-07-08 15:52:33.0553 UTC random_forest.cc:802] Training of tree  101/300 (tree index:100) done accuracy:0.73137 logloss:3.47524\n",
      "[INFO 23-07-08 15:52:33.1850 UTC random_forest.cc:802] Training of tree  111/300 (tree index:110) done accuracy:0.732262 logloss:3.40296\n",
      "[INFO 23-07-08 15:52:33.3129 UTC random_forest.cc:802] Training of tree  121/300 (tree index:120) done accuracy:0.73494 logloss:3.36064\n",
      "[INFO 23-07-08 15:52:33.4459 UTC random_forest.cc:802] Training of tree  131/300 (tree index:130) done accuracy:0.736725 logloss:3.30409\n",
      "[INFO 23-07-08 15:52:33.5754 UTC random_forest.cc:802] Training of tree  141/300 (tree index:140) done accuracy:0.73494 logloss:3.26287\n",
      "[INFO 23-07-08 15:52:33.7031 UTC random_forest.cc:802] Training of tree  151/300 (tree index:150) done accuracy:0.734047 logloss:3.24814\n",
      "[INFO 23-07-08 15:52:33.8333 UTC random_forest.cc:802] Training of tree  161/300 (tree index:160) done accuracy:0.735386 logloss:3.2076\n",
      "[INFO 23-07-08 15:52:33.9632 UTC random_forest.cc:802] Training of tree  171/300 (tree index:170) done accuracy:0.735386 logloss:3.17938\n",
      "[INFO 23-07-08 15:52:34.0889 UTC random_forest.cc:802] Training of tree  181/300 (tree index:180) done accuracy:0.735832 logloss:3.1797\n",
      "[INFO 23-07-08 15:52:34.2167 UTC random_forest.cc:802] Training of tree  191/300 (tree index:190) done accuracy:0.734494 logloss:3.06529\n",
      "[INFO 23-07-08 15:52:34.3455 UTC random_forest.cc:802] Training of tree  201/300 (tree index:200) done accuracy:0.736278 logloss:3.05029\n",
      "[INFO 23-07-08 15:52:34.4747 UTC random_forest.cc:802] Training of tree  211/300 (tree index:210) done accuracy:0.735386 logloss:3.00888\n",
      "[INFO 23-07-08 15:52:34.6011 UTC random_forest.cc:802] Training of tree  221/300 (tree index:220) done accuracy:0.736278 logloss:3.00955\n",
      "[INFO 23-07-08 15:52:34.7328 UTC random_forest.cc:802] Training of tree  231/300 (tree index:230) done accuracy:0.735832 logloss:2.99604\n",
      "[INFO 23-07-08 15:52:34.8680 UTC random_forest.cc:802] Training of tree  241/300 (tree index:240) done accuracy:0.73851 logloss:2.9385\n",
      "[INFO 23-07-08 15:52:35.0015 UTC random_forest.cc:802] Training of tree  251/300 (tree index:250) done accuracy:0.73851 logloss:2.92462\n",
      "[INFO 23-07-08 15:52:35.1337 UTC random_forest.cc:802] Training of tree  261/300 (tree index:260) done accuracy:0.73494 logloss:2.91002\n",
      "[INFO 23-07-08 15:52:35.2664 UTC random_forest.cc:802] Training of tree  271/300 (tree index:270) done accuracy:0.736725 logloss:2.91112\n",
      "[INFO 23-07-08 15:52:35.4009 UTC random_forest.cc:802] Training of tree  281/300 (tree index:280) done accuracy:0.738063 logloss:2.89743\n",
      "[INFO 23-07-08 15:52:35.5312 UTC random_forest.cc:802] Training of tree  291/300 (tree index:290) done accuracy:0.738063 logloss:2.88439\n",
      "[INFO 23-07-08 15:52:35.6501 UTC random_forest.cc:802] Training of tree  300/300 (tree index:299) done accuracy:0.738063 logloss:2.85583\n",
      "[INFO 23-07-08 15:52:35.6549 UTC random_forest.cc:882] Final OOB metrics: accuracy:0.738063 logloss:2.85583\n",
      "[INFO 23-07-08 15:52:35.6925 UTC hyperparameters_optimizer.cc:582] [26/50] Score: 0.738063 / 0.741187 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"min_examples\" value { integer: 2 } }\n",
      "[INFO 23-07-08 15:52:35.7055 UTC random_forest.cc:416] Training random forest on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-08 15:52:35.7395 UTC random_forest.cc:802] Training of tree  1/300 (tree index:0) done accuracy:0.716707 logloss:10.2109\n",
      "[INFO 23-07-08 15:52:35.8749 UTC random_forest.cc:802] Training of tree  11/300 (tree index:10) done accuracy:0.717303 logloss:6.53681\n",
      "[INFO 23-07-08 15:52:35.9943 UTC random_forest.cc:802] Training of tree  21/300 (tree index:20) done accuracy:0.730477 logloss:5.48935\n",
      "[INFO 23-07-08 15:52:36.1130 UTC random_forest.cc:802] Training of tree  31/300 (tree index:30) done accuracy:0.728246 logloss:4.88399\n",
      "[INFO 23-07-08 15:52:36.2314 UTC random_forest.cc:802] Training of tree  41/300 (tree index:40) done accuracy:0.73494 logloss:4.54454\n",
      "[INFO 23-07-08 15:52:36.3518 UTC random_forest.cc:802] Training of tree  51/300 (tree index:50) done accuracy:0.73137 logloss:4.35551\n",
      "[INFO 23-07-08 15:52:36.4753 UTC random_forest.cc:802] Training of tree  61/300 (tree index:60) done accuracy:0.73494 logloss:4.1666\n",
      "[INFO 23-07-08 15:52:36.6001 UTC random_forest.cc:802] Training of tree  71/300 (tree index:70) done accuracy:0.736725 logloss:3.89251\n",
      "[INFO 23-07-08 15:52:36.7228 UTC random_forest.cc:802] Training of tree  81/300 (tree index:80) done accuracy:0.733155 logloss:3.7622\n",
      "[INFO 23-07-08 15:52:36.8439 UTC random_forest.cc:802] Training of tree  91/300 (tree index:90) done accuracy:0.736278 logloss:3.67715\n",
      "[INFO 23-07-08 15:52:36.9653 UTC random_forest.cc:802] Training of tree  101/300 (tree index:100) done accuracy:0.736278 logloss:3.63581\n",
      "[INFO 23-07-08 15:52:37.0866 UTC random_forest.cc:802] Training of tree  111/300 (tree index:110) done accuracy:0.736278 logloss:3.54806\n",
      "[INFO 23-07-08 15:52:37.2075 UTC random_forest.cc:802] Training of tree  121/300 (tree index:120) done accuracy:0.738063 logloss:3.47819\n",
      "[INFO 23-07-08 15:52:37.3285 UTC random_forest.cc:802] Training of tree  131/300 (tree index:130) done accuracy:0.738956 logloss:3.38984\n",
      "[INFO 23-07-08 15:52:37.4457 UTC random_forest.cc:802] Training of tree  141/300 (tree index:140) done accuracy:0.739402 logloss:3.33103\n",
      "[INFO 23-07-08 15:52:37.5668 UTC random_forest.cc:802] Training of tree  151/300 (tree index:150) done accuracy:0.73851 logloss:3.28876\n",
      "[INFO 23-07-08 15:52:37.6890 UTC random_forest.cc:802] Training of tree  161/300 (tree index:160) done accuracy:0.738063 logloss:3.26062\n",
      "[INFO 23-07-08 15:52:37.8091 UTC random_forest.cc:802] Training of tree  171/300 (tree index:170) done accuracy:0.737171 logloss:3.20131\n",
      "[INFO 23-07-08 15:52:37.9312 UTC random_forest.cc:802] Training of tree  181/300 (tree index:180) done accuracy:0.739848 logloss:3.18617\n",
      "[INFO 23-07-08 15:52:38.0529 UTC random_forest.cc:802] Training of tree  191/300 (tree index:190) done accuracy:0.738956 logloss:3.17221\n",
      "[INFO 23-07-08 15:52:38.1737 UTC random_forest.cc:802] Training of tree  201/300 (tree index:200) done accuracy:0.739402 logloss:3.12874\n",
      "[INFO 23-07-08 15:52:38.2944 UTC random_forest.cc:802] Training of tree  211/300 (tree index:210) done accuracy:0.739848 logloss:3.12767\n",
      "[INFO 23-07-08 15:52:38.4150 UTC random_forest.cc:802] Training of tree  221/300 (tree index:220) done accuracy:0.739402 logloss:3.1293\n",
      "[INFO 23-07-08 15:52:38.5359 UTC random_forest.cc:802] Training of tree  231/300 (tree index:230) done accuracy:0.739848 logloss:3.03213\n",
      "[INFO 23-07-08 15:52:38.6560 UTC random_forest.cc:802] Training of tree  241/300 (tree index:240) done accuracy:0.741633 logloss:3.003\n",
      "[INFO 23-07-08 15:52:38.7760 UTC random_forest.cc:802] Training of tree  251/300 (tree index:250) done accuracy:0.741187 logloss:3.0034\n",
      "[INFO 23-07-08 15:52:38.8988 UTC random_forest.cc:802] Training of tree  261/300 (tree index:260) done accuracy:0.741187 logloss:3.00202\n",
      "[INFO 23-07-08 15:52:39.0244 UTC random_forest.cc:802] Training of tree  271/300 (tree index:270) done accuracy:0.740295 logloss:2.97425\n",
      "[INFO 23-07-08 15:52:39.1468 UTC random_forest.cc:802] Training of tree  281/300 (tree index:280) done accuracy:0.739402 logloss:2.96008\n",
      "[INFO 23-07-08 15:52:39.2671 UTC random_forest.cc:802] Training of tree  291/300 (tree index:290) done accuracy:0.741187 logloss:2.93156\n",
      "[INFO 23-07-08 15:52:39.3770 UTC random_forest.cc:802] Training of tree  300/300 (tree index:299) done accuracy:0.739402 logloss:2.91823\n",
      "[INFO 23-07-08 15:52:39.3808 UTC random_forest.cc:882] Final OOB metrics: accuracy:0.739402 logloss:2.91823\n",
      "[INFO 23-07-08 15:52:39.4093 UTC hyperparameters_optimizer.cc:582] [27/50] Score: 0.739402 / 0.741187 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 30 } } fields { name: \"min_examples\" value { integer: 5 } }\n",
      "[INFO 23-07-08 15:52:39.4312 UTC random_forest.cc:416] Training random forest on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-08 15:52:39.4899 UTC random_forest.cc:802] Training of tree  1/300 (tree index:0) done accuracy:0.730024 logloss:9.73091\n",
      "[INFO 23-07-08 15:52:39.5463 UTC random_forest.cc:802] Training of tree  11/300 (tree index:10) done accuracy:0.716854 logloss:6.7069\n",
      "[INFO 23-07-08 15:52:39.6043 UTC random_forest.cc:802] Training of tree  21/300 (tree index:20) done accuracy:0.722892 logloss:5.53166\n",
      "[INFO 23-07-08 15:52:39.6619 UTC random_forest.cc:802] Training of tree  31/300 (tree index:30) done accuracy:0.730477 logloss:4.83058\n",
      "[INFO 23-07-08 15:52:39.7211 UTC random_forest.cc:802] Training of tree  41/300 (tree index:40) done accuracy:0.732709 logloss:4.5775\n",
      "[INFO 23-07-08 15:52:39.7806 UTC random_forest.cc:802] Training of tree  51/300 (tree index:50) done accuracy:0.73137 logloss:4.40223\n",
      "[INFO 23-07-08 15:52:39.8364 UTC random_forest.cc:802] Training of tree  61/300 (tree index:60) done accuracy:0.73137 logloss:4.19695\n",
      "[INFO 23-07-08 15:52:39.8979 UTC random_forest.cc:802] Training of tree  71/300 (tree index:70) done accuracy:0.730031 logloss:3.99113\n",
      "[INFO 23-07-08 15:52:39.9582 UTC random_forest.cc:802] Training of tree  81/300 (tree index:80) done accuracy:0.732262 logloss:3.89057\n",
      "[INFO 23-07-08 15:52:40.0168 UTC random_forest.cc:802] Training of tree  91/300 (tree index:90) done accuracy:0.737617 logloss:3.80411\n",
      "[INFO 23-07-08 15:52:40.0729 UTC random_forest.cc:802] Training of tree  101/300 (tree index:100) done accuracy:0.735832 logloss:3.7034\n",
      "[INFO 23-07-08 15:52:40.1307 UTC random_forest.cc:802] Training of tree  111/300 (tree index:110) done accuracy:0.735386 logloss:3.63\n",
      "[INFO 23-07-08 15:52:40.1875 UTC random_forest.cc:802] Training of tree  121/300 (tree index:120) done accuracy:0.735832 logloss:3.60093\n",
      "[INFO 23-07-08 15:52:40.2462 UTC random_forest.cc:802] Training of tree  131/300 (tree index:130) done accuracy:0.738063 logloss:3.52744\n",
      "[INFO 23-07-08 15:52:40.3028 UTC random_forest.cc:802] Training of tree  141/300 (tree index:140) done accuracy:0.737617 logloss:3.47108\n",
      "[INFO 23-07-08 15:52:40.3599 UTC random_forest.cc:802] Training of tree  151/300 (tree index:150) done accuracy:0.738063 logloss:3.42785\n",
      "[INFO 23-07-08 15:52:40.4193 UTC random_forest.cc:802] Training of tree  161/300 (tree index:160) done accuracy:0.737617 logloss:3.35795\n",
      "[INFO 23-07-08 15:52:40.4780 UTC random_forest.cc:802] Training of tree  171/300 (tree index:170) done accuracy:0.737171 logloss:3.35953\n",
      "[INFO 23-07-08 15:52:40.5342 UTC random_forest.cc:802] Training of tree  181/300 (tree index:180) done accuracy:0.73851 logloss:3.33183\n",
      "[INFO 23-07-08 15:52:40.5907 UTC random_forest.cc:802] Training of tree  191/300 (tree index:190) done accuracy:0.738956 logloss:3.31968\n",
      "[INFO 23-07-08 15:52:40.6495 UTC random_forest.cc:802] Training of tree  201/300 (tree index:200) done accuracy:0.73851 logloss:3.2469\n",
      "[INFO 23-07-08 15:52:40.7096 UTC random_forest.cc:802] Training of tree  211/300 (tree index:210) done accuracy:0.738063 logloss:3.24686\n",
      "[INFO 23-07-08 15:52:40.7684 UTC random_forest.cc:802] Training of tree  221/300 (tree index:220) done accuracy:0.73851 logloss:3.20529\n",
      "[INFO 23-07-08 15:52:40.8244 UTC random_forest.cc:802] Training of tree  231/300 (tree index:230) done accuracy:0.735386 logloss:3.17724\n",
      "[INFO 23-07-08 15:52:40.8862 UTC random_forest.cc:802] Training of tree  241/300 (tree index:240) done accuracy:0.737617 logloss:3.17701\n",
      "[INFO 23-07-08 15:52:40.9430 UTC random_forest.cc:802] Training of tree  251/300 (tree index:250) done accuracy:0.737617 logloss:3.1624\n",
      "[INFO 23-07-08 15:52:41.0028 UTC random_forest.cc:802] Training of tree  261/300 (tree index:260) done accuracy:0.73851 logloss:3.1466\n",
      "[INFO 23-07-08 15:52:41.0611 UTC random_forest.cc:802] Training of tree  271/300 (tree index:270) done accuracy:0.737617 logloss:3.1331\n",
      "[INFO 23-07-08 15:52:41.1178 UTC random_forest.cc:802] Training of tree  281/300 (tree index:280) done accuracy:0.73851 logloss:3.11929\n",
      "[INFO 23-07-08 15:52:41.1761 UTC random_forest.cc:802] Training of tree  291/300 (tree index:290) done accuracy:0.736725 logloss:3.11908\n",
      "[INFO 23-07-08 15:52:41.2314 UTC random_forest.cc:802] Training of tree  300/300 (tree index:299) done accuracy:0.737171 logloss:3.105\n",
      "[INFO 23-07-08 15:52:41.2357 UTC random_forest.cc:882] Final OOB metrics: accuracy:0.737171 logloss:3.105\n",
      "[INFO 23-07-08 15:52:41.2645 UTC hyperparameters_optimizer.cc:582] [28/50] Score: 0.737171 / 0.741187 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 25 } } fields { name: \"min_examples\" value { integer: 5 } }\n",
      "[INFO 23-07-08 15:52:41.2775 UTC random_forest.cc:416] Training random forest on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-08 15:52:41.3557 UTC random_forest.cc:802] Training of tree  1/300 (tree index:0) done accuracy:0.725182 logloss:9.90546\n",
      "[INFO 23-07-08 15:52:41.4359 UTC random_forest.cc:802] Training of tree  11/300 (tree index:10) done accuracy:0.712809 logloss:6.71779\n",
      "[INFO 23-07-08 15:52:41.5110 UTC random_forest.cc:802] Training of tree  21/300 (tree index:20) done accuracy:0.718429 logloss:5.86332\n",
      "[INFO 23-07-08 15:52:41.5876 UTC random_forest.cc:802] Training of tree  31/300 (tree index:30) done accuracy:0.716644 logloss:5.3589\n",
      "[INFO 23-07-08 15:52:41.6649 UTC random_forest.cc:802] Training of tree  41/300 (tree index:40) done accuracy:0.717091 logloss:5.01699\n",
      "[INFO 23-07-08 15:52:41.7399 UTC random_forest.cc:802] Training of tree  51/300 (tree index:50) done accuracy:0.714413 logloss:4.81324\n",
      "[INFO 23-07-08 15:52:41.8185 UTC random_forest.cc:802] Training of tree  61/300 (tree index:60) done accuracy:0.716198 logloss:4.57938\n",
      "[INFO 23-07-08 15:52:41.8963 UTC random_forest.cc:802] Training of tree  71/300 (tree index:70) done accuracy:0.712628 logloss:4.33354\n",
      "[INFO 23-07-08 15:52:41.9717 UTC random_forest.cc:802] Training of tree  81/300 (tree index:80) done accuracy:0.719322 logloss:4.1302\n",
      "[INFO 23-07-08 15:52:42.0467 UTC random_forest.cc:802] Training of tree  91/300 (tree index:90) done accuracy:0.721999 logloss:4.08846\n",
      "[INFO 23-07-08 15:52:42.1214 UTC random_forest.cc:802] Training of tree  101/300 (tree index:100) done accuracy:0.722892 logloss:4.01709\n",
      "[INFO 23-07-08 15:52:42.1988 UTC random_forest.cc:802] Training of tree  111/300 (tree index:110) done accuracy:0.720214 logloss:3.93109\n",
      "[INFO 23-07-08 15:52:42.2748 UTC random_forest.cc:802] Training of tree  121/300 (tree index:120) done accuracy:0.721999 logloss:3.88842\n",
      "[INFO 23-07-08 15:52:42.3490 UTC random_forest.cc:802] Training of tree  131/300 (tree index:130) done accuracy:0.719322 logloss:3.81726\n",
      "[INFO 23-07-08 15:52:42.4231 UTC random_forest.cc:802] Training of tree  141/300 (tree index:140) done accuracy:0.720214 logloss:3.78882\n",
      "[INFO 23-07-08 15:52:42.5003 UTC random_forest.cc:802] Training of tree  151/300 (tree index:150) done accuracy:0.721999 logloss:3.74727\n",
      "[INFO 23-07-08 15:52:42.5748 UTC random_forest.cc:802] Training of tree  161/300 (tree index:160) done accuracy:0.722892 logloss:3.70431\n",
      "[INFO 23-07-08 15:52:42.6523 UTC random_forest.cc:802] Training of tree  171/300 (tree index:170) done accuracy:0.721107 logloss:3.64864\n",
      "[INFO 23-07-08 15:52:42.7284 UTC random_forest.cc:802] Training of tree  181/300 (tree index:180) done accuracy:0.722445 logloss:3.60579\n",
      "[INFO 23-07-08 15:52:42.8051 UTC random_forest.cc:802] Training of tree  191/300 (tree index:190) done accuracy:0.722445 logloss:3.59373\n",
      "[INFO 23-07-08 15:52:42.8808 UTC random_forest.cc:802] Training of tree  201/300 (tree index:200) done accuracy:0.720214 logloss:3.52027\n",
      "[INFO 23-07-08 15:52:42.9600 UTC random_forest.cc:802] Training of tree  211/300 (tree index:210) done accuracy:0.719768 logloss:3.49183\n",
      "[INFO 23-07-08 15:52:43.0368 UTC random_forest.cc:802] Training of tree  221/300 (tree index:220) done accuracy:0.718876 logloss:3.46435\n",
      "[INFO 23-07-08 15:52:43.1130 UTC random_forest.cc:802] Training of tree  231/300 (tree index:230) done accuracy:0.72066 logloss:3.43593\n",
      "[INFO 23-07-08 15:52:43.1885 UTC random_forest.cc:802] Training of tree  241/300 (tree index:240) done accuracy:0.721553 logloss:3.43634\n",
      "[INFO 23-07-08 15:52:43.2663 UTC random_forest.cc:802] Training of tree  251/300 (tree index:250) done accuracy:0.721107 logloss:3.43588\n",
      "[INFO 23-07-08 15:52:43.3449 UTC random_forest.cc:802] Training of tree  261/300 (tree index:260) done accuracy:0.720214 logloss:3.4198\n",
      "[INFO 23-07-08 15:52:43.4242 UTC random_forest.cc:802] Training of tree  271/300 (tree index:270) done accuracy:0.72066 logloss:3.40638\n",
      "[INFO 23-07-08 15:52:43.5016 UTC random_forest.cc:802] Training of tree  281/300 (tree index:280) done accuracy:0.721553 logloss:3.40654\n",
      "[INFO 23-07-08 15:52:43.5797 UTC random_forest.cc:802] Training of tree  291/300 (tree index:290) done accuracy:0.721999 logloss:3.4051\n",
      "[INFO 23-07-08 15:52:43.6538 UTC random_forest.cc:802] Training of tree  300/300 (tree index:299) done accuracy:0.72066 logloss:3.40527\n",
      "[INFO 23-07-08 15:52:43.6572 UTC random_forest.cc:882] Final OOB metrics: accuracy:0.72066 logloss:3.40527\n",
      "[INFO 23-07-08 15:52:43.7116 UTC hyperparameters_optimizer.cc:582] [29/50] Score: 0.72066 / 0.741187 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 20 } } fields { name: \"min_examples\" value { integer: 1 } }\n",
      "[INFO 23-07-08 15:52:43.7241 UTC random_forest.cc:416] Training random forest on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-08 15:52:43.8021 UTC random_forest.cc:802] Training of tree  1/300 (tree index:0) done accuracy:0.717918 logloss:10.1673\n",
      "[INFO 23-07-08 15:52:43.9458 UTC random_forest.cc:802] Training of tree  11/300 (tree index:10) done accuracy:0.719551 logloss:6.71844\n",
      "[INFO 23-07-08 15:52:44.0875 UTC random_forest.cc:802] Training of tree  21/300 (tree index:20) done accuracy:0.724676 logloss:5.74322\n",
      "[INFO 23-07-08 15:52:44.2276 UTC random_forest.cc:802] Training of tree  31/300 (tree index:30) done accuracy:0.719768 logloss:5.16457\n",
      "[INFO 23-07-08 15:52:44.3653 UTC random_forest.cc:802] Training of tree  41/300 (tree index:40) done accuracy:0.722445 logloss:4.86701\n",
      "[INFO 23-07-08 15:52:44.5063 UTC random_forest.cc:802] Training of tree  51/300 (tree index:50) done accuracy:0.718429 logloss:4.76865\n",
      "[INFO 23-07-08 15:52:44.6520 UTC random_forest.cc:802] Training of tree  61/300 (tree index:60) done accuracy:0.720214 logloss:4.53644\n",
      "[INFO 23-07-08 15:52:44.7943 UTC random_forest.cc:802] Training of tree  71/300 (tree index:70) done accuracy:0.718429 logloss:4.31984\n",
      "[INFO 23-07-08 15:52:44.9366 UTC random_forest.cc:802] Training of tree  81/300 (tree index:80) done accuracy:0.721107 logloss:4.1595\n",
      "[INFO 23-07-08 15:52:45.0782 UTC random_forest.cc:802] Training of tree  91/300 (tree index:90) done accuracy:0.721553 logloss:4.10379\n",
      "[INFO 23-07-08 15:52:45.2207 UTC random_forest.cc:802] Training of tree  101/300 (tree index:100) done accuracy:0.721999 logloss:4.03224\n",
      "[INFO 23-07-08 15:52:45.3653 UTC random_forest.cc:802] Training of tree  111/300 (tree index:110) done accuracy:0.721107 logloss:3.97416\n",
      "[INFO 23-07-08 15:52:45.5089 UTC random_forest.cc:802] Training of tree  121/300 (tree index:120) done accuracy:0.720214 logloss:3.90236\n",
      "[INFO 23-07-08 15:52:45.6536 UTC random_forest.cc:802] Training of tree  131/300 (tree index:130) done accuracy:0.719768 logloss:3.80166\n",
      "[INFO 23-07-08 15:52:45.7956 UTC random_forest.cc:802] Training of tree  141/300 (tree index:140) done accuracy:0.719322 logloss:3.74506\n",
      "[INFO 23-07-08 15:52:45.9427 UTC random_forest.cc:802] Training of tree  151/300 (tree index:150) done accuracy:0.721999 logloss:3.71658\n",
      "[INFO 23-07-08 15:52:46.0852 UTC random_forest.cc:802] Training of tree  161/300 (tree index:160) done accuracy:0.720214 logloss:3.64652\n",
      "[INFO 23-07-08 15:52:46.2308 UTC random_forest.cc:802] Training of tree  171/300 (tree index:170) done accuracy:0.718876 logloss:3.60469\n",
      "[INFO 23-07-08 15:52:46.3723 UTC random_forest.cc:802] Training of tree  181/300 (tree index:180) done accuracy:0.720214 logloss:3.56322\n",
      "[INFO 23-07-08 15:52:46.5130 UTC random_forest.cc:802] Training of tree  191/300 (tree index:190) done accuracy:0.721107 logloss:3.54877\n",
      "[INFO 23-07-08 15:52:46.6564 UTC random_forest.cc:802] Training of tree  201/300 (tree index:200) done accuracy:0.719768 logloss:3.50304\n",
      "[INFO 23-07-08 15:52:46.8043 UTC random_forest.cc:802] Training of tree  211/300 (tree index:210) done accuracy:0.718876 logloss:3.47443\n",
      "[INFO 23-07-08 15:52:46.9485 UTC random_forest.cc:802] Training of tree  221/300 (tree index:220) done accuracy:0.719322 logloss:3.47561\n",
      "[INFO 23-07-08 15:52:47.0895 UTC random_forest.cc:802] Training of tree  231/300 (tree index:230) done accuracy:0.719322 logloss:3.46114\n",
      "[INFO 23-07-08 15:52:47.2341 UTC random_forest.cc:802] Training of tree  241/300 (tree index:240) done accuracy:0.719322 logloss:3.46086\n",
      "[INFO 23-07-08 15:52:47.3761 UTC random_forest.cc:802] Training of tree  251/300 (tree index:250) done accuracy:0.718429 logloss:3.46087\n",
      "[INFO 23-07-08 15:52:47.5193 UTC random_forest.cc:802] Training of tree  261/300 (tree index:260) done accuracy:0.718876 logloss:3.44454\n",
      "[INFO 23-07-08 15:52:47.6666 UTC random_forest.cc:802] Training of tree  271/300 (tree index:270) done accuracy:0.717537 logloss:3.41778\n",
      "[INFO 23-07-08 15:52:47.8131 UTC random_forest.cc:802] Training of tree  281/300 (tree index:280) done accuracy:0.718429 logloss:3.40366\n",
      "[INFO 23-07-08 15:52:47.9556 UTC random_forest.cc:802] Training of tree  291/300 (tree index:290) done accuracy:0.719768 logloss:3.40292\n",
      "[INFO 23-07-08 15:52:48.0854 UTC random_forest.cc:802] Training of tree  300/300 (tree index:299) done accuracy:0.718876 logloss:3.36162\n",
      "[INFO 23-07-08 15:52:48.0887 UTC random_forest.cc:882] Final OOB metrics: accuracy:0.718876 logloss:3.36162\n",
      "[INFO 23-07-08 15:52:48.1368 UTC hyperparameters_optimizer.cc:582] [30/50] Score: 0.718876 / 0.741187 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 25 } } fields { name: \"min_examples\" value { integer: 1 } }\n",
      "[INFO 23-07-08 15:52:48.1478 UTC random_forest.cc:416] Training random forest on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-08 15:52:48.1895 UTC random_forest.cc:802] Training of tree  1/300 (tree index:0) done accuracy:0.717918 logloss:10.1673\n",
      "[INFO 23-07-08 15:52:48.2758 UTC random_forest.cc:802] Training of tree  11/300 (tree index:10) done accuracy:0.713258 logloss:6.72125\n",
      "[INFO 23-07-08 15:52:48.3435 UTC random_forest.cc:802] Training of tree  21/300 (tree index:20) done accuracy:0.721999 logloss:5.75432\n",
      "[INFO 23-07-08 15:52:48.4103 UTC random_forest.cc:802] Training of tree  31/300 (tree index:30) done accuracy:0.723338 logloss:5.14663\n",
      "[INFO 23-07-08 15:52:48.4801 UTC random_forest.cc:802] Training of tree  41/300 (tree index:40) done accuracy:0.725123 logloss:4.7304\n",
      "[INFO 23-07-08 15:52:48.5507 UTC random_forest.cc:802] Training of tree  51/300 (tree index:50) done accuracy:0.72066 logloss:4.52445\n",
      "[INFO 23-07-08 15:52:48.6203 UTC random_forest.cc:802] Training of tree  61/300 (tree index:60) done accuracy:0.721553 logloss:4.33619\n",
      "[INFO 23-07-08 15:52:48.6902 UTC random_forest.cc:802] Training of tree  71/300 (tree index:70) done accuracy:0.717983 logloss:4.13479\n",
      "[INFO 23-07-08 15:52:48.7598 UTC random_forest.cc:802] Training of tree  81/300 (tree index:80) done accuracy:0.721107 logloss:3.99013\n",
      "[INFO 23-07-08 15:52:48.8299 UTC random_forest.cc:802] Training of tree  91/300 (tree index:90) done accuracy:0.723338 logloss:3.93347\n",
      "[INFO 23-07-08 15:52:48.8998 UTC random_forest.cc:802] Training of tree  101/300 (tree index:100) done accuracy:0.723338 logloss:3.86142\n",
      "[INFO 23-07-08 15:52:48.9713 UTC random_forest.cc:802] Training of tree  111/300 (tree index:110) done accuracy:0.723784 logloss:3.76066\n",
      "[INFO 23-07-08 15:52:49.0436 UTC random_forest.cc:802] Training of tree  121/300 (tree index:120) done accuracy:0.727354 logloss:3.68956\n",
      "[INFO 23-07-08 15:52:49.1148 UTC random_forest.cc:802] Training of tree  131/300 (tree index:130) done accuracy:0.729139 logloss:3.60306\n",
      "[INFO 23-07-08 15:52:49.1866 UTC random_forest.cc:802] Training of tree  141/300 (tree index:140) done accuracy:0.727354 logloss:3.54629\n",
      "[INFO 23-07-08 15:52:49.2648 UTC random_forest.cc:802] Training of tree  151/300 (tree index:150) done accuracy:0.726015 logloss:3.53258\n",
      "[INFO 23-07-08 15:52:49.3371 UTC random_forest.cc:802] Training of tree  161/300 (tree index:160) done accuracy:0.726461 logloss:3.44608\n",
      "[INFO 23-07-08 15:52:49.4091 UTC random_forest.cc:802] Training of tree  171/300 (tree index:170) done accuracy:0.727354 logloss:3.43304\n",
      "[INFO 23-07-08 15:52:49.4790 UTC random_forest.cc:802] Training of tree  181/300 (tree index:180) done accuracy:0.726908 logloss:3.43218\n",
      "[INFO 23-07-08 15:52:49.5486 UTC random_forest.cc:802] Training of tree  191/300 (tree index:190) done accuracy:0.725569 logloss:3.39048\n",
      "[INFO 23-07-08 15:52:49.6181 UTC random_forest.cc:802] Training of tree  201/300 (tree index:200) done accuracy:0.726015 logloss:3.35902\n",
      "[INFO 23-07-08 15:52:49.6870 UTC random_forest.cc:802] Training of tree  211/300 (tree index:210) done accuracy:0.723784 logloss:3.35835\n",
      "[INFO 23-07-08 15:52:49.7566 UTC random_forest.cc:802] Training of tree  221/300 (tree index:220) done accuracy:0.726461 logloss:3.34615\n",
      "[INFO 23-07-08 15:52:49.8267 UTC random_forest.cc:802] Training of tree  231/300 (tree index:230) done accuracy:0.725123 logloss:3.31824\n",
      "[INFO 23-07-08 15:52:49.8992 UTC random_forest.cc:802] Training of tree  241/300 (tree index:240) done accuracy:0.727354 logloss:3.27458\n",
      "[INFO 23-07-08 15:52:49.9695 UTC random_forest.cc:802] Training of tree  251/300 (tree index:250) done accuracy:0.725569 logloss:3.27556\n",
      "[INFO 23-07-08 15:52:50.0385 UTC random_forest.cc:802] Training of tree  261/300 (tree index:260) done accuracy:0.725123 logloss:3.25957\n",
      "[INFO 23-07-08 15:52:50.1077 UTC random_forest.cc:802] Training of tree  271/300 (tree index:270) done accuracy:0.725123 logloss:3.2603\n",
      "[INFO 23-07-08 15:52:50.1766 UTC random_forest.cc:802] Training of tree  281/300 (tree index:280) done accuracy:0.726908 logloss:3.26035\n",
      "[INFO 23-07-08 15:52:50.2454 UTC random_forest.cc:802] Training of tree  291/300 (tree index:290) done accuracy:0.7278 logloss:3.24634\n",
      "[INFO 23-07-08 15:52:50.3093 UTC random_forest.cc:802] Training of tree  300/300 (tree index:299) done accuracy:0.725569 logloss:3.21742\n",
      "[INFO 23-07-08 15:52:50.3133 UTC random_forest.cc:882] Final OOB metrics: accuracy:0.725569 logloss:3.21742\n",
      "[INFO 23-07-08 15:52:50.3533 UTC hyperparameters_optimizer.cc:582] [31/50] Score: 0.725569 / 0.741187 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 16 } } fields { name: \"min_examples\" value { integer: 2 } }\n",
      "[INFO 23-07-08 15:52:50.3666 UTC random_forest.cc:416] Training random forest on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-08 15:52:50.4071 UTC random_forest.cc:802] Training of tree  1/300 (tree index:0) done accuracy:0.725182 logloss:9.90546\n",
      "[INFO 23-07-08 15:52:50.5014 UTC random_forest.cc:802] Training of tree  11/300 (tree index:10) done accuracy:0.712809 logloss:6.71779\n",
      "[INFO 23-07-08 15:52:50.5755 UTC random_forest.cc:802] Training of tree  21/300 (tree index:20) done accuracy:0.718429 logloss:5.86332\n",
      "[INFO 23-07-08 15:52:50.6525 UTC random_forest.cc:802] Training of tree  31/300 (tree index:30) done accuracy:0.716644 logloss:5.3589\n",
      "[INFO 23-07-08 15:52:50.7276 UTC random_forest.cc:802] Training of tree  41/300 (tree index:40) done accuracy:0.717091 logloss:5.01699\n",
      "[INFO 23-07-08 15:52:50.8070 UTC random_forest.cc:802] Training of tree  51/300 (tree index:50) done accuracy:0.714413 logloss:4.81324\n",
      "[INFO 23-07-08 15:52:50.8886 UTC random_forest.cc:802] Training of tree  61/300 (tree index:60) done accuracy:0.716198 logloss:4.57938\n",
      "[INFO 23-07-08 15:52:50.9691 UTC random_forest.cc:802] Training of tree  71/300 (tree index:70) done accuracy:0.712628 logloss:4.33354\n",
      "[INFO 23-07-08 15:52:51.0518 UTC random_forest.cc:802] Training of tree  81/300 (tree index:80) done accuracy:0.719322 logloss:4.1302\n",
      "[INFO 23-07-08 15:52:51.1325 UTC random_forest.cc:802] Training of tree  91/300 (tree index:90) done accuracy:0.721999 logloss:4.08846\n",
      "[INFO 23-07-08 15:52:51.2120 UTC random_forest.cc:802] Training of tree  101/300 (tree index:100) done accuracy:0.722892 logloss:4.01709\n",
      "[INFO 23-07-08 15:52:51.2936 UTC random_forest.cc:802] Training of tree  111/300 (tree index:110) done accuracy:0.720214 logloss:3.93109\n",
      "[INFO 23-07-08 15:52:51.3774 UTC random_forest.cc:802] Training of tree  121/300 (tree index:120) done accuracy:0.721999 logloss:3.88842\n",
      "[INFO 23-07-08 15:52:51.4610 UTC random_forest.cc:802] Training of tree  131/300 (tree index:130) done accuracy:0.719322 logloss:3.81726\n",
      "[INFO 23-07-08 15:52:51.5440 UTC random_forest.cc:802] Training of tree  141/300 (tree index:140) done accuracy:0.720214 logloss:3.78882\n",
      "[INFO 23-07-08 15:52:51.6286 UTC random_forest.cc:802] Training of tree  151/300 (tree index:150) done accuracy:0.721999 logloss:3.74727\n",
      "[INFO 23-07-08 15:52:51.7117 UTC random_forest.cc:802] Training of tree  161/300 (tree index:160) done accuracy:0.722892 logloss:3.70431\n",
      "[INFO 23-07-08 15:52:51.7954 UTC random_forest.cc:802] Training of tree  171/300 (tree index:170) done accuracy:0.721107 logloss:3.64864\n",
      "[INFO 23-07-08 15:52:51.8763 UTC random_forest.cc:802] Training of tree  181/300 (tree index:180) done accuracy:0.722445 logloss:3.60579\n",
      "[INFO 23-07-08 15:52:51.9580 UTC random_forest.cc:802] Training of tree  191/300 (tree index:190) done accuracy:0.722445 logloss:3.59373\n",
      "[INFO 23-07-08 15:52:52.0411 UTC random_forest.cc:802] Training of tree  201/300 (tree index:200) done accuracy:0.720214 logloss:3.52027\n",
      "[INFO 23-07-08 15:52:52.1261 UTC random_forest.cc:802] Training of tree  211/300 (tree index:210) done accuracy:0.719768 logloss:3.49183\n",
      "[INFO 23-07-08 15:52:52.2083 UTC random_forest.cc:802] Training of tree  221/300 (tree index:220) done accuracy:0.718876 logloss:3.46435\n",
      "[INFO 23-07-08 15:52:52.2908 UTC random_forest.cc:802] Training of tree  231/300 (tree index:230) done accuracy:0.72066 logloss:3.43593\n",
      "[INFO 23-07-08 15:52:52.3722 UTC random_forest.cc:802] Training of tree  241/300 (tree index:240) done accuracy:0.721553 logloss:3.43634\n",
      "[INFO 23-07-08 15:52:52.4555 UTC random_forest.cc:802] Training of tree  251/300 (tree index:250) done accuracy:0.721107 logloss:3.43588\n",
      "[INFO 23-07-08 15:52:52.5368 UTC random_forest.cc:802] Training of tree  261/300 (tree index:260) done accuracy:0.720214 logloss:3.4198\n",
      "[INFO 23-07-08 15:52:52.6198 UTC random_forest.cc:802] Training of tree  271/300 (tree index:270) done accuracy:0.72066 logloss:3.40638\n",
      "[INFO 23-07-08 15:52:52.7017 UTC random_forest.cc:802] Training of tree  281/300 (tree index:280) done accuracy:0.721553 logloss:3.40654\n",
      "[INFO 23-07-08 15:52:52.7868 UTC random_forest.cc:802] Training of tree  291/300 (tree index:290) done accuracy:0.721999 logloss:3.4051\n",
      "[INFO 23-07-08 15:52:52.8626 UTC random_forest.cc:802] Training of tree  300/300 (tree index:299) done accuracy:0.72066 logloss:3.40527\n",
      "[INFO 23-07-08 15:52:52.8671 UTC random_forest.cc:882] Final OOB metrics: accuracy:0.72066 logloss:3.40527\n",
      "[INFO 23-07-08 15:52:52.9168 UTC hyperparameters_optimizer.cc:582] [32/50] Score: 0.72066 / 0.741187 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 20 } } fields { name: \"min_examples\" value { integer: 1 } }\n",
      "[INFO 23-07-08 15:52:52.9277 UTC random_forest.cc:416] Training random forest on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-08 15:52:53.0302 UTC random_forest.cc:802] Training of tree  1/300 (tree index:0) done accuracy:0.708232 logloss:10.5164\n",
      "[INFO 23-07-08 15:52:53.1508 UTC random_forest.cc:802] Training of tree  11/300 (tree index:10) done accuracy:0.718652 logloss:6.44502\n",
      "[INFO 23-07-08 15:52:53.2690 UTC random_forest.cc:802] Training of tree  21/300 (tree index:20) done accuracy:0.725123 logloss:5.13537\n",
      "[INFO 23-07-08 15:52:53.3884 UTC random_forest.cc:802] Training of tree  31/300 (tree index:30) done accuracy:0.728246 logloss:4.60319\n",
      "[INFO 23-07-08 15:52:53.5076 UTC random_forest.cc:802] Training of tree  41/300 (tree index:40) done accuracy:0.73137 logloss:4.26236\n",
      "[INFO 23-07-08 15:52:53.6295 UTC random_forest.cc:802] Training of tree  51/300 (tree index:50) done accuracy:0.734047 logloss:4.07455\n",
      "[INFO 23-07-08 15:52:53.7535 UTC random_forest.cc:802] Training of tree  61/300 (tree index:60) done accuracy:0.734047 logloss:3.87288\n",
      "[INFO 23-07-08 15:52:54.0290 UTC random_forest.cc:802] Training of tree  71/300 (tree index:70) done accuracy:0.736278 logloss:3.63977\n",
      "[INFO 23-07-08 15:52:54.2668 UTC random_forest.cc:802] Training of tree  81/300 (tree index:80) done accuracy:0.736725 logloss:3.56523\n",
      "[INFO 23-07-08 15:52:54.5010 UTC random_forest.cc:802] Training of tree  91/300 (tree index:90) done accuracy:0.73851 logloss:3.47887\n",
      "[INFO 23-07-08 15:52:54.7370 UTC random_forest.cc:802] Training of tree  101/300 (tree index:100) done accuracy:0.738956 logloss:3.43864\n",
      "[INFO 23-07-08 15:52:54.9756 UTC random_forest.cc:802] Training of tree  111/300 (tree index:110) done accuracy:0.740295 logloss:3.36826\n",
      "[INFO 23-07-08 15:52:55.2180 UTC random_forest.cc:802] Training of tree  121/300 (tree index:120) done accuracy:0.739848 logloss:3.3395\n",
      "[INFO 23-07-08 15:52:55.4901 UTC random_forest.cc:802] Training of tree  131/300 (tree index:130) done accuracy:0.741633 logloss:3.26832\n",
      "[INFO 23-07-08 15:52:55.7280 UTC random_forest.cc:802] Training of tree  141/300 (tree index:140) done accuracy:0.744311 logloss:3.20827\n",
      "[INFO 23-07-08 15:52:55.9611 UTC random_forest.cc:802] Training of tree  151/300 (tree index:150) done accuracy:0.742079 logloss:3.12347\n",
      "[INFO 23-07-08 15:52:56.0987 UTC random_forest.cc:802] Training of tree  161/300 (tree index:160) done accuracy:0.742079 logloss:3.06648\n",
      "[INFO 23-07-08 15:52:56.2190 UTC random_forest.cc:802] Training of tree  171/300 (tree index:170) done accuracy:0.742972 logloss:3.03795\n",
      "[INFO 23-07-08 15:52:56.3395 UTC random_forest.cc:802] Training of tree  181/300 (tree index:180) done accuracy:0.746095 logloss:3.03807\n",
      "[INFO 23-07-08 15:52:56.4591 UTC random_forest.cc:802] Training of tree  191/300 (tree index:190) done accuracy:0.745203 logloss:3.03639\n",
      "[INFO 23-07-08 15:52:56.5777 UTC random_forest.cc:802] Training of tree  201/300 (tree index:200) done accuracy:0.743864 logloss:3.02041\n",
      "[INFO 23-07-08 15:52:56.7019 UTC random_forest.cc:802] Training of tree  211/300 (tree index:210) done accuracy:0.743418 logloss:3.02101\n",
      "[INFO 23-07-08 15:52:56.8228 UTC random_forest.cc:802] Training of tree  221/300 (tree index:220) done accuracy:0.742526 logloss:3.02043\n",
      "[INFO 23-07-08 15:52:56.9412 UTC random_forest.cc:802] Training of tree  231/300 (tree index:230) done accuracy:0.742526 logloss:2.93667\n",
      "[INFO 23-07-08 15:52:57.0646 UTC random_forest.cc:802] Training of tree  241/300 (tree index:240) done accuracy:0.742526 logloss:2.93633\n",
      "[INFO 23-07-08 15:52:57.1866 UTC random_forest.cc:802] Training of tree  251/300 (tree index:250) done accuracy:0.744311 logloss:2.92263\n",
      "[INFO 23-07-08 15:52:57.3083 UTC random_forest.cc:802] Training of tree  261/300 (tree index:260) done accuracy:0.743864 logloss:2.92187\n",
      "[INFO 23-07-08 15:52:57.4310 UTC random_forest.cc:802] Training of tree  271/300 (tree index:270) done accuracy:0.742972 logloss:2.86579\n",
      "[INFO 23-07-08 15:52:57.5533 UTC random_forest.cc:802] Training of tree  281/300 (tree index:280) done accuracy:0.743864 logloss:2.83746\n",
      "[INFO 23-07-08 15:52:57.6736 UTC random_forest.cc:802] Training of tree  291/300 (tree index:290) done accuracy:0.742972 logloss:2.82362\n",
      "[INFO 23-07-08 15:52:57.7819 UTC random_forest.cc:802] Training of tree  300/300 (tree index:299) done accuracy:0.742526 logloss:2.82433\n",
      "[INFO 23-07-08 15:52:57.7853 UTC random_forest.cc:882] Final OOB metrics: accuracy:0.742526 logloss:2.82433\n",
      "[INFO 23-07-08 15:52:57.8256 UTC random_forest.cc:416] Training random forest on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-08 15:52:57.8664 UTC random_forest.cc:802] Training of tree  1/300 (tree index:0) done accuracy:0.717918 logloss:10.1673\n",
      "[INFO 23-07-08 15:52:57.8879 UTC hyperparameters_optimizer.cc:582] [33/50] Score: 0.742526 / 0.742526 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"min_examples\" value { integer: 5 } }\n",
      "[INFO 23-07-08 15:52:58.0222 UTC random_forest.cc:802] Training of tree  11/300 (tree index:10) done accuracy:0.719551 logloss:6.71844\n",
      "[INFO 23-07-08 15:52:58.1641 UTC random_forest.cc:802] Training of tree  21/300 (tree index:20) done accuracy:0.724676 logloss:5.74322\n",
      "[INFO 23-07-08 15:52:58.3037 UTC random_forest.cc:802] Training of tree  31/300 (tree index:30) done accuracy:0.719768 logloss:5.16457\n",
      "[INFO 23-07-08 15:52:58.4429 UTC random_forest.cc:802] Training of tree  41/300 (tree index:40) done accuracy:0.722445 logloss:4.86701\n",
      "[INFO 23-07-08 15:52:58.5840 UTC random_forest.cc:802] Training of tree  51/300 (tree index:50) done accuracy:0.718429 logloss:4.76865\n",
      "[INFO 23-07-08 15:52:58.7298 UTC random_forest.cc:802] Training of tree  61/300 (tree index:60) done accuracy:0.720214 logloss:4.53644\n",
      "[INFO 23-07-08 15:52:58.8739 UTC random_forest.cc:802] Training of tree  71/300 (tree index:70) done accuracy:0.717983 logloss:4.30529\n",
      "[INFO 23-07-08 15:52:59.0163 UTC random_forest.cc:802] Training of tree  81/300 (tree index:80) done accuracy:0.72066 logloss:4.145\n",
      "[INFO 23-07-08 15:52:59.1616 UTC random_forest.cc:802] Training of tree  91/300 (tree index:90) done accuracy:0.721107 logloss:4.08935\n",
      "[INFO 23-07-08 15:52:59.3031 UTC random_forest.cc:802] Training of tree  101/300 (tree index:100) done accuracy:0.721107 logloss:4.0178\n",
      "[INFO 23-07-08 15:52:59.4452 UTC random_forest.cc:802] Training of tree  111/300 (tree index:110) done accuracy:0.720214 logloss:3.95979\n",
      "[INFO 23-07-08 15:52:59.5868 UTC random_forest.cc:802] Training of tree  121/300 (tree index:120) done accuracy:0.72066 logloss:3.88803\n",
      "[INFO 23-07-08 15:52:59.7312 UTC random_forest.cc:802] Training of tree  131/300 (tree index:130) done accuracy:0.719768 logloss:3.78737\n",
      "[INFO 23-07-08 15:52:59.8735 UTC random_forest.cc:802] Training of tree  141/300 (tree index:140) done accuracy:0.718876 logloss:3.73079\n",
      "[INFO 23-07-08 15:53:00.0191 UTC random_forest.cc:802] Training of tree  151/300 (tree index:150) done accuracy:0.721999 logloss:3.70234\n",
      "[INFO 23-07-08 15:53:00.1625 UTC random_forest.cc:802] Training of tree  161/300 (tree index:160) done accuracy:0.72066 logloss:3.6323\n",
      "[INFO 23-07-08 15:53:00.3053 UTC random_forest.cc:802] Training of tree  171/300 (tree index:170) done accuracy:0.718876 logloss:3.59049\n",
      "[INFO 23-07-08 15:53:00.4489 UTC random_forest.cc:802] Training of tree  181/300 (tree index:180) done accuracy:0.720214 logloss:3.54902\n",
      "[INFO 23-07-08 15:53:00.5901 UTC random_forest.cc:802] Training of tree  191/300 (tree index:190) done accuracy:0.721107 logloss:3.53461\n",
      "[INFO 23-07-08 15:53:00.7368 UTC random_forest.cc:802] Training of tree  201/300 (tree index:200) done accuracy:0.719322 logloss:3.4889\n",
      "[INFO 23-07-08 15:53:00.8834 UTC random_forest.cc:802] Training of tree  211/300 (tree index:210) done accuracy:0.718876 logloss:3.4603\n",
      "[INFO 23-07-08 15:53:01.0279 UTC random_forest.cc:802] Training of tree  221/300 (tree index:220) done accuracy:0.719322 logloss:3.4615\n",
      "[INFO 23-07-08 15:53:01.1946 UTC random_forest.cc:802] Training of tree  231/300 (tree index:230) done accuracy:0.719322 logloss:3.44704\n",
      "[INFO 23-07-08 15:53:01.4922 UTC random_forest.cc:802] Training of tree  241/300 (tree index:240) done accuracy:0.718876 logloss:3.44677\n",
      "[INFO 23-07-08 15:53:01.8005 UTC random_forest.cc:802] Training of tree  251/300 (tree index:250) done accuracy:0.718876 logloss:3.44672\n",
      "[INFO 23-07-08 15:53:02.1230 UTC random_forest.cc:802] Training of tree  261/300 (tree index:260) done accuracy:0.718876 logloss:3.43041\n",
      "[INFO 23-07-08 15:53:02.4205 UTC random_forest.cc:802] Training of tree  271/300 (tree index:270) done accuracy:0.717537 logloss:3.40367\n",
      "[INFO 23-07-08 15:53:02.7089 UTC random_forest.cc:802] Training of tree  281/300 (tree index:280) done accuracy:0.718429 logloss:3.38959\n",
      "[INFO 23-07-08 15:53:03.0021 UTC random_forest.cc:802] Training of tree  291/300 (tree index:290) done accuracy:0.719322 logloss:3.38887\n",
      "[INFO 23-07-08 15:53:03.2682 UTC random_forest.cc:802] Training of tree  300/300 (tree index:299) done accuracy:0.718876 logloss:3.34759\n",
      "[INFO 23-07-08 15:53:03.2739 UTC random_forest.cc:882] Final OOB metrics: accuracy:0.718876 logloss:3.34759\n",
      "[INFO 23-07-08 15:53:03.3725 UTC hyperparameters_optimizer.cc:582] [34/50] Score: 0.718876 / 0.742526 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 20 } } fields { name: \"min_examples\" value { integer: 1 } }\n",
      "[INFO 23-07-08 15:53:03.4045 UTC random_forest.cc:416] Training random forest on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-08 15:53:03.4487 UTC random_forest.cc:802] Training of tree  1/300 (tree index:0) done accuracy:0.717918 logloss:10.1673\n",
      "[INFO 23-07-08 15:53:03.6417 UTC random_forest.cc:802] Training of tree  11/300 (tree index:10) done accuracy:0.713258 logloss:6.72125\n",
      "[INFO 23-07-08 15:53:03.8302 UTC random_forest.cc:802] Training of tree  21/300 (tree index:20) done accuracy:0.721999 logloss:5.75432\n",
      "[INFO 23-07-08 15:53:03.9690 UTC random_forest.cc:802] Training of tree  31/300 (tree index:30) done accuracy:0.723338 logloss:5.14663\n",
      "[INFO 23-07-08 15:53:04.1062 UTC random_forest.cc:802] Training of tree  41/300 (tree index:40) done accuracy:0.725123 logloss:4.7304\n",
      "[INFO 23-07-08 15:53:04.2514 UTC random_forest.cc:802] Training of tree  51/300 (tree index:50) done accuracy:0.72066 logloss:4.52445\n",
      "[INFO 23-07-08 15:53:04.3918 UTC random_forest.cc:802] Training of tree  61/300 (tree index:60) done accuracy:0.721553 logloss:4.33619\n",
      "[INFO 23-07-08 15:53:04.5324 UTC random_forest.cc:802] Training of tree  71/300 (tree index:70) done accuracy:0.717983 logloss:4.13479\n",
      "[INFO 23-07-08 15:53:04.6665 UTC random_forest.cc:802] Training of tree  81/300 (tree index:80) done accuracy:0.721107 logloss:3.99013\n",
      "[INFO 23-07-08 15:53:04.8050 UTC random_forest.cc:802] Training of tree  91/300 (tree index:90) done accuracy:0.723338 logloss:3.93347\n",
      "[INFO 23-07-08 15:53:04.9370 UTC random_forest.cc:802] Training of tree  101/300 (tree index:100) done accuracy:0.723338 logloss:3.86142\n",
      "[INFO 23-07-08 15:53:05.0810 UTC random_forest.cc:802] Training of tree  111/300 (tree index:110) done accuracy:0.723784 logloss:3.76066\n",
      "[INFO 23-07-08 15:53:05.2166 UTC random_forest.cc:802] Training of tree  121/300 (tree index:120) done accuracy:0.727354 logloss:3.68956\n",
      "[INFO 23-07-08 15:53:05.3465 UTC random_forest.cc:802] Training of tree  131/300 (tree index:130) done accuracy:0.729139 logloss:3.60306\n",
      "[INFO 23-07-08 15:53:05.4654 UTC random_forest.cc:802] Training of tree  141/300 (tree index:140) done accuracy:0.727354 logloss:3.54629\n",
      "[INFO 23-07-08 15:53:05.5560 UTC random_forest.cc:802] Training of tree  151/300 (tree index:150) done accuracy:0.726015 logloss:3.53258\n",
      "[INFO 23-07-08 15:53:05.6221 UTC random_forest.cc:802] Training of tree  161/300 (tree index:160) done accuracy:0.726461 logloss:3.44608\n",
      "[INFO 23-07-08 15:53:05.6887 UTC random_forest.cc:802] Training of tree  171/300 (tree index:170) done accuracy:0.727354 logloss:3.43304\n",
      "[INFO 23-07-08 15:53:05.7521 UTC random_forest.cc:802] Training of tree  181/300 (tree index:180) done accuracy:0.726908 logloss:3.43218\n",
      "[INFO 23-07-08 15:53:05.8196 UTC random_forest.cc:802] Training of tree  191/300 (tree index:190) done accuracy:0.725569 logloss:3.39048\n",
      "[INFO 23-07-08 15:53:05.8890 UTC random_forest.cc:802] Training of tree  201/300 (tree index:200) done accuracy:0.726015 logloss:3.35902\n",
      "[INFO 23-07-08 15:53:05.9573 UTC random_forest.cc:802] Training of tree  211/300 (tree index:210) done accuracy:0.723784 logloss:3.35835\n",
      "[INFO 23-07-08 15:53:06.0333 UTC random_forest.cc:802] Training of tree  221/300 (tree index:220) done accuracy:0.726461 logloss:3.34615\n",
      "[INFO 23-07-08 15:53:06.1054 UTC random_forest.cc:802] Training of tree  231/300 (tree index:230) done accuracy:0.725123 logloss:3.31824\n",
      "[INFO 23-07-08 15:53:06.1777 UTC random_forest.cc:802] Training of tree  241/300 (tree index:240) done accuracy:0.727354 logloss:3.27458\n",
      "[INFO 23-07-08 15:53:06.2506 UTC random_forest.cc:802] Training of tree  251/300 (tree index:250) done accuracy:0.725569 logloss:3.27556\n",
      "[INFO 23-07-08 15:53:06.3209 UTC random_forest.cc:802] Training of tree  261/300 (tree index:260) done accuracy:0.725123 logloss:3.25957\n",
      "[INFO 23-07-08 15:53:06.3906 UTC random_forest.cc:802] Training of tree  271/300 (tree index:270) done accuracy:0.725123 logloss:3.2603\n",
      "[INFO 23-07-08 15:53:06.4613 UTC random_forest.cc:802] Training of tree  281/300 (tree index:280) done accuracy:0.726908 logloss:3.26035\n",
      "[INFO 23-07-08 15:53:06.5308 UTC random_forest.cc:802] Training of tree  291/300 (tree index:290) done accuracy:0.7278 logloss:3.24634\n",
      "[INFO 23-07-08 15:53:06.5960 UTC random_forest.cc:802] Training of tree  300/300 (tree index:299) done accuracy:0.725569 logloss:3.21742\n",
      "[INFO 23-07-08 15:53:06.5992 UTC random_forest.cc:882] Final OOB metrics: accuracy:0.725569 logloss:3.21742\n",
      "[INFO 23-07-08 15:53:06.6404 UTC hyperparameters_optimizer.cc:582] [35/50] Score: 0.725569 / 0.742526 HParams: fields { name: \"split_axis\" value { categorical: \"AXIS_ALIGNED\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 16 } } fields { name: \"min_examples\" value { integer: 2 } }\n",
      "[INFO 23-07-08 15:53:06.6835 UTC random_forest.cc:416] Training random forest on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-08 15:53:06.7741 UTC random_forest.cc:802] Training of tree  1/300 (tree index:0) done accuracy:0.700969 logloss:10.7782\n",
      "[INFO 23-07-08 15:53:06.9108 UTC random_forest.cc:802] Training of tree  11/300 (tree index:10) done accuracy:0.709663 logloss:6.86775\n",
      "[INFO 23-07-08 15:53:07.0454 UTC random_forest.cc:802] Training of tree  21/300 (tree index:20) done accuracy:0.729139 logloss:5.79166\n",
      "[INFO 23-07-08 15:53:07.1831 UTC random_forest.cc:802] Training of tree  31/300 (tree index:30) done accuracy:0.728693 logloss:5.16278\n",
      "[INFO 23-07-08 15:53:07.3209 UTC random_forest.cc:802] Training of tree  41/300 (tree index:40) done accuracy:0.726461 logloss:4.74693\n",
      "[INFO 23-07-08 15:53:07.4575 UTC random_forest.cc:802] Training of tree  51/300 (tree index:50) done accuracy:0.722892 logloss:4.55889\n",
      "[INFO 23-07-08 15:53:07.5968 UTC random_forest.cc:802] Training of tree  61/300 (tree index:60) done accuracy:0.72066 logloss:4.38352\n",
      "[INFO 23-07-08 15:53:07.7379 UTC random_forest.cc:802] Training of tree  71/300 (tree index:70) done accuracy:0.718429 logloss:4.13737\n",
      "[INFO 23-07-08 15:53:07.8807 UTC random_forest.cc:802] Training of tree  81/300 (tree index:80) done accuracy:0.723338 logloss:4.00727\n",
      "[INFO 23-07-08 15:53:08.0234 UTC random_forest.cc:802] Training of tree  91/300 (tree index:90) done accuracy:0.726015 logloss:3.89349\n",
      "[INFO 23-07-08 15:53:08.1652 UTC random_forest.cc:802] Training of tree  101/300 (tree index:100) done accuracy:0.72423 logloss:3.82181\n",
      "[INFO 23-07-08 15:53:08.3073 UTC random_forest.cc:802] Training of tree  111/300 (tree index:110) done accuracy:0.72423 logloss:3.73477\n",
      "[INFO 23-07-08 15:53:08.4485 UTC random_forest.cc:802] Training of tree  121/300 (tree index:120) done accuracy:0.72423 logloss:3.67673\n",
      "[INFO 23-07-08 15:53:08.5893 UTC random_forest.cc:802] Training of tree  131/300 (tree index:130) done accuracy:0.726908 logloss:3.58997\n",
      "[INFO 23-07-08 15:53:08.7275 UTC random_forest.cc:802] Training of tree  141/300 (tree index:140) done accuracy:0.725123 logloss:3.56164\n",
      "[INFO 23-07-08 15:53:08.8685 UTC random_forest.cc:802] Training of tree  151/300 (tree index:150) done accuracy:0.728693 logloss:3.54725\n",
      "[INFO 23-07-08 15:53:09.0062 UTC random_forest.cc:802] Training of tree  161/300 (tree index:160) done accuracy:0.728246 logloss:3.52065\n",
      "[INFO 23-07-08 15:53:09.1496 UTC random_forest.cc:802] Training of tree  171/300 (tree index:170) done accuracy:0.729139 logloss:3.47794\n",
      "[INFO 23-07-08 15:53:09.2880 UTC random_forest.cc:802] Training of tree  181/300 (tree index:180) done accuracy:0.730924 logloss:3.46369\n",
      "[INFO 23-07-08 15:53:09.4260 UTC random_forest.cc:802] Training of tree  191/300 (tree index:190) done accuracy:0.729139 logloss:3.39455\n",
      "[INFO 23-07-08 15:53:09.5656 UTC random_forest.cc:802] Training of tree  201/300 (tree index:200) done accuracy:0.729139 logloss:3.34769\n",
      "[INFO 23-07-08 15:53:09.7069 UTC random_forest.cc:802] Training of tree  211/300 (tree index:210) done accuracy:0.727354 logloss:3.33301\n",
      "[INFO 23-07-08 15:53:09.8493 UTC random_forest.cc:802] Training of tree  221/300 (tree index:220) done accuracy:0.729139 logloss:3.31913\n",
      "[INFO 23-07-08 15:53:09.9906 UTC random_forest.cc:802] Training of tree  231/300 (tree index:230) done accuracy:0.728246 logloss:3.30503\n",
      "[INFO 23-07-08 15:53:10.1318 UTC random_forest.cc:802] Training of tree  241/300 (tree index:240) done accuracy:0.729139 logloss:3.30535\n",
      "[INFO 23-07-08 15:53:10.2728 UTC random_forest.cc:802] Training of tree  251/300 (tree index:250) done accuracy:0.727354 logloss:3.30461\n",
      "[INFO 23-07-08 15:53:10.4190 UTC random_forest.cc:802] Training of tree  261/300 (tree index:260) done accuracy:0.728246 logloss:3.24674\n",
      "[INFO 23-07-08 15:53:10.5610 UTC random_forest.cc:802] Training of tree  271/300 (tree index:270) done accuracy:0.7278 logloss:3.24786\n",
      "[INFO 23-07-08 15:53:10.7033 UTC random_forest.cc:802] Training of tree  281/300 (tree index:280) done accuracy:0.729585 logloss:3.24735\n",
      "[INFO 23-07-08 15:53:10.8459 UTC random_forest.cc:802] Training of tree  291/300 (tree index:290) done accuracy:0.730924 logloss:3.20513\n",
      "[INFO 23-07-08 15:53:10.9736 UTC random_forest.cc:802] Training of tree  300/300 (tree index:299) done accuracy:0.730477 logloss:3.19127\n",
      "[INFO 23-07-08 15:53:10.9771 UTC random_forest.cc:882] Final OOB metrics: accuracy:0.730477 logloss:3.19127\n",
      "[INFO 23-07-08 15:53:11.0209 UTC hyperparameters_optimizer.cc:582] [36/50] Score: 0.730477 / 0.742526 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 20 } } fields { name: \"min_examples\" value { integer: 2 } }\n",
      "[INFO 23-07-08 15:53:11.0318 UTC random_forest.cc:416] Training random forest on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-08 15:53:11.1661 UTC random_forest.cc:802] Training of tree  1/300 (tree index:0) done accuracy:0.716707 logloss:10.2109\n",
      "[INFO 23-07-08 15:53:11.2887 UTC random_forest.cc:802] Training of tree  11/300 (tree index:10) done accuracy:0.717303 logloss:6.53681\n",
      "[INFO 23-07-08 15:53:11.4111 UTC random_forest.cc:802] Training of tree  21/300 (tree index:20) done accuracy:0.730477 logloss:5.48966\n",
      "[INFO 23-07-08 15:53:11.5334 UTC random_forest.cc:802] Training of tree  31/300 (tree index:30) done accuracy:0.728246 logloss:4.88417\n",
      "[INFO 23-07-08 15:53:11.6567 UTC random_forest.cc:802] Training of tree  41/300 (tree index:40) done accuracy:0.736278 logloss:4.5435\n",
      "[INFO 23-07-08 15:53:11.7762 UTC random_forest.cc:802] Training of tree  51/300 (tree index:50) done accuracy:0.732262 logloss:4.35447\n",
      "[INFO 23-07-08 15:53:11.8996 UTC random_forest.cc:802] Training of tree  61/300 (tree index:60) done accuracy:0.734494 logloss:4.1657\n",
      "[INFO 23-07-08 15:53:12.0215 UTC random_forest.cc:802] Training of tree  71/300 (tree index:70) done accuracy:0.737171 logloss:3.892\n",
      "[INFO 23-07-08 15:53:12.1424 UTC random_forest.cc:802] Training of tree  81/300 (tree index:80) done accuracy:0.73494 logloss:3.76169\n",
      "[INFO 23-07-08 15:53:12.2636 UTC random_forest.cc:802] Training of tree  91/300 (tree index:90) done accuracy:0.735386 logloss:3.67665\n",
      "[INFO 23-07-08 15:53:12.3849 UTC random_forest.cc:802] Training of tree  101/300 (tree index:100) done accuracy:0.737617 logloss:3.63528\n",
      "[INFO 23-07-08 15:53:12.5066 UTC random_forest.cc:802] Training of tree  111/300 (tree index:110) done accuracy:0.737617 logloss:3.54737\n",
      "[INFO 23-07-08 15:53:12.6269 UTC random_forest.cc:802] Training of tree  121/300 (tree index:120) done accuracy:0.73851 logloss:3.46324\n",
      "[INFO 23-07-08 15:53:12.7493 UTC random_forest.cc:802] Training of tree  131/300 (tree index:130) done accuracy:0.738063 logloss:3.38873\n",
      "[INFO 23-07-08 15:53:12.8699 UTC random_forest.cc:802] Training of tree  141/300 (tree index:140) done accuracy:0.738063 logloss:3.33019\n",
      "[INFO 23-07-08 15:53:12.9905 UTC random_forest.cc:802] Training of tree  151/300 (tree index:150) done accuracy:0.740741 logloss:3.28794\n",
      "[INFO 23-07-08 15:53:13.1107 UTC random_forest.cc:802] Training of tree  161/300 (tree index:160) done accuracy:0.739402 logloss:3.24359\n",
      "[INFO 23-07-08 15:53:13.2300 UTC random_forest.cc:802] Training of tree  171/300 (tree index:170) done accuracy:0.739402 logloss:3.19868\n",
      "[INFO 23-07-08 15:53:13.3504 UTC random_forest.cc:802] Training of tree  181/300 (tree index:180) done accuracy:0.741187 logloss:3.18378\n",
      "[INFO 23-07-08 15:53:13.4697 UTC random_forest.cc:802] Training of tree  191/300 (tree index:190) done accuracy:0.738063 logloss:3.17006\n",
      "[INFO 23-07-08 15:53:13.5897 UTC random_forest.cc:802] Training of tree  201/300 (tree index:200) done accuracy:0.73851 logloss:3.12701\n",
      "[INFO 23-07-08 15:53:13.7110 UTC random_forest.cc:802] Training of tree  211/300 (tree index:210) done accuracy:0.739402 logloss:3.12615\n",
      "[INFO 23-07-08 15:53:13.8315 UTC random_forest.cc:802] Training of tree  221/300 (tree index:220) done accuracy:0.738063 logloss:3.12792\n",
      "[INFO 23-07-08 15:53:13.9504 UTC random_forest.cc:802] Training of tree  231/300 (tree index:230) done accuracy:0.739402 logloss:3.03081\n",
      "[INFO 23-07-08 15:53:14.0695 UTC random_forest.cc:802] Training of tree  241/300 (tree index:240) done accuracy:0.73851 logloss:3.00172\n",
      "[INFO 23-07-08 15:53:14.1915 UTC random_forest.cc:802] Training of tree  251/300 (tree index:250) done accuracy:0.739402 logloss:3.0021\n",
      "[INFO 23-07-08 15:53:14.3135 UTC random_forest.cc:802] Training of tree  261/300 (tree index:260) done accuracy:0.740295 logloss:3.00067\n",
      "[INFO 23-07-08 15:53:14.4348 UTC random_forest.cc:802] Training of tree  271/300 (tree index:270) done accuracy:0.740295 logloss:2.9729\n",
      "[INFO 23-07-08 15:53:14.5571 UTC random_forest.cc:802] Training of tree  281/300 (tree index:280) done accuracy:0.739848 logloss:2.95883\n",
      "[INFO 23-07-08 15:53:14.6799 UTC random_forest.cc:802] Training of tree  291/300 (tree index:290) done accuracy:0.740741 logloss:2.93028\n",
      "[INFO 23-07-08 15:53:14.7896 UTC random_forest.cc:802] Training of tree  300/300 (tree index:299) done accuracy:0.741187 logloss:2.91689\n",
      "[INFO 23-07-08 15:53:14.7932 UTC random_forest.cc:882] Final OOB metrics: accuracy:0.741187 logloss:2.91689\n",
      "[INFO 23-07-08 15:53:14.8220 UTC hyperparameters_optimizer.cc:582] [37/50] Score: 0.741187 / 0.742526 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 16 } } fields { name: \"min_examples\" value { integer: 5 } }\n",
      "[INFO 23-07-08 15:53:14.8367 UTC random_forest.cc:416] Training random forest on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-08 15:53:14.9203 UTC random_forest.cc:802] Training of tree  1/300 (tree index:0) done accuracy:0.700969 logloss:10.7782\n",
      "[INFO 23-07-08 15:53:14.9985 UTC random_forest.cc:802] Training of tree  11/300 (tree index:10) done accuracy:0.713708 logloss:6.87245\n",
      "[INFO 23-07-08 15:53:15.0805 UTC random_forest.cc:802] Training of tree  21/300 (tree index:20) done accuracy:0.709058 logloss:5.37269\n",
      "[INFO 23-07-08 15:53:15.1561 UTC random_forest.cc:802] Training of tree  31/300 (tree index:30) done accuracy:0.709951 logloss:4.64262\n",
      "[INFO 23-07-08 15:53:15.2314 UTC random_forest.cc:802] Training of tree  41/300 (tree index:40) done accuracy:0.709951 logloss:4.43462\n",
      "[INFO 23-07-08 15:53:15.3078 UTC random_forest.cc:802] Training of tree  51/300 (tree index:50) done accuracy:0.712182 logloss:4.27208\n",
      "[INFO 23-07-08 15:53:15.3858 UTC random_forest.cc:802] Training of tree  61/300 (tree index:60) done accuracy:0.711736 logloss:4.14287\n",
      "[INFO 23-07-08 15:53:15.4627 UTC random_forest.cc:802] Training of tree  71/300 (tree index:70) done accuracy:0.711736 logloss:4.02476\n",
      "[INFO 23-07-08 15:53:15.5405 UTC random_forest.cc:802] Training of tree  81/300 (tree index:80) done accuracy:0.714413 logloss:3.95278\n",
      "[INFO 23-07-08 15:53:15.6182 UTC random_forest.cc:802] Training of tree  91/300 (tree index:90) done accuracy:0.713075 logloss:3.89522\n",
      "[INFO 23-07-08 15:53:15.6972 UTC random_forest.cc:802] Training of tree  101/300 (tree index:100) done accuracy:0.710397 logloss:3.80827\n",
      "[INFO 23-07-08 15:53:15.7771 UTC random_forest.cc:802] Training of tree  111/300 (tree index:110) done accuracy:0.713967 logloss:3.77754\n",
      "[INFO 23-07-08 15:53:15.8579 UTC random_forest.cc:802] Training of tree  121/300 (tree index:120) done accuracy:0.710843 logloss:3.7642\n",
      "[INFO 23-07-08 15:53:15.9369 UTC random_forest.cc:802] Training of tree  131/300 (tree index:130) done accuracy:0.712182 logloss:3.7625\n",
      "[INFO 23-07-08 15:53:16.0142 UTC random_forest.cc:802] Training of tree  141/300 (tree index:140) done accuracy:0.709505 logloss:3.7581\n",
      "[INFO 23-07-08 15:53:16.0922 UTC random_forest.cc:802] Training of tree  151/300 (tree index:150) done accuracy:0.712182 logloss:3.7159\n",
      "[INFO 23-07-08 15:53:16.1682 UTC random_forest.cc:802] Training of tree  161/300 (tree index:160) done accuracy:0.711736 logloss:3.65916\n",
      "[INFO 23-07-08 15:53:16.2450 UTC random_forest.cc:802] Training of tree  171/300 (tree index:170) done accuracy:0.712182 logloss:3.60123\n",
      "[INFO 23-07-08 15:53:16.3231 UTC random_forest.cc:802] Training of tree  181/300 (tree index:180) done accuracy:0.712628 logloss:3.58838\n",
      "[INFO 23-07-08 15:53:16.4001 UTC random_forest.cc:802] Training of tree  191/300 (tree index:190) done accuracy:0.709058 logloss:3.5469\n",
      "[INFO 23-07-08 15:53:16.4775 UTC random_forest.cc:802] Training of tree  201/300 (tree index:200) done accuracy:0.709505 logloss:3.50423\n",
      "[INFO 23-07-08 15:53:16.5595 UTC random_forest.cc:802] Training of tree  211/300 (tree index:210) done accuracy:0.709951 logloss:3.49142\n",
      "[INFO 23-07-08 15:53:16.6397 UTC random_forest.cc:802] Training of tree  221/300 (tree index:220) done accuracy:0.710397 logloss:3.44971\n",
      "[INFO 23-07-08 15:53:16.7206 UTC random_forest.cc:802] Training of tree  231/300 (tree index:230) done accuracy:0.709058 logloss:3.42257\n",
      "[INFO 23-07-08 15:53:16.7992 UTC random_forest.cc:802] Training of tree  241/300 (tree index:240) done accuracy:0.70772 logloss:3.38068\n",
      "[INFO 23-07-08 15:53:16.8771 UTC random_forest.cc:802] Training of tree  251/300 (tree index:250) done accuracy:0.709951 logloss:3.36667\n",
      "[INFO 23-07-08 15:53:16.9595 UTC random_forest.cc:802] Training of tree  261/300 (tree index:260) done accuracy:0.708612 logloss:3.36688\n",
      "[INFO 23-07-08 15:53:17.0378 UTC random_forest.cc:802] Training of tree  271/300 (tree index:270) done accuracy:0.708166 logloss:3.36725\n",
      "[INFO 23-07-08 15:53:17.1171 UTC random_forest.cc:802] Training of tree  281/300 (tree index:280) done accuracy:0.70772 logloss:3.36833\n",
      "[INFO 23-07-08 15:53:17.1929 UTC random_forest.cc:802] Training of tree  291/300 (tree index:290) done accuracy:0.709951 logloss:3.3399\n",
      "[INFO 23-07-08 15:53:17.2697 UTC random_forest.cc:802] Training of tree  300/300 (tree index:299) done accuracy:0.709951 logloss:3.34036\n",
      "[INFO 23-07-08 15:53:17.2729 UTC random_forest.cc:882] Final OOB metrics: accuracy:0.709951 logloss:3.34036\n",
      "[INFO 23-07-08 15:53:17.2775 UTC hyperparameters_optimizer.cc:582] [38/50] Score: 0.709951 / 0.742526 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 16 } } fields { name: \"min_examples\" value { integer: 40 } }\n",
      "[INFO 23-07-08 15:53:17.2865 UTC random_forest.cc:416] Training random forest on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-08 15:53:17.3448 UTC random_forest.cc:802] Training of tree  1/300 (tree index:0) done accuracy:0.716707 logloss:10.2109\n",
      "[INFO 23-07-08 15:53:17.3922 UTC random_forest.cc:802] Training of tree  11/300 (tree index:10) done accuracy:0.710112 logloss:6.63275\n",
      "[INFO 23-07-08 15:53:17.4391 UTC random_forest.cc:802] Training of tree  21/300 (tree index:20) done accuracy:0.728693 logloss:5.46481\n",
      "[INFO 23-07-08 15:53:17.4879 UTC random_forest.cc:802] Training of tree  31/300 (tree index:30) done accuracy:0.728246 logloss:4.99131\n",
      "[INFO 23-07-08 15:53:17.5342 UTC random_forest.cc:802] Training of tree  41/300 (tree index:40) done accuracy:0.729585 logloss:4.56309\n",
      "[INFO 23-07-08 15:53:17.5801 UTC random_forest.cc:802] Training of tree  51/300 (tree index:50) done accuracy:0.728246 logloss:4.34453\n",
      "[INFO 23-07-08 15:53:17.6273 UTC random_forest.cc:802] Training of tree  61/300 (tree index:60) done accuracy:0.733601 logloss:4.18214\n",
      "[INFO 23-07-08 15:53:17.6759 UTC random_forest.cc:802] Training of tree  71/300 (tree index:70) done accuracy:0.733601 logloss:3.99388\n",
      "[INFO 23-07-08 15:53:17.7256 UTC random_forest.cc:802] Training of tree  81/300 (tree index:80) done accuracy:0.732262 logloss:3.89545\n",
      "[INFO 23-07-08 15:53:17.7728 UTC random_forest.cc:802] Training of tree  91/300 (tree index:90) done accuracy:0.73494 logloss:3.8672\n",
      "[INFO 23-07-08 15:53:17.8180 UTC random_forest.cc:802] Training of tree  101/300 (tree index:100) done accuracy:0.73494 logloss:3.75001\n",
      "[INFO 23-07-08 15:53:17.8664 UTC random_forest.cc:802] Training of tree  111/300 (tree index:110) done accuracy:0.734047 logloss:3.67642\n",
      "[INFO 23-07-08 15:53:17.9142 UTC random_forest.cc:802] Training of tree  121/300 (tree index:120) done accuracy:0.733601 logloss:3.64851\n",
      "[INFO 23-07-08 15:53:17.9619 UTC random_forest.cc:802] Training of tree  131/300 (tree index:130) done accuracy:0.736278 logloss:3.54679\n",
      "[INFO 23-07-08 15:53:18.0095 UTC random_forest.cc:802] Training of tree  141/300 (tree index:140) done accuracy:0.736725 logloss:3.44668\n",
      "[INFO 23-07-08 15:53:18.0562 UTC random_forest.cc:802] Training of tree  151/300 (tree index:150) done accuracy:0.738956 logloss:3.40438\n",
      "[INFO 23-07-08 15:53:18.1042 UTC random_forest.cc:802] Training of tree  161/300 (tree index:160) done accuracy:0.737171 logloss:3.33383\n",
      "[INFO 23-07-08 15:53:18.1499 UTC random_forest.cc:802] Training of tree  171/300 (tree index:170) done accuracy:0.736725 logloss:3.30592\n",
      "[INFO 23-07-08 15:53:18.1998 UTC random_forest.cc:802] Training of tree  181/300 (tree index:180) done accuracy:0.736725 logloss:3.29276\n",
      "[INFO 23-07-08 15:53:18.2463 UTC random_forest.cc:802] Training of tree  191/300 (tree index:190) done accuracy:0.736725 logloss:3.26406\n",
      "[INFO 23-07-08 15:53:18.2919 UTC random_forest.cc:802] Training of tree  201/300 (tree index:200) done accuracy:0.736278 logloss:3.21833\n",
      "[INFO 23-07-08 15:53:18.3379 UTC random_forest.cc:802] Training of tree  211/300 (tree index:210) done accuracy:0.737617 logloss:3.18965\n",
      "[INFO 23-07-08 15:53:18.3858 UTC random_forest.cc:802] Training of tree  221/300 (tree index:220) done accuracy:0.736725 logloss:3.1477\n",
      "[INFO 23-07-08 15:53:18.4326 UTC random_forest.cc:802] Training of tree  231/300 (tree index:230) done accuracy:0.736278 logloss:3.13392\n",
      "[INFO 23-07-08 15:53:18.4811 UTC random_forest.cc:802] Training of tree  241/300 (tree index:240) done accuracy:0.735386 logloss:3.11915\n",
      "[INFO 23-07-08 15:53:18.5274 UTC random_forest.cc:802] Training of tree  251/300 (tree index:250) done accuracy:0.735386 logloss:3.11919\n",
      "[INFO 23-07-08 15:53:18.5732 UTC random_forest.cc:802] Training of tree  261/300 (tree index:260) done accuracy:0.735386 logloss:3.09101\n",
      "[INFO 23-07-08 15:53:18.6210 UTC random_forest.cc:802] Training of tree  271/300 (tree index:270) done accuracy:0.73494 logloss:3.06321\n",
      "[INFO 23-07-08 15:53:18.6712 UTC random_forest.cc:802] Training of tree  281/300 (tree index:280) done accuracy:0.736725 logloss:3.0483\n",
      "[INFO 23-07-08 15:53:18.7173 UTC random_forest.cc:802] Training of tree  291/300 (tree index:290) done accuracy:0.736278 logloss:3.03378\n",
      "[INFO 23-07-08 15:53:18.7605 UTC random_forest.cc:802] Training of tree  300/300 (tree index:299) done accuracy:0.736725 logloss:3.03436\n",
      "[INFO 23-07-08 15:53:18.7649 UTC random_forest.cc:882] Final OOB metrics: accuracy:0.736725 logloss:3.03436\n",
      "[INFO 23-07-08 15:53:18.7837 UTC hyperparameters_optimizer.cc:582] [39/50] Score: 0.736725 / 0.742526 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 16 } } fields { name: \"min_examples\" value { integer: 10 } }\n",
      "[INFO 23-07-08 15:53:18.7949 UTC random_forest.cc:416] Training random forest on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-08 15:53:18.8841 UTC random_forest.cc:802] Training of tree  1/300 (tree index:0) done accuracy:0.700969 logloss:10.7782\n",
      "[INFO 23-07-08 15:53:19.0215 UTC random_forest.cc:802] Training of tree  11/300 (tree index:10) done accuracy:0.709663 logloss:6.86775\n",
      "[INFO 23-07-08 15:53:19.1549 UTC random_forest.cc:802] Training of tree  21/300 (tree index:20) done accuracy:0.729139 logloss:5.79166\n",
      "[INFO 23-07-08 15:53:19.2909 UTC random_forest.cc:802] Training of tree  31/300 (tree index:30) done accuracy:0.728693 logloss:5.16278\n",
      "[INFO 23-07-08 15:53:19.4249 UTC random_forest.cc:802] Training of tree  41/300 (tree index:40) done accuracy:0.726461 logloss:4.74693\n",
      "[INFO 23-07-08 15:53:19.5614 UTC random_forest.cc:802] Training of tree  51/300 (tree index:50) done accuracy:0.722892 logloss:4.55889\n",
      "[INFO 23-07-08 15:53:19.6995 UTC random_forest.cc:802] Training of tree  61/300 (tree index:60) done accuracy:0.72066 logloss:4.38352\n",
      "[INFO 23-07-08 15:53:19.8391 UTC random_forest.cc:802] Training of tree  71/300 (tree index:70) done accuracy:0.718429 logloss:4.13737\n",
      "[INFO 23-07-08 15:53:19.9786 UTC random_forest.cc:802] Training of tree  81/300 (tree index:80) done accuracy:0.723338 logloss:4.00727\n",
      "[INFO 23-07-08 15:53:20.1148 UTC random_forest.cc:802] Training of tree  91/300 (tree index:90) done accuracy:0.726015 logloss:3.89349\n",
      "[INFO 23-07-08 15:53:20.2524 UTC random_forest.cc:802] Training of tree  101/300 (tree index:100) done accuracy:0.72423 logloss:3.82181\n",
      "[INFO 23-07-08 15:53:20.3908 UTC random_forest.cc:802] Training of tree  111/300 (tree index:110) done accuracy:0.72423 logloss:3.73477\n",
      "[INFO 23-07-08 15:53:20.5278 UTC random_forest.cc:802] Training of tree  121/300 (tree index:120) done accuracy:0.72423 logloss:3.67673\n",
      "[INFO 23-07-08 15:53:20.6667 UTC random_forest.cc:802] Training of tree  131/300 (tree index:130) done accuracy:0.726908 logloss:3.58997\n",
      "[INFO 23-07-08 15:53:20.8030 UTC random_forest.cc:802] Training of tree  141/300 (tree index:140) done accuracy:0.725123 logloss:3.56164\n",
      "[INFO 23-07-08 15:53:20.9437 UTC random_forest.cc:802] Training of tree  151/300 (tree index:150) done accuracy:0.728693 logloss:3.54725\n",
      "[INFO 23-07-08 15:53:21.0787 UTC random_forest.cc:802] Training of tree  161/300 (tree index:160) done accuracy:0.728246 logloss:3.52065\n",
      "[INFO 23-07-08 15:53:21.2138 UTC random_forest.cc:802] Training of tree  171/300 (tree index:170) done accuracy:0.729139 logloss:3.47794\n",
      "[INFO 23-07-08 15:53:21.3574 UTC random_forest.cc:802] Training of tree  181/300 (tree index:180) done accuracy:0.730924 logloss:3.46369\n",
      "[INFO 23-07-08 15:53:21.4972 UTC random_forest.cc:802] Training of tree  191/300 (tree index:190) done accuracy:0.729139 logloss:3.39455\n",
      "[INFO 23-07-08 15:53:21.6354 UTC random_forest.cc:802] Training of tree  201/300 (tree index:200) done accuracy:0.729139 logloss:3.34769\n",
      "[INFO 23-07-08 15:53:21.7735 UTC random_forest.cc:802] Training of tree  211/300 (tree index:210) done accuracy:0.727354 logloss:3.33301\n",
      "[INFO 23-07-08 15:53:21.9104 UTC random_forest.cc:802] Training of tree  221/300 (tree index:220) done accuracy:0.729139 logloss:3.31913\n",
      "[INFO 23-07-08 15:53:22.0472 UTC random_forest.cc:802] Training of tree  231/300 (tree index:230) done accuracy:0.728246 logloss:3.30503\n",
      "[INFO 23-07-08 15:53:22.1860 UTC random_forest.cc:802] Training of tree  241/300 (tree index:240) done accuracy:0.729139 logloss:3.30535\n",
      "[INFO 23-07-08 15:53:22.3220 UTC random_forest.cc:802] Training of tree  251/300 (tree index:250) done accuracy:0.727354 logloss:3.30461\n",
      "[INFO 23-07-08 15:53:22.4595 UTC random_forest.cc:802] Training of tree  261/300 (tree index:260) done accuracy:0.728246 logloss:3.24674\n",
      "[INFO 23-07-08 15:53:22.5964 UTC random_forest.cc:802] Training of tree  271/300 (tree index:270) done accuracy:0.7278 logloss:3.24786\n",
      "[INFO 23-07-08 15:53:22.7341 UTC random_forest.cc:802] Training of tree  281/300 (tree index:280) done accuracy:0.729585 logloss:3.24735\n",
      "[INFO 23-07-08 15:53:22.8701 UTC random_forest.cc:802] Training of tree  291/300 (tree index:290) done accuracy:0.730924 logloss:3.20513\n",
      "[INFO 23-07-08 15:53:22.9927 UTC random_forest.cc:802] Training of tree  300/300 (tree index:299) done accuracy:0.730477 logloss:3.19127\n",
      "[INFO 23-07-08 15:53:22.9967 UTC random_forest.cc:882] Final OOB metrics: accuracy:0.730477 logloss:3.19127\n",
      "[INFO 23-07-08 15:53:23.0388 UTC hyperparameters_optimizer.cc:582] [40/50] Score: 0.730477 / 0.742526 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 20 } } fields { name: \"min_examples\" value { integer: 2 } }\n",
      "[INFO 23-07-08 15:53:23.0522 UTC random_forest.cc:416] Training random forest on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-08 15:53:23.0921 UTC random_forest.cc:802] Training of tree  1/300 (tree index:0) done accuracy:0.700969 logloss:10.7782\n",
      "[INFO 23-07-08 15:53:23.2446 UTC random_forest.cc:802] Training of tree  11/300 (tree index:10) done accuracy:0.714157 logloss:6.67408\n",
      "[INFO 23-07-08 15:53:23.3784 UTC random_forest.cc:802] Training of tree  21/300 (tree index:20) done accuracy:0.726908 logloss:5.72781\n",
      "[INFO 23-07-08 15:53:23.5161 UTC random_forest.cc:802] Training of tree  31/300 (tree index:30) done accuracy:0.728693 logloss:5.12979\n",
      "[INFO 23-07-08 15:53:23.6517 UTC random_forest.cc:802] Training of tree  41/300 (tree index:40) done accuracy:0.7278 logloss:4.68474\n",
      "[INFO 23-07-08 15:53:23.7889 UTC random_forest.cc:802] Training of tree  51/300 (tree index:50) done accuracy:0.726461 logloss:4.5267\n",
      "[INFO 23-07-08 15:53:23.9275 UTC random_forest.cc:802] Training of tree  61/300 (tree index:60) done accuracy:0.721999 logloss:4.35235\n",
      "[INFO 23-07-08 15:53:24.0637 UTC random_forest.cc:802] Training of tree  71/300 (tree index:70) done accuracy:0.719768 logloss:4.12083\n",
      "[INFO 23-07-08 15:53:24.1983 UTC random_forest.cc:802] Training of tree  81/300 (tree index:80) done accuracy:0.722445 logloss:3.96188\n",
      "[INFO 23-07-08 15:53:24.3371 UTC random_forest.cc:802] Training of tree  91/300 (tree index:90) done accuracy:0.723784 logloss:3.84788\n",
      "[INFO 23-07-08 15:53:24.4748 UTC random_forest.cc:802] Training of tree  101/300 (tree index:100) done accuracy:0.726908 logloss:3.77728\n",
      "[INFO 23-07-08 15:53:24.6122 UTC random_forest.cc:802] Training of tree  111/300 (tree index:110) done accuracy:0.72423 logloss:3.69048\n",
      "[INFO 23-07-08 15:53:24.7496 UTC random_forest.cc:802] Training of tree  121/300 (tree index:120) done accuracy:0.726908 logloss:3.61873\n",
      "[INFO 23-07-08 15:53:24.8909 UTC random_forest.cc:802] Training of tree  131/300 (tree index:130) done accuracy:0.726015 logloss:3.55981\n",
      "[INFO 23-07-08 15:53:25.0266 UTC random_forest.cc:802] Training of tree  141/300 (tree index:140) done accuracy:0.725123 logloss:3.51762\n",
      "[INFO 23-07-08 15:53:25.1653 UTC random_forest.cc:802] Training of tree  151/300 (tree index:150) done accuracy:0.726015 logloss:3.48915\n",
      "[INFO 23-07-08 15:53:25.3073 UTC random_forest.cc:802] Training of tree  161/300 (tree index:160) done accuracy:0.728246 logloss:3.46235\n",
      "[INFO 23-07-08 15:53:25.4441 UTC random_forest.cc:802] Training of tree  171/300 (tree index:170) done accuracy:0.7278 logloss:3.4339\n",
      "[INFO 23-07-08 15:53:25.6570 UTC random_forest.cc:802] Training of tree  181/300 (tree index:180) done accuracy:0.729139 logloss:3.43296\n",
      "[INFO 23-07-08 15:53:25.7925 UTC random_forest.cc:802] Training of tree  191/300 (tree index:190) done accuracy:0.729585 logloss:3.37706\n",
      "[INFO 23-07-08 15:53:25.9322 UTC random_forest.cc:802] Training of tree  201/300 (tree index:200) done accuracy:0.728693 logloss:3.33026\n",
      "[INFO 23-07-08 15:53:26.0731 UTC random_forest.cc:802] Training of tree  211/300 (tree index:210) done accuracy:0.728693 logloss:3.30139\n",
      "[INFO 23-07-08 15:53:26.2110 UTC random_forest.cc:802] Training of tree  221/300 (tree index:220) done accuracy:0.7278 logloss:3.28826\n",
      "[INFO 23-07-08 15:53:26.3478 UTC random_forest.cc:802] Training of tree  231/300 (tree index:230) done accuracy:0.7278 logloss:3.28771\n",
      "[INFO 23-07-08 15:53:26.4833 UTC random_forest.cc:802] Training of tree  241/300 (tree index:240) done accuracy:0.726908 logloss:3.28816\n",
      "[INFO 23-07-08 15:53:26.6214 UTC random_forest.cc:802] Training of tree  251/300 (tree index:250) done accuracy:0.725569 logloss:3.27418\n",
      "[INFO 23-07-08 15:53:26.7608 UTC random_forest.cc:802] Training of tree  261/300 (tree index:260) done accuracy:0.726015 logloss:3.24411\n",
      "[INFO 23-07-08 15:53:26.9105 UTC random_forest.cc:802] Training of tree  271/300 (tree index:270) done accuracy:0.726015 logloss:3.24523\n",
      "[INFO 23-07-08 15:53:27.0670 UTC random_forest.cc:802] Training of tree  281/300 (tree index:280) done accuracy:0.7278 logloss:3.23106\n",
      "[INFO 23-07-08 15:53:27.2031 UTC random_forest.cc:802] Training of tree  291/300 (tree index:290) done accuracy:0.727354 logloss:3.20287\n",
      "[INFO 23-07-08 15:53:27.3252 UTC random_forest.cc:802] Training of tree  300/300 (tree index:299) done accuracy:0.728246 logloss:3.18905\n",
      "[INFO 23-07-08 15:53:27.3287 UTC random_forest.cc:882] Final OOB metrics: accuracy:0.728246 logloss:3.18905\n",
      "[INFO 23-07-08 15:53:27.3744 UTC hyperparameters_optimizer.cc:582] [41/50] Score: 0.728246 / 0.742526 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 16 } } fields { name: \"min_examples\" value { integer: 2 } }\n",
      "[INFO 23-07-08 15:53:27.3893 UTC random_forest.cc:416] Training random forest on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-08 15:53:27.4161 UTC random_forest.cc:802] Training of tree  1/300 (tree index:0) done accuracy:0.700969 logloss:10.7782\n",
      "[INFO 23-07-08 15:53:27.5158 UTC random_forest.cc:802] Training of tree  11/300 (tree index:10) done accuracy:0.713708 logloss:6.87245\n",
      "[INFO 23-07-08 15:53:27.5937 UTC random_forest.cc:802] Training of tree  21/300 (tree index:20) done accuracy:0.709058 logloss:5.37269\n",
      "[INFO 23-07-08 15:53:27.6730 UTC random_forest.cc:802] Training of tree  31/300 (tree index:30) done accuracy:0.709951 logloss:4.64262\n",
      "[INFO 23-07-08 15:53:27.7487 UTC random_forest.cc:802] Training of tree  41/300 (tree index:40) done accuracy:0.709951 logloss:4.43462\n",
      "[INFO 23-07-08 15:53:27.8269 UTC random_forest.cc:802] Training of tree  51/300 (tree index:50) done accuracy:0.712182 logloss:4.27208\n",
      "[INFO 23-07-08 15:53:27.9055 UTC random_forest.cc:802] Training of tree  61/300 (tree index:60) done accuracy:0.711736 logloss:4.14287\n",
      "[INFO 23-07-08 15:53:27.9839 UTC random_forest.cc:802] Training of tree  71/300 (tree index:70) done accuracy:0.711736 logloss:4.02476\n",
      "[INFO 23-07-08 15:53:28.0635 UTC random_forest.cc:802] Training of tree  81/300 (tree index:80) done accuracy:0.714413 logloss:3.95278\n",
      "[INFO 23-07-08 15:53:28.1430 UTC random_forest.cc:802] Training of tree  91/300 (tree index:90) done accuracy:0.713075 logloss:3.89522\n",
      "[INFO 23-07-08 15:53:28.2226 UTC random_forest.cc:802] Training of tree  101/300 (tree index:100) done accuracy:0.710397 logloss:3.80827\n",
      "[INFO 23-07-08 15:53:28.3013 UTC random_forest.cc:802] Training of tree  111/300 (tree index:110) done accuracy:0.713967 logloss:3.77754\n",
      "[INFO 23-07-08 15:53:28.3801 UTC random_forest.cc:802] Training of tree  121/300 (tree index:120) done accuracy:0.710843 logloss:3.7642\n",
      "[INFO 23-07-08 15:53:28.4585 UTC random_forest.cc:802] Training of tree  131/300 (tree index:130) done accuracy:0.712182 logloss:3.7625\n",
      "[INFO 23-07-08 15:53:28.5361 UTC random_forest.cc:802] Training of tree  141/300 (tree index:140) done accuracy:0.709505 logloss:3.7581\n",
      "[INFO 23-07-08 15:53:28.6138 UTC random_forest.cc:802] Training of tree  151/300 (tree index:150) done accuracy:0.712182 logloss:3.7159\n",
      "[INFO 23-07-08 15:53:28.6900 UTC random_forest.cc:802] Training of tree  161/300 (tree index:160) done accuracy:0.711736 logloss:3.65916\n",
      "[INFO 23-07-08 15:53:28.7658 UTC random_forest.cc:802] Training of tree  171/300 (tree index:170) done accuracy:0.712182 logloss:3.60123\n",
      "[INFO 23-07-08 15:53:28.8428 UTC random_forest.cc:802] Training of tree  181/300 (tree index:180) done accuracy:0.712628 logloss:3.58838\n",
      "[INFO 23-07-08 15:53:28.9198 UTC random_forest.cc:802] Training of tree  191/300 (tree index:190) done accuracy:0.709058 logloss:3.5469\n",
      "[INFO 23-07-08 15:53:29.0011 UTC random_forest.cc:802] Training of tree  201/300 (tree index:200) done accuracy:0.709505 logloss:3.50423\n",
      "[INFO 23-07-08 15:53:29.0787 UTC random_forest.cc:802] Training of tree  211/300 (tree index:210) done accuracy:0.709951 logloss:3.49142\n",
      "[INFO 23-07-08 15:53:29.1580 UTC random_forest.cc:802] Training of tree  221/300 (tree index:220) done accuracy:0.710397 logloss:3.44971\n",
      "[INFO 23-07-08 15:53:29.2377 UTC random_forest.cc:802] Training of tree  231/300 (tree index:230) done accuracy:0.709058 logloss:3.42257\n",
      "[INFO 23-07-08 15:53:29.3150 UTC random_forest.cc:802] Training of tree  241/300 (tree index:240) done accuracy:0.70772 logloss:3.38068\n",
      "[INFO 23-07-08 15:53:29.3912 UTC random_forest.cc:802] Training of tree  251/300 (tree index:250) done accuracy:0.709951 logloss:3.36667\n",
      "[INFO 23-07-08 15:53:29.4699 UTC random_forest.cc:802] Training of tree  261/300 (tree index:260) done accuracy:0.708612 logloss:3.36688\n",
      "[INFO 23-07-08 15:53:29.5461 UTC random_forest.cc:802] Training of tree  271/300 (tree index:270) done accuracy:0.708166 logloss:3.36725\n",
      "[INFO 23-07-08 15:53:29.6263 UTC random_forest.cc:802] Training of tree  281/300 (tree index:280) done accuracy:0.70772 logloss:3.36833\n",
      "[INFO 23-07-08 15:53:29.7049 UTC random_forest.cc:802] Training of tree  291/300 (tree index:290) done accuracy:0.709951 logloss:3.3399\n",
      "[INFO 23-07-08 15:53:29.7797 UTC random_forest.cc:802] Training of tree  300/300 (tree index:299) done accuracy:0.709951 logloss:3.34036\n",
      "[INFO 23-07-08 15:53:29.7848 UTC random_forest.cc:882] Final OOB metrics: accuracy:0.709951 logloss:3.34036\n",
      "[INFO 23-07-08 15:53:29.7901 UTC hyperparameters_optimizer.cc:582] [42/50] Score: 0.709951 / 0.742526 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 16 } } fields { name: \"min_examples\" value { integer: 40 } }\n",
      "[INFO 23-07-08 15:53:29.8005 UTC random_forest.cc:416] Training random forest on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-08 15:53:29.8588 UTC random_forest.cc:802] Training of tree  1/300 (tree index:0) done accuracy:0.708232 logloss:10.5164\n",
      "[INFO 23-07-08 15:53:29.9744 UTC random_forest.cc:802] Training of tree  11/300 (tree index:10) done accuracy:0.718652 logloss:6.44502\n",
      "[INFO 23-07-08 15:53:30.0898 UTC random_forest.cc:802] Training of tree  21/300 (tree index:20) done accuracy:0.725123 logloss:5.13537\n",
      "[INFO 23-07-08 15:53:30.2061 UTC random_forest.cc:802] Training of tree  31/300 (tree index:30) done accuracy:0.728246 logloss:4.60319\n",
      "[INFO 23-07-08 15:53:30.3210 UTC random_forest.cc:802] Training of tree  41/300 (tree index:40) done accuracy:0.73137 logloss:4.26236\n",
      "[INFO 23-07-08 15:53:30.4388 UTC random_forest.cc:802] Training of tree  51/300 (tree index:50) done accuracy:0.734047 logloss:4.07455\n",
      "[INFO 23-07-08 15:53:30.5571 UTC random_forest.cc:802] Training of tree  61/300 (tree index:60) done accuracy:0.734047 logloss:3.87288\n",
      "[INFO 23-07-08 15:53:30.6766 UTC random_forest.cc:802] Training of tree  71/300 (tree index:70) done accuracy:0.736278 logloss:3.63977\n",
      "[INFO 23-07-08 15:53:30.7942 UTC random_forest.cc:802] Training of tree  81/300 (tree index:80) done accuracy:0.736725 logloss:3.56523\n",
      "[INFO 23-07-08 15:53:30.9095 UTC random_forest.cc:802] Training of tree  91/300 (tree index:90) done accuracy:0.73851 logloss:3.47887\n",
      "[INFO 23-07-08 15:53:31.0294 UTC random_forest.cc:802] Training of tree  101/300 (tree index:100) done accuracy:0.738956 logloss:3.43864\n",
      "[INFO 23-07-08 15:53:31.1479 UTC random_forest.cc:802] Training of tree  111/300 (tree index:110) done accuracy:0.740295 logloss:3.36826\n",
      "[INFO 23-07-08 15:53:31.2658 UTC random_forest.cc:802] Training of tree  121/300 (tree index:120) done accuracy:0.739848 logloss:3.3395\n",
      "[INFO 23-07-08 15:53:31.3838 UTC random_forest.cc:802] Training of tree  131/300 (tree index:130) done accuracy:0.741633 logloss:3.26832\n",
      "[INFO 23-07-08 15:53:31.4981 UTC random_forest.cc:802] Training of tree  141/300 (tree index:140) done accuracy:0.744311 logloss:3.20827\n",
      "[INFO 23-07-08 15:53:31.6164 UTC random_forest.cc:802] Training of tree  151/300 (tree index:150) done accuracy:0.742079 logloss:3.12347\n",
      "[INFO 23-07-08 15:53:31.7353 UTC random_forest.cc:802] Training of tree  161/300 (tree index:160) done accuracy:0.742079 logloss:3.06648\n",
      "[INFO 23-07-08 15:53:31.8523 UTC random_forest.cc:802] Training of tree  171/300 (tree index:170) done accuracy:0.742972 logloss:3.03795\n",
      "[INFO 23-07-08 15:53:31.9683 UTC random_forest.cc:802] Training of tree  181/300 (tree index:180) done accuracy:0.746095 logloss:3.03807\n",
      "[INFO 23-07-08 15:53:32.0847 UTC random_forest.cc:802] Training of tree  191/300 (tree index:190) done accuracy:0.745203 logloss:3.03639\n",
      "[INFO 23-07-08 15:53:32.2057 UTC random_forest.cc:802] Training of tree  201/300 (tree index:200) done accuracy:0.743864 logloss:3.02041\n",
      "[INFO 23-07-08 15:53:32.3258 UTC random_forest.cc:802] Training of tree  211/300 (tree index:210) done accuracy:0.743418 logloss:3.02101\n",
      "[INFO 23-07-08 15:53:32.4421 UTC random_forest.cc:802] Training of tree  221/300 (tree index:220) done accuracy:0.742526 logloss:3.02043\n",
      "[INFO 23-07-08 15:53:32.5599 UTC random_forest.cc:802] Training of tree  231/300 (tree index:230) done accuracy:0.742526 logloss:2.93667\n",
      "[INFO 23-07-08 15:53:32.6792 UTC random_forest.cc:802] Training of tree  241/300 (tree index:240) done accuracy:0.742526 logloss:2.93633\n",
      "[INFO 23-07-08 15:53:32.7971 UTC random_forest.cc:802] Training of tree  251/300 (tree index:250) done accuracy:0.744311 logloss:2.92263\n",
      "[INFO 23-07-08 15:53:32.9154 UTC random_forest.cc:802] Training of tree  261/300 (tree index:260) done accuracy:0.743864 logloss:2.92187\n",
      "[INFO 23-07-08 15:53:33.0328 UTC random_forest.cc:802] Training of tree  271/300 (tree index:270) done accuracy:0.742972 logloss:2.86579\n",
      "[INFO 23-07-08 15:53:33.1511 UTC random_forest.cc:802] Training of tree  281/300 (tree index:280) done accuracy:0.743864 logloss:2.83746\n",
      "[INFO 23-07-08 15:53:33.2672 UTC random_forest.cc:802] Training of tree  291/300 (tree index:290) done accuracy:0.742972 logloss:2.82362\n",
      "[INFO 23-07-08 15:53:33.3736 UTC random_forest.cc:802] Training of tree  300/300 (tree index:299) done accuracy:0.742526 logloss:2.82433\n",
      "[INFO 23-07-08 15:53:33.3771 UTC random_forest.cc:882] Final OOB metrics: accuracy:0.742526 logloss:2.82433\n",
      "[INFO 23-07-08 15:53:33.4049 UTC hyperparameters_optimizer.cc:582] [43/50] Score: 0.742526 / 0.742526 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"min_examples\" value { integer: 5 } }\n",
      "[INFO 23-07-08 15:53:33.4190 UTC random_forest.cc:416] Training random forest on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-08 15:53:33.4437 UTC random_forest.cc:802] Training of tree  1/300 (tree index:0) done accuracy:0.72276 logloss:9.99273\n",
      "[INFO 23-07-08 15:53:33.5202 UTC random_forest.cc:802] Training of tree  11/300 (tree index:10) done accuracy:0.715955 logloss:6.35871\n",
      "[INFO 23-07-08 15:53:33.5845 UTC random_forest.cc:802] Training of tree  21/300 (tree index:20) done accuracy:0.729139 logloss:5.28613\n",
      "[INFO 23-07-08 15:53:33.6480 UTC random_forest.cc:802] Training of tree  31/300 (tree index:30) done accuracy:0.722892 logloss:4.63476\n",
      "[INFO 23-07-08 15:53:33.7087 UTC random_forest.cc:802] Training of tree  41/300 (tree index:40) done accuracy:0.726015 logloss:4.28068\n",
      "[INFO 23-07-08 15:53:33.7720 UTC random_forest.cc:802] Training of tree  51/300 (tree index:50) done accuracy:0.721999 logloss:4.10305\n",
      "[INFO 23-07-08 15:53:33.8330 UTC random_forest.cc:802] Training of tree  61/300 (tree index:60) done accuracy:0.723784 logloss:3.92752\n",
      "[INFO 23-07-08 15:53:33.8965 UTC random_forest.cc:802] Training of tree  71/300 (tree index:70) done accuracy:0.724676 logloss:3.7261\n",
      "[INFO 23-07-08 15:53:33.9597 UTC random_forest.cc:802] Training of tree  81/300 (tree index:80) done accuracy:0.728246 logloss:3.62358\n",
      "[INFO 23-07-08 15:53:34.0251 UTC random_forest.cc:802] Training of tree  91/300 (tree index:90) done accuracy:0.7278 logloss:3.55372\n",
      "[INFO 23-07-08 15:53:34.0881 UTC random_forest.cc:802] Training of tree  101/300 (tree index:100) done accuracy:0.729585 logloss:3.48207\n",
      "[INFO 23-07-08 15:53:34.1502 UTC random_forest.cc:802] Training of tree  111/300 (tree index:110) done accuracy:0.728693 logloss:3.45414\n",
      "[INFO 23-07-08 15:53:34.2119 UTC random_forest.cc:802] Training of tree  121/300 (tree index:120) done accuracy:0.730477 logloss:3.36771\n",
      "[INFO 23-07-08 15:53:34.2756 UTC random_forest.cc:802] Training of tree  131/300 (tree index:130) done accuracy:0.73137 logloss:3.3671\n",
      "[INFO 23-07-08 15:53:34.3405 UTC random_forest.cc:802] Training of tree  141/300 (tree index:140) done accuracy:0.730477 logloss:3.3222\n",
      "[INFO 23-07-08 15:53:34.4011 UTC random_forest.cc:802] Training of tree  151/300 (tree index:150) done accuracy:0.731816 logloss:3.30723\n",
      "[INFO 23-07-08 15:53:34.4631 UTC random_forest.cc:802] Training of tree  161/300 (tree index:160) done accuracy:0.730031 logloss:3.26524\n",
      "[INFO 23-07-08 15:53:34.5259 UTC random_forest.cc:802] Training of tree  171/300 (tree index:170) done accuracy:0.729585 logloss:3.17878\n",
      "[INFO 23-07-08 15:53:34.5891 UTC random_forest.cc:802] Training of tree  181/300 (tree index:180) done accuracy:0.731816 logloss:3.17934\n",
      "[INFO 23-07-08 15:53:34.6530 UTC random_forest.cc:802] Training of tree  191/300 (tree index:190) done accuracy:0.732262 logloss:3.179\n",
      "[INFO 23-07-08 15:53:34.7152 UTC random_forest.cc:802] Training of tree  201/300 (tree index:200) done accuracy:0.732262 logloss:3.17818\n",
      "[INFO 23-07-08 15:53:34.7753 UTC random_forest.cc:802] Training of tree  211/300 (tree index:210) done accuracy:0.734494 logloss:3.17807\n",
      "[INFO 23-07-08 15:53:34.8367 UTC random_forest.cc:802] Training of tree  221/300 (tree index:220) done accuracy:0.734047 logloss:3.13614\n",
      "[INFO 23-07-08 15:53:34.8980 UTC random_forest.cc:802] Training of tree  231/300 (tree index:230) done accuracy:0.730924 logloss:3.07985\n",
      "[INFO 23-07-08 15:53:34.9595 UTC random_forest.cc:802] Training of tree  241/300 (tree index:240) done accuracy:0.733601 logloss:2.95322\n",
      "[INFO 23-07-08 15:53:35.0224 UTC random_forest.cc:802] Training of tree  251/300 (tree index:250) done accuracy:0.732262 logloss:2.95343\n",
      "[INFO 23-07-08 15:53:35.0834 UTC random_forest.cc:802] Training of tree  261/300 (tree index:260) done accuracy:0.73137 logloss:2.93994\n",
      "[INFO 23-07-08 15:53:35.1461 UTC random_forest.cc:802] Training of tree  271/300 (tree index:270) done accuracy:0.732709 logloss:2.94014\n",
      "[INFO 23-07-08 15:53:35.2060 UTC random_forest.cc:802] Training of tree  281/300 (tree index:280) done accuracy:0.734494 logloss:2.94138\n",
      "[INFO 23-07-08 15:53:35.2677 UTC random_forest.cc:802] Training of tree  291/300 (tree index:290) done accuracy:0.734494 logloss:2.92751\n",
      "[INFO 23-07-08 15:53:35.3266 UTC random_forest.cc:802] Training of tree  300/300 (tree index:299) done accuracy:0.734494 logloss:2.92816\n",
      "[INFO 23-07-08 15:53:35.3306 UTC random_forest.cc:882] Final OOB metrics: accuracy:0.734494 logloss:2.92816\n",
      "[INFO 23-07-08 15:53:35.3690 UTC hyperparameters_optimizer.cc:582] [44/50] Score: 0.734494 / 0.742526 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"min_examples\" value { integer: 2 } }\n",
      "[INFO 23-07-08 15:53:35.4361 UTC random_forest.cc:416] Training random forest on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-08 15:53:35.5006 UTC random_forest.cc:802] Training of tree  1/300 (tree index:0) done accuracy:0.72276 logloss:9.99273\n",
      "[INFO 23-07-08 15:53:35.5558 UTC random_forest.cc:802] Training of tree  11/300 (tree index:10) done accuracy:0.720899 logloss:6.47713\n",
      "[INFO 23-07-08 15:53:35.6087 UTC random_forest.cc:802] Training of tree  21/300 (tree index:20) done accuracy:0.729585 logloss:5.31491\n",
      "[INFO 23-07-08 15:53:35.6639 UTC random_forest.cc:802] Training of tree  31/300 (tree index:30) done accuracy:0.728246 logloss:4.72396\n",
      "[INFO 23-07-08 15:53:35.7194 UTC random_forest.cc:802] Training of tree  41/300 (tree index:40) done accuracy:0.728246 logloss:4.50174\n",
      "[INFO 23-07-08 15:53:35.7750 UTC random_forest.cc:802] Training of tree  51/300 (tree index:50) done accuracy:0.733601 logloss:4.296\n",
      "[INFO 23-07-08 15:53:35.8296 UTC random_forest.cc:802] Training of tree  61/300 (tree index:60) done accuracy:0.732262 logloss:4.02055\n",
      "[INFO 23-07-08 15:53:35.8863 UTC random_forest.cc:802] Training of tree  71/300 (tree index:70) done accuracy:0.731816 logloss:3.72998\n",
      "[INFO 23-07-08 15:53:35.9422 UTC random_forest.cc:802] Training of tree  81/300 (tree index:80) done accuracy:0.732709 logloss:3.67193\n",
      "[INFO 23-07-08 15:53:35.9981 UTC random_forest.cc:802] Training of tree  91/300 (tree index:90) done accuracy:0.733601 logloss:3.5406\n",
      "[INFO 23-07-08 15:53:36.0523 UTC random_forest.cc:802] Training of tree  101/300 (tree index:100) done accuracy:0.736725 logloss:3.49795\n",
      "[INFO 23-07-08 15:53:36.1056 UTC random_forest.cc:802] Training of tree  111/300 (tree index:110) done accuracy:0.737617 logloss:3.36891\n",
      "[INFO 23-07-08 15:53:36.1598 UTC random_forest.cc:802] Training of tree  121/300 (tree index:120) done accuracy:0.737171 logloss:3.34046\n",
      "[INFO 23-07-08 15:53:36.2164 UTC random_forest.cc:802] Training of tree  131/300 (tree index:130) done accuracy:0.739402 logloss:3.29649\n",
      "[INFO 23-07-08 15:53:36.2717 UTC random_forest.cc:802] Training of tree  141/300 (tree index:140) done accuracy:0.737617 logloss:3.22591\n",
      "[INFO 23-07-08 15:53:36.3282 UTC random_forest.cc:802] Training of tree  151/300 (tree index:150) done accuracy:0.73851 logloss:3.17993\n",
      "[INFO 23-07-08 15:53:36.3833 UTC random_forest.cc:802] Training of tree  161/300 (tree index:160) done accuracy:0.739402 logloss:3.15116\n",
      "[INFO 23-07-08 15:53:36.4387 UTC random_forest.cc:802] Training of tree  171/300 (tree index:170) done accuracy:0.739402 logloss:3.12344\n",
      "[INFO 23-07-08 15:53:36.4956 UTC random_forest.cc:802] Training of tree  181/300 (tree index:180) done accuracy:0.738956 logloss:3.12507\n",
      "[INFO 23-07-08 15:53:36.5517 UTC random_forest.cc:802] Training of tree  191/300 (tree index:190) done accuracy:0.738063 logloss:3.11068\n",
      "[INFO 23-07-08 15:53:36.6062 UTC random_forest.cc:802] Training of tree  201/300 (tree index:200) done accuracy:0.739402 logloss:3.08143\n",
      "[INFO 23-07-08 15:53:36.6610 UTC random_forest.cc:802] Training of tree  211/300 (tree index:210) done accuracy:0.739402 logloss:3.06804\n",
      "[INFO 23-07-08 15:53:36.7160 UTC random_forest.cc:802] Training of tree  221/300 (tree index:220) done accuracy:0.737171 logloss:3.05403\n",
      "[INFO 23-07-08 15:53:36.7715 UTC random_forest.cc:802] Training of tree  231/300 (tree index:230) done accuracy:0.735832 logloss:3.04002\n",
      "[INFO 23-07-08 15:53:36.8268 UTC random_forest.cc:802] Training of tree  241/300 (tree index:240) done accuracy:0.735832 logloss:3.03943\n",
      "[INFO 23-07-08 15:53:36.8826 UTC random_forest.cc:802] Training of tree  251/300 (tree index:250) done accuracy:0.73851 logloss:3.02436\n",
      "[INFO 23-07-08 15:53:36.9394 UTC random_forest.cc:802] Training of tree  261/300 (tree index:260) done accuracy:0.738956 logloss:3.00982\n",
      "[INFO 23-07-08 15:53:36.9959 UTC random_forest.cc:802] Training of tree  271/300 (tree index:270) done accuracy:0.737617 logloss:2.99595\n",
      "[INFO 23-07-08 15:53:37.0511 UTC random_forest.cc:802] Training of tree  281/300 (tree index:280) done accuracy:0.73851 logloss:2.9944\n",
      "[INFO 23-07-08 15:53:37.1049 UTC random_forest.cc:802] Training of tree  291/300 (tree index:290) done accuracy:0.738063 logloss:2.99391\n",
      "[INFO 23-07-08 15:53:37.1562 UTC random_forest.cc:802] Training of tree  300/300 (tree index:299) done accuracy:0.738956 logloss:2.96506\n",
      "[INFO 23-07-08 15:53:37.1602 UTC random_forest.cc:882] Final OOB metrics: accuracy:0.738956 logloss:2.96506\n",
      "[INFO 23-07-08 15:53:37.2095 UTC hyperparameters_optimizer.cc:582] [45/50] Score: 0.738956 / 0.742526 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"min_examples\" value { integer: 5 } }\n",
      "[INFO 23-07-08 15:53:37.2178 UTC random_forest.cc:416] Training random forest on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-08 15:53:37.2519 UTC random_forest.cc:802] Training of tree  1/300 (tree index:0) done accuracy:0.72276 logloss:9.99273\n",
      "[INFO 23-07-08 15:53:37.3107 UTC random_forest.cc:802] Training of tree  11/300 (tree index:10) done accuracy:0.720899 logloss:6.47713\n",
      "[INFO 23-07-08 15:53:37.3653 UTC random_forest.cc:802] Training of tree  21/300 (tree index:20) done accuracy:0.729585 logloss:5.31491\n",
      "[INFO 23-07-08 15:53:37.4191 UTC random_forest.cc:802] Training of tree  31/300 (tree index:30) done accuracy:0.728246 logloss:4.72396\n",
      "[INFO 23-07-08 15:53:37.4765 UTC random_forest.cc:802] Training of tree  41/300 (tree index:40) done accuracy:0.728246 logloss:4.50174\n",
      "[INFO 23-07-08 15:53:37.5286 UTC random_forest.cc:802] Training of tree  51/300 (tree index:50) done accuracy:0.733601 logloss:4.296\n",
      "[INFO 23-07-08 15:53:37.5831 UTC random_forest.cc:802] Training of tree  61/300 (tree index:60) done accuracy:0.732262 logloss:4.02055\n",
      "[INFO 23-07-08 15:53:37.6392 UTC random_forest.cc:802] Training of tree  71/300 (tree index:70) done accuracy:0.731816 logloss:3.72998\n",
      "[INFO 23-07-08 15:53:37.6947 UTC random_forest.cc:802] Training of tree  81/300 (tree index:80) done accuracy:0.732709 logloss:3.67193\n",
      "[INFO 23-07-08 15:53:37.7494 UTC random_forest.cc:802] Training of tree  91/300 (tree index:90) done accuracy:0.733601 logloss:3.5406\n",
      "[INFO 23-07-08 15:53:37.8050 UTC random_forest.cc:802] Training of tree  101/300 (tree index:100) done accuracy:0.736725 logloss:3.49795\n",
      "[INFO 23-07-08 15:53:37.8591 UTC random_forest.cc:802] Training of tree  111/300 (tree index:110) done accuracy:0.737617 logloss:3.36891\n",
      "[INFO 23-07-08 15:53:37.9150 UTC random_forest.cc:802] Training of tree  121/300 (tree index:120) done accuracy:0.737171 logloss:3.34046\n",
      "[INFO 23-07-08 15:53:37.9692 UTC random_forest.cc:802] Training of tree  131/300 (tree index:130) done accuracy:0.739402 logloss:3.29649\n",
      "[INFO 23-07-08 15:53:38.0257 UTC random_forest.cc:802] Training of tree  141/300 (tree index:140) done accuracy:0.737617 logloss:3.22591\n",
      "[INFO 23-07-08 15:53:38.0809 UTC random_forest.cc:802] Training of tree  151/300 (tree index:150) done accuracy:0.73851 logloss:3.17993\n",
      "[INFO 23-07-08 15:53:38.1372 UTC random_forest.cc:802] Training of tree  161/300 (tree index:160) done accuracy:0.739402 logloss:3.15116\n",
      "[INFO 23-07-08 15:53:38.1897 UTC random_forest.cc:802] Training of tree  171/300 (tree index:170) done accuracy:0.739402 logloss:3.12344\n",
      "[INFO 23-07-08 15:53:38.2465 UTC random_forest.cc:802] Training of tree  181/300 (tree index:180) done accuracy:0.738956 logloss:3.12507\n",
      "[INFO 23-07-08 15:53:38.3001 UTC random_forest.cc:802] Training of tree  191/300 (tree index:190) done accuracy:0.738063 logloss:3.11068\n",
      "[INFO 23-07-08 15:53:38.3554 UTC random_forest.cc:802] Training of tree  201/300 (tree index:200) done accuracy:0.739402 logloss:3.08143\n",
      "[INFO 23-07-08 15:53:38.4110 UTC random_forest.cc:802] Training of tree  211/300 (tree index:210) done accuracy:0.739402 logloss:3.06804\n",
      "[INFO 23-07-08 15:53:38.4667 UTC random_forest.cc:802] Training of tree  221/300 (tree index:220) done accuracy:0.737171 logloss:3.05403\n",
      "[INFO 23-07-08 15:53:38.5223 UTC random_forest.cc:802] Training of tree  231/300 (tree index:230) done accuracy:0.735832 logloss:3.04002\n",
      "[INFO 23-07-08 15:53:38.5779 UTC random_forest.cc:802] Training of tree  241/300 (tree index:240) done accuracy:0.735832 logloss:3.03943\n",
      "[INFO 23-07-08 15:53:38.6329 UTC random_forest.cc:802] Training of tree  251/300 (tree index:250) done accuracy:0.73851 logloss:3.02436\n",
      "[INFO 23-07-08 15:53:38.6864 UTC random_forest.cc:802] Training of tree  261/300 (tree index:260) done accuracy:0.738956 logloss:3.00982\n",
      "[INFO 23-07-08 15:53:38.7420 UTC random_forest.cc:802] Training of tree  271/300 (tree index:270) done accuracy:0.737617 logloss:2.99595\n",
      "[INFO 23-07-08 15:53:38.7966 UTC random_forest.cc:802] Training of tree  281/300 (tree index:280) done accuracy:0.73851 logloss:2.9944\n",
      "[INFO 23-07-08 15:53:38.8513 UTC random_forest.cc:802] Training of tree  291/300 (tree index:290) done accuracy:0.738063 logloss:2.99391\n",
      "[INFO 23-07-08 15:53:38.9018 UTC random_forest.cc:802] Training of tree  300/300 (tree index:299) done accuracy:0.738956 logloss:2.96506\n",
      "[INFO 23-07-08 15:53:38.9059 UTC random_forest.cc:882] Final OOB metrics: accuracy:0.738956 logloss:2.96506\n",
      "[INFO 23-07-08 15:53:38.9306 UTC hyperparameters_optimizer.cc:582] [46/50] Score: 0.738956 / 0.742526 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"min_examples\" value { integer: 5 } }\n",
      "[INFO 23-07-08 15:53:38.9434 UTC random_forest.cc:416] Training random forest on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-08 15:53:38.9949 UTC random_forest.cc:802] Training of tree  1/300 (tree index:0) done accuracy:0.716707 logloss:10.2109\n",
      "[INFO 23-07-08 15:53:39.0424 UTC random_forest.cc:802] Training of tree  11/300 (tree index:10) done accuracy:0.710112 logloss:6.63275\n",
      "[INFO 23-07-08 15:53:39.0877 UTC random_forest.cc:802] Training of tree  21/300 (tree index:20) done accuracy:0.728693 logloss:5.46481\n",
      "[INFO 23-07-08 15:53:39.1357 UTC random_forest.cc:802] Training of tree  31/300 (tree index:30) done accuracy:0.728246 logloss:4.99131\n",
      "[INFO 23-07-08 15:53:39.1826 UTC random_forest.cc:802] Training of tree  41/300 (tree index:40) done accuracy:0.729585 logloss:4.56309\n",
      "[INFO 23-07-08 15:53:39.2295 UTC random_forest.cc:802] Training of tree  51/300 (tree index:50) done accuracy:0.728246 logloss:4.34453\n",
      "[INFO 23-07-08 15:53:39.2764 UTC random_forest.cc:802] Training of tree  61/300 (tree index:60) done accuracy:0.733601 logloss:4.18214\n",
      "[INFO 23-07-08 15:53:39.3249 UTC random_forest.cc:802] Training of tree  71/300 (tree index:70) done accuracy:0.733601 logloss:3.99388\n",
      "[INFO 23-07-08 15:53:39.3709 UTC random_forest.cc:802] Training of tree  81/300 (tree index:80) done accuracy:0.732262 logloss:3.89545\n",
      "[INFO 23-07-08 15:53:39.4161 UTC random_forest.cc:802] Training of tree  91/300 (tree index:90) done accuracy:0.73494 logloss:3.8672\n",
      "[INFO 23-07-08 15:53:39.4663 UTC random_forest.cc:802] Training of tree  101/300 (tree index:100) done accuracy:0.73494 logloss:3.75001\n",
      "[INFO 23-07-08 15:53:39.5115 UTC random_forest.cc:802] Training of tree  111/300 (tree index:110) done accuracy:0.734047 logloss:3.67642\n",
      "[INFO 23-07-08 15:53:39.5586 UTC random_forest.cc:802] Training of tree  121/300 (tree index:120) done accuracy:0.733601 logloss:3.64851\n",
      "[INFO 23-07-08 15:53:39.6061 UTC random_forest.cc:802] Training of tree  131/300 (tree index:130) done accuracy:0.736278 logloss:3.54679\n",
      "[INFO 23-07-08 15:53:39.6544 UTC random_forest.cc:802] Training of tree  141/300 (tree index:140) done accuracy:0.736725 logloss:3.44668\n",
      "[INFO 23-07-08 15:53:39.7012 UTC random_forest.cc:802] Training of tree  151/300 (tree index:150) done accuracy:0.738956 logloss:3.40438\n",
      "[INFO 23-07-08 15:53:39.7497 UTC random_forest.cc:802] Training of tree  161/300 (tree index:160) done accuracy:0.737171 logloss:3.33383\n",
      "[INFO 23-07-08 15:53:39.7973 UTC random_forest.cc:802] Training of tree  171/300 (tree index:170) done accuracy:0.736725 logloss:3.30592\n",
      "[INFO 23-07-08 15:53:39.8423 UTC random_forest.cc:802] Training of tree  181/300 (tree index:180) done accuracy:0.736725 logloss:3.29276\n",
      "[INFO 23-07-08 15:53:39.8899 UTC random_forest.cc:802] Training of tree  191/300 (tree index:190) done accuracy:0.736725 logloss:3.26406\n",
      "[INFO 23-07-08 15:53:39.9398 UTC random_forest.cc:802] Training of tree  201/300 (tree index:200) done accuracy:0.736278 logloss:3.21833\n",
      "[INFO 23-07-08 15:53:39.9851 UTC random_forest.cc:802] Training of tree  211/300 (tree index:210) done accuracy:0.737617 logloss:3.18965\n",
      "[INFO 23-07-08 15:53:40.0338 UTC random_forest.cc:802] Training of tree  221/300 (tree index:220) done accuracy:0.736725 logloss:3.1477\n",
      "[INFO 23-07-08 15:53:40.0812 UTC random_forest.cc:802] Training of tree  231/300 (tree index:230) done accuracy:0.736278 logloss:3.13392\n",
      "[INFO 23-07-08 15:53:40.1268 UTC random_forest.cc:802] Training of tree  241/300 (tree index:240) done accuracy:0.735386 logloss:3.11915\n",
      "[INFO 23-07-08 15:53:40.1732 UTC random_forest.cc:802] Training of tree  251/300 (tree index:250) done accuracy:0.735386 logloss:3.11919\n",
      "[INFO 23-07-08 15:53:40.2205 UTC random_forest.cc:802] Training of tree  261/300 (tree index:260) done accuracy:0.735386 logloss:3.09101\n",
      "[INFO 23-07-08 15:53:40.2685 UTC random_forest.cc:802] Training of tree  271/300 (tree index:270) done accuracy:0.73494 logloss:3.06321\n",
      "[INFO 23-07-08 15:53:40.3158 UTC random_forest.cc:802] Training of tree  281/300 (tree index:280) done accuracy:0.736725 logloss:3.0483\n",
      "[INFO 23-07-08 15:53:40.3631 UTC random_forest.cc:802] Training of tree  291/300 (tree index:290) done accuracy:0.736278 logloss:3.03378\n",
      "[INFO 23-07-08 15:53:40.4089 UTC random_forest.cc:802] Training of tree  300/300 (tree index:299) done accuracy:0.736725 logloss:3.03436\n",
      "[INFO 23-07-08 15:53:40.4132 UTC random_forest.cc:882] Final OOB metrics: accuracy:0.736725 logloss:3.03436\n",
      "[INFO 23-07-08 15:53:40.4326 UTC hyperparameters_optimizer.cc:582] [47/50] Score: 0.736725 / 0.742526 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 25 } } fields { name: \"min_examples\" value { integer: 10 } }\n",
      "[INFO 23-07-08 15:53:40.4429 UTC random_forest.cc:416] Training random forest on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-08 15:53:40.5172 UTC random_forest.cc:802] Training of tree  1/300 (tree index:0) done accuracy:0.700969 logloss:10.7782\n",
      "[INFO 23-07-08 15:53:40.5946 UTC random_forest.cc:802] Training of tree  11/300 (tree index:10) done accuracy:0.713708 logloss:6.87245\n",
      "[INFO 23-07-08 15:53:40.6735 UTC random_forest.cc:802] Training of tree  21/300 (tree index:20) done accuracy:0.709058 logloss:5.37269\n",
      "[INFO 23-07-08 15:53:40.7530 UTC random_forest.cc:802] Training of tree  31/300 (tree index:30) done accuracy:0.709951 logloss:4.64262\n",
      "[INFO 23-07-08 15:53:40.8295 UTC random_forest.cc:802] Training of tree  41/300 (tree index:40) done accuracy:0.709951 logloss:4.43462\n",
      "[INFO 23-07-08 15:53:40.9087 UTC random_forest.cc:802] Training of tree  51/300 (tree index:50) done accuracy:0.712182 logloss:4.27208\n",
      "[INFO 23-07-08 15:53:40.9873 UTC random_forest.cc:802] Training of tree  61/300 (tree index:60) done accuracy:0.711736 logloss:4.14287\n",
      "[INFO 23-07-08 15:53:41.0644 UTC random_forest.cc:802] Training of tree  71/300 (tree index:70) done accuracy:0.711736 logloss:4.02476\n",
      "[INFO 23-07-08 15:53:41.1435 UTC random_forest.cc:802] Training of tree  81/300 (tree index:80) done accuracy:0.714413 logloss:3.95278\n",
      "[INFO 23-07-08 15:53:41.2215 UTC random_forest.cc:802] Training of tree  91/300 (tree index:90) done accuracy:0.713075 logloss:3.89522\n",
      "[INFO 23-07-08 15:53:41.2992 UTC random_forest.cc:802] Training of tree  101/300 (tree index:100) done accuracy:0.710397 logloss:3.80827\n",
      "[INFO 23-07-08 15:53:41.3798 UTC random_forest.cc:802] Training of tree  111/300 (tree index:110) done accuracy:0.713967 logloss:3.77754\n",
      "[INFO 23-07-08 15:53:41.4588 UTC random_forest.cc:802] Training of tree  121/300 (tree index:120) done accuracy:0.710843 logloss:3.7642\n",
      "[INFO 23-07-08 15:53:41.5356 UTC random_forest.cc:802] Training of tree  131/300 (tree index:130) done accuracy:0.712182 logloss:3.7625\n",
      "[INFO 23-07-08 15:53:41.6107 UTC random_forest.cc:802] Training of tree  141/300 (tree index:140) done accuracy:0.709505 logloss:3.7581\n",
      "[INFO 23-07-08 15:53:41.6885 UTC random_forest.cc:802] Training of tree  151/300 (tree index:150) done accuracy:0.712182 logloss:3.7159\n",
      "[INFO 23-07-08 15:53:41.7644 UTC random_forest.cc:802] Training of tree  161/300 (tree index:160) done accuracy:0.711736 logloss:3.65916\n",
      "[INFO 23-07-08 15:53:41.8424 UTC random_forest.cc:802] Training of tree  171/300 (tree index:170) done accuracy:0.712182 logloss:3.60123\n",
      "[INFO 23-07-08 15:53:41.9244 UTC random_forest.cc:802] Training of tree  181/300 (tree index:180) done accuracy:0.712628 logloss:3.58838\n",
      "[INFO 23-07-08 15:53:42.0035 UTC random_forest.cc:802] Training of tree  191/300 (tree index:190) done accuracy:0.709058 logloss:3.5469\n",
      "[INFO 23-07-08 15:53:42.0839 UTC random_forest.cc:802] Training of tree  201/300 (tree index:200) done accuracy:0.709505 logloss:3.50423\n",
      "[INFO 23-07-08 15:53:42.1638 UTC random_forest.cc:802] Training of tree  211/300 (tree index:210) done accuracy:0.709951 logloss:3.49142\n",
      "[INFO 23-07-08 15:53:42.2454 UTC random_forest.cc:802] Training of tree  221/300 (tree index:220) done accuracy:0.710397 logloss:3.44971\n",
      "[INFO 23-07-08 15:53:42.3240 UTC random_forest.cc:802] Training of tree  231/300 (tree index:230) done accuracy:0.709058 logloss:3.42257\n",
      "[INFO 23-07-08 15:53:42.4022 UTC random_forest.cc:802] Training of tree  241/300 (tree index:240) done accuracy:0.70772 logloss:3.38068\n",
      "[INFO 23-07-08 15:53:42.4798 UTC random_forest.cc:802] Training of tree  251/300 (tree index:250) done accuracy:0.709951 logloss:3.36667\n",
      "[INFO 23-07-08 15:53:42.5605 UTC random_forest.cc:802] Training of tree  261/300 (tree index:260) done accuracy:0.708612 logloss:3.36688\n",
      "[INFO 23-07-08 15:53:42.6432 UTC random_forest.cc:802] Training of tree  271/300 (tree index:270) done accuracy:0.708166 logloss:3.36725\n",
      "[INFO 23-07-08 15:53:42.7219 UTC random_forest.cc:802] Training of tree  281/300 (tree index:280) done accuracy:0.70772 logloss:3.36833\n",
      "[INFO 23-07-08 15:53:42.8005 UTC random_forest.cc:802] Training of tree  291/300 (tree index:290) done accuracy:0.709951 logloss:3.3399\n",
      "[INFO 23-07-08 15:53:42.8736 UTC random_forest.cc:802] Training of tree  300/300 (tree index:299) done accuracy:0.709951 logloss:3.34036\n",
      "[INFO 23-07-08 15:53:42.8777 UTC random_forest.cc:882] Final OOB metrics: accuracy:0.709951 logloss:3.34036\n",
      "[INFO 23-07-08 15:53:42.8847 UTC hyperparameters_optimizer.cc:582] [48/50] Score: 0.709951 / 0.742526 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 16 } } fields { name: \"min_examples\" value { integer: 40 } }\n",
      "[INFO 23-07-08 15:53:42.8919 UTC random_forest.cc:416] Training random forest on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-08 15:53:42.9568 UTC random_forest.cc:802] Training of tree  1/300 (tree index:0) done accuracy:0.708232 logloss:10.5164\n",
      "[INFO 23-07-08 15:53:43.0650 UTC random_forest.cc:802] Training of tree  11/300 (tree index:10) done accuracy:0.719101 logloss:6.33719\n",
      "[INFO 23-07-08 15:53:43.1679 UTC random_forest.cc:802] Training of tree  21/300 (tree index:20) done accuracy:0.722892 logloss:5.2419\n",
      "[INFO 23-07-08 15:53:43.2716 UTC random_forest.cc:802] Training of tree  31/300 (tree index:30) done accuracy:0.726015 logloss:4.77975\n",
      "[INFO 23-07-08 15:53:43.3751 UTC random_forest.cc:802] Training of tree  41/300 (tree index:40) done accuracy:0.732262 logloss:4.48539\n",
      "[INFO 23-07-08 15:53:43.4807 UTC random_forest.cc:802] Training of tree  51/300 (tree index:50) done accuracy:0.728693 logloss:4.33824\n",
      "[INFO 23-07-08 15:53:43.5933 UTC random_forest.cc:802] Training of tree  61/300 (tree index:60) done accuracy:0.732709 logloss:4.11863\n",
      "[INFO 23-07-08 15:53:43.7017 UTC random_forest.cc:802] Training of tree  71/300 (tree index:70) done accuracy:0.732262 logloss:3.81381\n",
      "[INFO 23-07-08 15:53:43.8075 UTC random_forest.cc:802] Training of tree  81/300 (tree index:80) done accuracy:0.730477 logloss:3.68409\n",
      "[INFO 23-07-08 15:53:43.9133 UTC random_forest.cc:802] Training of tree  91/300 (tree index:90) done accuracy:0.733601 logloss:3.54006\n",
      "[INFO 23-07-08 15:53:44.0194 UTC random_forest.cc:802] Training of tree  101/300 (tree index:100) done accuracy:0.732262 logloss:3.45508\n",
      "[INFO 23-07-08 15:53:44.1267 UTC random_forest.cc:802] Training of tree  111/300 (tree index:110) done accuracy:0.732262 logloss:3.42407\n",
      "[INFO 23-07-08 15:53:44.2310 UTC random_forest.cc:802] Training of tree  121/300 (tree index:120) done accuracy:0.731816 logloss:3.39622\n",
      "[INFO 23-07-08 15:53:44.3359 UTC random_forest.cc:802] Training of tree  131/300 (tree index:130) done accuracy:0.730924 logloss:3.23497\n",
      "[INFO 23-07-08 15:53:44.4399 UTC random_forest.cc:802] Training of tree  141/300 (tree index:140) done accuracy:0.732709 logloss:3.20596\n",
      "[INFO 23-07-08 15:53:44.5455 UTC random_forest.cc:802] Training of tree  151/300 (tree index:150) done accuracy:0.733601 logloss:3.17656\n",
      "[INFO 23-07-08 15:53:44.6551 UTC random_forest.cc:802] Training of tree  161/300 (tree index:160) done accuracy:0.735832 logloss:3.14806\n",
      "[INFO 23-07-08 15:53:44.7615 UTC random_forest.cc:802] Training of tree  171/300 (tree index:170) done accuracy:0.734047 logloss:3.13536\n",
      "[INFO 23-07-08 15:53:44.8667 UTC random_forest.cc:802] Training of tree  181/300 (tree index:180) done accuracy:0.735386 logloss:3.09296\n",
      "[INFO 23-07-08 15:53:44.9727 UTC random_forest.cc:802] Training of tree  191/300 (tree index:190) done accuracy:0.735386 logloss:3.09429\n",
      "[INFO 23-07-08 15:53:45.0785 UTC random_forest.cc:802] Training of tree  201/300 (tree index:200) done accuracy:0.735832 logloss:3.06507\n",
      "[INFO 23-07-08 15:53:45.1837 UTC random_forest.cc:802] Training of tree  211/300 (tree index:210) done accuracy:0.735832 logloss:3.05233\n",
      "[INFO 23-07-08 15:53:45.2897 UTC random_forest.cc:802] Training of tree  221/300 (tree index:220) done accuracy:0.736278 logloss:3.05248\n",
      "[INFO 23-07-08 15:53:45.3959 UTC random_forest.cc:802] Training of tree  231/300 (tree index:230) done accuracy:0.736725 logloss:2.96758\n",
      "[INFO 23-07-08 15:53:45.5026 UTC random_forest.cc:802] Training of tree  241/300 (tree index:240) done accuracy:0.736278 logloss:2.85421\n",
      "[INFO 23-07-08 15:53:45.6067 UTC random_forest.cc:802] Training of tree  251/300 (tree index:250) done accuracy:0.736725 logloss:2.84186\n",
      "[INFO 23-07-08 15:53:45.7131 UTC random_forest.cc:802] Training of tree  261/300 (tree index:260) done accuracy:0.737171 logloss:2.81327\n",
      "[INFO 23-07-08 15:53:45.8223 UTC random_forest.cc:802] Training of tree  271/300 (tree index:270) done accuracy:0.735386 logloss:2.80004\n",
      "[INFO 23-07-08 15:53:45.9292 UTC random_forest.cc:802] Training of tree  281/300 (tree index:280) done accuracy:0.738063 logloss:2.77158\n",
      "[INFO 23-07-08 15:53:46.0354 UTC random_forest.cc:802] Training of tree  291/300 (tree index:290) done accuracy:0.73851 logloss:2.75736\n",
      "[INFO 23-07-08 15:53:46.1321 UTC random_forest.cc:802] Training of tree  300/300 (tree index:299) done accuracy:0.73851 logloss:2.75699\n",
      "[INFO 23-07-08 15:53:46.1357 UTC random_forest.cc:882] Final OOB metrics: accuracy:0.73851 logloss:2.75699\n",
      "[INFO 23-07-08 15:53:46.1533 UTC hyperparameters_optimizer.cc:582] [49/50] Score: 0.73851 / 0.742526 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"min_examples\" value { integer: 10 } }\n",
      "[INFO 23-07-08 15:53:46.1670 UTC random_forest.cc:416] Training random forest on 2241 example(s) and 6 feature(s).\n",
      "[INFO 23-07-08 15:53:46.1964 UTC random_forest.cc:802] Training of tree  1/300 (tree index:0) done accuracy:0.702179 logloss:10.7345\n",
      "[INFO 23-07-08 15:53:46.3038 UTC random_forest.cc:802] Training of tree  11/300 (tree index:10) done accuracy:0.710562 logloss:6.57439\n",
      "[INFO 23-07-08 15:53:46.4061 UTC random_forest.cc:802] Training of tree  21/300 (tree index:20) done accuracy:0.723784 logloss:5.3979\n",
      "[INFO 23-07-08 15:53:46.5095 UTC random_forest.cc:802] Training of tree  31/300 (tree index:30) done accuracy:0.729585 logloss:4.76787\n",
      "[INFO 23-07-08 15:53:46.6140 UTC random_forest.cc:802] Training of tree  41/300 (tree index:40) done accuracy:0.730924 logloss:4.4903\n",
      "[INFO 23-07-08 15:53:46.7235 UTC random_forest.cc:802] Training of tree  51/300 (tree index:50) done accuracy:0.73137 logloss:4.29551\n",
      "[INFO 23-07-08 15:53:46.8346 UTC random_forest.cc:802] Training of tree  61/300 (tree index:60) done accuracy:0.734494 logloss:4.09206\n",
      "[INFO 23-07-08 15:53:46.9414 UTC random_forest.cc:802] Training of tree  71/300 (tree index:70) done accuracy:0.737617 logloss:3.91753\n",
      "[INFO 23-07-08 15:53:47.0470 UTC random_forest.cc:802] Training of tree  81/300 (tree index:80) done accuracy:0.73494 logloss:3.72881\n",
      "[INFO 23-07-08 15:53:47.1534 UTC random_forest.cc:802] Training of tree  91/300 (tree index:90) done accuracy:0.737617 logloss:3.59751\n",
      "[INFO 23-07-08 15:53:47.2600 UTC random_forest.cc:802] Training of tree  101/300 (tree index:100) done accuracy:0.737617 logloss:3.53982\n",
      "[INFO 23-07-08 15:53:47.3684 UTC random_forest.cc:802] Training of tree  111/300 (tree index:110) done accuracy:0.738063 logloss:3.49579\n",
      "[INFO 23-07-08 15:53:47.4743 UTC random_forest.cc:802] Training of tree  121/300 (tree index:120) done accuracy:0.738956 logloss:3.46867\n",
      "[INFO 23-07-08 15:53:47.5794 UTC random_forest.cc:802] Training of tree  131/300 (tree index:130) done accuracy:0.740295 logloss:3.35234\n",
      "[INFO 23-07-08 15:53:47.6859 UTC random_forest.cc:802] Training of tree  141/300 (tree index:140) done accuracy:0.737617 logloss:3.30928\n",
      "[INFO 23-07-08 15:53:47.7960 UTC random_forest.cc:802] Training of tree  151/300 (tree index:150) done accuracy:0.736278 logloss:3.28073\n",
      "[INFO 23-07-08 15:53:47.9017 UTC random_forest.cc:802] Training of tree  161/300 (tree index:160) done accuracy:0.738956 logloss:3.25215\n",
      "[INFO 23-07-08 15:53:48.0079 UTC random_forest.cc:802] Training of tree  171/300 (tree index:170) done accuracy:0.739402 logloss:3.23938\n",
      "[INFO 23-07-08 15:53:48.1129 UTC random_forest.cc:802] Training of tree  181/300 (tree index:180) done accuracy:0.740295 logloss:3.19694\n",
      "[INFO 23-07-08 15:53:48.2172 UTC random_forest.cc:802] Training of tree  191/300 (tree index:190) done accuracy:0.739848 logloss:3.19727\n",
      "[INFO 23-07-08 15:53:48.3232 UTC random_forest.cc:802] Training of tree  201/300 (tree index:200) done accuracy:0.739848 logloss:3.12628\n",
      "[INFO 23-07-08 15:53:48.4291 UTC random_forest.cc:802] Training of tree  211/300 (tree index:210) done accuracy:0.740295 logloss:3.11127\n",
      "[INFO 23-07-08 15:53:48.5369 UTC random_forest.cc:802] Training of tree  221/300 (tree index:220) done accuracy:0.738956 logloss:3.11175\n",
      "[INFO 23-07-08 15:53:48.6441 UTC random_forest.cc:802] Training of tree  231/300 (tree index:230) done accuracy:0.737617 logloss:3.01417\n",
      "[INFO 23-07-08 15:53:48.7500 UTC random_forest.cc:802] Training of tree  241/300 (tree index:240) done accuracy:0.739848 logloss:2.88744\n",
      "[INFO 23-07-08 15:53:48.8553 UTC random_forest.cc:802] Training of tree  251/300 (tree index:250) done accuracy:0.740741 logloss:2.87439\n",
      "[INFO 23-07-08 15:53:48.9666 UTC random_forest.cc:802] Training of tree  261/300 (tree index:260) done accuracy:0.742079 logloss:2.85934\n",
      "[INFO 23-07-08 15:53:49.0755 UTC random_forest.cc:802] Training of tree  271/300 (tree index:270) done accuracy:0.741187 logloss:2.85886\n",
      "[INFO 23-07-08 15:53:49.1841 UTC random_forest.cc:802] Training of tree  281/300 (tree index:280) done accuracy:0.741633 logloss:2.84431\n",
      "[INFO 23-07-08 15:53:49.2936 UTC random_forest.cc:802] Training of tree  291/300 (tree index:290) done accuracy:0.739848 logloss:2.83022\n",
      "[INFO 23-07-08 15:53:49.3921 UTC random_forest.cc:802] Training of tree  300/300 (tree index:299) done accuracy:0.740741 logloss:2.83054\n",
      "[INFO 23-07-08 15:53:49.3951 UTC random_forest.cc:882] Final OOB metrics: accuracy:0.740741 logloss:2.83054\n",
      "[INFO 23-07-08 15:53:49.4153 UTC hyperparameters_optimizer.cc:582] [50/50] Score: 0.740741 / 0.742526 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 25 } } fields { name: \"min_examples\" value { integer: 10 } }\n",
      "[INFO 23-07-08 15:53:49.4364 UTC hyperparameters_optimizer.cc:219] Best hyperparameters:\n",
      "fields {\n",
      "  name: \"split_axis\"\n",
      "  value {\n",
      "    categorical: \"SPARSE_OBLIQUE\"\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"sparse_oblique_projection_density_factor\"\n",
      "  value {\n",
      "    real: 4\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"sparse_oblique_normalization\"\n",
      "  value {\n",
      "    categorical: \"NONE\"\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"sparse_oblique_weights\"\n",
      "  value {\n",
      "    categorical: \"CONTINUOUS\"\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"categorical_algorithm\"\n",
      "  value {\n",
      "    categorical: \"RANDOM\"\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"winner_take_all\"\n",
      "  value {\n",
      "    categorical: \"true\"\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"max_depth\"\n",
      "  value {\n",
      "    integer: 12\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"min_examples\"\n",
      "  value {\n",
      "    integer: 5\n",
      "  }\n",
      "}\n",
      "\n",
      "[INFO 23-07-08 15:53:49.4370 UTC kernel.cc:926] Export model in log directory: /var/tmp/tmpgxiuwd92 with prefix e1cffb4f4ec749f7\n",
      "[INFO 23-07-08 15:53:49.5716 UTC kernel.cc:944] Save model in resources\n",
      "[INFO 23-07-08 15:53:49.6061 UTC abstract_model.cc:849] Model self evaluation:\n",
      "Number of predictions (without weights): 2241\n",
      "Number of predictions (with weights): 2241\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.742526  CI95[W][0.72688 0.7577]\n",
      "LogLoss: : 2.82433\n",
      "ErrorRate: : 0.257474\n",
      "\n",
      "Default Accuracy: : 0.483713\n",
      "Default LogLoss: : 1.15674\n",
      "Default ErrorRate: : 0.516287\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "   0    1    2    3   4\n",
      "0  0    0    0    0   0\n",
      "1  0  336   44   21   0\n",
      "2  0   49  380  227   1\n",
      "3  0   21  120  938   5\n",
      "4  0    3    6   80  10\n",
      "Total: 2241\n",
      "\n",
      "One vs other classes:\n",
      "\n",
      "[INFO 23-07-08 15:53:49.6703 UTC kernel.cc:1243] Loading model from path /var/tmp/tmpgxiuwd92/model/ with prefix e1cffb4f4ec749f7\n",
      "[INFO 23-07-08 15:53:49.9598 UTC decision_forest.cc:660] Model loaded with 300 root(s), 85372 node(s), and 6 input feature(s).\n",
      "[INFO 23-07-08 15:53:49.9628 UTC abstract_model.cc:1311] Engine \"RandomForestGeneric\" built\n",
      "[INFO 23-07-08 15:53:49.9628 UTC kernel.cc:1075] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained in 0:02:27.280888\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-08 15:53:50.018540: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype string and shape [2241]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function InferenceCoreModel.make_predict_function.<locals>.predict_function_trained at 0x7f0e349525f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function InferenceCoreModel.make_predict_function.<locals>.predict_function_trained at 0x7f0e349525f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "WARNING:tensorflow:5 out of the last 8 calls to <function InferenceCoreModel.yggdrasil_model_path_tensor at 0x7f0e34951ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 8 calls to <function InferenceCoreModel.yggdrasil_model_path_tensor at 0x7f0e34951ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0e38c42590>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner = tfdf.tuner.RandomSearch(num_trials=50, use_predefined_hps=True)\n",
    "# Specify the model.\n",
    "if model_tree_type==1:\n",
    "    print(\"GradientBoostedTreesModel\")\n",
    "    tuned_model=tfdf.keras.GradientBoostedTreesModel(tuner=tuner)\n",
    "else:\n",
    "    print(\"RandomForestModel\")\n",
    "    tuned_model = tfdf.keras.RandomForestModel(tuner=tuner)\n",
    "\n",
    "tuned_model.fit(x=train_ds,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "c36921b9-d118-4a92-82c2-23ed332defca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total execution :  0.08\n",
      "2023-07-08 15:56:19.066607\n"
     ]
    }
   ],
   "source": [
    "t_End=time.time()\n",
    "t_elapsed=(t_End-t_Start)/60/60\n",
    "print('Total execution : ',round(t_elapsed,2)) \n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b6f489-e628-41c2-bba2-d71ce40392c5",
   "metadata": {},
   "source": [
    "# Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "ed1044ae-7da6-4273-acac-363700e7aecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function InferenceCoreModel.make_test_function.<locals>.test_function at 0x7f0e34952320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-08 15:56:22.984596: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_6' with dtype int64 and shape [561]\n",
      "\t [[{{node Placeholder/_6}}]]\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function InferenceCoreModel.make_test_function.<locals>.test_function at 0x7f0e34952320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy with the TF-DF hyper-parameter tuner: 0.7059\n"
     ]
    }
   ],
   "source": [
    "tuned_model.compile([\"accuracy\"])\n",
    "tuned_test_accuracy = tuned_model.evaluate(test_ds, return_dict=True, verbose=0)[\"accuracy\"]\n",
    "print(f\"Test accuracy with the TF-DF hyper-parameter tuner: {tuned_test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba6e508-1298-4916-a8f1-af00990c0645",
   "metadata": {},
   "source": [
    "# Inspect and debug decision forest models\n",
    "## Model structure and feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "161a5f2c-c349-48ab-abb6-1a484eb2fb4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>evaluation_time</th>\n",
       "      <th>best</th>\n",
       "      <th>split_axis</th>\n",
       "      <th>sparse_oblique_projection_density_factor</th>\n",
       "      <th>sparse_oblique_normalization</th>\n",
       "      <th>sparse_oblique_weights</th>\n",
       "      <th>categorical_algorithm</th>\n",
       "      <th>winner_take_all</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_examples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.705042</td>\n",
       "      <td>1.011091</td>\n",
       "      <td>False</td>\n",
       "      <td>SPARSE_OBLIQUE</td>\n",
       "      <td>5.0</td>\n",
       "      <td>MIN_MAX</td>\n",
       "      <td>BINARY</td>\n",
       "      <td>CART</td>\n",
       "      <td>true</td>\n",
       "      <td>12</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.720214</td>\n",
       "      <td>3.448616</td>\n",
       "      <td>False</td>\n",
       "      <td>SPARSE_OBLIQUE</td>\n",
       "      <td>5.0</td>\n",
       "      <td>MIN_MAX</td>\n",
       "      <td>CONTINUOUS</td>\n",
       "      <td>CART</td>\n",
       "      <td>true</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.740741</td>\n",
       "      <td>6.737096</td>\n",
       "      <td>False</td>\n",
       "      <td>SPARSE_OBLIQUE</td>\n",
       "      <td>4.0</td>\n",
       "      <td>MIN_MAX</td>\n",
       "      <td>CONTINUOUS</td>\n",
       "      <td>RANDOM</td>\n",
       "      <td>true</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.724230</td>\n",
       "      <td>9.026426</td>\n",
       "      <td>False</td>\n",
       "      <td>SPARSE_OBLIQUE</td>\n",
       "      <td>4.0</td>\n",
       "      <td>STANDARD_DEVIATION</td>\n",
       "      <td>BINARY</td>\n",
       "      <td>CART</td>\n",
       "      <td>true</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.736725</td>\n",
       "      <td>10.593147</td>\n",
       "      <td>False</td>\n",
       "      <td>SPARSE_OBLIQUE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MIN_MAX</td>\n",
       "      <td>CONTINUOUS</td>\n",
       "      <td>CART</td>\n",
       "      <td>true</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score  evaluation_time   best      split_axis  \\\n",
       "0  0.705042         1.011091  False  SPARSE_OBLIQUE   \n",
       "1  0.720214         3.448616  False  SPARSE_OBLIQUE   \n",
       "2  0.740741         6.737096  False  SPARSE_OBLIQUE   \n",
       "3  0.724230         9.026426  False  SPARSE_OBLIQUE   \n",
       "4  0.736725        10.593147  False  SPARSE_OBLIQUE   \n",
       "\n",
       "   sparse_oblique_projection_density_factor sparse_oblique_normalization  \\\n",
       "0                                       5.0                      MIN_MAX   \n",
       "1                                       5.0                      MIN_MAX   \n",
       "2                                       4.0                      MIN_MAX   \n",
       "3                                       4.0           STANDARD_DEVIATION   \n",
       "4                                       1.0                      MIN_MAX   \n",
       "\n",
       "  sparse_oblique_weights categorical_algorithm winner_take_all  max_depth  \\\n",
       "0                 BINARY                  CART            true         12   \n",
       "1             CONTINUOUS                  CART            true         16   \n",
       "2             CONTINUOUS                RANDOM            true         16   \n",
       "3                 BINARY                  CART            true         25   \n",
       "4             CONTINUOUS                  CART            true         20   \n",
       "\n",
       "   min_examples  \n",
       "0            40  \n",
       "1             1  \n",
       "2            10  \n",
       "3             2  \n",
       "4            10  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the tuning logs.\n",
    "tuning_logs = tuned_model.make_inspector().tuning_logs()\n",
    "tuning_logs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "bb31ca9d-04c7-45a6-895b-fc8bee1febd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "score                                             0.742526\n",
       "evaluation_time                                  95.078428\n",
       "best                                                  True\n",
       "split_axis                                  SPARSE_OBLIQUE\n",
       "sparse_oblique_projection_density_factor               4.0\n",
       "sparse_oblique_normalization                          NONE\n",
       "sparse_oblique_weights                          CONTINUOUS\n",
       "categorical_algorithm                               RANDOM\n",
       "winner_take_all                                       true\n",
       "max_depth                                               12\n",
       "min_examples                                             5\n",
       "Name: 32, dtype: object"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best hyper-parameters.\n",
    "tuning_logs[tuning_logs.best].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cadf966-6f4f-417b-8529-2ec2e64759b7",
   "metadata": {},
   "source": [
    "# Plotting the training logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "68a3292b-f7cc-4f0c-b491-e84206636957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(tuning_logs[\"score\"], label=\"current trial\")\n",
    "plt.plot(tuning_logs[\"score\"].cummax(), label=\"best trial\")\n",
    "plt.xlabel(\"Tuning step\")\n",
    "plt.ylabel(\"Tuning score\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74420e30-fbb5-4730-bb48-b8a3efce49ce",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "2b21d1d7-6d34-4c40-b0a2-fac22ca7097e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "WARNING:absl:Found untraced functions such as call_get_leaves, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: gs://demo-tuned-tf-incident-pongthorn/model_tuned_rf_tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: gs://demo-tuned-tf-incident-pongthorn/model_tuned_rf_tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    }
   ],
   "source": [
    "# https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/distribute/save_and_load.ipynb#scrollTo=jFcuzsI94bNA\n",
    "#save_options = tf.saved_model.SaveOptions(experimental_io_device='/job:localhost')\n",
    "# model.save(model_gs_path,options=save_options)\n",
    "# model.save(model_local_path,options=save_options)\n",
    "tuned_model.save(model_gs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62b65f7-d674-4dd9-8fb2-d7fcb2f7e355",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-12.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-12:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
