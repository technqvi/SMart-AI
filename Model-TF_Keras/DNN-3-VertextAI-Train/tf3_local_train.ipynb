{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9ae199c-8589-46ed-9d1b-43955d41ca29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guide for Tuturial\n",
    "#https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/prediction/custom_batch_prediction_feature_filter.ipynb\n",
    "#https://cloud.google.com/vertex-ai/docs/tutorials/train-tensorflow-bigquery\n",
    "#https://cloud.google.com/vertex-ai/docs/tutorials/tabular-bq-prediction\n",
    "\n",
    "#https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/custom/custom-tabular-bq-managed-dataset.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2671a710-86f5-4cac-a321-023064dc86f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "from typing import Tuple, Optional\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00ccaf78-6aa4-46fe-a65d-6aa5c9008bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 32\n",
    "TRAIN_STRATEGY = \"single\"\n",
    "\n",
    "\n",
    "mean_and_std_json_file=\"incident_mean_and_std.json\"\n",
    "\n",
    "LABEL_COLUMN = \"severity_name\"\n",
    "UNUSED_COLUMNS = ['severity_id','label_binary_severity','label_multi_severity']\n",
    "\n",
    "model_dir='model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec911c00-ea96-4977-a7f7-b521eb2a2433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_data_bq(sql:str):\n",
    "#  client_bq = bigquery.Client()\n",
    "#  query_result=client_bq.query(sql)\n",
    "#  df=query_result.to_dataframe()\n",
    "#  return df\n",
    "\n",
    "# def download_table(bq_table_uri: str):\n",
    "#     # Remove bq:// prefix if present\n",
    "#     bqclient= bigquery.Client()\n",
    "#     prefix = \"bq://\"\n",
    "#     if bq_table_uri.startswith(prefix):\n",
    "#         bq_table_uri = bq_table_uri[len(prefix) :]\n",
    "\n",
    "#     table = bigquery.TableReference.from_string(bq_table_uri)\n",
    "#     rows = bqclient.list_rows(\n",
    "#         table,\n",
    "#     )\n",
    "#     return rows.to_dataframe()\n",
    "\n",
    "# df = download_table(\"pongthorn.SMartML.TrainEval_Incident_20230316\")\n",
    "\n",
    "def load_ml_data(data_path):\n",
    " df=pd.read_csv(data_path)\n",
    " df =df.drop(columns=UNUSED_COLUMNS)\n",
    " return df\n",
    "\n",
    "root_path='../../data'    \n",
    "\n",
    "dfAll=pd.read_csv(f\"{root_path}/ML_Incident_20230316.csv\",\n",
    "                  usecols=['severity_name','sla','product_type','brand','service_type','incident_type'])\n",
    "\n",
    "df_train = load_ml_data(f\"{root_path}/train_incident.csv\")\n",
    "# val=train.copy()\n",
    "df_validation=load_ml_data(f\"{root_path}/validation_incident.csv\")\n",
    "# test =val.copy()\n",
    "df_test =load_ml_data(f\"{root_path}/test_incident.csv\")\n",
    "\n",
    "# sr_predict=df.iloc[-1,:]\n",
    "# df=df.iloc[0:len(df)-1,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25a8902a-ffc1-4cf6-8e42-2fc15bf64a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2143 entries, 0 to 2142\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   severity_name  2143 non-null   object\n",
      " 1   sla            2143 non-null   object\n",
      " 2   product_type   2143 non-null   object\n",
      " 3   brand          2143 non-null   object\n",
      " 4   service_type   2143 non-null   object\n",
      " 5   incident_type  2143 non-null   object\n",
      "dtypes: object(6)\n",
      "memory usage: 100.6+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>severity_name</th>\n",
       "      <th>sla</th>\n",
       "      <th>product_type</th>\n",
       "      <th>brand</th>\n",
       "      <th>service_type</th>\n",
       "      <th>incident_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2138</th>\n",
       "      <td>Major</td>\n",
       "      <td>24x7 4Hrs Resolution Time</td>\n",
       "      <td>Server</td>\n",
       "      <td>HPE</td>\n",
       "      <td>Incident</td>\n",
       "      <td>General Incident</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2139</th>\n",
       "      <td>Major</td>\n",
       "      <td>24x7 4Hrs Resolution Time</td>\n",
       "      <td>Server</td>\n",
       "      <td>HPE</td>\n",
       "      <td>Incident</td>\n",
       "      <td>General Incident</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2140</th>\n",
       "      <td>Minor</td>\n",
       "      <td>24x7 4Hrs Response Time</td>\n",
       "      <td>Server</td>\n",
       "      <td>DELL</td>\n",
       "      <td>Incident</td>\n",
       "      <td>General Incident</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2141</th>\n",
       "      <td>Major</td>\n",
       "      <td>24x7 4Hrs Response Time</td>\n",
       "      <td>Storage</td>\n",
       "      <td>NetApp</td>\n",
       "      <td>Incident</td>\n",
       "      <td>Hard Disk Drive Failure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2142</th>\n",
       "      <td>Major</td>\n",
       "      <td>24x7 4Hrs Response Time</td>\n",
       "      <td>Storage</td>\n",
       "      <td>NetApp</td>\n",
       "      <td>Incident</td>\n",
       "      <td>Maintenance System</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     severity_name                        sla product_type   brand  \\\n",
       "2138         Major  24x7 4Hrs Resolution Time       Server     HPE   \n",
       "2139         Major  24x7 4Hrs Resolution Time       Server     HPE   \n",
       "2140         Minor    24x7 4Hrs Response Time       Server    DELL   \n",
       "2141         Major    24x7 4Hrs Response Time      Storage  NetApp   \n",
       "2142         Major    24x7 4Hrs Response Time      Storage  NetApp   \n",
       "\n",
       "     service_type            incident_type  \n",
       "2138     Incident         General Incident  \n",
       "2139     Incident         General Incident  \n",
       "2140     Incident         General Incident  \n",
       "2141     Incident  Hard Disk Drive Failure  \n",
       "2142     Incident       Maintenance System  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dfAll.info())\n",
    "dfAll.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f3a19a8-7d21-4a50-92ac-5edfe110d8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Critical' 'Major' 'Minor' 'Cosmatic']\n",
      "['24x7 4Hrs Response Time' '24x7 4Hrs Resolution Time'\n",
      " '24x7 6Hrs Resolution Time' '24x7 6Hrs Response Time'\n",
      " '8x5 4Hrs Response Time' '9x5xNBD 4Hrs Response Time']\n",
      "['Server' 'Storage' 'Hardware' 'Software' 'Tape Library' 'Access Point'\n",
      " 'Firewall' 'Other' 'Switch' 'Security']\n",
      "['HPE' 'Oracle' 'VMWare' 'NetApp' 'YIP' 'DELL' 'Veeam' 'Cisco' 'Red Hat'\n",
      " 'Palo Alto' 'Veritas' 'Trend Micro' 'F5' 'EMC' 'IBM' 'Nutanix'\n",
      " 'Microsoft' 'Broadcom' 'CheckPoint' 'Fortinet' 'SAPB1' 'eUnite']\n",
      "['Incident' 'Request']\n",
      "['Network Card Failure' 'Memory Failure' 'Hard Disk Drive Failure'\n",
      " 'General Incident' 'Software' 'Power Supply Failure'\n",
      " 'Configuration Change' 'Upgrade Software' 'Network Adapter Failure'\n",
      " 'Report' 'Battery Failure' 'System Board Failure' 'OS / Firmware'\n",
      " 'Controller/Node Failure' 'Backup Failure' 'Maintenance System'\n",
      " 'CPU Failure' 'Network Cable Failure' 'Other Failure'\n",
      " 'Cache Battery Failure' 'Fan Failure']\n"
     ]
    }
   ],
   "source": [
    "list_label=dfAll[LABEL_COLUMN].unique()\n",
    "print(list_label)\n",
    "\n",
    "cate_sla=dfAll['sla'].unique()\n",
    "print(cate_sla)\n",
    "\n",
    "cate_productType=dfAll['product_type'].unique()\n",
    "print(cate_productType)\n",
    "\n",
    "cate_brand=dfAll['brand'].unique()\n",
    "print(cate_brand)\n",
    "\n",
    "cate_serviceType=dfAll['service_type'].unique()\n",
    "print(cate_serviceType)\n",
    "\n",
    "cate_incidentType=dfAll['incident_type'].unique()\n",
    "print(cate_incidentType)\n",
    "\n",
    "\n",
    "_CATEGORICAL_TYPES = {  \n",
    "    LABEL_COLUMN:pd.api.types.CategoricalDtype(categories=list_label),\n",
    "    \"sla\": pd.api.types.CategoricalDtype(categories=cate_sla),\n",
    "    \"product_type\": pd.api.types.CategoricalDtype(categories=cate_productType),\n",
    "    \"brand\": pd.api.types.CategoricalDtype(categories=cate_brand),\n",
    "    \"service_type\": pd.api.types.CategoricalDtype(categories=cate_serviceType),\n",
    "    \"incident_type\": pd.api.types.CategoricalDtype(categories=cate_incidentType),\n",
    "}\n",
    "#print(_CATEGORICAL_TYPES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "193f9da3-2e23-495c-9f3f-23b95cfe645d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_mean_and_std(mean_and_std_json_file):\n",
    "    \"\"\"Download mean and std for each column\"\"\"\n",
    "    import json\n",
    "    file_path=mean_and_std_json_file\n",
    "    # bucket, file_path = extract_bucket_and_prefix_from_gcs_path(mean_and_std_json_file)\n",
    "    # download_blob(bucket_name=bucket, source_blob_name=file_path, destination_file_name=file_path)\n",
    "    \n",
    "    with open(file_path, 'r') as file:\n",
    "        return json.loads(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "670db99c-42d4-4456-9150-052fe70b6f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    \"\"\"Converts categorical features to numeric. Removes unused columns.\n",
    "\n",
    "    Args:\n",
    "      df: Pandas df with raw data\n",
    "\n",
    "    Returns:\n",
    "      df with preprocessed data\n",
    "    \"\"\"\n",
    "\n",
    "    # Drop rows with NaN's\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Convert integer valued (numeric) columns to floating point\n",
    "    numeric_columns = df.select_dtypes([\"int32\", \"float32\", \"float64\"]).columns\n",
    "    df[numeric_columns] = df[numeric_columns].astype(\"float32\")\n",
    "\n",
    "    # Convert categorical columns to numeric\n",
    "    cat_columns = df.select_dtypes([\"object\"]).columns\n",
    "\n",
    "    df[cat_columns] = df[cat_columns].apply(\n",
    "        lambda x: x.astype(_CATEGORICAL_TYPES[x.name])\n",
    "    )\n",
    "    df[cat_columns] = df[cat_columns].apply(lambda x: x.cat.codes)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6462d09-a694-4b37-b789-027e457ef155",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(df, mean_and_std):\n",
    "    \"\"\"Scales numerical columns using their means and standard deviation to get\n",
    "    z-scores: the mean of each numerical column becomes 0, and the standard\n",
    "    deviation becomes 1. This can help the model converge during training.\n",
    "\n",
    "    Args:\n",
    "      df: Pandas df\n",
    "\n",
    "    Returns:\n",
    "      Input df with the numerical columns scaled to z-scores\n",
    "    \"\"\"\n",
    "    dtypes = list(zip(df.dtypes.index, map(str, df.dtypes)))\n",
    "    # Normalize numeric columns.\n",
    "    for column, dtype in dtypes:\n",
    "        if dtype == \"float32\":\n",
    "            df[column] -= mean_and_std[column][\"mean\"]\n",
    "            df[column] /= mean_and_std[column][\"std\"]\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc947ca4-0df0-46a8-8d8d-bf5bab072fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dataframe_to_dataset(\n",
    "    df_train,\n",
    "    df_validation,\n",
    "    mean_and_std\n",
    "):\n",
    "\n",
    "    df_train_x, df_train_y = df_train, df_train.pop(LABEL_COLUMN)\n",
    "    df_validation_x, df_validation_y = df_validation, df_validation.pop(LABEL_COLUMN)\n",
    "\n",
    "    # Join train_x and eval_x to normalize on overall means and standard\n",
    "    # deviations. Then separate them again.\n",
    "    all_x = pd.concat([df_train_x, df_validation_x], keys=[\"train\", \"eval\"])\n",
    "    all_x = standardize(all_x, mean_and_std)\n",
    "    df_train_x, df_validation_x = all_x.xs(\"train\"), all_x.xs(\"eval\")\n",
    "\n",
    "    y_train = np.asarray(df_train_y).astype(\"float32\")\n",
    "    y_validation = np.asarray(df_validation_y).astype(\"float32\")\n",
    "\n",
    "    # Convert to numpy representation\n",
    "    x_train = np.asarray(df_train_x)\n",
    "    x_test = np.asarray(df_validation_x)\n",
    "\n",
    "    # Convert to one-hot representation\n",
    "    y_train = tf.keras.utils.to_categorical(y_train, num_classes=len(list_label))\n",
    "    y_validation = tf.keras.utils.to_categorical(y_validation, num_classes=len(list_label))\n",
    "    \n",
    "    print(x_train.shape,y_train.shape, x_test.shape,y_validation.shape)\n",
    "    \n",
    "    # return   x_train,y_train, x_test,y_validation\n",
    "\n",
    "    dataset_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "    dataset_validation = tf.data.Dataset.from_tensor_slices((x_test, y_validation))\n",
    "    \n",
    "    return (dataset_train, dataset_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f05e780a-f88a-4770-ae6f-abde7b242706",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(num_features,num_classes):\n",
    "    # Create model\n",
    "    Dense = tf.keras.layers.Dense\n",
    "    model = tf.keras.Sequential(\n",
    "        [\n",
    "            Dense(\n",
    "                32,\n",
    "                activation=tf.nn.relu,\n",
    "                input_dim=num_features,\n",
    "            ),\n",
    "            Dense(32, activation=tf.nn.relu),\n",
    "            Dense(num_classes, activation=tf.nn.softmax),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Compile Keras model\n",
    "    # optimizer = tf.keras.optimizers.RMSprop(lr=0.001)\n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer='adam'\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06e68102-686a-471b-98c3-31cae4cb3bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'open_to_close_hour': {'mean': 95.19261960326722, 'std': 264.21816839738614}, 'response_to_resolved_hour': {'mean': 71.93835083625049, 'std': 224.20193515437524}}\n"
     ]
    }
   ],
   "source": [
    "mean_and_std = download_mean_and_std(mean_and_std_json_file)\n",
    "print(mean_and_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81c4ae00-8223-4503-9abf-f6906fe9470a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1714 entries, 0 to 1713\n",
      "Data columns (total 8 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   severity_name              1714 non-null   int8   \n",
      " 1   sla                        1714 non-null   int8   \n",
      " 2   product_type               1714 non-null   int8   \n",
      " 3   brand                      1714 non-null   int8   \n",
      " 4   service_type               1714 non-null   int8   \n",
      " 5   incident_type              1714 non-null   int8   \n",
      " 6   open_to_close_hour         1714 non-null   float32\n",
      " 7   response_to_resolved_hour  1714 non-null   float32\n",
      "dtypes: float32(2), int8(6)\n",
      "memory usage: 23.6 KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>severity_name</th>\n",
       "      <th>sla</th>\n",
       "      <th>product_type</th>\n",
       "      <th>brand</th>\n",
       "      <th>service_type</th>\n",
       "      <th>incident_type</th>\n",
       "      <th>open_to_close_hour</th>\n",
       "      <th>response_to_resolved_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1463.416626</td>\n",
       "      <td>1463.233276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5.916667</td>\n",
       "      <td>5.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>113.849998</td>\n",
       "      <td>90.516670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>17.116667</td>\n",
       "      <td>0.716667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   severity_name  sla  product_type  brand  service_type  incident_type  \\\n",
       "0              1    1             3      8             0              3   \n",
       "1              1    2             1      3             0              2   \n",
       "2              1    0             3      2             0              6   \n",
       "3              1    1             1      0             0              2   \n",
       "4              2    0             3      2             0              3   \n",
       "\n",
       "   open_to_close_hour  response_to_resolved_hour  \n",
       "0         1463.416626                1463.233276  \n",
       "1            5.916667                   5.916667  \n",
       "2            0.883333                   0.500000  \n",
       "3          113.849998                  90.516670  \n",
       "4           17.116667                   0.716667  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = preprocess(df_train)\n",
    "df_validation = preprocess(df_validation)\n",
    "\n",
    "print(df_train.info())\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7cfc2224-809c-4f55-be45-932359bc9888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1714, 7) (1714, 4) (214, 7) (214, 4)\n"
     ]
    }
   ],
   "source": [
    "dataset_train, dataset_validation = convert_dataframe_to_dataset(\n",
    "  df_train, \n",
    "  df_validation, \n",
    "  mean_and_std\n",
    ")\n",
    "dataset_train = dataset_train.shuffle(len(df_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21d141b4-6afc-4542-bb7f-ce7035490dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                256       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4)                 132       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,444\n",
      "Trainable params: 1,444\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model( num_features=dataset_train._flat_shapes[0].dims[0].value,num_classes=len(list_label))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "effae586-27b5-49b9-b838-5ce2d60d483f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = dataset_train.batch(BATCH_SIZE)\n",
    "dataset_validation = dataset_validation.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c5c716d-ae5a-4d6b-8a1d-910a7832938e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "54/54 [==============================] - 3s 13ms/step - loss: 1.3609 - accuracy: 0.4055 - val_loss: 1.2150 - val_accuracy: 0.5140\n",
      "Epoch 2/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1843 - accuracy: 0.5076 - val_loss: 1.1284 - val_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.1202 - accuracy: 0.5280 - val_loss: 1.0825 - val_accuracy: 0.5093\n",
      "Epoch 4/100\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 1.0608 - accuracy: 0.5799 - val_loss: 1.0258 - val_accuracy: 0.5748\n",
      "Epoch 5/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.9993 - accuracy: 0.6243 - val_loss: 0.9625 - val_accuracy: 0.5654\n",
      "Epoch 6/100\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.9413 - accuracy: 0.6389 - val_loss: 0.9177 - val_accuracy: 0.6168\n",
      "Epoch 7/100\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.8972 - accuracy: 0.6400 - val_loss: 0.8842 - val_accuracy: 0.6308\n",
      "Epoch 8/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.8653 - accuracy: 0.6424 - val_loss: 0.8601 - val_accuracy: 0.6308\n",
      "Epoch 9/100\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.8470 - accuracy: 0.6400 - val_loss: 0.8531 - val_accuracy: 0.6168\n",
      "Epoch 10/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.8341 - accuracy: 0.6523 - val_loss: 0.8633 - val_accuracy: 0.6075\n",
      "Epoch 11/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.8200 - accuracy: 0.6464 - val_loss: 0.8530 - val_accuracy: 0.5981\n",
      "Epoch 12/100\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.8120 - accuracy: 0.6569 - val_loss: 0.8451 - val_accuracy: 0.6262\n",
      "Epoch 13/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.8065 - accuracy: 0.6599 - val_loss: 0.8408 - val_accuracy: 0.6308\n",
      "Epoch 14/100\n",
      "54/54 [==============================] - 1s 9ms/step - loss: 0.8046 - accuracy: 0.6599 - val_loss: 0.8407 - val_accuracy: 0.6495\n",
      "Epoch 15/100\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.7929 - accuracy: 0.6709 - val_loss: 0.8272 - val_accuracy: 0.6355\n",
      "Epoch 16/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.7914 - accuracy: 0.6686 - val_loss: 0.8316 - val_accuracy: 0.6355\n",
      "Epoch 17/100\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.7880 - accuracy: 0.6686 - val_loss: 0.8241 - val_accuracy: 0.6355\n",
      "Epoch 18/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.7826 - accuracy: 0.6739 - val_loss: 0.8245 - val_accuracy: 0.6402\n",
      "Epoch 19/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.7840 - accuracy: 0.6721 - val_loss: 0.8317 - val_accuracy: 0.6495\n",
      "Epoch 20/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.7729 - accuracy: 0.6820 - val_loss: 0.8310 - val_accuracy: 0.6449\n",
      "Epoch 21/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.7718 - accuracy: 0.6779 - val_loss: 0.8257 - val_accuracy: 0.6355\n",
      "Epoch 22/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.7686 - accuracy: 0.6797 - val_loss: 0.8363 - val_accuracy: 0.6542\n",
      "Epoch 23/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.7667 - accuracy: 0.6855 - val_loss: 0.8327 - val_accuracy: 0.6308\n",
      "Epoch 24/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.7661 - accuracy: 0.6826 - val_loss: 0.8286 - val_accuracy: 0.6495\n",
      "Epoch 25/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.7638 - accuracy: 0.6814 - val_loss: 0.8330 - val_accuracy: 0.6308\n",
      "Epoch 26/100\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.7659 - accuracy: 0.6657 - val_loss: 0.8218 - val_accuracy: 0.6402\n",
      "Epoch 27/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.7549 - accuracy: 0.6832 - val_loss: 0.8244 - val_accuracy: 0.6636\n",
      "Epoch 28/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.7559 - accuracy: 0.6867 - val_loss: 0.8433 - val_accuracy: 0.6495\n",
      "Epoch 29/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.7529 - accuracy: 0.6884 - val_loss: 0.8249 - val_accuracy: 0.6589\n",
      "Epoch 30/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.7515 - accuracy: 0.6849 - val_loss: 0.8260 - val_accuracy: 0.7009\n",
      "Epoch 31/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.7486 - accuracy: 0.6902 - val_loss: 0.8192 - val_accuracy: 0.6402\n",
      "Epoch 32/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.7498 - accuracy: 0.6925 - val_loss: 0.8241 - val_accuracy: 0.6636\n",
      "Epoch 33/100\n",
      "54/54 [==============================] - 1s 9ms/step - loss: 0.7445 - accuracy: 0.6919 - val_loss: 0.8113 - val_accuracy: 0.6589\n",
      "Epoch 34/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.7418 - accuracy: 0.6943 - val_loss: 0.8309 - val_accuracy: 0.6495\n",
      "Epoch 35/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.7418 - accuracy: 0.6954 - val_loss: 0.8228 - val_accuracy: 0.6729\n",
      "Epoch 36/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.7378 - accuracy: 0.6949 - val_loss: 0.8242 - val_accuracy: 0.6542\n",
      "Epoch 37/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.7402 - accuracy: 0.6919 - val_loss: 0.8264 - val_accuracy: 0.6729\n",
      "Epoch 38/100\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.7390 - accuracy: 0.7013 - val_loss: 0.8427 - val_accuracy: 0.6495\n",
      "Epoch 39/100\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.7326 - accuracy: 0.6960 - val_loss: 0.8219 - val_accuracy: 0.6542\n",
      "Epoch 40/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.7317 - accuracy: 0.7013 - val_loss: 0.8329 - val_accuracy: 0.6355\n",
      "Epoch 41/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.7274 - accuracy: 0.7007 - val_loss: 0.8188 - val_accuracy: 0.6308\n",
      "Epoch 42/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.7291 - accuracy: 0.6989 - val_loss: 0.8194 - val_accuracy: 0.6636\n",
      "Epoch 43/100\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.7291 - accuracy: 0.6937 - val_loss: 0.8233 - val_accuracy: 0.6589\n",
      "Epoch 43: early stopping\n"
     ]
    }
   ],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    "history=model.fit(dataset_train, epochs=EPOCHS, validation_data=dataset_validation,batch_size=BATCH_SIZE,callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa9d75aa-9891-4037-bbb8-71aae66fb433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 8ms/step - loss: 0.8233 - accuracy: 0.6589\n",
      "Average Accuracy on Eveluation 0.65887850522995\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(dataset_validation)\n",
    "print(\"Average Accuracy on Eveluation\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27d3ef03-bb34-40e4-83c6-fb3d3f54587f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model, model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5efddd5-ff55-422a-8df2-85d1d85e279d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01abd76d-acb0-4231-b4bc-6df3b8a2ccd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6f85005-bed9-48ea-8d9e-66b5b038cd80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 215 entries, 0 to 214\n",
      "Data columns (total 8 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   severity_name              215 non-null    int8   \n",
      " 1   sla                        215 non-null    int8   \n",
      " 2   product_type               215 non-null    int8   \n",
      " 3   brand                      215 non-null    int8   \n",
      " 4   service_type               215 non-null    int8   \n",
      " 5   incident_type              215 non-null    int8   \n",
      " 6   open_to_close_hour         215 non-null    float32\n",
      " 7   response_to_resolved_hour  215 non-null    float32\n",
      "dtypes: float32(2), int8(6)\n",
      "memory usage: 3.1 KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>severity_name</th>\n",
       "      <th>sla</th>\n",
       "      <th>product_type</th>\n",
       "      <th>brand</th>\n",
       "      <th>service_type</th>\n",
       "      <th>incident_type</th>\n",
       "      <th>open_to_close_hour</th>\n",
       "      <th>response_to_resolved_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>16.033333</td>\n",
       "      <td>15.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.766667</td>\n",
       "      <td>4.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>123.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     severity_name  sla  product_type  brand  service_type  incident_type  \\\n",
       "210              1    0             1      0             0              3   \n",
       "211              0    1             0      0             0              2   \n",
       "212              0    1             7      0             0             11   \n",
       "213              3    0             3      2             1              3   \n",
       "214              2    1             5      7             0              3   \n",
       "\n",
       "     open_to_close_hour  response_to_resolved_hour  \n",
       "210           16.033333                      15.95  \n",
       "211            4.766667                       4.70  \n",
       "212          124.000000                     123.00  \n",
       "213            8.800000                       8.00  \n",
       "214            1.000000                       1.00  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_test = preprocess(df_test)\n",
    "print(df2_test.info())\n",
    "df2_test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "148d6ce2-4ead-422e-817f-b95ecf70a3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dataframe_to_list(df, mean_and_st):\n",
    "    df = preprocess(df)\n",
    "\n",
    "    df_x, df_y = df, df.pop(LABEL_COLUMN)\n",
    "\n",
    "    # Normalize on overall means and standard deviations.\n",
    "    df = standardize(df, mean_and_std)\n",
    "\n",
    "    y = np.asarray(df_y).astype(\"float32\")\n",
    "\n",
    "    # Convert to numpy representation\n",
    "    x = np.asarray(df_x)\n",
    "\n",
    "    # Convert to one-hot representation\n",
    "    return x.tolist(), y.tolist(), df_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d19a15ad-be5e-4fa3-b82f-98d3d71293a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test, df_x = convert_dataframe_to_list(df2_test, mean_and_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b8d8501-f62a-4faa-926b-91633a13c414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset columns: Index(['sla', 'product_type', 'brand', 'service_type', 'incident_type',\n",
      "       'open_to_close_hour', 'response_to_resolved_hour', 'id'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "ID_COLUMN_NAME = \"id\"\n",
    "df_x_with_id = df_x.copy()\n",
    "df_x_with_id[ID_COLUMN_NAME] = [i for i in range(0, df_x_with_id.shape[0])]\n",
    "\n",
    "# Print columns of the datafram\n",
    "print(f\"Test dataset columns: {df_x_with_id.columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eb20bfc9-6ce5-42b7-8394-45312061f2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://codelabs.developers.google.com/vertex-xgb-wit#7\n",
    "#https://codelabs.developers.google.com/vertex-p2p-predictions#3\n",
    "\n",
    "#https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/model_registry/get_started_with_model_registry.ipynb\n",
    "#https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/courses/machine_learning/deepdive2/introduction_to_tensorflow/solutions/1_training_at_scale_vertex.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7fddf6-85f0-4c70-90b8-9c289660b606",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
