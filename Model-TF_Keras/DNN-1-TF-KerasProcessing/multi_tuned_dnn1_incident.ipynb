{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "efd54814-e227-4302-9a81-3d6ddcf0e9a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.11.0'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import necessary libraries\n",
    "\n",
    "#https://codelabs.developers.google.com/codelabs/fraud-detection-ai-explanations?hl=en#0\n",
    "#he Explainable AI SDK and Copy Model to Deploy\n",
    "\n",
    "#https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/courses/machine_learning/deepdive2/introduction_to_tensorflow/solutions/preprocessing_layers.ipynb\n",
    "#https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/custom/custom-tabular-bq-managed-dataset.ipynb\n",
    "#https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/experiments/comparing_local_trained_models.ipynb\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense,DenseFeatures\n",
    "\n",
    "from datetime import date, timedelta, datetime # Date Functions\n",
    "import time\n",
    "\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "from google.cloud import aiplatform as vertex_ai\n",
    "from tensorflow.python.keras.utils import data_utils\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d28a9538-ca23-45f0-817b-e4b067cf9ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cateCols=['sla','product_type','brand','service_type','incident_type']\n",
    "numbericCols=['open_to_close_hour','response_to_resolved_hour']\n",
    "\n",
    "unusedCols=['severity_id','severity_name','label_binary_severity']\n",
    "labelCol='label_multi_severity'\n",
    "\n",
    "main_metric='accuracy'\n",
    "main_objective=f'val_{main_metric}'\n",
    "\n",
    "seed=1932\n",
    "\n",
    "EPOCHS =100\n",
    "BATCH_SIZE = 32\n",
    "unitList=[8,16,32,64,96,128]\n",
    "dropOutList= [0.1, 0.2,0.3]\n",
    "lrList=[0.1,0.01,0.001]\n",
    "nMax_trials=10\n",
    "nExecutions_per_trial=3\n",
    "nEarlyPatience=7\n",
    "\n",
    "# EPOCHS =20\n",
    "# BATCH_SIZE = 64\n",
    "# nEarlyPatience=5\n",
    "# unitList=[32,64]\n",
    "# dropOutList= [0.1, 0.2]\n",
    "# lrList=[0.1,0.01]\n",
    "# nMax_trials=10\n",
    "# nExecutions_per_trial=1\n",
    "# nEarlyPatience=5\n",
    "\n",
    "model_tuned_dir='tuned_model'\n",
    "\n",
    "# df['label_multi_severity'] =df['severity_name'].map({'Cosmatic':0,'Minor': 1, \"Major\": 2, \"Critical\": 3}) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0aa901-563f-4d2c-9203-67175431c32f",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ddea3e1-b732-48c4-95fc-637108802a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 0, 1, 3]\n",
      "No target label : 4\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1696 entries, 0 to 1695\n",
      "Data columns (total 8 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   sla                        1696 non-null   object \n",
      " 1   product_type               1696 non-null   object \n",
      " 2   brand                      1696 non-null   object \n",
      " 3   service_type               1696 non-null   object \n",
      " 4   incident_type              1696 non-null   object \n",
      " 5   open_to_close_hour         1696 non-null   float64\n",
      " 6   response_to_resolved_hour  1696 non-null   float64\n",
      " 7   label_multi_severity       1696 non-null   int64  \n",
      "dtypes: float64(2), int64(1), object(5)\n",
      "memory usage: 106.1+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sla</th>\n",
       "      <th>product_type</th>\n",
       "      <th>brand</th>\n",
       "      <th>service_type</th>\n",
       "      <th>incident_type</th>\n",
       "      <th>open_to_close_hour</th>\n",
       "      <th>response_to_resolved_hour</th>\n",
       "      <th>label_multi_severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1691</th>\n",
       "      <td>24x7 4Hrs Resolution Time</td>\n",
       "      <td>Firewall</td>\n",
       "      <td>Palo Alto</td>\n",
       "      <td>Incident</td>\n",
       "      <td>Software</td>\n",
       "      <td>13.633333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1692</th>\n",
       "      <td>24x7 4Hrs Response Time</td>\n",
       "      <td>Software</td>\n",
       "      <td>Veritas</td>\n",
       "      <td>Incident</td>\n",
       "      <td>General Incident</td>\n",
       "      <td>1.283333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1693</th>\n",
       "      <td>24x7 4Hrs Resolution Time</td>\n",
       "      <td>Switch</td>\n",
       "      <td>Cisco</td>\n",
       "      <td>Incident</td>\n",
       "      <td>General Incident</td>\n",
       "      <td>484.750000</td>\n",
       "      <td>271.016667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1694</th>\n",
       "      <td>24x7 4Hrs Resolution Time</td>\n",
       "      <td>Hardware</td>\n",
       "      <td>Oracle</td>\n",
       "      <td>Incident</td>\n",
       "      <td>Hard Disk Drive Failure</td>\n",
       "      <td>25.833333</td>\n",
       "      <td>23.916667</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1695</th>\n",
       "      <td>24x7 6Hrs Resolution Time</td>\n",
       "      <td>Software</td>\n",
       "      <td>VMWare</td>\n",
       "      <td>Incident</td>\n",
       "      <td>General Incident</td>\n",
       "      <td>1.416667</td>\n",
       "      <td>1.266667</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            sla product_type      brand service_type  \\\n",
       "1691  24x7 4Hrs Resolution Time     Firewall  Palo Alto     Incident   \n",
       "1692    24x7 4Hrs Response Time     Software    Veritas     Incident   \n",
       "1693  24x7 4Hrs Resolution Time       Switch      Cisco     Incident   \n",
       "1694  24x7 4Hrs Resolution Time     Hardware     Oracle     Incident   \n",
       "1695  24x7 6Hrs Resolution Time     Software     VMWare     Incident   \n",
       "\n",
       "                incident_type  open_to_close_hour  response_to_resolved_hour  \\\n",
       "1691                 Software           13.633333                   0.833333   \n",
       "1692         General Incident            1.283333                   1.000000   \n",
       "1693         General Incident          484.750000                 271.016667   \n",
       "1694  Hard Disk Drive Failure           25.833333                  23.916667   \n",
       "1695         General Incident            1.416667                   1.266667   \n",
       "\n",
       "      label_multi_severity  \n",
       "1691                     2  \n",
       "1692                     2  \n",
       "1693                     1  \n",
       "1694                     2  \n",
       "1695                     2  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_ml_data(data_path):\n",
    " df=pd.read_csv(data_path)\n",
    " df =df.drop(columns=unusedCols)\n",
    " return df\n",
    "    \n",
    "root_path='../../data'    \n",
    "train = load_ml_data(f\"{root_path}/train_incident.csv\")\n",
    "# val=train.copy()\n",
    "val=load_ml_data(f\"{root_path}/validation_incident.csv\")\n",
    "# test =val.copy()\n",
    "test =load_ml_data(f\"{root_path}/test_incident.csv\")\n",
    "\n",
    "labelList=list(train[labelCol].unique())\n",
    "print(labelList)\n",
    "nLabel=len(labelList)\n",
    "print(f\"No target label : {nLabel}\")\n",
    "\n",
    "# sr_predict=df.iloc[-1,:]\n",
    "# df=df.iloc[0:len(df)-1,:]\n",
    "                 \n",
    "print(train.info())\n",
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64adbe5e-d737-45a4-a04e-340a2926ad2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train-No-Severity</th>\n",
       "      <th>Train-%-Severity</th>\n",
       "      <th>Val-No-Severity</th>\n",
       "      <th>Val-%-Severity</th>\n",
       "      <th>Test-No-Severity</th>\n",
       "      <th>Test-%-Severity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label_multi_severity</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>305</td>\n",
       "      <td>18.0</td>\n",
       "      <td>35</td>\n",
       "      <td>17.0</td>\n",
       "      <td>42</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>487</td>\n",
       "      <td>29.0</td>\n",
       "      <td>54</td>\n",
       "      <td>25.0</td>\n",
       "      <td>68</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>812</td>\n",
       "      <td>48.0</td>\n",
       "      <td>111</td>\n",
       "      <td>52.0</td>\n",
       "      <td>96</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>92</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Train-No-Severity  Train-%-Severity  Val-No-Severity  \\\n",
       "label_multi_severity                                                         \n",
       "0                                   305              18.0               35   \n",
       "1                                   487              29.0               54   \n",
       "2                                   812              48.0              111   \n",
       "3                                    92               5.0               12   \n",
       "\n",
       "                      Val-%-Severity  Test-No-Severity  Test-%-Severity  \n",
       "label_multi_severity                                                     \n",
       "0                               17.0                42             20.0  \n",
       "1                               25.0                68             32.0  \n",
       "2                               52.0                96             45.0  \n",
       "3                                6.0                 6              3.0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def CalPctEachTargetClass(dfx,colSev,colPctSev):\n",
    "    dfClassSummary=dfx.groupby([labelCol]).size().to_frame(colSev)\n",
    "    dfClassSummary[colPctSev]= dfClassSummary[colSev]/dfClassSummary[colSev].sum() *100\n",
    "    dfClassSummary=dfClassSummary.round(0)\n",
    "    return dfClassSummary\n",
    "\n",
    "pctDF1=CalPctEachTargetClass(train,'Train-No-Severity','Train-%-Severity')\n",
    "pctDF2=CalPctEachTargetClass(val,'Val-No-Severity','Val-%-Severity')\n",
    "pdcDF3=CalPctEachTargetClass(test,'Test-No-Severity','Test-%-Severity')\n",
    "pctDF=pd.concat([pctDF1,pctDF2,pdcDF3],axis=1)\n",
    "\n",
    "pctDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c59e9916-6668-4c4e-8974-af63c3f840b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_class(df):\n",
    "#     fig , ax = plt.subplots(figsize=(15,5))\n",
    "#     ax =sns.countplot(x=labelCol, data=df,)\n",
    "#     for p in ax.patches:\n",
    "#        ax.annotate('{:.1f}'.format(p.get_height()), (p.get_x()+0.25, p.get_height()+0.01))\n",
    "#     plt.title(labelCol.title())\n",
    "#     plt.show()\n",
    "    \n",
    "# plot_class(train)\n",
    "# plot_class(val)\n",
    "# plot_class(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa30d3fd-14e9-4c3d-a6aa-45d8114f5362",
   "metadata": {},
   "source": [
    "# Process Data  Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d9d3a943-09d5-4a43-b8d8-633bc4a90353",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_label_df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
    "  features = dataframe.copy()\n",
    "  labels = features.pop(labelCol)\n",
    "  labels  = tf.keras.utils.to_categorical(labels, num_classes=nLabel)\n",
    "    \n",
    "  ds = tf.data.Dataset.from_tensor_slices(( dict(features), labels ))\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(buffer_size=len(features))\n",
    "  ds = ds.batch(batch_size)\n",
    "  ds = ds.prefetch(batch_size)\n",
    "  return ds\n",
    "     \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "02ad8837-968e-4d68-bdb6-1c7eba97e69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalization_layer(name, dataset):\n",
    "  # Create a Normalization layer for our feature.\n",
    "  normalizer = preprocessing.Normalization(axis=None)\n",
    "\n",
    "  # Prepare a Dataset that only yields our feature.\n",
    "  feature_ds = dataset.map(lambda x, y: x[name])\n",
    "\n",
    "  # Learn the statistics of the data.\n",
    "  normalizer.adapt(feature_ds)\n",
    "\n",
    "  return normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "237bce3c-9c77-4318-8682-fc36af0a6804",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_encoding_layer(name, dataset, dtype, max_tokens=None):\n",
    "  # Create a StringLookup layer which will turn strings into integer indices\n",
    "  if dtype == 'string':\n",
    "    index = preprocessing.StringLookup(max_tokens=max_tokens)\n",
    "  else:\n",
    "    index = preprocessing.IntegerLookup(max_tokens=max_tokens)\n",
    "\n",
    "  # Prepare a Dataset that only yields our feature\n",
    "  feature_ds = dataset.map(lambda x, y: x[name])\n",
    "\n",
    "  # Learn the set of possible values and assign them a fixed integer index.\n",
    "  index.adapt(feature_ds)\n",
    "\n",
    "  # Create a Discretization for our integer indices.\n",
    "  encoder = preprocessing.CategoryEncoding(num_tokens=index.vocabulary_size())\n",
    "\n",
    "  # Apply one-hot encoding to our indices. The lambda function captures the\n",
    "  # layer so we can use them, or include them in the functional model later.\n",
    "  return lambda feature: encoder(index(feature))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a5c78f01-000a-4d3e-9fbf-6f4660cfb75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size =32\n",
    "train_ds = multiple_label_df_to_dataset (train, batch_size=batch_size)\n",
    "val_ds = multiple_label_df_to_dataset(val, batch_size=batch_size)\n",
    "test_ds = multiple_label_df_to_dataset(test, batch_size=batch_size)\n",
    "# for element in train_ds.as_numpy_iterator():\n",
    "#     print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "723a69b6-d9c1-49d9-bc81-ed421d8700cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "open_to_close_hour\n",
      "response_to_resolved_hour\n",
      "sla\n",
      "product_type\n",
      "brand\n",
      "service_type\n",
      "incident_type\n"
     ]
    }
   ],
   "source": [
    "all_inputs = []\n",
    "encoded_features = []\n",
    "\n",
    "# Numeric features.\n",
    "for header in numbericCols:\n",
    "  print(header)  \n",
    "  numeric_col = tf.keras.Input(shape=(1,), name=header)\n",
    "  normalization_layer = get_normalization_layer(header, train_ds)\n",
    "  encoded_numeric_col = normalization_layer(numeric_col)\n",
    "  all_inputs.append(numeric_col)\n",
    "  encoded_features.append(encoded_numeric_col)\n",
    "    \n",
    "    # Categorical features encoded as string.\n",
    "categorical_cols = cateCols\n",
    "for header in categorical_cols:\n",
    "  print(header)  \n",
    "  categorical_col = tf.keras.Input(shape=(1,), name=header, dtype='string')\n",
    "  encoding_layer = get_category_encoding_layer(header, train_ds, dtype='string')\n",
    "                                        \n",
    "  encoded_categorical_col = encoding_layer(categorical_col)\n",
    "  all_inputs.append(categorical_col)\n",
    "  encoded_features.append(encoded_categorical_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78419953-d126-4562-afe4-8b85c938a148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f85f8a-4471-44e1-a389-102232c296e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf75dae1-683f-403d-9f2d-aca95c970a21",
   "metadata": {},
   "source": [
    "# Tune HyperParameter By Keras Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c97a4d39-0145-49cd-9abf-277e76bd03af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 Complete [00h 00m 28s]\n",
      "val_accuracy: 0.7764150977134705\n",
      "\n",
      "Best val_accuracy So Far: 0.7764150977134705\n",
      "Total elapsed time: 00h 08m 31s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Total execution :  0.14\n",
      "2023-03-23 14:12:08.687566\n",
      "=============================================================\n",
      "{'units': 128, 'Dropout_rate': 0.1, 'learning_rate': 0.01}\n"
     ]
    }
   ],
   "source": [
    "#https://github.com/technqvi/TimeSeriesML-FinMarket/blob/main/lstm-tune-dev/Tuned-MultiVarToManyOutputLSTM.ipynb\n",
    "#https://www.tensorflow.org/tutorials/keras/keras_tuner\n",
    "#https://keras.io/guides/keras_tuner/getting_started/\n",
    "import keras_tuner as kt\n",
    "from keras_tuner.engine.hyperparameters import HyperParameters\n",
    "\n",
    "tune_folder=\"IncidentMLP\"\n",
    "\n",
    "\n",
    "buildtime = datetime.now().strftime('%d%m%y_%H%M')\n",
    "project_model=f\"{tune_folder}_{buildtime}\"\n",
    "print(project_model)\n",
    "\n",
    "t_Start=time.time()\n",
    "\n",
    "print(f\"Start tund at {datetime.now()}\")\n",
    "print(\"=============================================================\")\n",
    "\n",
    "def build_model_for_tuning(hp):\n",
    "    \n",
    "\n",
    "    all_features = tf.keras.layers.concatenate(encoded_features)\n",
    "    # hp.Int('units', min_value=32, max_value=160, step=32)\n",
    "    x = tf.keras.layers.Dense(hp.Choice('units', unitList), activation=\"relu\")(all_features)\n",
    "    x = tf.keras.layers.Dropout(hp.Choice('Dropout_rate',dropOutList))(x)\n",
    "    output = tf.keras.layers.Dense(nLabel,activation=tf.nn.softmax)(x)\n",
    "    \n",
    "    model = tf.keras.Model(all_inputs, output)\n",
    "    \n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=lrList)\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                  loss=tf.keras.losses.CategoricalCrossentropy(),metrics=[main_metric])\n",
    "    return model\n",
    "\n",
    "tuner = kt.BayesianOptimization(\n",
    "## tuner = kt.Hyperband(\n",
    "# tuner = keras_tuner.RandomSearch(\n",
    "    build_model_for_tuning, objective=main_objective,max_trials=nMax_trials,\n",
    "    seed=seed,executions_per_trial=nExecutions_per_trial,\n",
    "    directory=f\"tuning/{tune_folder}/\",project_name= project_model)\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor=main_objective, patience=nEarlyPatience)\n",
    "tuner.search(train_ds, batch_size=BATCH_SIZE,epochs=EPOCHS,validation_data=val_ds,callbacks=[stop_early])\n",
    "    \n",
    "t_End=time.time()\n",
    "t_elapsed=(t_End-t_Start)/60/60\n",
    "print('Total execution : ',round(t_elapsed,2)) \n",
    "print(datetime.now())\n",
    "print(\"=============================================================\")\n",
    "\n",
    "\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(best_hps.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "544099f0-746c-4e7b-af73-58e6351d90a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build the model with the optimal hyperparameters and train it on the data to find  N epochs\n",
      "Epoch 1/150\n",
      "53/53 [==============================] - 1s 8ms/step - loss: 0.8606 - accuracy: 0.6368 - val_loss: 0.6977 - val_accuracy: 0.7311\n",
      "Epoch 2/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.7160 - accuracy: 0.6958 - val_loss: 0.6804 - val_accuracy: 0.7736\n",
      "Epoch 3/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.6766 - accuracy: 0.7123 - val_loss: 0.6701 - val_accuracy: 0.7311\n",
      "Epoch 4/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.6404 - accuracy: 0.7429 - val_loss: 0.6969 - val_accuracy: 0.7358\n",
      "Epoch 5/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.6382 - accuracy: 0.7317 - val_loss: 0.6843 - val_accuracy: 0.7500\n",
      "Epoch 6/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.6102 - accuracy: 0.7447 - val_loss: 0.7207 - val_accuracy: 0.7453\n",
      "Epoch 7/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5918 - accuracy: 0.7588 - val_loss: 0.7418 - val_accuracy: 0.7642\n",
      "Epoch 8/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.6004 - accuracy: 0.7577 - val_loss: 0.7042 - val_accuracy: 0.7736\n",
      "Epoch 9/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5884 - accuracy: 0.7600 - val_loss: 0.7613 - val_accuracy: 0.7547\n",
      "Epoch 10/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5840 - accuracy: 0.7529 - val_loss: 0.7421 - val_accuracy: 0.7453\n",
      "Epoch 11/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5806 - accuracy: 0.7588 - val_loss: 0.7165 - val_accuracy: 0.7689\n",
      "Epoch 12/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5670 - accuracy: 0.7683 - val_loss: 0.7658 - val_accuracy: 0.7642\n",
      "Epoch 13/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5577 - accuracy: 0.7671 - val_loss: 0.7780 - val_accuracy: 0.7547\n",
      "Epoch 14/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5461 - accuracy: 0.7742 - val_loss: 0.8107 - val_accuracy: 0.7689\n",
      "Epoch 15/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5450 - accuracy: 0.7683 - val_loss: 0.8154 - val_accuracy: 0.7594\n",
      "Epoch 16/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5515 - accuracy: 0.7689 - val_loss: 0.7715 - val_accuracy: 0.7500\n",
      "Epoch 17/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5424 - accuracy: 0.7718 - val_loss: 0.8019 - val_accuracy: 0.7642\n",
      "Epoch 18/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5362 - accuracy: 0.7795 - val_loss: 0.8197 - val_accuracy: 0.7594\n",
      "Epoch 19/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5404 - accuracy: 0.7783 - val_loss: 0.8071 - val_accuracy: 0.7500\n",
      "Epoch 20/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5396 - accuracy: 0.7754 - val_loss: 0.8125 - val_accuracy: 0.7689\n",
      "Epoch 21/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5330 - accuracy: 0.7830 - val_loss: 0.8043 - val_accuracy: 0.7453\n",
      "Epoch 22/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5272 - accuracy: 0.7765 - val_loss: 0.8178 - val_accuracy: 0.7689\n",
      "Epoch 23/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5280 - accuracy: 0.7807 - val_loss: 0.8583 - val_accuracy: 0.7736\n",
      "Epoch 24/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5223 - accuracy: 0.7783 - val_loss: 0.8779 - val_accuracy: 0.7642\n",
      "Epoch 25/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5167 - accuracy: 0.7913 - val_loss: 0.8589 - val_accuracy: 0.7689\n",
      "Epoch 26/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5109 - accuracy: 0.7895 - val_loss: 0.8982 - val_accuracy: 0.7453\n",
      "Epoch 27/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5171 - accuracy: 0.7877 - val_loss: 0.8862 - val_accuracy: 0.7689\n",
      "Epoch 28/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5306 - accuracy: 0.7801 - val_loss: 0.9065 - val_accuracy: 0.7264\n",
      "Epoch 29/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7836 - val_loss: 0.9066 - val_accuracy: 0.7311\n",
      "Epoch 30/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.7871 - val_loss: 0.8987 - val_accuracy: 0.7642\n",
      "Epoch 31/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5286 - accuracy: 0.7848 - val_loss: 0.9337 - val_accuracy: 0.7689\n",
      "Epoch 32/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5015 - accuracy: 0.7895 - val_loss: 0.9689 - val_accuracy: 0.7783\n",
      "Epoch 33/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5163 - accuracy: 0.7777 - val_loss: 0.9313 - val_accuracy: 0.7547\n",
      "Epoch 34/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5122 - accuracy: 0.7871 - val_loss: 0.9664 - val_accuracy: 0.7358\n",
      "Epoch 35/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7807 - val_loss: 0.9340 - val_accuracy: 0.7689\n",
      "Epoch 36/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7866 - val_loss: 0.9633 - val_accuracy: 0.7783\n",
      "Epoch 37/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4979 - accuracy: 0.7942 - val_loss: 0.9810 - val_accuracy: 0.7783\n",
      "Epoch 38/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7777 - val_loss: 1.0524 - val_accuracy: 0.7453\n",
      "Epoch 39/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.7895 - val_loss: 0.9703 - val_accuracy: 0.7406\n",
      "Epoch 40/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5236 - accuracy: 0.7830 - val_loss: 0.9131 - val_accuracy: 0.7642\n",
      "Epoch 41/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5116 - accuracy: 0.7913 - val_loss: 0.9356 - val_accuracy: 0.7689\n",
      "Epoch 42/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7936 - val_loss: 0.9411 - val_accuracy: 0.7689\n",
      "Epoch 43/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4953 - accuracy: 0.7966 - val_loss: 0.9790 - val_accuracy: 0.7736\n",
      "Epoch 44/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4903 - accuracy: 0.7960 - val_loss: 1.0264 - val_accuracy: 0.7311\n",
      "Epoch 45/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4874 - accuracy: 0.7983 - val_loss: 1.0483 - val_accuracy: 0.7689\n",
      "Epoch 46/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5144 - accuracy: 0.7948 - val_loss: 1.0310 - val_accuracy: 0.7689\n",
      "Epoch 47/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5025 - accuracy: 0.7907 - val_loss: 0.9942 - val_accuracy: 0.7877\n",
      "Epoch 48/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4919 - accuracy: 0.7925 - val_loss: 1.0481 - val_accuracy: 0.7736\n",
      "Epoch 49/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4936 - accuracy: 0.7942 - val_loss: 1.0009 - val_accuracy: 0.7453\n",
      "Epoch 50/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4875 - accuracy: 0.7907 - val_loss: 1.0006 - val_accuracy: 0.7453\n",
      "Epoch 51/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4874 - accuracy: 0.7983 - val_loss: 1.0288 - val_accuracy: 0.7594\n",
      "Epoch 52/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4857 - accuracy: 0.7954 - val_loss: 1.0336 - val_accuracy: 0.7689\n",
      "Epoch 53/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4866 - accuracy: 0.7972 - val_loss: 1.0393 - val_accuracy: 0.7594\n",
      "Epoch 54/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.4930 - accuracy: 0.7907 - val_loss: 1.0762 - val_accuracy: 0.7642\n",
      "Epoch 55/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4899 - accuracy: 0.7960 - val_loss: 1.1402 - val_accuracy: 0.7642\n",
      "Epoch 56/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4856 - accuracy: 0.7948 - val_loss: 1.0507 - val_accuracy: 0.7689\n",
      "Epoch 57/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4960 - accuracy: 0.7989 - val_loss: 1.0344 - val_accuracy: 0.7642\n",
      "Epoch 58/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4772 - accuracy: 0.7895 - val_loss: 1.0907 - val_accuracy: 0.7736\n",
      "Epoch 59/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4739 - accuracy: 0.7983 - val_loss: 1.1155 - val_accuracy: 0.7594\n",
      "Epoch 60/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4773 - accuracy: 0.8001 - val_loss: 1.0894 - val_accuracy: 0.7594\n",
      "Epoch 61/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4755 - accuracy: 0.7930 - val_loss: 1.0856 - val_accuracy: 0.7689\n",
      "Epoch 62/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4880 - accuracy: 0.8007 - val_loss: 1.1277 - val_accuracy: 0.7123\n",
      "Epoch 63/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4839 - accuracy: 0.8019 - val_loss: 1.1136 - val_accuracy: 0.7453\n",
      "Epoch 64/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4849 - accuracy: 0.7925 - val_loss: 1.0729 - val_accuracy: 0.7594\n",
      "Epoch 65/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4795 - accuracy: 0.7983 - val_loss: 1.0994 - val_accuracy: 0.7311\n",
      "Epoch 66/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4735 - accuracy: 0.7966 - val_loss: 1.1421 - val_accuracy: 0.7547\n",
      "Epoch 67/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4894 - accuracy: 0.7925 - val_loss: 1.1219 - val_accuracy: 0.7500\n",
      "Epoch 68/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4801 - accuracy: 0.8025 - val_loss: 1.1401 - val_accuracy: 0.7689\n",
      "Epoch 69/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4751 - accuracy: 0.7978 - val_loss: 1.1329 - val_accuracy: 0.7642\n",
      "Epoch 70/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4682 - accuracy: 0.7983 - val_loss: 1.1311 - val_accuracy: 0.7406\n",
      "Epoch 71/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4793 - accuracy: 0.8019 - val_loss: 1.1383 - val_accuracy: 0.7783\n",
      "Epoch 72/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4806 - accuracy: 0.8042 - val_loss: 1.1834 - val_accuracy: 0.7358\n",
      "Epoch 73/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4697 - accuracy: 0.8060 - val_loss: 1.1644 - val_accuracy: 0.7406\n",
      "Epoch 74/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4676 - accuracy: 0.8042 - val_loss: 1.1611 - val_accuracy: 0.7500\n",
      "Epoch 75/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4811 - accuracy: 0.7995 - val_loss: 1.1281 - val_accuracy: 0.7736\n",
      "Epoch 76/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4790 - accuracy: 0.8001 - val_loss: 1.1551 - val_accuracy: 0.7594\n",
      "Epoch 77/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.4695 - accuracy: 0.8078 - val_loss: 1.1352 - val_accuracy: 0.7783\n",
      "Epoch 78/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4878 - accuracy: 0.7877 - val_loss: 1.3145 - val_accuracy: 0.7547\n",
      "Epoch 79/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4814 - accuracy: 0.7972 - val_loss: 1.2252 - val_accuracy: 0.7594\n",
      "Epoch 80/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4786 - accuracy: 0.8001 - val_loss: 1.1542 - val_accuracy: 0.7689\n",
      "Epoch 81/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4712 - accuracy: 0.8013 - val_loss: 1.2175 - val_accuracy: 0.7642\n",
      "Epoch 82/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4692 - accuracy: 0.8072 - val_loss: 1.2099 - val_accuracy: 0.7594\n",
      "Epoch 83/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4714 - accuracy: 0.8001 - val_loss: 1.2492 - val_accuracy: 0.7689\n",
      "Epoch 84/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4667 - accuracy: 0.7989 - val_loss: 1.1581 - val_accuracy: 0.7783\n",
      "Epoch 85/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4675 - accuracy: 0.8031 - val_loss: 1.2106 - val_accuracy: 0.7594\n",
      "Epoch 86/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4715 - accuracy: 0.7989 - val_loss: 1.2424 - val_accuracy: 0.7594\n",
      "Epoch 87/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4852 - accuracy: 0.7978 - val_loss: 1.2060 - val_accuracy: 0.7406\n",
      "Epoch 88/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4697 - accuracy: 0.8025 - val_loss: 1.1984 - val_accuracy: 0.7642\n",
      "Epoch 89/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4698 - accuracy: 0.8001 - val_loss: 1.2165 - val_accuracy: 0.7736\n",
      "Epoch 90/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4747 - accuracy: 0.8025 - val_loss: 1.2052 - val_accuracy: 0.7689\n",
      "Epoch 91/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4844 - accuracy: 0.7972 - val_loss: 1.2271 - val_accuracy: 0.7358\n",
      "Epoch 92/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4701 - accuracy: 0.7983 - val_loss: 1.2103 - val_accuracy: 0.7358\n",
      "Epoch 93/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.7930 - val_loss: 1.2660 - val_accuracy: 0.7642\n",
      "Epoch 94/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4724 - accuracy: 0.8007 - val_loss: 1.2322 - val_accuracy: 0.7594\n",
      "Epoch 95/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4601 - accuracy: 0.8084 - val_loss: 1.2949 - val_accuracy: 0.7406\n",
      "Epoch 96/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4626 - accuracy: 0.8031 - val_loss: 1.2951 - val_accuracy: 0.7642\n",
      "Epoch 97/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4634 - accuracy: 0.8019 - val_loss: 1.2792 - val_accuracy: 0.7453\n",
      "Epoch 98/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4653 - accuracy: 0.7972 - val_loss: 1.2981 - val_accuracy: 0.7594\n",
      "Epoch 99/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4694 - accuracy: 0.8019 - val_loss: 1.3199 - val_accuracy: 0.7594\n",
      "Epoch 100/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4586 - accuracy: 0.8060 - val_loss: 1.3295 - val_accuracy: 0.7358\n",
      "Epoch 101/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4780 - accuracy: 0.7972 - val_loss: 1.2772 - val_accuracy: 0.7736\n",
      "Epoch 102/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4702 - accuracy: 0.7936 - val_loss: 1.3200 - val_accuracy: 0.7547\n",
      "Epoch 103/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4634 - accuracy: 0.8060 - val_loss: 1.3430 - val_accuracy: 0.7500\n",
      "Epoch 104/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4725 - accuracy: 0.8031 - val_loss: 1.3522 - val_accuracy: 0.7689\n",
      "Epoch 105/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4704 - accuracy: 0.7983 - val_loss: 1.2968 - val_accuracy: 0.7547\n",
      "Epoch 106/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4659 - accuracy: 0.8078 - val_loss: 1.3214 - val_accuracy: 0.7500\n",
      "Epoch 107/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4644 - accuracy: 0.8078 - val_loss: 1.2558 - val_accuracy: 0.7594\n",
      "Epoch 108/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4699 - accuracy: 0.8048 - val_loss: 1.2760 - val_accuracy: 0.7689\n",
      "Epoch 109/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4636 - accuracy: 0.8048 - val_loss: 1.2926 - val_accuracy: 0.7642\n",
      "Epoch 110/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4664 - accuracy: 0.8001 - val_loss: 1.3241 - val_accuracy: 0.7689\n",
      "Epoch 111/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4643 - accuracy: 0.8101 - val_loss: 1.3660 - val_accuracy: 0.7642\n",
      "Epoch 112/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4691 - accuracy: 0.8025 - val_loss: 1.3193 - val_accuracy: 0.7594\n",
      "Epoch 113/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4576 - accuracy: 0.8025 - val_loss: 1.3242 - val_accuracy: 0.7642\n",
      "Epoch 114/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4636 - accuracy: 0.7954 - val_loss: 1.3776 - val_accuracy: 0.7594\n",
      "Epoch 115/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4589 - accuracy: 0.7989 - val_loss: 1.3860 - val_accuracy: 0.7689\n",
      "Epoch 116/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4533 - accuracy: 0.8031 - val_loss: 1.4173 - val_accuracy: 0.7453\n",
      "Epoch 117/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4660 - accuracy: 0.7995 - val_loss: 1.3724 - val_accuracy: 0.7594\n",
      "Epoch 118/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.7983 - val_loss: 1.3701 - val_accuracy: 0.7547\n",
      "Epoch 119/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4597 - accuracy: 0.7972 - val_loss: 1.3504 - val_accuracy: 0.7830\n",
      "Epoch 120/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4636 - accuracy: 0.7989 - val_loss: 1.4253 - val_accuracy: 0.7689\n",
      "Epoch 121/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4576 - accuracy: 0.8025 - val_loss: 1.3749 - val_accuracy: 0.7358\n",
      "Epoch 122/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4847 - accuracy: 0.7972 - val_loss: 1.3586 - val_accuracy: 0.7311\n",
      "Epoch 123/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4588 - accuracy: 0.8119 - val_loss: 1.3925 - val_accuracy: 0.7358\n",
      "Epoch 124/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4616 - accuracy: 0.8101 - val_loss: 1.3955 - val_accuracy: 0.7594\n",
      "Epoch 125/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4609 - accuracy: 0.7989 - val_loss: 1.5230 - val_accuracy: 0.7358\n",
      "Epoch 126/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4542 - accuracy: 0.8096 - val_loss: 1.4935 - val_accuracy: 0.7547\n",
      "Epoch 127/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4565 - accuracy: 0.8119 - val_loss: 1.5460 - val_accuracy: 0.7264\n",
      "Epoch 128/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4728 - accuracy: 0.8031 - val_loss: 1.4901 - val_accuracy: 0.7594\n",
      "Epoch 129/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4593 - accuracy: 0.7978 - val_loss: 1.4384 - val_accuracy: 0.7689\n",
      "Epoch 130/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4560 - accuracy: 0.8090 - val_loss: 1.4700 - val_accuracy: 0.7453\n",
      "Epoch 131/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4583 - accuracy: 0.8019 - val_loss: 1.5253 - val_accuracy: 0.7642\n",
      "Epoch 132/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4520 - accuracy: 0.8131 - val_loss: 1.4878 - val_accuracy: 0.7642\n",
      "Epoch 133/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.4527 - accuracy: 0.8149 - val_loss: 1.5346 - val_accuracy: 0.7406\n",
      "Epoch 134/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4478 - accuracy: 0.8143 - val_loss: 1.5229 - val_accuracy: 0.7358\n",
      "Epoch 135/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4502 - accuracy: 0.8107 - val_loss: 1.5341 - val_accuracy: 0.7594\n",
      "Epoch 136/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4583 - accuracy: 0.8096 - val_loss: 1.5007 - val_accuracy: 0.7689\n",
      "Epoch 137/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4580 - accuracy: 0.8119 - val_loss: 1.5590 - val_accuracy: 0.7500\n",
      "Epoch 138/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4562 - accuracy: 0.8037 - val_loss: 1.5666 - val_accuracy: 0.7594\n",
      "Epoch 139/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4638 - accuracy: 0.8125 - val_loss: 1.4872 - val_accuracy: 0.7594\n",
      "Epoch 140/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4820 - accuracy: 0.8101 - val_loss: 1.4508 - val_accuracy: 0.7642\n",
      "Epoch 141/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4689 - accuracy: 0.8072 - val_loss: 1.4963 - val_accuracy: 0.7594\n",
      "Epoch 142/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4647 - accuracy: 0.8131 - val_loss: 1.4743 - val_accuracy: 0.7642\n",
      "Epoch 143/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4706 - accuracy: 0.8066 - val_loss: 1.5199 - val_accuracy: 0.7594\n",
      "Epoch 144/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4642 - accuracy: 0.8154 - val_loss: 1.5256 - val_accuracy: 0.7642\n",
      "Epoch 145/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4669 - accuracy: 0.8025 - val_loss: 1.4888 - val_accuracy: 0.7547\n",
      "Epoch 146/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4699 - accuracy: 0.8078 - val_loss: 1.4417 - val_accuracy: 0.7736\n",
      "Epoch 147/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4565 - accuracy: 0.8131 - val_loss: 1.4452 - val_accuracy: 0.7642\n",
      "Epoch 148/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.8096 - val_loss: 1.3570 - val_accuracy: 0.7783\n",
      "Epoch 149/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4564 - accuracy: 0.8154 - val_loss: 1.4477 - val_accuracy: 0.7642\n",
      "Epoch 150/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4474 - accuracy: 0.8090 - val_loss: 1.4220 - val_accuracy: 0.7642\n",
      "Best epoch: 47\n"
     ]
    }
   ],
   "source": [
    "print(\"Build the model with the optimal hyperparameters and train it on the data to find  N epochs\")\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "# model.summary()\n",
    "history = best_model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
    "\n",
    "val_acc_per_epoch = history.history['val_accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print(f'Best epoch: {best_epoch}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0719611-4770-47de-96fb-343698c0e381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fid Optimal Best Epoch  by Re-instantiating the hypermodel and train it\n",
      "Epoch 1/47\n",
      "53/53 [==============================] - 1s 8ms/step - loss: 0.8532 - accuracy: 0.6344 - val_loss: 0.6837 - val_accuracy: 0.7311\n",
      "Epoch 2/47\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.7150 - accuracy: 0.6899 - val_loss: 0.6747 - val_accuracy: 0.7170\n",
      "Epoch 3/47\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.6728 - accuracy: 0.7252 - val_loss: 0.6872 - val_accuracy: 0.7500\n",
      "Epoch 4/47\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.6608 - accuracy: 0.7241 - val_loss: 0.6792 - val_accuracy: 0.7311\n",
      "Epoch 5/47\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.6290 - accuracy: 0.7476 - val_loss: 0.6945 - val_accuracy: 0.7689\n",
      "Epoch 6/47\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.6118 - accuracy: 0.7494 - val_loss: 0.7172 - val_accuracy: 0.7358\n",
      "Epoch 7/47\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5974 - accuracy: 0.7541 - val_loss: 0.7218 - val_accuracy: 0.7594\n",
      "Epoch 8/47\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5986 - accuracy: 0.7594 - val_loss: 0.7444 - val_accuracy: 0.7453\n",
      "Epoch 9/47\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5926 - accuracy: 0.7512 - val_loss: 0.7498 - val_accuracy: 0.7217\n",
      "Epoch 10/47\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5851 - accuracy: 0.7612 - val_loss: 0.7673 - val_accuracy: 0.7217\n",
      "Epoch 11/47\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5725 - accuracy: 0.7653 - val_loss: 0.7657 - val_accuracy: 0.7642\n",
      "Epoch 12/47\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5531 - accuracy: 0.7712 - val_loss: 0.8101 - val_accuracy: 0.7123\n",
      "Epoch 13/47\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5593 - accuracy: 0.7630 - val_loss: 0.8091 - val_accuracy: 0.7358\n",
      "Epoch 14/47\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5468 - accuracy: 0.7706 - val_loss: 0.8493 - val_accuracy: 0.7594\n",
      "Epoch 15/47\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5534 - accuracy: 0.7824 - val_loss: 0.8445 - val_accuracy: 0.7217\n",
      "Epoch 16/47\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5501 - accuracy: 0.7689 - val_loss: 0.8447 - val_accuracy: 0.7547\n",
      "Epoch 17/47\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5506 - accuracy: 0.7718 - val_loss: 0.8215 - val_accuracy: 0.7358\n",
      "Epoch 18/47\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5416 - accuracy: 0.7812 - val_loss: 0.8244 - val_accuracy: 0.7453\n",
      "Epoch 19/47\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5320 - accuracy: 0.7842 - val_loss: 0.8547 - val_accuracy: 0.7217\n",
      "Epoch 20/47\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5370 - accuracy: 0.7866 - val_loss: 0.8786 - val_accuracy: 0.7736\n",
      "Epoch 21/47\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5349 - accuracy: 0.7736 - val_loss: 0.8821 - val_accuracy: 0.7264\n",
      "Epoch 22/47\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5342 - accuracy: 0.7795 - val_loss: 0.8712 - val_accuracy: 0.7689\n",
      "Epoch 23/47\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5287 - accuracy: 0.7783 - val_loss: 0.8834 - val_accuracy: 0.7736\n",
      "Epoch 24/47\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5198 - accuracy: 0.7836 - val_loss: 0.8941 - val_accuracy: 0.7642\n",
      "Epoch 25/47\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5222 - accuracy: 0.7771 - val_loss: 0.9211 - val_accuracy: 0.7689\n",
      "Epoch 26/47\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5299 - accuracy: 0.7860 - val_loss: 0.9400 - val_accuracy: 0.7311\n",
      "Epoch 27/47\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5236 - accuracy: 0.7807 - val_loss: 0.9042 - val_accuracy: 0.7689\n",
      "Epoch 28/47\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5298 - accuracy: 0.7807 - val_loss: 0.9405 - val_accuracy: 0.7358\n",
      "Epoch 29/47\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5260 - accuracy: 0.7736 - val_loss: 0.9248 - val_accuracy: 0.7689\n",
      "Epoch 30/47\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7866 - val_loss: 0.9530 - val_accuracy: 0.7689\n",
      "Epoch 31/47\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5250 - accuracy: 0.7883 - val_loss: 0.9264 - val_accuracy: 0.7547\n",
      "Epoch 32/47\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5108 - accuracy: 0.7907 - val_loss: 0.9812 - val_accuracy: 0.7736\n",
      "Epoch 33/47\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5176 - accuracy: 0.7836 - val_loss: 0.9627 - val_accuracy: 0.7642\n",
      "Epoch 34/47\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5117 - accuracy: 0.7807 - val_loss: 0.9640 - val_accuracy: 0.7689\n",
      "Epoch 35/47\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5012 - accuracy: 0.7836 - val_loss: 0.9816 - val_accuracy: 0.7689\n",
      "Epoch 36/47\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5129 - accuracy: 0.7871 - val_loss: 0.9975 - val_accuracy: 0.7500\n",
      "Epoch 37/47\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7901 - val_loss: 1.0230 - val_accuracy: 0.7264\n",
      "Epoch 38/47\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5005 - accuracy: 0.7913 - val_loss: 1.0153 - val_accuracy: 0.7594\n",
      "Epoch 39/47\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5140 - accuracy: 0.7842 - val_loss: 0.9981 - val_accuracy: 0.7642\n",
      "Epoch 40/47\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4978 - accuracy: 0.7877 - val_loss: 1.0274 - val_accuracy: 0.7736\n",
      "Epoch 41/47\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4997 - accuracy: 0.7907 - val_loss: 1.0571 - val_accuracy: 0.7358\n",
      "Epoch 42/47\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7883 - val_loss: 0.9985 - val_accuracy: 0.7689\n",
      "Epoch 43/47\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.4881 - accuracy: 0.8013 - val_loss: 1.0808 - val_accuracy: 0.7689\n",
      "Epoch 44/47\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7877 - val_loss: 1.0485 - val_accuracy: 0.7689\n",
      "Epoch 45/47\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4970 - accuracy: 0.7942 - val_loss: 1.0297 - val_accuracy: 0.7406\n",
      "Epoch 46/47\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4960 - accuracy: 0.7860 - val_loss: 1.1105 - val_accuracy: 0.7594\n",
      "Epoch 47/47\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4973 - accuracy: 0.7966 - val_loss: 1.0403 - val_accuracy: 0.7406\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0403 - accuracy: 0.7406\n",
      "Eveluation on Val-Data at 47 epochs : loss=1.0402859449386597 and accuracy= 0.7405660152435303\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8832 - accuracy: 0.7311\n",
      "Evaluation on Test-Data at 47 epochs : loss=0.8831631541252136 and accuracy= 0.7311320900917053\n"
     ]
    }
   ],
   "source": [
    "print(\"Fid Optimal Best Epoch  by Re-instantiating the hypermodel and train it\")\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "# Retrain the model to get final\n",
    "history_hypermodel=model.fit(train_ds, validation_data=val_ds, epochs=best_epoch)\n",
    "\n",
    "val_loss, val_accuracy = model.evaluate(val_ds)\n",
    "print(f\"Eveluation on Val-Data at {best_epoch} epochs : loss={val_loss} and {main_metric}= {val_accuracy}\")\n",
    "test_loss, test_accuracy = model.evaluate(test_ds)\n",
    "print(f\"Evaluation on Test-Data at {best_epoch} epochs : loss={test_loss} and {main_metric}= {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee6ca53e-78d8-400e-a48e-cdcb93d2030f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(history,metric):\n",
    "    plt.figure(figsize=(15,8))\n",
    "    plt.title(metric)\n",
    "    plt.plot(history.history[metric], label='train')\n",
    "    plt.plot(history.history[f'val_{metric}'], label='validation')\n",
    "    plt.legend()\n",
    "    plt.show() \n",
    "\n",
    "print(\"4#Explore Result model\")\n",
    "plot_metrics(history,main_metric)\n",
    "plot_metrics(history,\"loss\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ccf5e4-6b93-4353-81b6-78b6b6435f76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff49fc4-517c-4708-9861-13890bc08ba1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2bcf9758-bf3f-46aa-a0a0-1554b78d5baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tuned_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tuned_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(model_tuned_dir)\n",
    "# quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24b15af3-b755-4bdb-acbf-ad8409ebc2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sla': '24x7 4Hrs Response Time', 'product_type': 'Server', 'brand': 'VMWare', 'service_type': 'Incident', 'incident_type': 'General Incident', 'open_to_close_hour': 10, 'response_to_resolved_hour': 8.0}\n",
      "===============================================================================================================\n",
      "convert pain data to serdor as input to predict\n",
      "{'sla': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'24x7 4Hrs Response Time'], dtype=object)>, 'product_type': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Server'], dtype=object)>, 'brand': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'VMWare'], dtype=object)>, 'service_type': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Incident'], dtype=object)>, 'incident_type': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'General Incident'], dtype=object)>, 'open_to_close_hour': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([10])>, 'response_to_resolved_hour': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([8.], dtype=float32)>}\n",
      "1/1 [==============================] - 0s 303ms/step\n",
      "[[0.0073715  0.46528834 0.526338   0.00100224]]\n",
      "[50.18429  61.426796 62.862854 50.02505 ] %  as Severity\n"
     ]
    }
   ],
   "source": [
    "reloaded_model = tf.keras.models.load_model(model_tuned_dir)\n",
    "#label_multi_severity\n",
    "sample={\"sla\":\"24x7 4Hrs Response Time\",\n",
    "        \"product_type\":\"Server\",\n",
    "        \"brand\":\"VMWare\",                \n",
    "        \"service_type\":\"Incident\",\n",
    "        \"incident_type\":\"General Incident\",\n",
    "        \"open_to_close_hour\":10,\n",
    "        \"response_to_resolved_hour\":8.000000 \\\n",
    "       }\n",
    "\n",
    "print(sample)\n",
    "              \n",
    "print(\"===============================================================================================================\")    \n",
    "print(\"convert pain data to serdor as input to predict\")    \n",
    "input_dict = {name: tf.convert_to_tensor([value]) for name, value in sample.items()}\n",
    "print(input_dict)\n",
    "\n",
    "predictionList = reloaded_model.predict(input_dict)\n",
    "print(predictionList)\n",
    "prob = tf.nn.sigmoid(predictionList[0])\n",
    "print(f\"{(100 * prob)} %  as Severity\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197af355-c0d4-4c00-aa6e-d1d7ca6d0be6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61641e5e-6ecd-4c92-b199-2981c02e1bd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217b56cb-75ff-4661-9145-fb59b8516b91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499f77f8-03ed-4485-b0e6-7f6f5da16223",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5587682-2265-4eff-985f-ca1f7852ddf4",
   "metadata": {},
   "source": [
    "# Copy Model From Local To GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "eaabd3ac-47ad-43ae-b6e5-fc16fecec238",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying file://.\\model\\saved_model.pb [Content-Type=application/octet-stream]...\n",
      "Copying file://.\\model\\variables\\variables.data-00000-of-00001 [Content-Type=application/octet-stream]...\n",
      "/ [0/5 files][    0.0 B/527.8 KiB]   0% Done                                    \n",
      "/ [0/5 files][    0.0 B/527.8 KiB]   0% Done                                    \n",
      "Copying file://.\\model\\fingerprint.pb [Content-Type=application/octet-stream]...\n",
      "Copying file://.\\model\\keras_metadata.pb [Content-Type=application/octet-stream]...\n",
      "/ [0/5 files][    0.0 B/527.8 KiB]   0% Done                                    \n",
      "/ [0/5 files][    0.0 B/527.8 KiB]   0% Done                                    \n",
      "Copying file://.\\model\\variables\\variables.index [Content-Type=application/octet-stream]...\n",
      "/ [0/5 files][    0.0 B/527.8 KiB]   0% Done                                    \n",
      "/ [1/5 files][ 97.0 KiB/527.8 KiB]  18% Done                                    \n",
      "/ [2/5 files][ 97.0 KiB/527.8 KiB]  18% Done                                    \n",
      "/ [3/5 files][ 97.0 KiB/527.8 KiB]  18% Done                                    \n",
      "/ [4/5 files][ 97.0 KiB/527.8 KiB]  18% Done                                    \n",
      "-\n",
      "- [5/5 files][527.8 KiB/527.8 KiB] 100% Done                                    \n",
      "\n",
      "Operation completed over 5 objects/527.8 KiB.                                    \n"
     ]
    }
   ],
   "source": [
    "# #https://codelabs.developers.google.com/codelabs/fraud-detection-ai-explanations?hl=en#6\n",
    "# press_y3=input(f\"Press y=True to save model to Google Cloud storage : \") \n",
    "# if press_y3.lower()=='y':\n",
    "#     MODEL_BUCKET = 'gs://tf1-incident-pongthorn'\n",
    "#     MODEL_NAME = 'tf1_incident_multi_model'\n",
    "\n",
    "# # !gsutil mb -l $REGION $MODEL_BUCKET\n",
    "# # !gsutil -m cp -r ./$model_tuned_dir/* $MODEL_BUCKET/model\n",
    "# else:\n",
    "#  quite()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc32a07-c2fc-4ff6-a771-fc3532630f01",
   "metadata": {},
   "source": [
    "# Import Model to Vertex AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9774f1-2293-43db-9464-47ea7f44b540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://cloud.google.com/vertex-ai/docs/model-registry/import-model#get-operation\n",
    "\n",
    "#https://codelabs.developers.google.com/vertex-p2p-predictions#3\n",
    "# Import model manually\n",
    "#https://console.cloud.google.com/vertex-ai/models?project=pongthorn\n",
    "# Upload wand wait for vertex to complete process (Email notification)\n",
    "# if run package ( you need to specify precuild-pacage\n",
    "\n",
    "\n",
    "#Import model programactically\n",
    "# https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers\n",
    "\n",
    "# from google.cloud import aiplatform\n",
    "# DEPLOY_IMAGE = \"asia-docker.pkg.dev/vertex-ai/prediction/xgboost-cpu.1-6:latest\"\n",
    "\n",
    "# model = aip.Model.upload(\n",
    "#     display_name=\"ponghthorn_xgb_\" + TIMESTAMP,\n",
    "#     artifact_uri=MODEL_DIR,\n",
    "#     serving_container_image_uri=DEPLOY_IMAGE,\n",
    "#     sync=False,\n",
    "# )\n",
    "\n",
    "# model.wait()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2792371f-3e81-4717-95f5-4acff020cfb3",
   "metadata": {},
   "source": [
    "# Deploy Model to EndPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbcd51c-0dce-4b75-bc53-70539c352ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://codelabs.developers.google.com/vertex-p2p-predictions#4\n",
    "# Manual\n",
    "\n",
    "# Program\n",
    "# my_model = aiplatform.Model(\"projects/{PROJECT_NUMBER}/locations/us-central1/models/{MODEL_ID}\") \n",
    "\n",
    "# endpoint = my_model.deploy(\n",
    "#      deployed_model_display_name='my-endpoint',\n",
    "#      traffic_split={\"0\": 100},\n",
    "#      machine_type=\"n1-standard-4\",\n",
    "#      accelerator_count=0,\n",
    "#      min_replica_count=1,\n",
    "#      max_replica_count=1,\n",
    "#    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a601d87-b648-4eea-b2de-b85b7723c5ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "20082661-dc7f-414b-a759-3478163adcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy to AIPlatform (Deprecated)\n",
    "# MODEL = MODEL_NAME\n",
    "# VERSION = 'v1'\n",
    "# model_path = MODEL_BUCKET + '/model'\n",
    "\n",
    "# # !gcloud ai-platform models create $MODEL --region=$REGION\n",
    "\n",
    "# MACHINE_TYPE='n1-standard-2'\n",
    "\n",
    "# !gcloud  ai-platform versions create $VERSION --model $MODEL --origin $model_path --runtime-version 2.11 --framework TENSORFLOW --machine-type $MACHINE_TYPE --python-version 3.7 --region=$REGION\n",
    "# !gcloud ai-platform versions describe $VERSION --model $MODEL --region=$REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6465851a-f078-41a2-991c-80a71d3e695d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0f6c5d-3ea4-4fae-ba78-b8decf134a92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff433f46-0e98-48ec-8b32-25b840541253",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
