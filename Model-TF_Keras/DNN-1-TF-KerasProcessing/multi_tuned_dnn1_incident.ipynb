{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6dd8df7-648e-44c8-87ec-599b76a0934c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://pair-code.github.io/lit/\n",
    "#https://www.tensorflow.org/tensorboard/get_started\n",
    "# https://www.tensorflow.org/tensorboard/dataframe_api\n",
    "# https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks\n",
    "#https://keras.io/guides/keras_tuner/visualize_tuning/\n",
    "\n",
    "#https://github.com/technqvi/TimeSeriesML-FinMarket/blob/main/MultiVarToManyOutputLSTM.ipynb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efd54814-e227-4302-9a81-3d6ddcf0e9a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n",
      "2.12.0\n"
     ]
    }
   ],
   "source": [
    "# import necessary libraries\n",
    "\n",
    "#https://codelabs.developers.google.com/codelabs/fraud-detection-ai-explanations?hl=en#0\n",
    "#he Explainable AI SDK and Copy Model to Deploy\n",
    "\n",
    "#https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/courses/machine_learning/deepdive2/introduction_to_tensorflow/solutions/preprocessing_layers.ipynb\n",
    "#https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/custom/custom-tabular-bq-managed-dataset.ipynb\n",
    "#https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/experiments/comparing_local_trained_models.ipynb\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense,DenseFeatures\n",
    "\n",
    "from datetime import date, timedelta, datetime # Date Functions\n",
    "import time\n",
    "\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "# from google.cloud import aiplatform as vertex_ai\n",
    "from tensorflow.python.keras.utils import data_utils\n",
    "\n",
    "import tensorboard as tb\n",
    "\n",
    "# from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "print(tf.__version__)\n",
    "print(tb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebf74622-6c60-4bda-9b9b-9a799bfaed45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# major_ver, minor_ver, _ = version.parse(tb.__version__).release\n",
    "# assert major_ver >= 2 and minor_ver >= 3, \\\n",
    "#     \"This notebook requires TensorBoard 2.3 or later.\"\n",
    "# print(\"TensorBoard version: \", tb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab04a472-7abe-4315-b555-0583fdb2a5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any logs from previous runs\n",
    "# !rm -rf ./logs/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d28a9538-ca23-45f0-817b-e4b067cf9ab3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cateCols=['sla','product_type','brand','service_type','incident_type']\n",
    "numbericCols=['open_to_close_hour','response_to_resolved_hour']\n",
    "unusedCols=['severity_id','severity_name','label_binary_severity']\n",
    "\n",
    "# cateCols=['service_type','product_type','incident_type',]\n",
    "# numbericCols=[]\n",
    "# unusedCols=['severity_id','severity_name','label_binary_severity'. \\\n",
    "#            'open_to_close_hour','response_to_resolved_hour' .\\\n",
    "#             'sla'\n",
    "#            ]\n",
    "\n",
    "# cateCols=['sla','product_type','service_type','incident_type']\n",
    "# numbericCols=['open_to_close_hour']\n",
    "# unusedCols=['severity_id','severity_name','label_binary_severity','brand','response_to_resolved_hour']\n",
    "\n",
    "labelCol='label_multi_severity'\n",
    "\n",
    "main_metric='accuracy'\n",
    "main_objective=f'val_{main_metric}'\n",
    "\n",
    "\n",
    "objective_to_tued_and_monitor='val_loss' \n",
    "# objective_to_tued_and_monitor=main_objective\n",
    "\n",
    "seed=1932\n",
    "\n",
    "EPOCHS =100\n",
    "BATCH_SIZE = 32\n",
    "unitList=[16,32,64,128]\n",
    "dropOutList= [0.1, 0.2]\n",
    "lrList=[0.01,0.001,0.0001]\n",
    "nAtleastMaxTrials=10\n",
    "nExecutions_per_trial=3  # 3,5\n",
    "nEarlyPatience=11\n",
    "\n",
    "\n",
    "# EPOCHS =20\n",
    "# BATCH_SIZE = 32\n",
    "# unitList=[32]\n",
    "# dropOutList= [0.1,0.2]\n",
    "# lrList=[0.01,0.001]\n",
    "# nAtleastMaxTrials=10\n",
    "# nExecutions_per_trial=1  # 3,5\n",
    "# nEarlyPatience=10\n",
    "\n",
    "model_tuned_dir='tuned_model_V2'\n",
    "\n",
    "# df['label_multi_severity'] =df['severity_name'].map({'Cosmatic':0,'Minor': 1, \"Major\": 2, \"Critical\": 3}) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0aa901-563f-4d2c-9203-67175431c32f",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1db6b46-bd0e-4053-8b4e-42e43f822da7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "projectId='pongthorn'\n",
    "client = bigquery.Client(project=projectId)\n",
    "dataset_id='SMartML'\n",
    "\n",
    "train_name='train_incident'\n",
    "validation_name='validation_incident'\n",
    "test_name='test_incident'\n",
    "\n",
    "train_table_id=f\"{projectId}.{dataset_id}.{train_name}\"\n",
    "val_tabel_id=f\"{projectId}.{dataset_id}.{validation_name}\"\n",
    "test_tabel_id=f\"{projectId}.{dataset_id}.{test_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ddea3e1-b732-48c4-95fc-637108802a2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2731, 8)\n",
      "(341, 8)\n",
      "(342, 8)\n",
      "[2, 1, 0, 3]\n",
      "No target label : 4\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2731 entries, 0 to 2730\n",
      "Data columns (total 8 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   sla                        2731 non-null   object \n",
      " 1   product_type               2731 non-null   object \n",
      " 2   brand                      2731 non-null   object \n",
      " 3   service_type               2731 non-null   object \n",
      " 4   incident_type              2731 non-null   object \n",
      " 5   open_to_close_hour         2731 non-null   float64\n",
      " 6   response_to_resolved_hour  2731 non-null   float64\n",
      " 7   label_multi_severity       2731 non-null   Int64  \n",
      "dtypes: Int64(1), float64(2), object(5)\n",
      "memory usage: 173.5+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sla</th>\n",
       "      <th>product_type</th>\n",
       "      <th>brand</th>\n",
       "      <th>service_type</th>\n",
       "      <th>incident_type</th>\n",
       "      <th>open_to_close_hour</th>\n",
       "      <th>response_to_resolved_hour</th>\n",
       "      <th>label_multi_severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2726</th>\n",
       "      <td>24x7 4Hrs Response Time</td>\n",
       "      <td>Security</td>\n",
       "      <td>Trend Micro</td>\n",
       "      <td>Request</td>\n",
       "      <td>General Incident</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2727</th>\n",
       "      <td>24x7 6Hrs Resolution Time</td>\n",
       "      <td>Software</td>\n",
       "      <td>Trend Micro</td>\n",
       "      <td>Request</td>\n",
       "      <td>General Incident</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2728</th>\n",
       "      <td>24x7 4Hrs Response Time</td>\n",
       "      <td>Security</td>\n",
       "      <td>Trend Micro</td>\n",
       "      <td>Request</td>\n",
       "      <td>OS / Firmware</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2729</th>\n",
       "      <td>24x7 4Hrs Response Time</td>\n",
       "      <td>Software</td>\n",
       "      <td>Trend Micro</td>\n",
       "      <td>Request</td>\n",
       "      <td>General Incident</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>7.283333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2730</th>\n",
       "      <td>24x7 6Hrs Resolution Time</td>\n",
       "      <td>Software</td>\n",
       "      <td>Trend Micro</td>\n",
       "      <td>Request</td>\n",
       "      <td>General Incident</td>\n",
       "      <td>5.483333</td>\n",
       "      <td>5.483333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            sla product_type        brand service_type  \\\n",
       "2726    24x7 4Hrs Response Time     Security  Trend Micro      Request   \n",
       "2727  24x7 6Hrs Resolution Time     Software  Trend Micro      Request   \n",
       "2728    24x7 4Hrs Response Time     Security  Trend Micro      Request   \n",
       "2729    24x7 4Hrs Response Time     Software  Trend Micro      Request   \n",
       "2730  24x7 6Hrs Resolution Time     Software  Trend Micro      Request   \n",
       "\n",
       "         incident_type  open_to_close_hour  response_to_resolved_hour  \\\n",
       "2726  General Incident            0.333333                   0.333333   \n",
       "2727  General Incident            0.883333                   0.716667   \n",
       "2728     OS / Firmware           16.666667                  16.666667   \n",
       "2729  General Incident            7.400000                   7.283333   \n",
       "2730  General Incident            5.483333                   5.483333   \n",
       "\n",
       "      label_multi_severity  \n",
       "2726                     0  \n",
       "2727                     0  \n",
       "2728                     0  \n",
       "2729                     0  \n",
       "2730                     0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def load_ml_data(data_path):\n",
    "#  df=pd.read_csv(data_path)\n",
    "#  df =df.drop(columns=unusedCols)\n",
    "#  return df\n",
    "\n",
    "# root_path='../../data'    \n",
    "# train = load_ml_data(f\"{root_path}/train_incident.csv\")\n",
    "# # val=train.copy()\n",
    "# val=load_ml_data(f\"{root_path}/validation_incident.csv\")\n",
    "# # test =val.copy()\n",
    "# test =load_ml_data(f\"{root_path}/test_incident.csv\")\n",
    "\n",
    "def load_data_bq(sql:str):\n",
    " \n",
    " query_result=client.query(sql)\n",
    " df=query_result.to_dataframe()\n",
    " df =df.drop(columns=unusedCols)\n",
    "  \n",
    " return df\n",
    "    \n",
    "\n",
    "train=load_data_bq(f\"SELECT * FROM {train_table_id}\")\n",
    "val=load_data_bq(f\"SELECT * FROM {val_tabel_id}\")\n",
    "test=load_data_bq(f\"SELECT * FROM {test_tabel_id}\")\n",
    "\n",
    "print(train.shape)\n",
    "print(val.shape)\n",
    "print(test.shape)\n",
    "\n",
    "\n",
    "labelList=list(train[labelCol].unique())\n",
    "print(labelList)\n",
    "nLabel=len(labelList)\n",
    "print(f\"No target label : {nLabel}\")\n",
    "\n",
    "# sr_predict=df.iloc[-1,:]\n",
    "# df=df.iloc[0:len(df)-1,:]\n",
    "                 \n",
    "print(train.info())\n",
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64adbe5e-d737-45a4-a04e-340a2926ad2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train-No-Severity</th>\n",
       "      <th>Train-%-Severity</th>\n",
       "      <th>Val-No-Severity</th>\n",
       "      <th>Val-%-Severity</th>\n",
       "      <th>Test-No-Severity</th>\n",
       "      <th>Test-%-Severity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label_multi_severity</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>511</td>\n",
       "      <td>19.0</td>\n",
       "      <td>53</td>\n",
       "      <td>16.0</td>\n",
       "      <td>55</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>778</td>\n",
       "      <td>28.0</td>\n",
       "      <td>97</td>\n",
       "      <td>28.0</td>\n",
       "      <td>92</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1341</td>\n",
       "      <td>49.0</td>\n",
       "      <td>180</td>\n",
       "      <td>53.0</td>\n",
       "      <td>181</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Train-No-Severity  Train-%-Severity  Val-No-Severity  \\\n",
       "label_multi_severity                                                         \n",
       "0                                   511              19.0               53   \n",
       "1                                   778              28.0               97   \n",
       "2                                  1341              49.0              180   \n",
       "3                                   101               4.0               11   \n",
       "\n",
       "                      Val-%-Severity  Test-No-Severity  Test-%-Severity  \n",
       "label_multi_severity                                                     \n",
       "0                               16.0                55             16.0  \n",
       "1                               28.0                92             27.0  \n",
       "2                               53.0               181             53.0  \n",
       "3                                3.0                14              4.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def CalPctEachTargetClass(dfx,colSev,colPctSev):\n",
    "    dfClassSummary=dfx.groupby([labelCol]).size().to_frame(colSev)\n",
    "    dfClassSummary[colPctSev]= dfClassSummary[colSev]/dfClassSummary[colSev].sum() *100\n",
    "    dfClassSummary=dfClassSummary.round(0)\n",
    "    return dfClassSummary\n",
    "\n",
    "pctDF1=CalPctEachTargetClass(train,'Train-No-Severity','Train-%-Severity')\n",
    "pctDF2=CalPctEachTargetClass(val,'Val-No-Severity','Val-%-Severity')\n",
    "pdcDF3=CalPctEachTargetClass(test,'Test-No-Severity','Test-%-Severity')\n",
    "pctDF=pd.concat([pctDF1,pctDF2,pdcDF3],axis=1)\n",
    "\n",
    "pctDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa30d3fd-14e9-4c3d-a6aa-45d8114f5362",
   "metadata": {},
   "source": [
    "# Process Data  Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9d3a943-09d5-4a43-b8d8-633bc4a90353",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def multiple_label_df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
    "  features = dataframe.copy()\n",
    "  labels = features.pop(labelCol)\n",
    "  labels  = tf.keras.utils.to_categorical(labels, num_classes=nLabel)\n",
    "    \n",
    "  ds = tf.data.Dataset.from_tensor_slices(( dict(features), labels ))\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(buffer_size=len(features))\n",
    "  ds = ds.batch(batch_size)\n",
    "  ds = ds.prefetch(batch_size)\n",
    "  return ds\n",
    "     \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02ad8837-968e-4d68-bdb6-1c7eba97e69c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_normalization_layer(name, dataset):\n",
    "  # Create a Normalization layer for our feature.\n",
    "  normalizer = preprocessing.Normalization(axis=None)\n",
    "\n",
    "  # Prepare a Dataset that only yields our feature.\n",
    "  feature_ds = dataset.map(lambda x, y: x[name])\n",
    "\n",
    "  # Learn the statistics of the data.\n",
    "  normalizer.adapt(feature_ds)\n",
    "\n",
    "  return normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "237bce3c-9c77-4318-8682-fc36af0a6804",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_category_encoding_layer(name, dataset, dtype, max_tokens=None):\n",
    "  # Create a StringLookup layer which will turn strings into integer indices\n",
    "  if dtype == 'string':\n",
    "    index = preprocessing.StringLookup(max_tokens=max_tokens)\n",
    "  else:\n",
    "    index = preprocessing.IntegerLookup(max_tokens=max_tokens)\n",
    "\n",
    "  # Prepare a Dataset that only yields our feature\n",
    "  feature_ds = dataset.map(lambda x, y: x[name])\n",
    "\n",
    "  # Learn the set of possible values and assign them a fixed integer index.\n",
    "  index.adapt(feature_ds)\n",
    "\n",
    "  # Create a Discretization for our integer indices.\n",
    "  encoder = preprocessing.CategoryEncoding(num_tokens=index.vocabulary_size())\n",
    "\n",
    "  # Apply one-hot encoding to our indices. The lambda function captures the\n",
    "  # layer so we can use them, or include them in the functional model later.\n",
    "  return lambda feature: encoder(index(feature))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5c78f01-000a-4d3e-9fbf-6f4660cfb75b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size =32\n",
    "train_ds = multiple_label_df_to_dataset (train, batch_size=batch_size)\n",
    "val_ds = multiple_label_df_to_dataset(val, batch_size=batch_size)\n",
    "test_ds = multiple_label_df_to_dataset(test, batch_size=batch_size)\n",
    "# for element in train_ds.as_numpy_iterator():\n",
    "#     print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "723a69b6-d9c1-49d9-bc81-ed421d8700cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "open_to_close_hour\n",
      "header: Mean=120.7417429512999 and Std=339.9325107996055\n",
      "========================================================================\n",
      "response_to_resolved_hour\n",
      "header: Mean=92.4087208592701 and Std=292.40800375934094\n",
      "========================================================================\n",
      "sla = 7 : ['24x7 4Hrs Resolution Time' '24x7 4Hrs Response Time'\n",
      " '24x7 6Hrs Resolution Time' '8x5 4Hrs Response Time'\n",
      " '9x5 NBD 4Hrs Response Time' '24x7 6Hrs Response Time' 'Non MA']\n",
      "sla\n",
      "product_type = 13 : ['Other' 'Printer' 'Storage' 'Software' 'Server' 'Access Point' 'Switch'\n",
      " 'Hardware' 'Tape Library' 'Security' 'Service' 'Notebook' 'Firewall']\n",
      "product_type\n",
      "brand = 28 : ['F5' 'HP' 'EMC' 'HPE' 'IBM' 'YIP' 'DELL' 'QNAP' 'Cisco' 'SAPB1' 'Veeam'\n",
      " 'NetApp' 'Oracle' 'VMWare' 'Zabbix' 'eUnite' 'Nutanix' 'Red Hat'\n",
      " 'Veritas' 'Alfresco' 'Broadcom' 'Fortinet' 'Commvault' 'Microsoft'\n",
      " 'Palo Alto' 'CIMCO-CMMS' 'CheckPoint' 'Trend Micro']\n",
      "brand\n",
      "service_type = 2 : ['Incident' 'Request']\n",
      "service_type\n",
      "incident_type = 21 : ['General Incident' 'Network Adapter Failure' 'Software'\n",
      " 'Maintenance System' 'Hard Disk Drive Failure' 'Power Supply Failure'\n",
      " 'Report' 'System Board Failure' 'Memory Failure' 'Network Card Failure'\n",
      " 'Controller/Node Failure' 'Backup Failure' 'Upgrade Software'\n",
      " 'CPU Failure' 'OS / Firmware' 'Configuration Change'\n",
      " 'Cache Battery Failure' 'Other Failure' 'Network Cable Failure'\n",
      " 'Battery Failure' 'Fan Failure']\n",
      "incident_type\n"
     ]
    }
   ],
   "source": [
    "all_inputs = []\n",
    "encoded_features = []\n",
    "numInputFeatToInitNodeUnit=0\n",
    "# Numeric features.\n",
    "for header in numbericCols:\n",
    "  print(header)  \n",
    "  stat_data=train[header].describe()\n",
    "  print(f\"header: Mean={stat_data['mean']} and Std={stat_data['std']}\") \n",
    "  numeric_col = tf.keras.Input(shape=(1,), name=header)\n",
    "  normalization_layer = get_normalization_layer(header, train_ds)\n",
    "  encoded_numeric_col = normalization_layer(numeric_col)\n",
    "  all_inputs.append(numeric_col)\n",
    "  encoded_features.append(encoded_numeric_col)\n",
    "  print(\"========================================================================\")\n",
    "    \n",
    "numInputFeatToInitNodeUnit=numInputFeatToInitNodeUnit+len(numbericCols)\n",
    " \n",
    "# Categorical features encoded as string.\n",
    "categorical_cols = cateCols\n",
    "for header in categorical_cols:\n",
    "    \n",
    "  listCateItem=train[header].unique()\n",
    "  noCateItem=len(listCateItem)\n",
    "  numInputFeatToInitNodeUnit=numInputFeatToInitNodeUnit+noCateItem +1  # last 1 is unknow  \n",
    "  print(f\"{header} = {noCateItem} : {listCateItem}\")    \n",
    "    \n",
    "  print(header)  \n",
    "  categorical_col = tf.keras.Input(shape=(1,), name=header, dtype='string')\n",
    "  encoding_layer = get_category_encoding_layer(header, train_ds, dtype='string')\n",
    "                                        \n",
    "  encoded_categorical_col = encoding_layer(categorical_col)\n",
    "  all_inputs.append(categorical_col)\n",
    "  encoded_features.append(encoded_categorical_col)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f85f8a-4471-44e1-a389-102232c296e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf75dae1-683f-403d-9f2d-aca95c970a21",
   "metadata": {},
   "source": [
    "# Tune HyperParameter By Keras Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07dacd5c-0af5-4415-a20e-6e808850de18",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16, 32, 64, 128, 78, 156] [0.1, 0.2] [0.01, 0.001, 0.0001]\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "unitList.append(numInputFeatToInitNodeUnit)\n",
    "unitList.append(numInputFeatToInitNodeUnit*2)\n",
    "print(unitList,dropOutList,lrList)\n",
    "nMax_trials=len(unitList)*len(dropOutList)*len(lrList)\n",
    "if nMax_trials<nAtleastMaxTrials:\n",
    " nMax_trials=nAtleastMaxTrials \n",
    "print(nMax_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4267752a-455a-4fde-a7b9-518229a81a0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#https://github.com/technqvi/TimeSeriesML-FinMarket/blob/main/lstm-tune-dev/Tuned-MultiVarToManyOutputLSTM.ipynb\n",
    "#https://www.tensorflow.org/tutorials/keras/keras_tuner\n",
    "#https://keras.io/guides/keras_tuner/getting_started/\n",
    "import keras_tuner as kt\n",
    "from keras_tuner.engine.hyperparameters import HyperParameters\n",
    "tune_folder=\"IncidentMLP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e44461a8-a751-40ae-98c4-e6578a1855e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start tund at 2023-11-11 01:42:16.446807\n",
      "=============================================================\n",
      "IncidentMLP_111123_0142\n"
     ]
    }
   ],
   "source": [
    "t_Start=time.time()\n",
    "\n",
    "print(f\"Start tund at {datetime.now()}\")\n",
    "print(\"=============================================================\")\n",
    "buildtime = datetime.now().strftime('%d%m%y_%H%M')\n",
    "project_model=f\"{tune_folder}_{buildtime}\"\n",
    "print(project_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c97a4d39-0145-49cd-9abf-277e76bd03af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model_for_tuning(hp):\n",
    "    \n",
    "    all_features = tf.keras.layers.concatenate(encoded_features)\n",
    "    \n",
    "    x = tf.keras.layers.Dense(hp.Choice('units', unitList), activation=\"relu\")(all_features)\n",
    "    \n",
    "    x = tf.keras.layers.Dropout(hp.Choice('Dropout_rate',dropOutList))(x)\n",
    "    \n",
    "    output = tf.keras.layers.Dense(nLabel,activation=tf.nn.softmax)(x)\n",
    "    \n",
    "    model = tf.keras.Model(all_inputs, output)\n",
    "    # model.compile(optimizer='adam',loss=tf.keras.losses.CategoricalCrossentropy(),metrics=[main_metric])\n",
    "    \n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=lrList) \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                  loss=tf.keras.losses.CategoricalCrossentropy(),metrics=[main_metric])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a501b2-88c6-4b15-9724-2b05849fde59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 Complete [00h 01m 19s]\n",
      "val_loss: 0.6891810695330302\n",
      "\n",
      "Best val_loss So Far: 0.6891810695330302\n",
      "Total elapsed time: 00h 03m 43s\n",
      "\n",
      "Search: Running Trial #4\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "64                |128               |units\n",
      "0.2               |0.2               |Dropout_rate\n",
      "0.0001            |0.0001            |learning_rate\n",
      "\n",
      "Epoch 1/100\n",
      " 1/86 [..............................] - ETA: 1:17 - loss: 1.4654 - accuracy: 0.1875WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0026s). Check your callbacks.\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 1.3711 - accuracy: 0.2889 - val_loss: 1.3211 - val_accuracy: 0.3226\n",
      "Epoch 2/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.2728 - accuracy: 0.4145 - val_loss: 1.2262 - val_accuracy: 0.5455\n",
      "Epoch 3/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.1954 - accuracy: 0.5247 - val_loss: 1.1485 - val_accuracy: 0.6246\n",
      "Epoch 4/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.1279 - accuracy: 0.5932 - val_loss: 1.0834 - val_accuracy: 0.6393\n",
      "Epoch 5/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.0769 - accuracy: 0.6086 - val_loss: 1.0298 - val_accuracy: 0.6510\n",
      "Epoch 6/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.0303 - accuracy: 0.6148 - val_loss: 0.9842 - val_accuracy: 0.6452\n",
      "Epoch 7/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.9976 - accuracy: 0.6302 - val_loss: 0.9475 - val_accuracy: 0.6364\n",
      "Epoch 8/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.9611 - accuracy: 0.6294 - val_loss: 0.9160 - val_accuracy: 0.6481\n",
      "Epoch 9/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.9262 - accuracy: 0.6364 - val_loss: 0.8906 - val_accuracy: 0.6452\n",
      "Epoch 10/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.9068 - accuracy: 0.6576 - val_loss: 0.8686 - val_accuracy: 0.6540\n",
      "Epoch 11/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.8935 - accuracy: 0.6485 - val_loss: 0.8502 - val_accuracy: 0.6598\n",
      "Epoch 12/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.8726 - accuracy: 0.6620 - val_loss: 0.8344 - val_accuracy: 0.6598\n",
      "Epoch 13/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.8590 - accuracy: 0.6650 - val_loss: 0.8204 - val_accuracy: 0.6716\n",
      "Epoch 14/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.8450 - accuracy: 0.6734 - val_loss: 0.8089 - val_accuracy: 0.6686\n",
      "Epoch 15/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.8333 - accuracy: 0.6792 - val_loss: 0.7988 - val_accuracy: 0.6833\n",
      "Epoch 16/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.8257 - accuracy: 0.6759 - val_loss: 0.7901 - val_accuracy: 0.6833\n",
      "Epoch 17/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.8142 - accuracy: 0.6814 - val_loss: 0.7825 - val_accuracy: 0.6833\n",
      "Epoch 18/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.8076 - accuracy: 0.6814 - val_loss: 0.7754 - val_accuracy: 0.6862\n",
      "Epoch 19/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7989 - accuracy: 0.6899 - val_loss: 0.7694 - val_accuracy: 0.6891\n",
      "Epoch 20/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7900 - accuracy: 0.6869 - val_loss: 0.7640 - val_accuracy: 0.6891\n",
      "Epoch 21/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7857 - accuracy: 0.6866 - val_loss: 0.7597 - val_accuracy: 0.6891\n",
      "Epoch 22/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7753 - accuracy: 0.6946 - val_loss: 0.7557 - val_accuracy: 0.6921\n",
      "Epoch 23/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7799 - accuracy: 0.6895 - val_loss: 0.7524 - val_accuracy: 0.6921\n",
      "Epoch 24/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7715 - accuracy: 0.6851 - val_loss: 0.7494 - val_accuracy: 0.6891\n",
      "Epoch 25/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7679 - accuracy: 0.6899 - val_loss: 0.7465 - val_accuracy: 0.6891\n",
      "Epoch 26/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7607 - accuracy: 0.6880 - val_loss: 0.7439 - val_accuracy: 0.6891\n",
      "Epoch 27/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7571 - accuracy: 0.6917 - val_loss: 0.7415 - val_accuracy: 0.6891\n",
      "Epoch 28/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7549 - accuracy: 0.7005 - val_loss: 0.7394 - val_accuracy: 0.6950\n",
      "Epoch 29/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7562 - accuracy: 0.6935 - val_loss: 0.7374 - val_accuracy: 0.6979\n",
      "Epoch 30/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7526 - accuracy: 0.6917 - val_loss: 0.7359 - val_accuracy: 0.6979\n",
      "Epoch 31/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7506 - accuracy: 0.6986 - val_loss: 0.7345 - val_accuracy: 0.6979\n",
      "Epoch 32/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7420 - accuracy: 0.6946 - val_loss: 0.7328 - val_accuracy: 0.6979\n",
      "Epoch 33/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7408 - accuracy: 0.6975 - val_loss: 0.7319 - val_accuracy: 0.7009\n",
      "Epoch 34/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7449 - accuracy: 0.6968 - val_loss: 0.7308 - val_accuracy: 0.7009\n",
      "Epoch 35/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7402 - accuracy: 0.6953 - val_loss: 0.7296 - val_accuracy: 0.7038\n",
      "Epoch 36/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7445 - accuracy: 0.6979 - val_loss: 0.7288 - val_accuracy: 0.7038\n",
      "Epoch 37/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.6997 - val_loss: 0.7278 - val_accuracy: 0.7038\n",
      "Epoch 38/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7374 - accuracy: 0.6983 - val_loss: 0.7274 - val_accuracy: 0.7038\n",
      "Epoch 39/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7338 - accuracy: 0.6997 - val_loss: 0.7265 - val_accuracy: 0.7038\n",
      "Epoch 40/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7275 - accuracy: 0.7030 - val_loss: 0.7256 - val_accuracy: 0.7009\n",
      "Epoch 41/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7344 - accuracy: 0.7008 - val_loss: 0.7249 - val_accuracy: 0.7009\n",
      "Epoch 42/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7306 - accuracy: 0.7060 - val_loss: 0.7240 - val_accuracy: 0.7009\n",
      "Epoch 43/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.7291 - accuracy: 0.7001 - val_loss: 0.7236 - val_accuracy: 0.7009\n",
      "Epoch 44/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7285 - accuracy: 0.7019 - val_loss: 0.7231 - val_accuracy: 0.7038\n",
      "Epoch 45/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7227 - accuracy: 0.7049 - val_loss: 0.7224 - val_accuracy: 0.7038\n",
      "Epoch 46/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7239 - accuracy: 0.7063 - val_loss: 0.7222 - val_accuracy: 0.7038\n",
      "Epoch 47/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7205 - accuracy: 0.7030 - val_loss: 0.7215 - val_accuracy: 0.7038\n",
      "Epoch 48/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7245 - accuracy: 0.6994 - val_loss: 0.7212 - val_accuracy: 0.7038\n",
      "Epoch 49/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7214 - accuracy: 0.7008 - val_loss: 0.7205 - val_accuracy: 0.7038\n",
      "Epoch 50/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7212 - accuracy: 0.7074 - val_loss: 0.7202 - val_accuracy: 0.7038\n",
      "Epoch 51/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7198 - accuracy: 0.6994 - val_loss: 0.7193 - val_accuracy: 0.7038\n",
      "Epoch 52/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7180 - accuracy: 0.7071 - val_loss: 0.7191 - val_accuracy: 0.7009\n",
      "Epoch 53/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7139 - accuracy: 0.6990 - val_loss: 0.7190 - val_accuracy: 0.7009\n",
      "Epoch 54/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7159 - accuracy: 0.7052 - val_loss: 0.7189 - val_accuracy: 0.7038\n",
      "Epoch 55/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7155 - accuracy: 0.7074 - val_loss: 0.7181 - val_accuracy: 0.7038\n",
      "Epoch 56/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.7239 - accuracy: 0.6972 - val_loss: 0.7182 - val_accuracy: 0.7038\n",
      "Epoch 57/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7104 - accuracy: 0.7060 - val_loss: 0.7180 - val_accuracy: 0.7038\n",
      "Epoch 58/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7130 - accuracy: 0.6964 - val_loss: 0.7176 - val_accuracy: 0.7038\n",
      "Epoch 59/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7109 - accuracy: 0.7129 - val_loss: 0.7173 - val_accuracy: 0.7038\n",
      "Epoch 60/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7097 - accuracy: 0.7052 - val_loss: 0.7170 - val_accuracy: 0.7038\n",
      "Epoch 61/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7036 - accuracy: 0.7045 - val_loss: 0.7168 - val_accuracy: 0.7038\n",
      "Epoch 62/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7018 - accuracy: 0.7155 - val_loss: 0.7165 - val_accuracy: 0.7038\n",
      "Epoch 63/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7043 - accuracy: 0.7078 - val_loss: 0.7163 - val_accuracy: 0.7038\n",
      "Epoch 64/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7110 - accuracy: 0.7115 - val_loss: 0.7159 - val_accuracy: 0.7038\n",
      "Epoch 65/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.7032 - accuracy: 0.7137 - val_loss: 0.7159 - val_accuracy: 0.7038\n",
      "Epoch 66/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6987 - accuracy: 0.7085 - val_loss: 0.7157 - val_accuracy: 0.7038\n",
      "Epoch 67/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6981 - accuracy: 0.7133 - val_loss: 0.7156 - val_accuracy: 0.7038\n",
      "Epoch 68/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6974 - accuracy: 0.7137 - val_loss: 0.7149 - val_accuracy: 0.7038\n",
      "Epoch 69/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.7005 - accuracy: 0.7115 - val_loss: 0.7151 - val_accuracy: 0.7038\n",
      "Epoch 70/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6984 - accuracy: 0.7140 - val_loss: 0.7146 - val_accuracy: 0.7067\n",
      "Epoch 71/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.6966 - accuracy: 0.7137 - val_loss: 0.7148 - val_accuracy: 0.7067\n",
      "Epoch 72/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.6969 - accuracy: 0.7155 - val_loss: 0.7146 - val_accuracy: 0.7038\n",
      "Epoch 73/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7024 - accuracy: 0.7008 - val_loss: 0.7144 - val_accuracy: 0.7067\n",
      "Epoch 74/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6952 - accuracy: 0.7104 - val_loss: 0.7141 - val_accuracy: 0.7067\n",
      "Epoch 75/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6907 - accuracy: 0.7170 - val_loss: 0.7139 - val_accuracy: 0.7067\n",
      "Epoch 76/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6996 - accuracy: 0.7041 - val_loss: 0.7135 - val_accuracy: 0.7038\n",
      "Epoch 77/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6951 - accuracy: 0.7082 - val_loss: 0.7135 - val_accuracy: 0.7067\n",
      "Epoch 78/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6966 - accuracy: 0.7155 - val_loss: 0.7132 - val_accuracy: 0.7038\n",
      "Epoch 79/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.6906 - accuracy: 0.7195 - val_loss: 0.7133 - val_accuracy: 0.7038\n",
      "Epoch 80/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.6981 - accuracy: 0.7045 - val_loss: 0.7133 - val_accuracy: 0.7067\n",
      "Epoch 81/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6980 - accuracy: 0.7067 - val_loss: 0.7128 - val_accuracy: 0.7067\n",
      "Epoch 82/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.6872 - accuracy: 0.7188 - val_loss: 0.7131 - val_accuracy: 0.7067\n",
      "Epoch 83/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6909 - accuracy: 0.7107 - val_loss: 0.7126 - val_accuracy: 0.7067\n",
      "Epoch 84/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.6866 - accuracy: 0.7170 - val_loss: 0.7127 - val_accuracy: 0.7038\n",
      "Epoch 85/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6916 - accuracy: 0.7184 - val_loss: 0.7124 - val_accuracy: 0.7126\n",
      "Epoch 86/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.6891 - accuracy: 0.7155 - val_loss: 0.7124 - val_accuracy: 0.7126\n",
      "Epoch 87/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6866 - accuracy: 0.7155 - val_loss: 0.7124 - val_accuracy: 0.7067\n",
      "Epoch 88/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6896 - accuracy: 0.7093 - val_loss: 0.7120 - val_accuracy: 0.7067\n",
      "Epoch 89/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.6862 - accuracy: 0.7148 - val_loss: 0.7121 - val_accuracy: 0.7126\n",
      "Epoch 90/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6820 - accuracy: 0.7140 - val_loss: 0.7118 - val_accuracy: 0.7155\n",
      "Epoch 91/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6819 - accuracy: 0.7159 - val_loss: 0.7117 - val_accuracy: 0.7155\n",
      "Epoch 92/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.6796 - accuracy: 0.7096 - val_loss: 0.7117 - val_accuracy: 0.7155\n",
      "Epoch 93/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.6820 - accuracy: 0.7206 - val_loss: 0.7118 - val_accuracy: 0.7155\n",
      "Epoch 94/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6824 - accuracy: 0.7181 - val_loss: 0.7114 - val_accuracy: 0.7155\n",
      "Epoch 95/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.6838 - accuracy: 0.7166 - val_loss: 0.7115 - val_accuracy: 0.7185\n",
      "Epoch 96/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6788 - accuracy: 0.7155 - val_loss: 0.7113 - val_accuracy: 0.7185\n",
      "Epoch 97/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6801 - accuracy: 0.7162 - val_loss: 0.7108 - val_accuracy: 0.7185\n",
      "Epoch 98/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.6784 - accuracy: 0.7192 - val_loss: 0.7109 - val_accuracy: 0.7185\n",
      "Epoch 99/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.6786 - accuracy: 0.7239 - val_loss: 0.7111 - val_accuracy: 0.7185\n",
      "Epoch 100/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6837 - accuracy: 0.7202 - val_loss: 0.7108 - val_accuracy: 0.7185\n",
      "Epoch 1/100\n",
      "86/86 [==============================] - 2s 16ms/step - loss: 1.3265 - accuracy: 0.3823 - val_loss: 1.2437 - val_accuracy: 0.4399\n",
      "Epoch 2/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 1.2467 - accuracy: 0.4339 - val_loss: 1.1717 - val_accuracy: 0.5044\n",
      "Epoch 3/100\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 1.1898 - accuracy: 0.4771 - val_loss: 1.1121 - val_accuracy: 0.5249\n",
      "Epoch 4/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 1.1326 - accuracy: 0.4896 - val_loss: 1.0632 - val_accuracy: 0.5308\n",
      "Epoch 5/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.0890 - accuracy: 0.5024 - val_loss: 1.0229 - val_accuracy: 0.5543\n",
      "Epoch 6/100\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 1.0505 - accuracy: 0.5262 - val_loss: 0.9878 - val_accuracy: 0.5718\n",
      "Epoch 7/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 1.0163 - accuracy: 0.5482 - val_loss: 0.9570 - val_accuracy: 0.5836\n",
      "Epoch 8/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.9845 - accuracy: 0.5826 - val_loss: 0.9295 - val_accuracy: 0.6276\n",
      "Epoch 9/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.9574 - accuracy: 0.6122 - val_loss: 0.9055 - val_accuracy: 0.6364\n",
      "Epoch 10/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.9324 - accuracy: 0.6313 - val_loss: 0.8841 - val_accuracy: 0.6305\n",
      "Epoch 11/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.9141 - accuracy: 0.6360 - val_loss: 0.8651 - val_accuracy: 0.6598\n",
      "Epoch 12/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.8913 - accuracy: 0.6448 - val_loss: 0.8483 - val_accuracy: 0.6716\n",
      "Epoch 13/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.8743 - accuracy: 0.6620 - val_loss: 0.8333 - val_accuracy: 0.6804\n",
      "Epoch 14/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.8549 - accuracy: 0.6756 - val_loss: 0.8206 - val_accuracy: 0.7009\n",
      "Epoch 15/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.8436 - accuracy: 0.6807 - val_loss: 0.8088 - val_accuracy: 0.7009\n",
      "Epoch 16/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.8359 - accuracy: 0.6726 - val_loss: 0.7986 - val_accuracy: 0.7009\n",
      "Epoch 17/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.8190 - accuracy: 0.6899 - val_loss: 0.7898 - val_accuracy: 0.6891\n",
      "Epoch 18/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.8123 - accuracy: 0.6778 - val_loss: 0.7823 - val_accuracy: 0.6950\n",
      "Epoch 19/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.8002 - accuracy: 0.6884 - val_loss: 0.7756 - val_accuracy: 0.7009\n",
      "Epoch 20/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.7960 - accuracy: 0.6851 - val_loss: 0.7694 - val_accuracy: 0.7009\n",
      "Epoch 21/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7905 - accuracy: 0.6953 - val_loss: 0.7641 - val_accuracy: 0.6979\n",
      "Epoch 22/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.7861 - accuracy: 0.6910 - val_loss: 0.7594 - val_accuracy: 0.7009\n",
      "Epoch 23/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.7810 - accuracy: 0.7005 - val_loss: 0.7554 - val_accuracy: 0.7009\n",
      "Epoch 24/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.7795 - accuracy: 0.6939 - val_loss: 0.7519 - val_accuracy: 0.7067\n",
      "Epoch 25/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.7715 - accuracy: 0.6932 - val_loss: 0.7485 - val_accuracy: 0.7067\n",
      "Epoch 26/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.7616 - accuracy: 0.6968 - val_loss: 0.7456 - val_accuracy: 0.7067\n",
      "Epoch 27/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.7597 - accuracy: 0.6983 - val_loss: 0.7430 - val_accuracy: 0.7097\n",
      "Epoch 28/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.7621 - accuracy: 0.6913 - val_loss: 0.7405 - val_accuracy: 0.7067\n",
      "Epoch 29/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.7615 - accuracy: 0.7023 - val_loss: 0.7385 - val_accuracy: 0.7067\n",
      "Epoch 30/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.7526 - accuracy: 0.6986 - val_loss: 0.7365 - val_accuracy: 0.7067\n",
      "Epoch 31/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.7512 - accuracy: 0.6950 - val_loss: 0.7349 - val_accuracy: 0.7067\n",
      "Epoch 32/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.7417 - accuracy: 0.7067 - val_loss: 0.7331 - val_accuracy: 0.7097\n",
      "Epoch 33/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.7445 - accuracy: 0.7005 - val_loss: 0.7312 - val_accuracy: 0.7097\n",
      "Epoch 34/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7458 - accuracy: 0.6994 - val_loss: 0.7296 - val_accuracy: 0.7097\n",
      "Epoch 35/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.7425 - accuracy: 0.7038 - val_loss: 0.7284 - val_accuracy: 0.7097\n",
      "Epoch 36/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.7307 - accuracy: 0.7052 - val_loss: 0.7272 - val_accuracy: 0.7097\n",
      "Epoch 37/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.7349 - accuracy: 0.7071 - val_loss: 0.7259 - val_accuracy: 0.7126\n",
      "Epoch 38/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.7340 - accuracy: 0.7067 - val_loss: 0.7247 - val_accuracy: 0.7126\n",
      "Epoch 39/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.7345 - accuracy: 0.6964 - val_loss: 0.7240 - val_accuracy: 0.7126\n",
      "Epoch 40/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.7303 - accuracy: 0.6994 - val_loss: 0.7231 - val_accuracy: 0.7126\n",
      "Epoch 41/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.7284 - accuracy: 0.7049 - val_loss: 0.7221 - val_accuracy: 0.7097\n",
      "Epoch 42/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.7283 - accuracy: 0.7177 - val_loss: 0.7215 - val_accuracy: 0.7097\n",
      "Epoch 43/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.7172 - accuracy: 0.7155 - val_loss: 0.7208 - val_accuracy: 0.7185\n",
      "Epoch 44/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.7278 - accuracy: 0.7067 - val_loss: 0.7202 - val_accuracy: 0.7097\n",
      "Epoch 45/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.7240 - accuracy: 0.7085 - val_loss: 0.7197 - val_accuracy: 0.7097\n",
      "Epoch 46/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7217 - accuracy: 0.7078 - val_loss: 0.7191 - val_accuracy: 0.7097\n",
      "Epoch 47/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.7199 - accuracy: 0.7052 - val_loss: 0.7184 - val_accuracy: 0.7097\n",
      "Epoch 48/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.7130 - accuracy: 0.7107 - val_loss: 0.7175 - val_accuracy: 0.7097\n",
      "Epoch 49/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.7116 - accuracy: 0.7129 - val_loss: 0.7175 - val_accuracy: 0.7067\n",
      "Epoch 50/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.7210 - accuracy: 0.7060 - val_loss: 0.7171 - val_accuracy: 0.7067\n",
      "Epoch 51/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.7140 - accuracy: 0.7045 - val_loss: 0.7166 - val_accuracy: 0.7067\n",
      "Epoch 52/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.7131 - accuracy: 0.7082 - val_loss: 0.7162 - val_accuracy: 0.7067\n",
      "Epoch 53/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.7122 - accuracy: 0.7159 - val_loss: 0.7158 - val_accuracy: 0.7067\n",
      "Epoch 54/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.7135 - accuracy: 0.7027 - val_loss: 0.7153 - val_accuracy: 0.7097\n",
      "Epoch 55/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7062 - accuracy: 0.7140 - val_loss: 0.7150 - val_accuracy: 0.7097\n",
      "Epoch 56/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.7123 - accuracy: 0.7089 - val_loss: 0.7145 - val_accuracy: 0.7126\n",
      "Epoch 57/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.7079 - accuracy: 0.7104 - val_loss: 0.7143 - val_accuracy: 0.7126\n",
      "Epoch 58/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.7111 - accuracy: 0.7074 - val_loss: 0.7140 - val_accuracy: 0.7097\n",
      "Epoch 59/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7065 - accuracy: 0.7122 - val_loss: 0.7134 - val_accuracy: 0.7097\n",
      "Epoch 60/100\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7111 - accuracy: 0.7074 - val_loss: 0.7132 - val_accuracy: 0.7126\n",
      "Epoch 61/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.7101 - accuracy: 0.7118 - val_loss: 0.7128 - val_accuracy: 0.7097\n",
      "Epoch 62/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.7047 - accuracy: 0.7071 - val_loss: 0.7123 - val_accuracy: 0.7155\n",
      "Epoch 63/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.7065 - accuracy: 0.7162 - val_loss: 0.7117 - val_accuracy: 0.7243\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.BayesianOptimization(\n",
    "## tuner = kt.Hyperband(\n",
    "# tuner = keras_tuner.RandomSearch(  #main_objective\n",
    "    build_model_for_tuning, objective=objective_to_tued_and_monitor,seed=seed,\n",
    "    max_trials=nMax_trials,executions_per_trial=nExecutions_per_trial,\n",
    "    directory=f\"tuning/{tune_folder}/\",project_name= project_model)\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor=objective_to_tued_and_monitor, patience=nEarlyPatience)\n",
    "tuner.search(train_ds, batch_size=BATCH_SIZE,epochs=EPOCHS,validation_data=val_ds)\n",
    "\n",
    "# log_dir = \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# tsb_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "\n",
    "# stop_early = tf.keras.callbacks.EarlyStopping(monitor=objective_to_tued_and_monitor, patience=nEarlyPatience)\n",
    "# tuner.search(train_ds, batch_size=BATCH_SIZE,epochs=EPOCHS,validation_data=val_ds,callbacks=[stop_early, tsb_callback])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4c6208-4f0b-4c98-b847-f58b0a5b1308",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(best_hps.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b213ad70-70d9-44d4-b70d-453d2f93c431",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t_End=time.time()\n",
    "t_elapsed=(t_End-t_Start)/60/60\n",
    "print('Total execution : ',round(t_elapsed,2)) \n",
    "print(datetime.now())\n",
    "print(\"=============================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a507e4-8375-4ccd-900f-77afa85f20ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the TensorBoard notebook extension\n",
    "# %load_ext tensorboard\n",
    "# # %tensorboard --logdir logs/fit \n",
    "# #%tensorboard --logdir logs/fit --host 0.0.0.0\n",
    "\n",
    "# from tensorboard import notebook\n",
    "# notebook.list() # View open TensorBoard instances\n",
    "# # Control TensorBoard display. If no port is provided, \n",
    "# # the most recently launched TensorBoard is used\n",
    "# notebook.display(port=6006, height=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e48b135-26b3-4513-8bf0-bc3726258613",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8cd0fa5-eb89-4a0d-9575-ccb10b981adc",
   "metadata": {},
   "source": [
    "# Retain by best model to product model to production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "544099f0-746c-4e7b-af73-58e6351d90a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build the model with the optimal hyperparameters and train it on the data to find  N epochs\n",
      "Epoch 1/20\n",
      "86/86 [==============================] - 2s 9ms/step - loss: 1.0880 - accuracy: 0.5225 - val_loss: 0.8661 - val_accuracy: 0.7009\n",
      "Epoch 2/20\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.8315 - accuracy: 0.6840 - val_loss: 0.7561 - val_accuracy: 0.7067\n",
      "Epoch 3/20\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.7556 - accuracy: 0.6990 - val_loss: 0.7245 - val_accuracy: 0.7097\n",
      "Epoch 4/20\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.7325 - accuracy: 0.7016 - val_loss: 0.7130 - val_accuracy: 0.7126\n",
      "Epoch 5/20\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.7087 - accuracy: 0.7162 - val_loss: 0.7098 - val_accuracy: 0.7185\n",
      "Epoch 6/20\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6991 - accuracy: 0.7129 - val_loss: 0.7051 - val_accuracy: 0.7243\n",
      "Epoch 7/20\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.6891 - accuracy: 0.7133 - val_loss: 0.7059 - val_accuracy: 0.7126\n",
      "Epoch 8/20\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.6836 - accuracy: 0.7148 - val_loss: 0.7079 - val_accuracy: 0.7214\n",
      "Epoch 9/20\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.6731 - accuracy: 0.7228 - val_loss: 0.6973 - val_accuracy: 0.7214\n",
      "Epoch 10/20\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.6668 - accuracy: 0.7235 - val_loss: 0.6977 - val_accuracy: 0.7185\n",
      "Epoch 11/20\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.6582 - accuracy: 0.7294 - val_loss: 0.7046 - val_accuracy: 0.7302\n",
      "Epoch 12/20\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.6522 - accuracy: 0.7283 - val_loss: 0.6974 - val_accuracy: 0.7243\n",
      "Epoch 13/20\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.6454 - accuracy: 0.7272 - val_loss: 0.6974 - val_accuracy: 0.7273\n",
      "Epoch 14/20\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.6426 - accuracy: 0.7323 - val_loss: 0.6974 - val_accuracy: 0.7155\n",
      "Epoch 15/20\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.6435 - accuracy: 0.7276 - val_loss: 0.6955 - val_accuracy: 0.7243\n",
      "Epoch 16/20\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.6378 - accuracy: 0.7378 - val_loss: 0.6943 - val_accuracy: 0.7302\n",
      "Epoch 17/20\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.6327 - accuracy: 0.7360 - val_loss: 0.6946 - val_accuracy: 0.7273\n",
      "Epoch 18/20\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6304 - accuracy: 0.7338 - val_loss: 0.6920 - val_accuracy: 0.7243\n",
      "Epoch 19/20\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.6237 - accuracy: 0.7360 - val_loss: 0.6923 - val_accuracy: 0.7273\n",
      "Epoch 20/20\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.6171 - accuracy: 0.7448 - val_loss: 0.6932 - val_accuracy: 0.7273\n"
     ]
    }
   ],
   "source": [
    "print(\"Build the model with the optimal hyperparameters and train it on the data to find  N epochs\")\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "# model.summary()\n",
    "history = best_model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3958dd9f-5d48-4572-90af-b27754928f3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch: 11\n"
     ]
    }
   ],
   "source": [
    "val_acc_per_epoch = history.history['val_accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print(f'Best epoch: {best_epoch}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d0719611-4770-47de-96fb-343698c0e381",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fid Optimal Best Epoch  by Re-instantiating the hypermodel and train it\n",
      "Epoch 1/11\n",
      "86/86 [==============================] - 2s 10ms/step - loss: 1.0336 - accuracy: 0.5610 - val_loss: 0.8403 - val_accuracy: 0.6979\n",
      "Epoch 2/11\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.8115 - accuracy: 0.6877 - val_loss: 0.7490 - val_accuracy: 0.7038\n",
      "Epoch 3/11\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.7534 - accuracy: 0.6990 - val_loss: 0.7288 - val_accuracy: 0.6979\n",
      "Epoch 4/11\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.7237 - accuracy: 0.7096 - val_loss: 0.7177 - val_accuracy: 0.7067\n",
      "Epoch 5/11\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.7073 - accuracy: 0.7115 - val_loss: 0.7153 - val_accuracy: 0.7126\n",
      "Epoch 6/11\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.7015 - accuracy: 0.7082 - val_loss: 0.7091 - val_accuracy: 0.7097\n",
      "Epoch 7/11\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6857 - accuracy: 0.7126 - val_loss: 0.7030 - val_accuracy: 0.7302\n",
      "Epoch 8/11\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6789 - accuracy: 0.7206 - val_loss: 0.7012 - val_accuracy: 0.7214\n",
      "Epoch 9/11\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.6729 - accuracy: 0.7228 - val_loss: 0.7021 - val_accuracy: 0.7185\n",
      "Epoch 10/11\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.6675 - accuracy: 0.7243 - val_loss: 0.7009 - val_accuracy: 0.7185\n",
      "Epoch 11/11\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6616 - accuracy: 0.7199 - val_loss: 0.7000 - val_accuracy: 0.7243\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7000 - accuracy: 0.7243\n",
      "Eveluation on Val-Data at 11 epochs : loss=0.6999762058258057 and accuracy= 0.7243402004241943\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6786 - accuracy: 0.7251\n",
      "Evaluation on Test-Data at 11 epochs : loss=0.6786440014839172 and accuracy= 0.7251461744308472\n"
     ]
    }
   ],
   "source": [
    "print(\"Fid Optimal Best Epoch  by Re-instantiating the hypermodel and train it\")\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "# Retrain the model to get final\n",
    "history_hypermodel=model.fit(train_ds, validation_data=val_ds, epochs=best_epoch)\n",
    "\n",
    "val_loss, val_accuracy = model.evaluate(val_ds)\n",
    "print(f\"Eveluation on Val-Data at {best_epoch} epochs : loss={val_loss} and {main_metric}= {val_accuracy}\")\n",
    "test_loss, test_accuracy = model.evaluate(test_ds)\n",
    "print(f\"Evaluation on Test-Data at {best_epoch} epochs : loss={test_loss} and {main_metric}= {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ee6ca53e-78d8-400e-a48e-cdcb93d2030f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4#Explore Result model\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[140], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow() \n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4#Explore Result model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m plot_metrics(\u001b[43mhistory\u001b[49m,main_metric)\n\u001b[0;32m     11\u001b[0m plot_metrics(history,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_metrics(history,metric):\n",
    "    plt.figure(figsize=(15,8))\n",
    "    plt.title(metric)\n",
    "    plt.plot(history.history[metric], label='train')\n",
    "    plt.plot(history.history[f'val_{metric}'], label='validation')\n",
    "    plt.legend()\n",
    "    plt.show() \n",
    "\n",
    "print(\"4#Explore Result model\")\n",
    "plot_metrics(history,main_metric)\n",
    "plot_metrics(history,\"loss\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff49fc4-517c-4708-9861-13890bc08ba1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2bcf9758-bf3f-46aa-a0a0-1554b78d5baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tuned_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tuned_model\\assets\n"
     ]
    }
   ],
   "source": [
    "# model.save(model_tuned_dir)\n",
    "# quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "24b15af3-b755-4bdb-acbf-ad8409ebc2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sla': '24x7 4Hrs Response Time', 'product_type': 'Server', 'brand': 'VMWare', 'service_type': 'Incident', 'incident_type': 'General Incident', 'open_to_close_hour': 10, 'response_to_resolved_hour': 8.0}\n",
      "===============================================================================================================\n",
      "convert pain data to serdor as input to predict\n",
      "{'sla': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'24x7 4Hrs Response Time'], dtype=object)>, 'product_type': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Server'], dtype=object)>, 'brand': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'VMWare'], dtype=object)>, 'service_type': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Incident'], dtype=object)>, 'incident_type': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'General Incident'], dtype=object)>, 'open_to_close_hour': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([10])>, 'response_to_resolved_hour': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([8.], dtype=float32)>}\n",
      "1/1 [==============================] - 1s 529ms/step\n",
      "[[0.00572414 0.17363077 0.79714    0.02350508]]\n",
      "[50.143105 54.329895 68.93623  50.5876  ] %  as Severity\n"
     ]
    }
   ],
   "source": [
    "reloaded_model = tf.keras.models.load_model(model_tuned_dir)\n",
    "#label_multi_severity\n",
    "sample={\"sla\":\"24x7 4Hrs Response Time\",\n",
    "        \"product_type\":\"Server\",\n",
    "        \"brand\":\"VMWare\",                \n",
    "        \"service_type\":\"Incident\",\n",
    "        \"incident_type\":\"General Incident\",\n",
    "        \"open_to_close_hour\":10,\n",
    "        \"response_to_resolved_hour\":8.000000 \\\n",
    "       }\n",
    "\n",
    "print(sample)\n",
    "              \n",
    "print(\"===============================================================================================================\")    \n",
    "print(\"convert pain data to serdor as input to predict\")    \n",
    "input_dict = {name: tf.convert_to_tensor([value]) for name, value in sample.items()}\n",
    "print(input_dict)\n",
    "\n",
    "predictionList = reloaded_model.predict(input_dict)\n",
    "print(predictionList)\n",
    "prob = tf.nn.sigmoid(predictionList[0])\n",
    "print(f\"{(100 * prob)} %  as Severity\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499f77f8-03ed-4485-b0e6-7f6f5da16223",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
