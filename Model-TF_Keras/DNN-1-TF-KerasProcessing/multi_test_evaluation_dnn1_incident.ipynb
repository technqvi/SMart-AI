{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b8a4684-bb85-4e37-bcd9-26177ef1eaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "#https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/custom/custom-tabular-bq-managed-dataset.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3015b10-ce8e-4004-afd2-e5c60d3b5c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1692648c-491b-4d51-bb58-84c4b3a30312",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!gsutil cp gs://smart-ml-pongthorn/New_Incident.csv data\n",
    "\n",
    "# !gsutil -m cp -r \"gs://tf1-incident-pongthorn/model\" ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a3a91ce-d7ff-423a-9aee-4be795283c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "unUsedColtoPredict=['severity','id','severity_id','severity_name','imported_at']\n",
    "isLocalModel=True\n",
    "\n",
    "filePath='../../data/New_Incident.csv'\n",
    "\n",
    "modelFile_endPoint=2\n",
    "\n",
    "localFile=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43d52b41-422e-42f8-8cae-79ad17f1e475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def download_table(bq_table_uri: str):\n",
    "#     # Remove bq:// prefix if present\n",
    "#     bqclient= bigquery.Client()\n",
    "#     prefix = \"bq://\"\n",
    "#     if bq_table_uri.startswith(prefix):\n",
    "#         bq_table_uri = bq_table_uri[len(prefix) :]\n",
    "\n",
    "#     table = bigquery.TableReference.from_string(bq_table_uri)\n",
    "#     rows = bqclient.list_rows(table)\n",
    "#     return rows.to_dataframe()\n",
    "\n",
    "# dfNewData=download_table(\"pongthorn.SMartML.new_incident\")\n",
    "# dfNewData.to_csv(filePath,index=False)       \n",
    "# dfNewData.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c26dc93-8386-4960-bf33-c53cbe9618c4",
   "metadata": {},
   "source": [
    "\n",
    "# Load and Map Data Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c83042ef-da1a-4929-8cb1-d0e225f2849a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3 entries, 20 to 3\n",
      "Data columns (total 11 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   id                         3 non-null      int64  \n",
      " 1   severity_id                3 non-null      int64  \n",
      " 2   severity_name              3 non-null      object \n",
      " 3   sla                        3 non-null      object \n",
      " 4   product_type               3 non-null      object \n",
      " 5   brand                      3 non-null      object \n",
      " 6   service_type               3 non-null      object \n",
      " 7   incident_type              3 non-null      object \n",
      " 8   open_to_close_hour         3 non-null      float64\n",
      " 9   response_to_resolved_hour  3 non-null      float64\n",
      " 10  imported_at                3 non-null      object \n",
      "dtypes: float64(2), int64(2), object(7)\n",
      "memory usage: 288.0+ bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "if  localFile:\n",
    "    dfNewData=pd.read_csv(filePath)\n",
    "\n",
    "dfNewData=dfNewData.sample(3)\n",
    "print(dfNewData.info())\n",
    "# dfNewData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cad9950-cb7a-4421-8e4d-89d1d0367f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Cosmatic': 0, 'Minor': 1, 'Major': 2, 'Critical': 3}\n"
     ]
    }
   ],
   "source": [
    "mapping_file=\"incident_sevirity_to_class.json\"\n",
    "\n",
    "def download_map_severity_class_as_dict():\n",
    " \n",
    "    storage_client = storage.Client()\n",
    "    buckdfNewData = storage_client.bucket(\"smart-ml-pongthorn\")\n",
    "    blob = bucket.blob(mapping_file)\n",
    "    blob.download_to_filename(mapping_file)\n",
    "    with open(mapping_file, 'r') as file:\n",
    "            return json.loads(file.read())\n",
    "\n",
    "if  localFile==False:    \n",
    "    map_sevirity_to_class= download_map_severity_class_as_dict()\n",
    "else:\n",
    "   with open(mapping_file, 'r') as json_file:\n",
    "     map_sevirity_to_class= json.load(json_file)\n",
    "                                  \n",
    "                                  \n",
    "print(map_sevirity_to_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a8a438e-a9cb-40cf-81ea-01f326e35c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3 entries, 20 to 3\n",
      "Data columns (total 12 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   id                         3 non-null      int64  \n",
      " 1   severity_id                3 non-null      int64  \n",
      " 2   severity                   3 non-null      int64  \n",
      " 3   severity_name              3 non-null      object \n",
      " 4   sla                        3 non-null      object \n",
      " 5   product_type               3 non-null      object \n",
      " 6   brand                      3 non-null      object \n",
      " 7   service_type               3 non-null      object \n",
      " 8   incident_type              3 non-null      object \n",
      " 9   open_to_close_hour         3 non-null      float64\n",
      " 10  response_to_resolved_hour  3 non-null      float64\n",
      " 11  imported_at                3 non-null      object \n",
      "dtypes: float64(2), int64(3), object(7)\n",
      "memory usage: 312.0+ bytes\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>severity_id</th>\n",
       "      <th>severity</th>\n",
       "      <th>severity_name</th>\n",
       "      <th>sla</th>\n",
       "      <th>product_type</th>\n",
       "      <th>brand</th>\n",
       "      <th>service_type</th>\n",
       "      <th>incident_type</th>\n",
       "      <th>open_to_close_hour</th>\n",
       "      <th>response_to_resolved_hour</th>\n",
       "      <th>imported_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2477</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Major</td>\n",
       "      <td>24x7 4Hrs Resolution Time</td>\n",
       "      <td>Software</td>\n",
       "      <td>VMWare</td>\n",
       "      <td>Incident</td>\n",
       "      <td>Software</td>\n",
       "      <td>3.350000</td>\n",
       "      <td>3.216667</td>\n",
       "      <td>27:09.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2465</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Minor</td>\n",
       "      <td>24x7 4Hrs Response Time</td>\n",
       "      <td>Software</td>\n",
       "      <td>NetApp</td>\n",
       "      <td>Incident</td>\n",
       "      <td>General Incident</td>\n",
       "      <td>24.766667</td>\n",
       "      <td>24.550000</td>\n",
       "      <td>27:09.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2518</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Major</td>\n",
       "      <td>24x7 4Hrs Resolution Time</td>\n",
       "      <td>Server</td>\n",
       "      <td>HPE</td>\n",
       "      <td>Incident</td>\n",
       "      <td>Hard Disk Drive Failure</td>\n",
       "      <td>7.166667</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>27:09.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  severity_id  severity severity_name                        sla  \\\n",
       "20  2477            2         2         Major  24x7 4Hrs Resolution Time   \n",
       "29  2465            3         1         Minor    24x7 4Hrs Response Time   \n",
       "3   2518            2         2         Major  24x7 4Hrs Resolution Time   \n",
       "\n",
       "   product_type   brand service_type            incident_type  \\\n",
       "20     Software  VMWare     Incident                 Software   \n",
       "29     Software  NetApp     Incident         General Incident   \n",
       "3        Server     HPE     Incident  Hard Disk Drive Failure   \n",
       "\n",
       "    open_to_close_hour  response_to_resolved_hour imported_at  \n",
       "20            3.350000                   3.216667     27:09.0  \n",
       "29           24.766667                  24.550000     27:09.0  \n",
       "3             7.166667                   7.000000     27:09.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfNewData.insert(2, 'severity', dfNewData['severity_name'].map(map_sevirity_to_class),True)\n",
    "print(dfNewData.info())\n",
    "dfNewData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c10ab762-9c54-4838-be2e-fd14f94c837d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>_predict_severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [_id, _predict_severity]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdPrediction=pd.DataFrame(columns=['_id','_predict_severity'])\n",
    "pdPrediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93793bce-3345-490d-b051-596cd6577210",
   "metadata": {},
   "source": [
    "# Load Model from Directory to Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9336b4-1e34-4e2d-91b5-50dc9b0567cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if modelFile_endPoint==1 :\n",
    "\n",
    "    if  isLocalModel: # Window Enviroment\n",
    "        PATH_FOLDER_ARTIFACTS=\"model\"    \n",
    "    else: # For running on Vertex AI Notebook t\n",
    "        PATH_FOLDER_ARTIFACTS=\"gs://tf1-incident-pongthorn/model\"\n",
    "\n",
    "    model = tf.keras.models.load_model(PATH_FOLDER_ARTIFACTS)    \n",
    "    print(f\"Load from {PATH_FOLDER_ARTIFACTS}\")\n",
    "    # model.summary()\n",
    "\n",
    "    \n",
    "    for  row_dict in dfNewData.to_dict(orient=\"records\"):\n",
    "          incident_id=row_dict['id']\n",
    "          print(f\"{incident_id} - {row_dict['severity']}({row_dict['severity_name']})\") \n",
    "          for key_removed in unUsedColtoPredict:\n",
    "           row_dict.pop(key_removed)\n",
    "          # print(row_dict)  \n",
    "\n",
    "          input_dict = {name: tf.convert_to_tensor([value]) for name, value in row_dict.items()}\n",
    "\n",
    "\n",
    "          predictionResult = model.predict(input_dict)\n",
    "          # print(f\"{predictionResult}\")   \n",
    "          # maxResult=np.max(arryResult)\n",
    "          # maxResult=round( maxResult,4)\n",
    "          # print(f\"{maxResult} of {arryResult}\")\n",
    "\n",
    "          prob = tf.nn.softmax(predictionResult)\n",
    "          prob_pct=(100 * prob)  \n",
    "          _class = tf.argmax(predictionResult,-1).numpy()[0]\n",
    "          \n",
    "          pdPrediction =pd.concat([pdPrediction,pd.DataFrame.from_dict([{'_id':incident_id, '_predict_severity':_class}])] )\n",
    "          # print(input_dict)  \n",
    "            \n",
    "          print(f\"{prob_pct} %   as {_class}\")     \n",
    "          print(\"======================================================================================\")\n",
    "\n",
    "    dfPredictData=pd.merge(dfNewData,pdPrediction,how='inner',left_on='id',right_on='_id')\n",
    "    dfPredictData=dfPredictData.drop(columns=['_id'])\n",
    "    dfPredictData=dfPredictData[['id','_predict_severity','severity','severity_name']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81ffff1-c715-4b97-aa85-46a6bbca6514",
   "metadata": {},
   "source": [
    "# Load Model from Online EndPpint to Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4513b75c-77fa-472c-ba60-03058374c045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instances = []\n",
    "# dfX=dfNewData.drop(columns=unUsedColtoPredict)\n",
    "# for index,row in dfX.iterrows():\n",
    "#     dict_item=row.to_dict()\n",
    "#     instance = {}\n",
    "#     for key, value in dict_item.items():\n",
    "#         if key in unUsedColtoPredict:\n",
    "#             continue\n",
    "#         if value is None:\n",
    "#             value = \"\"\n",
    "#         instance[key] = [value]\n",
    "#         # instance[key] = value\n",
    "#     instances.append(instance)\n",
    "\n",
    "# print(len(instances))\n",
    "# print(instances[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "761734e0-53f1-4813-ba85-baa561e55d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NUMBER=\"pongthorn\"\n",
    "REGION=\"asia-southeast1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f314c67-2d1c-46a9-aee8-50ba071a9ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"sla\": [\"24x7 4Hrs Resolution Time\"], \"product_type\": [\"Software\"], \"brand\": [\"VMWare\"], \"service_type\": [\"Incident\"], \"incident_type\": [\"Software\"], \"open_to_close_hour\": [3.35], \"response_to_resolved_hour\": [3.216666667]}\n",
      "{\"sla\": [\"24x7 4Hrs Response Time\"], \"product_type\": [\"Software\"], \"brand\": [\"NetApp\"], \"service_type\": [\"Incident\"], \"incident_type\": [\"General Incident\"], \"open_to_close_hour\": [24.76666667], \"response_to_resolved_hour\": [24.55]}\n",
      "{\"sla\": [\"24x7 4Hrs Resolution Time\"], \"product_type\": [\"Server\"], \"brand\": [\"HPE\"], \"service_type\": [\"Incident\"], \"incident_type\": [\"Hard Disk Drive Failure\"], \"open_to_close_hour\": [7.166666667], \"response_to_resolved_hour\": [7.0]}\n"
     ]
    }
   ],
   "source": [
    "# isEndpointAvaiable=False\n",
    "\n",
    "# try:\n",
    "#     ENDPOINT_ID=\"2704182877817405440\"\n",
    "#     endpoint = aiplatform.Endpoint(\n",
    "#     endpoint_name=f\"projects/{PROJECT_NUMBER}/locations/{REGION}/endpoints/{ENDPOINT_ID}\")\n",
    "#     print(endpoint)\n",
    "#     isEndpointAvaiable=True\n",
    "# except Exception as error:\n",
    "#     print(str(error)\n",
    "    \n",
    "listRequestData=[]\n",
    "if 1==1:\n",
    "# if modelFile_endPoint==2 and isEndpointAvaiable:\n",
    "\n",
    "    for data in dfNewData.to_dict(orient=\"records\"):\n",
    "        incident_id=data['id']\n",
    "        severity=data['severity']\n",
    "        severity_name=data['severity_name']\n",
    "        #{(a if condition else b): value for key, value in dict.items()}\n",
    "        request_data = {key : [value] for key,value in data.items() }\n",
    "        for key_removed in unUsedColtoPredict:\n",
    "           request_data.pop(key_removed)\n",
    "        request_data = json.dumps(request_data)\n",
    "        listRequestData.append(request_data)\n",
    "        print(request_data)\n",
    "\n",
    "#         response = endpoint.predict([request_data])\n",
    "#         y_predicted = np.argmax(response.predictions, axis=1)\n",
    "#         predictionResult=response[0][0]\n",
    "#         print(predictionResult)\n",
    "#         print(y_predicted)\n",
    "\n",
    "#         pdPrediction =pd.concat([pdPrediction,pd.DataFrame.from_dict([{'_id':incident_id, '_predict_severity':y_predicted[0]}])] )\n",
    "#         print(\"======================================================================================\")\n",
    "\n",
    "#     dfPredictData=pd.merge(dfNewData,pdPrediction,how='inner',left_on='id',right_on='_id')\n",
    "#     dfPredictData=dfPredictData.drop(columns=['_id'])\n",
    "#     dfPredictData=dfPredictData[['id','_predict_severity','severity','severity_name']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9d4e823-db79-4d1a-a10e-dd79b490b4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "with jsonlines.open('inoutput/incident_input_batch.jsonl', mode='w') as writer:\n",
    "  for data in listRequestData:  \n",
    "    writer.write(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd4f304-0054-4464-af76-7948133d8557",
   "metadata": {},
   "source": [
    "# Load model by refering to vertext-ai registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6dd0f7e5-86c5-4760-8fc2-a7b22bc8f168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projects/pongthorn/locations/asia-southeast1/models/2102389377610022912\n"
     ]
    }
   ],
   "source": [
    "# MODEL_ID=\"2102389377610022912\"\n",
    "# MODEL_URI =  f'projects/{PROJECT_NUMBER}/locations/{REGION}/models/{MODEL_ID}'\n",
    "# print(MODEL_URI)\n",
    "\n",
    "# model = aiplatform.Model(MODEL_URI)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bd131514-e828-40f5-a490-2dde50649623",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying gs://tf1-incident-pongthorn/batch_prediction/output_batch/prediction-tf1_dnn_incident_yip-2023_03_28T05_55_06_072Z/prediction.errors_stats-00000-of-00001...\n",
      "Copying gs://tf1-incident-pongthorn/batch_prediction/output_batch/prediction-tf1_dnn_incident_yip-2023_03_28T05_55_06_072Z/prediction.results-00000-of-00001...\n",
      "/ [0/2 files][    0.0 B/   83.0 B]   0% Done                                    \n",
      "/ [0/2 files][    0.0 B/   83.0 B]   0% Done                                    \n",
      "/ [1/2 files][    0.0 B/   83.0 B]   0% Done                                    \n",
      "/ [2/2 files][   83.0 B/   83.0 B] 100% Done                                    \n",
      "\n",
      "Operation completed over 2 objects/83.0 B.                                       \n"
     ]
    }
   ],
   "source": [
    "# !gsutil -m cp \\\n",
    "#   \"gs://tf1-incident-pongthorn/batch_prediction/output_batch/prediction-tf1_dnn_incident_yip-2023_03_28T05_55_06_072Z/prediction.errors_stats-00000-of-00001\" \\\n",
    "#   \"gs://tf1-incident-pongthorn/batch_prediction/output_batch/prediction-tf1_dnn_incident_yip-2023_03_28T05_55_06_072Z/prediction.results-00000-of-00001\" \\\n",
    "#   ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead027ef-253b-410b-8b4b-beee59285895",
   "metadata": {},
   "source": [
    "# Classification Rerport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "b4486552-395b-45db-9ae1-44b676ca7ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "dd0fdbe1-71ac-456b-9b09-ee8cd4ac01fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>_predict_severity</th>\n",
       "      <th>severity</th>\n",
       "      <th>severity_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2487</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Major</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2505</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Minor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2490</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Major</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2517</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Major</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2516</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Minor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2508</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Minor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2506</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Major</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2480</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Major</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2434</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Major</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2501</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Major</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id _predict_severity  severity severity_name\n",
       "0  2487                 2         2         Major\n",
       "1  2505                 2         1         Minor\n",
       "2  2490                 2         2         Major\n",
       "3  2517                 2         2         Major\n",
       "4  2516                 2         1         Minor\n",
       "5  2508                 2         1         Minor\n",
       "6  2506                 2         2         Major\n",
       "7  2480                 2         2         Major\n",
       "8  2434                 2         2         Major\n",
       "9  2501                 2         2         Major"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfPredictData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "5e8eb7cb-6811-486c-80f5-8ccc0090affa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predcited-1</th>\n",
       "      <th>predcited-2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual-1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual-2</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          predcited-1  predcited-2\n",
       "actual-1            0            3\n",
       "actual-2            0            7"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "className=list(set().union(list(dfPredictData['severity'].unique()),list(dfPredictData['_predict_severity'].unique())))\n",
    "actualClass=[  f'actual-{x}' for x in  className]\n",
    "predictedlClass=[  f'predcited-{x}' for x in className]\n",
    "\n",
    "y_true=list(dfPredictData['severity'])\n",
    "y_pred=list(dfPredictData['_predict_severity'])\n",
    "cnf_matrix = confusion_matrix(y_true,y_pred)\n",
    "cnf_matrix\n",
    "\n",
    "# #index=actual , column=prediction\n",
    "cm_df = pd.DataFrame(cnf_matrix,\n",
    "                     index = actualClass, \n",
    "                     columns = predictedlClass)\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "f909f102-3288-4433-ad58-84811cf84484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       0.70      1.00      0.82         7\n",
      "\n",
      "    accuracy                           0.70        10\n",
      "   macro avg       0.35      0.50      0.41        10\n",
      "weighted avg       0.49      0.70      0.58        10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\envs\\dev_google\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\ProgramData\\Anaconda3\\envs\\dev_google\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\ProgramData\\Anaconda3\\envs\\dev_google\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(classification_report(y_true, y_pred, labels=className))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8da4a4a-32ae-4d62-ad8b-cf686e01f8ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
