{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "50d3f8fc-de52-4c03-b3da-46145fc5adaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from datetime import date,datetime,timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "fe374606-a5e7-4850-b91b-b14a6dbdcf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_id = \"pongthorn.SMartML.new_incident\"\n",
    "predictResult_table_id=\"pongthorn.SMartML.new_result_prediction_incident\"\n",
    "mapping_file=\"incident_sevirity_to_class.json\"\n",
    "PATH_FOLDER_ARTIFACTS=\"model\"\n",
    "unUsedColtoPredict=['severity','id','severity_id','severity_name','imported_at']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a87c14ef-f2bc-4bdd-aeae-e333350a89b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Cosmatic': 0, 'Minor': 1, 'Major': 2, 'Critical': 3}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open(mapping_file, 'r') as json_file:\n",
    "     map_sevirity_to_class= json.load(json_file)\n",
    "print(map_sevirity_to_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5c09568e-df8f-4715-adb8-8f94e46802dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get data between 2023-03-27 to 2023-03-28 to predict sevirity level\n"
     ]
    }
   ],
   "source": [
    "# Get today's date\n",
    "prediction_datetime=datetime.now()\n",
    "\n",
    "today = date.today()\n",
    "# Yesterday date\n",
    "yesterday = today - timedelta(days = 1)\n",
    "str_today=today.strftime('%Y-%m-%d')\n",
    "str_yesterday=yesterday.strftime('%Y-%m-%d')\n",
    "print(f\"Get data between {str_yesterday} to {str_today} to predict sevirity level\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4a9808f7-b785-430b-a34c-00686a10cdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_bq(sql:str):\n",
    " client_bq = bigquery.Client()\n",
    " query_result=client_bq.query(sql)\n",
    " df=query_result.to_dataframe()\n",
    " return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a4a03ba4-3ed0-4fa4-b376-3898c271ccb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3 entries, 0 to 2\n",
      "Data columns (total 12 columns):\n",
      " #   Column                     Non-Null Count  Dtype         \n",
      "---  ------                     --------------  -----         \n",
      " 0   id                         3 non-null      Int64         \n",
      " 1   severity_id                3 non-null      Int64         \n",
      " 2   severity                   3 non-null      int64         \n",
      " 3   severity_name              3 non-null      object        \n",
      " 4   sla                        3 non-null      object        \n",
      " 5   product_type               3 non-null      object        \n",
      " 6   brand                      3 non-null      object        \n",
      " 7   service_type               3 non-null      object        \n",
      " 8   incident_type              3 non-null      object        \n",
      " 9   open_to_close_hour         3 non-null      float64       \n",
      " 10  response_to_resolved_hour  3 non-null      float64       \n",
      " 11  imported_at                3 non-null      datetime64[ns]\n",
      "dtypes: Int64(2), datetime64[ns](1), float64(2), int64(1), object(6)\n",
      "memory usage: 318.0+ bytes\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>severity_id</th>\n",
       "      <th>severity</th>\n",
       "      <th>severity_name</th>\n",
       "      <th>sla</th>\n",
       "      <th>product_type</th>\n",
       "      <th>brand</th>\n",
       "      <th>service_type</th>\n",
       "      <th>incident_type</th>\n",
       "      <th>open_to_close_hour</th>\n",
       "      <th>response_to_resolved_hour</th>\n",
       "      <th>imported_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2491</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Minor</td>\n",
       "      <td>24x7 4Hrs Resolution Time</td>\n",
       "      <td>Storage</td>\n",
       "      <td>NetApp</td>\n",
       "      <td>Request</td>\n",
       "      <td>Hard Disk Drive Failure</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>2023-03-27 05:27:08.968019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2516</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Minor</td>\n",
       "      <td>24x7 4Hrs Resolution Time</td>\n",
       "      <td>Firewall</td>\n",
       "      <td>CheckPoint</td>\n",
       "      <td>Request</td>\n",
       "      <td>General Incident</td>\n",
       "      <td>24.483333</td>\n",
       "      <td>24.016667</td>\n",
       "      <td>2023-03-27 05:27:08.968019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2502</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Minor</td>\n",
       "      <td>24x7 6Hrs Resolution Time</td>\n",
       "      <td>Software</td>\n",
       "      <td>SAPB1</td>\n",
       "      <td>Request</td>\n",
       "      <td>General Incident</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>2023-03-27 05:27:08.968019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  severity_id  severity severity_name                        sla  \\\n",
       "0  2491            3         1         Minor  24x7 4Hrs Resolution Time   \n",
       "1  2516            3         1         Minor  24x7 4Hrs Resolution Time   \n",
       "2  2502            3         1         Minor  24x7 6Hrs Resolution Time   \n",
       "\n",
       "  product_type       brand service_type            incident_type  \\\n",
       "0      Storage      NetApp      Request  Hard Disk Drive Failure   \n",
       "1     Firewall  CheckPoint      Request         General Incident   \n",
       "2     Software       SAPB1      Request         General Incident   \n",
       "\n",
       "   open_to_close_hour  response_to_resolved_hour                imported_at  \n",
       "0            7.666667                   7.666667 2023-03-27 05:27:08.968019  \n",
       "1           24.483333                  24.016667 2023-03-27 05:27:08.968019  \n",
       "2          313.000000                 313.000000 2023-03-27 05:27:08.968019  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql=f\"\"\"\n",
    "SELECT *  FROM `{table_id}` \n",
    "WHERE DATE(imported_at) >= '{str_yesterday}' and DATE(imported_at) < '{str_today}'  \n",
    "LIMIT 3\n",
    "\"\"\"\n",
    "\n",
    "dfNewData=load_data_bq(sql)\n",
    "dfNewData=dfNewData.drop_duplicates(subset=['id'],keep='first')\n",
    "\n",
    "dfNewData.insert(2, 'severity', dfNewData['severity_name'].map(map_sevirity_to_class),True)\n",
    "\n",
    "\n",
    "print(dfNewData.info())\n",
    "dfNewData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ece7849d-e583-436d-86be-3ea189fe0b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load from model\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sla (InputLayer)               [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " product_type (InputLayer)      [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " brand (InputLayer)             [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " service_type (InputLayer)      [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " incident_type (InputLayer)     [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " open_to_close_hour (InputLayer  [(None, 1)]         0           []                               \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " response_to_resolved_hour (Inp  [(None, 1)]         0           []                               \n",
      " utLayer)                                                                                         \n",
      "                                                                                                  \n",
      " string_lookup_1 (StringLookup)  (None, 1)           0           ['sla[0][0]']                    \n",
      "                                                                                                  \n",
      " string_lookup_2 (StringLookup)  (None, 1)           0           ['product_type[0][0]']           \n",
      "                                                                                                  \n",
      " string_lookup_3 (StringLookup)  (None, 1)           0           ['brand[0][0]']                  \n",
      "                                                                                                  \n",
      " string_lookup_4 (StringLookup)  (None, 1)           0           ['service_type[0][0]']           \n",
      "                                                                                                  \n",
      " string_lookup_5 (StringLookup)  (None, 1)           0           ['incident_type[0][0]']          \n",
      "                                                                                                  \n",
      " normalization_1 (Normalization  (None, 1)           3           ['open_to_close_hour[0][0]']     \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " normalization_2 (Normalization  (None, 1)           3           ['response_to_resolved_hour[0][0]\n",
      " )                                                               ']                               \n",
      "                                                                                                  \n",
      " category_encoding_1 (CategoryE  (None, 7)           0           ['string_lookup_1[0][0]']        \n",
      " ncoding)                                                                                         \n",
      "                                                                                                  \n",
      " category_encoding_2 (CategoryE  (None, 10)          0           ['string_lookup_2[0][0]']        \n",
      " ncoding)                                                                                         \n",
      "                                                                                                  \n",
      " category_encoding_3 (CategoryE  (None, 21)          0           ['string_lookup_3[0][0]']        \n",
      " ncoding)                                                                                         \n",
      "                                                                                                  \n",
      " category_encoding_4 (CategoryE  (None, 3)           0           ['string_lookup_4[0][0]']        \n",
      " ncoding)                                                                                         \n",
      "                                                                                                  \n",
      " category_encoding_5 (CategoryE  (None, 22)          0           ['string_lookup_5[0][0]']        \n",
      " ncoding)                                                                                         \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 65)           0           ['normalization_1[0][0]',        \n",
      "                                                                  'normalization_2[0][0]',        \n",
      "                                                                  'category_encoding_1[0][0]',    \n",
      "                                                                  'category_encoding_2[0][0]',    \n",
      "                                                                  'category_encoding_3[0][0]',    \n",
      "                                                                  'category_encoding_4[0][0]',    \n",
      "                                                                  'category_encoding_5[0][0]']    \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 32)           2112        ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 32)           0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 4)            132         ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,250\n",
      "Trainable params: 2,244\n",
      "Non-trainable params: 6\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(PATH_FOLDER_ARTIFACTS)    \n",
    "print(f\"Load from {PATH_FOLDER_ARTIFACTS}\")\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "687618c3-7fdb-4294-bfc4-ce0783cc8212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2491 - 1(Minor)\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "0.20702027,0.700546,0.08181793,0.01061574\n",
      "[[23.030441 37.72574  20.320179 18.923645]] %   as 1\n",
      "======================================================================================\n",
      "2516 - 1(Minor)\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "0.12305665,0.11055092,0.7646284,0.0017640598\n",
      "[[20.952015 20.691626 39.7976   18.558765]] %   as 2\n",
      "======================================================================================\n",
      "2502 - 1(Minor)\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "0.9542967,0.043510735,0.0021846048,7.928289e-06\n",
      "[[46.01469  18.507475 17.758223 17.71961 ]] %   as 0\n",
      "======================================================================================\n"
     ]
    }
   ],
   "source": [
    "pdPrediction=pd.DataFrame(columns=['_id','predict_severity','prob_severity'])\n",
    "\n",
    "for  row_dict in dfNewData.to_dict(orient=\"records\"):\n",
    "      incident_id=row_dict['id']\n",
    "      print(f\"{incident_id} - {row_dict['severity']}({row_dict['severity_name']})\") \n",
    "      for key_removed in unUsedColtoPredict:\n",
    "       row_dict.pop(key_removed)\n",
    "      # print(row_dict)  \n",
    "\n",
    "      input_dict = {name: tf.convert_to_tensor([value]) for name, value in row_dict.items()}\n",
    "\n",
    "\n",
    "      predictionResult = model.predict(input_dict)\n",
    "      result_str=','.join([ str(prob) for prob in predictionResult[0]])  \n",
    "      print(result_str)   \n",
    "\n",
    "      prob = tf.nn.softmax(predictionResult)\n",
    "      prob_pct=(100 * prob)  \n",
    "      _class = tf.argmax(predictionResult,-1).numpy()[0]\n",
    "      \n",
    "      dictPrediction={'_id':incident_id, 'predict_severity':_class,'prob_severity':result_str} \n",
    "      pdPrediction =pd.concat([pdPrediction,pd.DataFrame.from_dict([dictPrediction])] )\n",
    "\n",
    "      print(f\"{prob_pct} %   as {_class}\")     \n",
    "      print(\"======================================================================================\")\n",
    "            \n",
    "dfPredictData=pd.merge(dfNewData,pdPrediction,how='inner',left_on='id',right_on='_id')\n",
    "dfPredictData=dfPredictData.drop(columns=['_id'])\n",
    "dfPredictData['predict_severity']=dfPredictData['predict_severity'].astype('int')\n",
    "dfPredictData=dfPredictData[['id','prob_severity','predict_severity','severity']]\n",
    "dfPredictData['prediction_item_date']= datetime.strptime(str(yesterday), '%Y-%m-%d')\n",
    "dfPredictData['prediction_datetime']=prediction_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3488b1e9-b0df-4c1c-b834-3006c7809aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3 entries, 0 to 2\n",
      "Data columns (total 6 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   id                    3 non-null      object        \n",
      " 1   prob_severity         3 non-null      object        \n",
      " 2   predict_severity      3 non-null      int32         \n",
      " 3   severity              3 non-null      int64         \n",
      " 4   prediction_item_date  3 non-null      datetime64[ns]\n",
      " 5   prediction_datetime   3 non-null      datetime64[ns]\n",
      "dtypes: datetime64[ns](2), int32(1), int64(1), object(2)\n",
      "memory usage: 156.0+ bytes\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prob_severity</th>\n",
       "      <th>predict_severity</th>\n",
       "      <th>severity</th>\n",
       "      <th>prediction_item_date</th>\n",
       "      <th>prediction_datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2491</td>\n",
       "      <td>0.20702027,0.700546,0.08181793,0.01061574</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-03-27</td>\n",
       "      <td>2023-03-28 23:23:22.868127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2516</td>\n",
       "      <td>0.12305665,0.11055092,0.7646284,0.0017640598</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-03-27</td>\n",
       "      <td>2023-03-28 23:23:22.868127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2502</td>\n",
       "      <td>0.9542967,0.043510735,0.0021846048,7.928289e-06</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-03-27</td>\n",
       "      <td>2023-03-28 23:23:22.868127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                    prob_severity  predict_severity  \\\n",
       "0  2491        0.20702027,0.700546,0.08181793,0.01061574                 1   \n",
       "1  2516     0.12305665,0.11055092,0.7646284,0.0017640598                 2   \n",
       "2  2502  0.9542967,0.043510735,0.0021846048,7.928289e-06                 0   \n",
       "\n",
       "   severity prediction_item_date        prediction_datetime  \n",
       "0         1           2023-03-27 2023-03-28 23:23:22.868127  \n",
       "1         1           2023-03-27 2023-03-28 23:23:22.868127  \n",
       "2         1           2023-03-27 2023-03-28 23:23:22.868127  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dfPredictData.info())\n",
    "dfPredictData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ec2119b1-a353-48fd-91e2-6203367758c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created table pongthorn.SMartML.new_result_prediction_incident\n"
     ]
    }
   ],
   "source": [
    "#https://cloud.google.com/bigquery/docs/samples/bigquery-create-table#bigquery_create_table-python\n",
    "\n",
    "try:\n",
    "    client = bigquery.Client()\n",
    "    client.get_table(predictResult_table_id)  # Make an API request.\n",
    "    print(\"Predict Result Table {} already exists.\".format(predictResult_table_id))\n",
    "except Exception as ex:\n",
    "    schema = [\n",
    "    bigquery.SchemaField(\"id\", \"INTEGER\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"prob_severity\", \"STRING\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"predict_severity\", \"INTEGER\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"severity\", \"INTEGER\", mode=\"REQUIRED\"),    \n",
    "    bigquery.SchemaField(\"prediction_item_date\", \"DATETIME\", mode=\"REQUIRED\"),    \n",
    "    bigquery.SchemaField(\"prediction_datetime\", \"DATETIME\", mode=\"REQUIRED\") \n",
    "    ]\n",
    "\n",
    "    table = bigquery.Table(predictResult_table_id,schema=schema)\n",
    "    table.time_partitioning = bigquery.TimePartitioning(\n",
    "    type_=bigquery.TimePartitioningType.DAY,field=\"prediction_item_date\")\n",
    "    \n",
    "    table = client.create_table(table)  # Make an API request.\n",
    "    \n",
    "    print(\n",
    "        \"Created table {}.{}.{}\".format(table.project, table.dataset_id, table.table_id)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "43baaa51-ffc8-451f-ba8d-d9d3003256da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Prediction ML  3 Imported igquery successfully\n"
     ]
    }
   ],
   "source": [
    "def loadDataFrameToBQ():\n",
    "    try:\n",
    "        job_config = bigquery.LoadJobConfig(\n",
    "            write_disposition=\"WRITE_APPEND\",\n",
    "        )\n",
    "\n",
    "        job = client.load_table_from_dataframe(\n",
    "            dfPredictData, predictResult_table_id, job_config=job_config\n",
    "        )\n",
    "        job.result()  # Wait for the job to complete.\n",
    "        print(\"Total Prediction ML \", len(dfPredictData), \"Imported igquery successfully\")\n",
    "\n",
    "    except BadRequest as e:\n",
    "        print(\"Bigquery Error\\n\")\n",
    "        for e in job.errors:\n",
    "            print('ERROR: {}'.format(e['message']))\n",
    "\n",
    "try:\n",
    "    loadDataFrameToBQ()\n",
    "except Exception as ex:\n",
    "    raise ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f842295f-2a5a-4ee7-8abb-fa0fdd06a96b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
