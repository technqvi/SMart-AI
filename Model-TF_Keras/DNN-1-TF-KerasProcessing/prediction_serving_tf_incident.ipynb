{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50d3f8fc-de52-4c03-b3da-46145fc5adaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import json\n",
    "import os\n",
    "from datetime import date,datetime,timedelta\n",
    "\n",
    "import functions_framework\n",
    "\n",
    "from google.cloud.exceptions import NotFound\n",
    "from google.api_core.exceptions import BadRequest\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9e4719a-8535-4db4-b01f-806edace1dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @functions_framework.http\n",
    "# def predict_incident_severity_by_tf(request):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ca5511f-5570-4f5a-bcd5-ad3ec26129b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID='smart-data-ml'\n",
    "\n",
    "# PATH_FOLDER_ARTIFACTS=\"gs://tf1-incident-smart-ml-yip/model\"\n",
    "PATH_FOLDER_ARTIFACTS=\"model\" \n",
    "\n",
    "predict_from_date=os.environ.get('predict_from_date', '')\n",
    "# predict_from_date='2023-03-01'\n",
    "\n",
    "# map_sevirity_to_class={'Cosmatic': 0, 'Minor': 1, 'Major': 2, 'Critical': 3}\n",
    "\n",
    "\n",
    "# load_model_option=os.environ.get('load_model_option', '1')\n",
    "# if load_model_option=='1':\n",
    "#   PATH_FOLDER_ARTIFACTS=Model_Local_Path  \n",
    "# elif load_model_option=='2':\n",
    "#   PATH_FOLDER_ARTIFACTS=Model_GS_Path\n",
    "# else:\n",
    "#   raise Exception(\"Allow you to set 1 for local and 2 for google storage\")\n",
    "# print(f\"Load data from {PATH_FOLDER_ARTIFACTS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe374606-a5e7-4850-b91b-b14a6dbdcf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_id = f\"{PROJECT_ID}.SMartML.new_incident\"\n",
    "predictResult_table_id=f\"{PROJECT_ID}.SMartML.new_result_prediction_incident\"\n",
    "unUsedColtoPredict=['severity','id','severity_id','severity_name','imported_at']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a87c14ef-f2bc-4bdd-aeae-e333350a89b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Cosmatic': 0, 'Minor': 1, 'Major': 2, 'Critical': 3}\n"
     ]
    }
   ],
   "source": [
    "mapping_file=\"incident_sevirity_to_class.json\"\n",
    "with open(mapping_file, 'r') as json_file:\n",
    "     map_sevirity_to_class= json.load(json_file)\n",
    "\n",
    "print(map_sevirity_to_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c09568e-df8f-4715-adb8-8f94e46802dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get data between 2023-03-31 to 2023-04-01 to predict sevirity level\n"
     ]
    }
   ],
   "source": [
    "# Get today's date\n",
    "prediction_datetime=datetime.now()\n",
    "\n",
    "today = date.today()\n",
    "\n",
    "# Yesterday date\n",
    "if predict_from_date=='':\n",
    " yesterday = today - timedelta(days = 1)\n",
    " str_yesterday=yesterday.strftime('%Y-%m-%d')\n",
    "else:\n",
    " str_yesterday=predict_from_date\n",
    "\n",
    "str_today=today.strftime('%Y-%m-%d')\n",
    "\n",
    "print(f\"Get data between {str_yesterday} to {str_today} to predict sevirity level\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a9808f7-b785-430b-a34c-00686a10cdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = bigquery.Client(PROJECT_ID)\n",
    "def load_data_bq(sql:str):\n",
    " \n",
    " query_result=client.query(sql)\n",
    " df=query_result.to_dataframe()\n",
    " return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4a03ba4-3ed0-4fa4-b376-3898c271ccb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SELECT *  FROM `smart-data-ml.SMartML.new_incident` \n",
      "LIMIT 2\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2 entries, 0 to 1\n",
      "Data columns (total 12 columns):\n",
      " #   Column                     Non-Null Count  Dtype         \n",
      "---  ------                     --------------  -----         \n",
      " 0   id                         2 non-null      Int64         \n",
      " 1   severity_id                2 non-null      Int64         \n",
      " 2   severity                   2 non-null      int64         \n",
      " 3   severity_name              2 non-null      object        \n",
      " 4   sla                        2 non-null      object        \n",
      " 5   product_type               2 non-null      object        \n",
      " 6   brand                      2 non-null      object        \n",
      " 7   service_type               2 non-null      object        \n",
      " 8   incident_type              2 non-null      object        \n",
      " 9   open_to_close_hour         2 non-null      float64       \n",
      " 10  response_to_resolved_hour  2 non-null      float64       \n",
      " 11  imported_at                2 non-null      datetime64[ns]\n",
      "dtypes: Int64(2), datetime64[ns](1), float64(2), int64(1), object(6)\n",
      "memory usage: 212.0+ bytes\n",
      "None\n",
      "     id  severity_id  severity severity_name                        sla  \\\n",
      "0  1867            4         0      Cosmatic  24x7 4Hrs Resolution Time   \n",
      "1  2391            2         2         Major    24x7 6Hrs Response Time   \n",
      "\n",
      "  product_type brand service_type         incident_type  open_to_close_hour  \\\n",
      "0        Other    F5      Request  Configuration Change         2756.966667   \n",
      "1       Server   HPE     Incident      General Incident          239.783333   \n",
      "\n",
      "   response_to_resolved_hour                imported_at  \n",
      "0                1582.450000 2023-04-01 07:49:43.444534  \n",
      "1                 239.783333 2023-04-01 07:49:43.444534  \n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (3326159740.py, line 22)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\pongthsa\\AppData\\Local\\Temp\\ipykernel_22128\\3326159740.py\"\u001b[1;36m, line \u001b[1;32m22\u001b[0m\n\u001b[1;33m    return \"No Data To predict\"\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "sql=f\"\"\"\n",
    "SELECT *  FROM `{table_id}` \n",
    " WHERE DATE(imported_at) >= '{str_yesterday}' and DATE(imported_at) < '{str_today}' \n",
    "\n",
    "\"\"\"\n",
    "print(sql)\n",
    "#LIMIT 2\n",
    "dfNewData=load_data_bq(sql)\n",
    "dfNewData=dfNewData.drop_duplicates(subset=['id'],keep='first')\n",
    "\n",
    "dfNewData.insert(2, 'severity', dfNewData['severity_name'].map(map_sevirity_to_class),True)\n",
    "\n",
    "\n",
    "print(dfNewData.info())\n",
    "print(dfNewData)\n",
    "\n",
    "if len(dfNewData)==0:\n",
    "    print(\"No Data To predict\")\n",
    "    quit()\n",
    "    #return \"No Data To predict\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ece7849d-e583-436d-86be-3ea189fe0b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load from model\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    model = tf.keras.models.load_model(PATH_FOLDER_ARTIFACTS)    \n",
    "    print(f\"Load from {PATH_FOLDER_ARTIFACTS}\")\n",
    "    # print(model.summary())\n",
    "except Exception as error:\n",
    "    \n",
    "  print(str(error))\n",
    "  raise error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "687618c3-7fdb-4294-bfc4-ce0783cc8212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1867 - 0(Cosmatic)\n",
      "1/1 [==============================] - 1s 729ms/step\n",
      "0.9363888,0.056718506,0.006891827,8.9424395e-07\n",
      "[[45.419174 18.84531  17.92932  17.806196]] %   as 0\n",
      "======================================================================================\n",
      "2391 - 2(Major)\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "0.0034482381,0.10939542,0.81639844,0.070757896\n",
      "[[18.396084 20.45209  41.474884 19.676943]] %   as 2\n",
      "======================================================================================\n"
     ]
    }
   ],
   "source": [
    "pdPrediction=pd.DataFrame(columns=['_id','predict_severity','prob_severity'])\n",
    "\n",
    "for  row_dict in dfNewData.to_dict(orient=\"records\"):\n",
    "      incident_id=row_dict['id']\n",
    "      print(f\"{incident_id} - {row_dict['severity']}({row_dict['severity_name']})\") \n",
    "      for key_removed in unUsedColtoPredict:\n",
    "       row_dict.pop(key_removed)\n",
    "      # print(row_dict)  \n",
    "\n",
    "      input_dict = {name: tf.convert_to_tensor([value]) for name, value in row_dict.items()}\n",
    "\n",
    "\n",
    "      predictionResult = model.predict(input_dict)\n",
    "      result_str=','.join([ str(prob) for prob in predictionResult[0]])  \n",
    "      print(result_str)   \n",
    "\n",
    "      prob = tf.nn.softmax(predictionResult)\n",
    "      prob_pct=(100 * prob)  \n",
    "      _class = tf.argmax(predictionResult,-1).numpy()[0]\n",
    "      \n",
    "      dictPrediction={'_id':incident_id, 'predict_severity':_class,'prob_severity':result_str} \n",
    "      pdPrediction =pd.concat([pdPrediction,pd.DataFrame.from_dict([dictPrediction])] )\n",
    "\n",
    "      print(f\"{prob_pct} %   as {_class}\")     \n",
    "      print(\"======================================================================================\")\n",
    "            \n",
    "dfPredictData=pd.merge(dfNewData,pdPrediction,how='inner',left_on='id',right_on='_id')\n",
    "dfPredictData=dfPredictData.drop(columns=['_id'])\n",
    "dfPredictData['predict_severity']=dfPredictData['predict_severity'].astype('int')\n",
    "dfPredictData=dfPredictData[['id','prob_severity','predict_severity','severity']]\n",
    "dfPredictData['prediction_item_date']= datetime.strptime(str_yesterday, '%Y-%m-%d')\n",
    "dfPredictData['prediction_datetime']=prediction_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3488b1e9-b0df-4c1c-b834-3006c7809aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2 entries, 0 to 1\n",
      "Data columns (total 6 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   id                    2 non-null      object        \n",
      " 1   prob_severity         2 non-null      object        \n",
      " 2   predict_severity      2 non-null      int32         \n",
      " 3   severity              2 non-null      int64         \n",
      " 4   prediction_item_date  2 non-null      datetime64[ns]\n",
      " 5   prediction_datetime   2 non-null      datetime64[ns]\n",
      "dtypes: datetime64[ns](2), int32(1), int64(1), object(2)\n",
      "memory usage: 104.0+ bytes\n",
      "None\n",
      "     id                                    prob_severity  predict_severity  \\\n",
      "0  1867  0.9363888,0.056718506,0.006891827,8.9424395e-07                 0   \n",
      "1  2391   0.0034482381,0.10939542,0.81639844,0.070757896                 2   \n",
      "\n",
      "   severity prediction_item_date        prediction_datetime  \n",
      "0         0           2023-03-31 2023-04-01 20:52:29.182846  \n",
      "1         2           2023-03-31 2023-04-01 20:52:29.182846  \n"
     ]
    }
   ],
   "source": [
    "print(dfPredictData.info())\n",
    "print(dfPredictData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec2119b1-a353-48fd-91e2-6203367758c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict Result Table smart-data-ml.SMartML.new_result_prediction_incident already exists.\n"
     ]
    }
   ],
   "source": [
    "#https://cloud.google.com/bigquery/docs/samples/bigquery-create-table#bigquery_create_table-python\n",
    "\n",
    "try:\n",
    "    client.get_table(predictResult_table_id)  # Make an API request.\n",
    "    print(\"Predict Result Table {} already exists.\".format(predictResult_table_id))\n",
    "except Exception as ex:\n",
    "    schema = [\n",
    "    bigquery.SchemaField(\"id\", \"INTEGER\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"prob_severity\", \"STRING\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"predict_severity\", \"INTEGER\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"severity\", \"INTEGER\", mode=\"REQUIRED\"),    \n",
    "    bigquery.SchemaField(\"prediction_item_date\", \"DATETIME\", mode=\"REQUIRED\"),    \n",
    "    bigquery.SchemaField(\"prediction_datetime\", \"DATETIME\", mode=\"REQUIRED\") \n",
    "    ]\n",
    "\n",
    "    table = bigquery.Table(predictResult_table_id,schema=schema)\n",
    "    table.time_partitioning = bigquery.TimePartitioning(\n",
    "    type_=bigquery.TimePartitioningType.DAY,field=\"prediction_item_date\")\n",
    "    \n",
    "    table = client.create_table(table)  # Make an API request.\n",
    "    \n",
    "    print(\n",
    "        \"Created table {}.{}.{}\".format(table.project, table.dataset_id, table.table_id)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43baaa51-ffc8-451f-ba8d-d9d3003256da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Prediction ML  2 Imported igquery successfully\n"
     ]
    }
   ],
   "source": [
    "def loadDataFrameToBQ():\n",
    "    try:\n",
    "        job_config = bigquery.LoadJobConfig(\n",
    "            write_disposition=\"WRITE_APPEND\",\n",
    "        )\n",
    "\n",
    "        job = client.load_table_from_dataframe(\n",
    "            dfPredictData, predictResult_table_id, job_config=job_config\n",
    "        )\n",
    "        job.result()  # Wait for the job to complete.\n",
    "        print(\"Total Prediction ML \", len(dfPredictData), \"Imported bigquery successfully\")\n",
    "\n",
    "    except BadRequest as e:\n",
    "        print(\"Bigquery Error\\n\")\n",
    "        for e in job.errors:\n",
    "            print('ERROR: {}'.format(e['message']))\n",
    "\n",
    "try:\n",
    "    loadDataFrameToBQ()\n",
    "except Exception as ex:\n",
    "    raise ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bbed47-52ee-4a09-bed3-12c70cf03f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return 'ok'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f842295f-2a5a-4ee7-8abb-fa0fdd06a96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#  result=predict_incident_severity_by_tf(None)\n",
    "#  print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950857cf-eb31-4973-9925-aa7f0b1434d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c87c03-93b1-4461-af09-9418520b4606",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
