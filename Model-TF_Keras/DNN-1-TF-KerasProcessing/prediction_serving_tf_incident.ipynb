{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "50d3f8fc-de52-4c03-b3da-46145fc5adaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import json\n",
    "import os\n",
    "from datetime import date,datetime,timedelta,timezone\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud.exceptions import NotFound\n",
    "from google.api_core.exceptions import BadRequest\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b9e4719a-8535-4db4-b01f-806edace1dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import functions_framework\n",
    "# @functions_framework.http\n",
    "# def predict_incident_severity_by_tf(request):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0ca5511f-5570-4f5a-bcd5-ad3ec26129b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction From = \n",
      "All prediction = 1\n"
     ]
    }
   ],
   "source": [
    "PATH_FOLDER_ARTIFACTS=\"model\" \n",
    "#PATH_FOLDER_ARTIFACTS=\"tuned_model\" \n",
    "#PATH_FOLDER_ARTIFACTS=\"gs://demo-tf-incident-pongthorn/model\"\n",
    "\n",
    "model_version='model_v2_t150723'\n",
    "\n",
    "PROJECT_ID='pongthorn' # 'smart-data-ml'\n",
    "dataset_id='SMartML'\n",
    "\n",
    "client = bigquery.Client(PROJECT_ID)\n",
    "\n",
    "#credentials = service_account.Credentials.from_service_account_file(r'C:\\Windows\\smart-data-ml-91b6f6204773.json')\n",
    "#client = bigquery.Client(credentials=credentials, project=PROJECT_ID)\n",
    "\n",
    "predict_from_date=os.environ.get('predict_from_date', '')\n",
    "all_prediction=os.environ.get('all_prediction', '1')  # 1 is all , 0 is 1 day\n",
    "\n",
    "\n",
    "print(f\"Prediction From = {predict_from_date}\")\n",
    "print(f\"All prediction = {all_prediction}\")\n",
    "\n",
    "# map_sevirity_to_class={'Cosmatic': 0, 'Minor': 1, 'Major': 2, 'Critical': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fe374606-a5e7-4850-b91b-b14a6dbdcf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_id = f\"{PROJECT_ID}.{dataset_id}.new_incident\"\n",
    "predictResult_table_id=f\"{PROJECT_ID}.{dataset_id}.new_result_prediction_incident\"\n",
    "unUsedColtoPredict=['severity','id','severity_id','severity_name','imported_at']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a87c14ef-f2bc-4bdd-aeae-e333350a89b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load label target multiclasses\n",
      "{'Cosmetic': 0, 'Minor': 1, 'Major': 2, 'Critical': 3}\n"
     ]
    }
   ],
   "source": [
    "print(\"Load label target multiclasses\")\n",
    "mapping_file=\"incident_severity_to_class.json\"\n",
    "with open(mapping_file, 'r') as json_file:\n",
    "     map_sevirity_to_class= json.load(json_file)\n",
    "\n",
    "print(map_sevirity_to_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f6097b60-9950-4963-b1e4-2edecb4b132e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-30 15:33:19.367014+00:00\n",
      "Prediction at 2023-10-30 15:33:19.367014+00:00 for 2023-10-30 (2023-10-30 00:00:00)\n"
     ]
    }
   ],
   "source": [
    "# Get today's date\n",
    "prediction_datetime=datetime.now(timezone.utc)\n",
    "today_str=prediction_datetime.strftime(\"%Y-%m-%d\")\n",
    "today=datetime.strptime(today_str,\"%Y-%m-%d\")\n",
    "print(prediction_datetime)\n",
    "\n",
    "print(f\"Prediction at {prediction_datetime} for {today_str} ({today})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4a9808f7-b785-430b-a34c-00686a10cdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_bq(sql:str):\n",
    " \n",
    " query_result=client.query(sql)\n",
    " df=query_result.to_dataframe()\n",
    " return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6c1718f0-3076-406c-81fd-178248304117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    SELECT *  FROM `pongthorn.SMartML.new_incident` \n",
      "     order by imported_at\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "if int(all_prediction)==0:\n",
    "    sql=f\"\"\"\n",
    "    SELECT *  FROM `{table_id}` \n",
    "     WHERE DATE(imported_at) = '{today_str}' \n",
    "     order by imported_at\n",
    "    \"\"\"\n",
    "else:\n",
    "    sql=f\"\"\"\n",
    "    SELECT *  FROM `{table_id}` \n",
    "     order by imported_at\n",
    "    \"\"\"\n",
    "print(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a4a03ba4-3ed0-4fa4-b376-3898c271ccb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id  severity_id  severity severity_name                        sla  \\\n",
      "0   3745            2         2         Major    24x7 4Hrs Response Time   \n",
      "1   3837            2         2         Major    24x7 4Hrs Response Time   \n",
      "2   3838            2         2         Major    24x7 4Hrs Response Time   \n",
      "3   3846            2         2         Major  24x7 4Hrs Resolution Time   \n",
      "4   3847            2         2         Major  24x7 4Hrs Resolution Time   \n",
      "5   3848            4         0      Cosmetic  24x7 4Hrs Resolution Time   \n",
      "6   3844            4         0      Cosmetic    24x7 4Hrs Response Time   \n",
      "7   3858            2         2         Major  24x7 4Hrs Resolution Time   \n",
      "8   3854            3         1         Minor    24x7 4Hrs Response Time   \n",
      "9   3852            3         1         Minor    24x7 4Hrs Response Time   \n",
      "10  3855            4         0      Cosmetic    24x7 6Hrs Response Time   \n",
      "\n",
      "   product_type      brand service_type         incident_type  \\\n",
      "0       Storage        EMC     Incident  Power Supply Failure   \n",
      "1        Server       DELL     Incident      General Incident   \n",
      "2       Storage        HPE     Incident      General Incident   \n",
      "3      Firewall  Palo Alto     Incident      General Incident   \n",
      "4      Firewall  Palo Alto     Incident      General Incident   \n",
      "5       Storage     Oracle     Incident  Power Supply Failure   \n",
      "6      Software    Red Hat      Request      General Incident   \n",
      "7      Firewall  Palo Alto     Incident      General Incident   \n",
      "8      Software     VMWare     Incident      General Incident   \n",
      "9      Software    Red Hat     Incident      General Incident   \n",
      "10      Service        YIP      Request      General Incident   \n",
      "\n",
      "    open_to_close_hour  response_to_resolved_hour                imported_at  \n",
      "0           269.966667                 219.433333 2023-10-27 17:30:04.982977  \n",
      "1             2.166667                   0.500000 2023-10-27 17:30:04.982977  \n",
      "2            51.733333                  51.450000 2023-10-27 17:30:04.982977  \n",
      "3             0.750000                   0.716667 2023-10-27 17:30:04.982977  \n",
      "4             0.483333                   0.466667 2023-10-27 17:30:04.982977  \n",
      "5             2.400000                   2.000000 2023-10-27 17:30:04.982977  \n",
      "6             2.000000                   0.083333 2023-10-27 17:30:04.982977  \n",
      "7             0.700000                   0.700000 2023-10-29 17:30:04.570780  \n",
      "8             2.483333                   2.350000 2023-10-29 17:30:04.570780  \n",
      "9             5.350000                   5.000000 2023-10-29 17:30:04.570780  \n",
      "10           21.066667                  20.983333 2023-10-29 17:30:04.570780  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11 entries, 0 to 10\n",
      "Data columns (total 12 columns):\n",
      " #   Column                     Non-Null Count  Dtype         \n",
      "---  ------                     --------------  -----         \n",
      " 0   id                         11 non-null     Int64         \n",
      " 1   severity_id                11 non-null     Int64         \n",
      " 2   severity                   11 non-null     int64         \n",
      " 3   severity_name              11 non-null     object        \n",
      " 4   sla                        11 non-null     object        \n",
      " 5   product_type               11 non-null     object        \n",
      " 6   brand                      11 non-null     object        \n",
      " 7   service_type               11 non-null     object        \n",
      " 8   incident_type              11 non-null     object        \n",
      " 9   open_to_close_hour         11 non-null     float64       \n",
      " 10  response_to_resolved_hour  11 non-null     float64       \n",
      " 11  imported_at                11 non-null     datetime64[ns]\n",
      "dtypes: Int64(2), datetime64[ns](1), float64(2), int64(1), object(6)\n",
      "memory usage: 1.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "dfNewData=load_data_bq(sql)\n",
    "\n",
    "if dfNewData.empty==True:\n",
    "    print(\"No Data To predict\")\n",
    "    quit()\n",
    "    # return \"No Data To predict\"\n",
    "else:\n",
    "    dfNewData=dfNewData.drop_duplicates(subset=['id'],keep='last')\n",
    "    dfNewData.insert(2, 'severity', dfNewData['severity_name'].map(map_sevirity_to_class),True)\n",
    "    print(dfNewData)\n",
    "    print(dfNewData.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ece7849d-e583-436d-86be-3ea189fe0b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load from model\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    model = tf.keras.models.load_model(PATH_FOLDER_ARTIFACTS)    \n",
    "    print(f\"Load from {PATH_FOLDER_ARTIFACTS}\")\n",
    "    # print(model.summary())\n",
    "except Exception as error:\n",
    "    \n",
    "  print(str(error))\n",
    "  raise error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "687618c3-7fdb-4294-bfc4-ce0783cc8212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3745 - 2(Major)\n",
      "1/1 [==============================] - 0s 255ms/step\n",
      "0.0039673964,0.25249773,0.74289894,0.0006359592\n",
      "[[18.61327  23.86481  38.970554 18.551365]] %   as 2\n",
      "======================================================================================\n",
      "3837 - 2(Major)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "0.018443331,0.3881473,0.5803142,0.013095099\n",
      "[[19.24586  27.854649 33.75629  19.143202]] %   as 2\n",
      "======================================================================================\n",
      "3838 - 2(Major)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "0.027710058,0.18937078,0.77057546,0.012343647\n",
      "[[19.003595 22.337994 39.944603 18.713812]] %   as 2\n",
      "======================================================================================\n",
      "3846 - 2(Major)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "0.0006580507,0.03255238,0.96333605,0.0034535702\n",
      "[[17.686882 18.260084 46.316635 17.736395]] %   as 2\n",
      "======================================================================================\n",
      "3847 - 2(Major)\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "0.00065789284,0.03251572,0.963375,0.0034514014\n",
      "[[17.686687 18.259216 46.317936 17.736162]] %   as 2\n",
      "======================================================================================\n",
      "3848 - 0(Cosmetic)\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "0.009496449,0.16295482,0.82053274,0.007015942\n",
      "[[18.471926 21.535664 41.566242 18.426163]] %   as 2\n",
      "======================================================================================\n",
      "3844 - 0(Cosmetic)\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "0.91374326,0.07769666,0.008422912,0.0001372022\n",
      "[[44.664623 19.35857  18.062923 17.913877]] %   as 0\n",
      "======================================================================================\n",
      "3858 - 2(Major)\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "0.00065803656,0.03254674,0.963342,0.003453183\n",
      "[[17.686852 18.25995  46.316833 17.736359]] %   as 2\n",
      "======================================================================================\n",
      "3854 - 1(Minor)\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "0.01673095,0.448098,0.53068644,0.004484564\n",
      "[[19.234173 29.608324 32.157444 19.00006 ]] %   as 2\n",
      "======================================================================================\n",
      "3852 - 1(Minor)\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "0.008748755,0.7794193,0.20896679,0.0028650954\n",
      "[[18.597668 40.193558 22.720196 18.488567]] %   as 1\n",
      "======================================================================================\n",
      "3855 - 0(Cosmetic)\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "0.56997746,0.35877377,0.056940425,0.014308386\n",
      "[[33.53485  27.150122 20.076466 19.23855 ]] %   as 0\n",
      "======================================================================================\n"
     ]
    }
   ],
   "source": [
    "pdPrediction=pd.DataFrame(columns=['_id','predict_severity','prob_severity'])\n",
    "\n",
    "for  row_dict in dfNewData.to_dict(orient=\"records\"):\n",
    "      incident_id=row_dict['id']\n",
    "      print(f\"{incident_id} - {row_dict['severity']}({row_dict['severity_name']})\") \n",
    "      for key_removed in unUsedColtoPredict:\n",
    "       row_dict.pop(key_removed)\n",
    "      # print(row_dict)  \n",
    "\n",
    "      input_dict = {name: tf.convert_to_tensor([value]) for name, value in row_dict.items()}\n",
    "      predictionResult = model.predict(input_dict)\n",
    "      result_str=','.join([ str(prob) for prob in predictionResult[0]])  \n",
    "      print(result_str)   \n",
    "\n",
    "      prob = tf.nn.softmax(predictionResult)\n",
    "      prob_pct=(100 * prob)  \n",
    "      _class = tf.argmax(predictionResult,-1).numpy()[0]\n",
    "      \n",
    "      dictPrediction={'_id':incident_id, 'predict_severity':_class,'prob_severity':result_str} \n",
    "      pdPrediction =pd.concat([pdPrediction,pd.DataFrame.from_dict([dictPrediction])] )\n",
    "\n",
    "      print(f\"{prob_pct} %   as {_class}\")     \n",
    "      print(\"======================================================================================\")\n",
    "            \n",
    "dfPredictData=pd.merge(dfNewData,pdPrediction,how='inner',left_on='id',right_on='_id')\n",
    "dfPredictData=dfPredictData.drop(columns=['_id'])\n",
    "dfPredictData['predict_severity']=dfPredictData['predict_severity'].astype('int')\n",
    "dfPredictData=dfPredictData[['id','prob_severity','predict_severity','severity']]\n",
    "dfPredictData['prediction_item_date']= datetime.strptime(today_str, '%Y-%m-%d')\n",
    "dfPredictData['prediction_datetime']=prediction_datetime\n",
    "dfPredictData['model_version']=model_version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3488b1e9-b0df-4c1c-b834-3006c7809aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11 entries, 0 to 10\n",
      "Data columns (total 7 columns):\n",
      " #   Column                Non-Null Count  Dtype              \n",
      "---  ------                --------------  -----              \n",
      " 0   id                    11 non-null     object             \n",
      " 1   prob_severity         11 non-null     object             \n",
      " 2   predict_severity      11 non-null     int32              \n",
      " 3   severity              11 non-null     int64              \n",
      " 4   prediction_item_date  11 non-null     datetime64[ns]     \n",
      " 5   prediction_datetime   11 non-null     datetime64[ns, UTC]\n",
      " 6   model_version         11 non-null     object             \n",
      "dtypes: datetime64[ns, UTC](1), datetime64[ns](1), int32(1), int64(1), object(3)\n",
      "memory usage: 700.0+ bytes\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prediction_item_date</th>\n",
       "      <th>predict_severity</th>\n",
       "      <th>severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3745</td>\n",
       "      <td>2023-10-30</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3837</td>\n",
       "      <td>2023-10-30</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3838</td>\n",
       "      <td>2023-10-30</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3846</td>\n",
       "      <td>2023-10-30</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3847</td>\n",
       "      <td>2023-10-30</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3848</td>\n",
       "      <td>2023-10-30</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3844</td>\n",
       "      <td>2023-10-30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3858</td>\n",
       "      <td>2023-10-30</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3854</td>\n",
       "      <td>2023-10-30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3852</td>\n",
       "      <td>2023-10-30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3855</td>\n",
       "      <td>2023-10-30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id prediction_item_date  predict_severity  severity\n",
       "0   3745           2023-10-30                 2         2\n",
       "1   3837           2023-10-30                 2         2\n",
       "2   3838           2023-10-30                 2         2\n",
       "3   3846           2023-10-30                 2         2\n",
       "4   3847           2023-10-30                 2         2\n",
       "5   3848           2023-10-30                 2         0\n",
       "6   3844           2023-10-30                 0         0\n",
       "7   3858           2023-10-30                 2         2\n",
       "8   3854           2023-10-30                 2         1\n",
       "9   3852           2023-10-30                 1         1\n",
       "10  3855           2023-10-30                 0         0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dfPredictData.info())\n",
    "dfPredictData[['id','prediction_item_date','predict_severity','severity']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcfd50d-0bc8-4c5b-80e3-02c3dfe76ecb",
   "metadata": {},
   "source": [
    "# Save predictoin resutl to Bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ec2119b1-a353-48fd-91e2-6203367758c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict Result Table pongthorn.SMartML.new_result_prediction_incident already exists.\n"
     ]
    }
   ],
   "source": [
    "#https://cloud.google.com/bigquery/docs/samples/bigquery-create-table#bigquery_create_table-python\n",
    "\n",
    "try:\n",
    "    client.get_table(predictResult_table_id)  # Make an API request.\n",
    "    print(\"Predict Result Table {} already exists.\".format(predictResult_table_id))\n",
    "except Exception as ex:\n",
    "    schema = [\n",
    "    bigquery.SchemaField(\"id\", \"INTEGER\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"prob_severity\", \"STRING\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"predict_severity\", \"INTEGER\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"severity\", \"INTEGER\", mode=\"REQUIRED\"),    \n",
    "    bigquery.SchemaField(\"prediction_item_date\", \"DATETIME\", mode=\"REQUIRED\"),    \n",
    "    bigquery.SchemaField(\"prediction_datetime\", \"DATETIME\", mode=\"REQUIRED\"), \n",
    "    bigquery.SchemaField(\"model_version\",  \"STRING\", mode=\"REQUIRED\")     \n",
    "    ]\n",
    "\n",
    "    table = bigquery.Table(predictResult_table_id,schema=schema)\n",
    "    table.time_partitioning = bigquery.TimePartitioning(\n",
    "    type_=bigquery.TimePartitioningType.DAY,field=\"prediction_item_date\")\n",
    "    \n",
    "    table = client.create_table(table)  # Make an API request.\n",
    "    \n",
    "    print(\n",
    "        \"Created table {}.{}.{}\".format(table.project, table.dataset_id, table.table_id)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "43baaa51-ffc8-451f-ba8d-d9d3003256da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Prediction ML  11 Imported bigquery successfully\n"
     ]
    }
   ],
   "source": [
    "def loadDataFrameToBQ():\n",
    "    try:\n",
    "        job_config = bigquery.LoadJobConfig(\n",
    "            write_disposition=\"WRITE_APPEND\",\n",
    "        )\n",
    "\n",
    "        job = client.load_table_from_dataframe(\n",
    "            dfPredictData, predictResult_table_id, job_config=job_config\n",
    "        )\n",
    "        job.result()  # Wait for the job to complete.\n",
    "        print(\"Total Prediction ML \", len(dfPredictData), \"Imported bigquery successfully\")\n",
    "\n",
    "    except BadRequest as e:\n",
    "        print(\"Bigquery Error\\n\")\n",
    "        for e in job.errors:\n",
    "            print('ERROR: {}'.format(e['message']))\n",
    "\n",
    "try:\n",
    "    loadDataFrameToBQ()\n",
    "except Exception as ex:\n",
    "    raise ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30050fa4-e771-4c93-884e-fe096202c928",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d100f629-1e0c-4c2d-8c10-a391334b5d0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bbed47-52ee-4a09-bed3-12c70cf03f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return 'All incidents has been predicted completely.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f842295f-2a5a-4ee7-8abb-fa0fdd06a96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#  result=predict_incident_severity_by_tf(None)\n",
    "#  print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950857cf-eb31-4973-9925-aa7f0b1434d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c87c03-93b1-4461-af09-9418520b4606",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
