{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d3f8fc-de52-4c03-b3da-46145fc5adaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import json\n",
    "import os\n",
    "from datetime import date,datetime,timedelta,timezone\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud.exceptions import NotFound\n",
    "from google.api_core.exceptions import BadRequest\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e4719a-8535-4db4-b01f-806edace1dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import functions_framework\n",
    "# @functions_framework.http\n",
    "# def predict_incident_severity_by_tf(request):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca5511f-5570-4f5a-bcd5-ad3ec26129b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_FOLDER_ARTIFACTS=\"model\" \n",
    "#PATH_FOLDER_ARTIFACTS=\"tuned_model\" \n",
    "#PATH_FOLDER_ARTIFACTS=\"gs://demo-tf-incident-pongthorn/model\"\n",
    "\n",
    "model_version='model_v2_t150723'\n",
    "\n",
    "PROJECT_ID='pongthorn' # 'smart-data-ml'\n",
    "dataset_id='SMartML'\n",
    "\n",
    "client = bigquery.Client(PROJECT_ID)\n",
    "\n",
    "#credentials = service_account.Credentials.from_service_account_file(r'C:\\Windows\\smart-data-ml-91b6f6204773.json')\n",
    "#client = bigquery.Client(credentials=credentials, project=PROJECT_ID)\n",
    "\n",
    "predict_from_date=os.environ.get('predict_from_date', '')\n",
    "all_prediction=os.environ.get('all_prediction', '1')  # 1 is all , 0 is 1 day\n",
    "\n",
    "\n",
    "print(f\"Prediction From = {predict_from_date}\")\n",
    "print(f\"All prediction = {all_prediction}\")\n",
    "\n",
    "# map_sevirity_to_class={'Cosmatic': 0, 'Minor': 1, 'Major': 2, 'Critical': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe374606-a5e7-4850-b91b-b14a6dbdcf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_id = f\"{PROJECT_ID}.{dataset_id}.new_incident\"\n",
    "predictResult_table_id=f\"{PROJECT_ID}.{dataset_id}.new_result_prediction_incident\"\n",
    "unUsedColtoPredict=['severity','id','severity_id','severity_name','imported_at']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87c14ef-f2bc-4bdd-aeae-e333350a89b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Load label target multiclasses\")\n",
    "mapping_file=\"incident_severity_to_class.json\"\n",
    "with open(mapping_file, 'r') as json_file:\n",
    "     map_sevirity_to_class= json.load(json_file)\n",
    "\n",
    "print(map_sevirity_to_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6097b60-9950-4963-b1e4-2edecb4b132e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get today's date\n",
    "prediction_datetime=datetime.now(timezone.utc)\n",
    "today_str=prediction_datetime.strftime(\"%Y-%m-%d\")\n",
    "today=datetime.strptime(today_str,\"%Y-%m-%d\")\n",
    "print(prediction_datetime)\n",
    "\n",
    "print(f\"Prediction at {prediction_datetime} for {today_str} ({today})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9808f7-b785-430b-a34c-00686a10cdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_bq(sql:str):\n",
    " \n",
    " query_result=client.query(sql)\n",
    " df=query_result.to_dataframe()\n",
    " return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1718f0-3076-406c-81fd-178248304117",
   "metadata": {},
   "outputs": [],
   "source": [
    "if int(all_prediction)==0:\n",
    "    sql=f\"\"\"\n",
    "    SELECT *  FROM `{table_id}` \n",
    "     WHERE DATE(imported_at) = '{today_str}' \n",
    "     order by imported_at\n",
    "    \"\"\"\n",
    "else:\n",
    "    sql=f\"\"\"\n",
    "    SELECT *  FROM `{table_id}` \n",
    "     order by imported_at\n",
    "    \"\"\"\n",
    "print(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a03ba4-3ed0-4fa4-b376-3898c271ccb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNewData=load_data_bq(sql)\n",
    "\n",
    "if dfNewData.empty==True:\n",
    "    print(\"No Data To predict\")\n",
    "    quit()\n",
    "    # return \"No Data To predict\"\n",
    "else:\n",
    "    dfNewData=dfNewData.drop_duplicates(subset=['id'],keep='last')\n",
    "    dfNewData.insert(2, 'severity', dfNewData['severity_name'].map(map_sevirity_to_class),True)\n",
    "    print(dfNewData)\n",
    "    print(dfNewData.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece7849d-e583-436d-86be-3ea189fe0b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    model = tf.keras.models.load_model(PATH_FOLDER_ARTIFACTS)    \n",
    "    print(f\"Load from {PATH_FOLDER_ARTIFACTS}\")\n",
    "    print(model.tensorflow_version)\n",
    "    print(model.summary())\n",
    "except Exception as error:\n",
    "    \n",
    "  print(str(error))\n",
    "  raise error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687618c3-7fdb-4294-bfc4-ce0783cc8212",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdPrediction=pd.DataFrame(columns=['_id','predict_severity','prob_severity'])\n",
    "\n",
    "for  row_dict in dfNewData.to_dict(orient=\"records\"):\n",
    "      incident_id=row_dict['id']\n",
    "      print(f\"{incident_id} - {row_dict['severity']}({row_dict['severity_name']})\") \n",
    "      for key_removed in unUsedColtoPredict:\n",
    "       row_dict.pop(key_removed)\n",
    "      # print(row_dict)  \n",
    "\n",
    "      input_dict = {name: tf.convert_to_tensor([value]) for name, value in row_dict.items()}\n",
    "      predictionResult = model.predict(input_dict)\n",
    "      result_str=','.join([ str(prob) for prob in predictionResult[0]])  \n",
    "      print(result_str)   \n",
    "\n",
    "      prob = tf.nn.softmax(predictionResult)\n",
    "      prob_pct=(100 * prob)  \n",
    "      _class = tf.argmax(predictionResult,-1).numpy()[0]\n",
    "      \n",
    "      dictPrediction={'_id':incident_id, 'predict_severity':_class,'prob_severity':result_str} \n",
    "      pdPrediction =pd.concat([pdPrediction,pd.DataFrame.from_dict([dictPrediction])] )\n",
    "\n",
    "      print(f\"{prob_pct} %   as {_class}\")     \n",
    "      print(\"======================================================================================\")\n",
    "            \n",
    "dfPredictData=pd.merge(dfNewData,pdPrediction,how='inner',left_on='id',right_on='_id')\n",
    "dfPredictData=dfPredictData.drop(columns=['_id'])\n",
    "dfPredictData['predict_severity']=dfPredictData['predict_severity'].astype('int')\n",
    "dfPredictData=dfPredictData[['id','prob_severity','predict_severity','severity']]\n",
    "dfPredictData['prediction_item_date']= datetime.strptime(today_str, '%Y-%m-%d')\n",
    "dfPredictData['prediction_datetime']=prediction_datetime\n",
    "dfPredictData['model_version']=model_version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3488b1e9-b0df-4c1c-b834-3006c7809aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfPredictData.info())\n",
    "dfPredictData[['id','prediction_item_date','predict_severity','severity']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcfd50d-0bc8-4c5b-80e3-02c3dfe76ecb",
   "metadata": {},
   "source": [
    "# Save predictoin resutl to Bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2119b1-a353-48fd-91e2-6203367758c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://cloud.google.com/bigquery/docs/samples/bigquery-create-table#bigquery_create_table-python\n",
    "\n",
    "try:\n",
    "    client.get_table(predictResult_table_id)  # Make an API request.\n",
    "    print(\"Predict Result Table {} already exists.\".format(predictResult_table_id))\n",
    "except Exception as ex:\n",
    "    schema = [\n",
    "    bigquery.SchemaField(\"id\", \"INTEGER\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"prob_severity\", \"STRING\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"predict_severity\", \"INTEGER\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"severity\", \"INTEGER\", mode=\"REQUIRED\"),    \n",
    "    bigquery.SchemaField(\"prediction_item_date\", \"DATETIME\", mode=\"REQUIRED\"),    \n",
    "    bigquery.SchemaField(\"prediction_datetime\", \"DATETIME\", mode=\"REQUIRED\"), \n",
    "    bigquery.SchemaField(\"model_version\",  \"STRING\", mode=\"REQUIRED\")     \n",
    "    ]\n",
    "\n",
    "    table = bigquery.Table(predictResult_table_id,schema=schema)\n",
    "    table.time_partitioning = bigquery.TimePartitioning(\n",
    "    type_=bigquery.TimePartitioningType.DAY,field=\"prediction_item_date\")\n",
    "    \n",
    "    table = client.create_table(table)  # Make an API request.\n",
    "    \n",
    "    print(\n",
    "        \"Created table {}.{}.{}\".format(table.project, table.dataset_id, table.table_id)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43baaa51-ffc8-451f-ba8d-d9d3003256da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataFrameToBQ():\n",
    "    try:\n",
    "        job_config = bigquery.LoadJobConfig(\n",
    "            write_disposition=\"WRITE_APPEND\",\n",
    "        )\n",
    "\n",
    "        job = client.load_table_from_dataframe(\n",
    "            dfPredictData, predictResult_table_id, job_config=job_config\n",
    "        )\n",
    "        job.result()  # Wait for the job to complete.\n",
    "        print(\"Total Prediction ML \", len(dfPredictData), \"Imported bigquery successfully\")\n",
    "\n",
    "    except BadRequest as e:\n",
    "        print(\"Bigquery Error\\n\")\n",
    "        for e in job.errors:\n",
    "            print('ERROR: {}'.format(e['message']))\n",
    "\n",
    "try:\n",
    "    loadDataFrameToBQ()\n",
    "except Exception as ex:\n",
    "    raise ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30050fa4-e771-4c93-884e-fe096202c928",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d100f629-1e0c-4c2d-8c10-a391334b5d0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bbed47-52ee-4a09-bed3-12c70cf03f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return 'All incidents has been predicted completely.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f842295f-2a5a-4ee7-8abb-fa0fdd06a96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#  result=predict_incident_severity_by_tf(None)\n",
    "#  print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950857cf-eb31-4973-9925-aa7f0b1434d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c87c03-93b1-4461-af09-9418520b4606",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
