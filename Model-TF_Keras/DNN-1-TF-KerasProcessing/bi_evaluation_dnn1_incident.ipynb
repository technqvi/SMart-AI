{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8a4684-bb85-4e37-bcd9-26177ef1eaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/custom/custom-tabular-bq-managed-dataset.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3015b10-ce8e-4004-afd2-e5c60d3b5c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3a91ce-d7ff-423a-9aee-4be795283c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#table_id='new_incident'\n",
    "table_id='test_incident'\n",
    "# table_id='validation_incident'\n",
    "\n",
    "projectId='pongthorn'\n",
    "dataset_id='DemoSMartDW'\n",
    "REGION=\"asia-southeast1\"\n",
    "\n",
    "if  table_id=='new_incident':\n",
    " unUsedColtoPredict=['severity','id','severity_id','severity_name','imported_at']\n",
    " filePath='../../data/Bi_Prediction_New_Incident.csv'\n",
    "elif table_id=='test_incident' or table_id=='validation_incident':\n",
    " unUsedColtoPredict=['severity','id','severity_id','severity_name']  \n",
    " filePath=f'../../data/Bi_Prediction_{table_id}.csv'\n",
    "    \n",
    "isLocalModel=True\n",
    "\n",
    "isBQToCSV=True\n",
    "\n",
    "PATH_FOLDER_ARTIFACTS=\"model_binary\"  \n",
    "\n",
    "modelFile_endPoint=1 \n",
    "#1=local(dev)/gcs(clound function) and 2=vertext\n",
    "\n",
    "localFile=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d52b41-422e-42f8-8cae-79ad17f1e475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.oauth2 import service_account\n",
    "# mycredentials = service_account.Credentials.from_service_account_file(r'C:\\Windows\\smart-data-ml-91b6f6204773.json')\n",
    "\n",
    "if isBQToCSV:\n",
    "    \n",
    "    bqclient= bigquery.Client(project=projectId)\n",
    "    # bqclient= bigquery.Client(project=projectId,credentials=mycredentials)\n",
    "    def download_table(bq_table_uri: str):\n",
    "\n",
    "        prefix = \"bq://\"\n",
    "        if bq_table_uri.startswith(prefix):\n",
    "            bq_table_uri = bq_table_uri[len(prefix) :]\n",
    "\n",
    "        table = bigquery.TableReference.from_string(bq_table_uri)\n",
    "        rows = bqclient.list_rows(table)\n",
    "        return rows.to_dataframe()\n",
    "\n",
    "    dfNewData=download_table(f\"{projectId}.{dataset_id}.{table_id}\")\n",
    "    dfNewData.to_csv(filePath,index=False)    \n",
    "    print(dfNewData.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c26dc93-8386-4960-bf33-c53cbe9618c4",
   "metadata": {},
   "source": [
    "\n",
    "# Load and Map Data Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83042ef-da1a-4929-8cb1-d0e225f2849a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if  localFile:\n",
    "    dfNewData=pd.read_csv(filePath)\n",
    "\n",
    "# dfNewData=dfNewData.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cad9950-cb7a-4421-8e4d-89d1d0367f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_file=\"incident_severity_to_binary.json\"\n",
    "\n",
    "with open(mapping_file, 'r') as json_file:\n",
    " map_sevirity_to_class= json.load(json_file)\n",
    "                                  \n",
    "print(map_sevirity_to_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8a438e-a9cb-40cf-81ea-01f326e35c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if table_id=='new_incident':\n",
    "    dfNewData.insert(2, 'severity', dfNewData['severity_name'].map(map_sevirity_to_class),True)\n",
    "    print(dfNewData.info())\n",
    "elif table_id=='test_incident' or table_id=='validation_incident':\n",
    "    \n",
    "    dfNewData=dfNewData.rename(columns={'label_binary_severity':'severity'})\n",
    "    dfNewData=dfNewData.drop(columns=['label_multi_severity'])\n",
    "    if 'id' not in dfNewData.columns.to_list():\n",
    "        dfNewData=dfNewData.reset_index(drop=True)\n",
    "        dfNewData = dfNewData.reset_index(level=0)\n",
    "        dfNewData.rename(columns={\"index\": \"id\"},inplace=True)\n",
    "        dfNewData['id']=dfNewData['id']+1\n",
    "print(filePath)  \n",
    "\n",
    "# dfNewData=dfNewData.sample(10)\n",
    "print(dfNewData.info())\n",
    "dfNewData.tail(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d8d093-e85d-4b90-9533-90292b721769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_class(df):\n",
    "    fig , ax = plt.subplots(figsize=(8,5))\n",
    "    ax =sns.countplot(x='severity', data=df,)\n",
    "    for p in ax.patches:\n",
    "       ax.annotate('{:.1f}'.format(p.get_height()), (p.get_x()+0.25, p.get_height()+0.01))\n",
    "    plt.title('Severity')\n",
    "    plt.show()\n",
    "    \n",
    "plot_class(dfNewData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93793bce-3345-490d-b051-596cd6577210",
   "metadata": {},
   "source": [
    "# Load Model from Directory to Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14420b33-941e-4445-bab8-baa9675c432f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(PATH_FOLDER_ARTIFACTS)    \n",
    "print(f\"Load from {PATH_FOLDER_ARTIFACTS}\")\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9336b4-1e34-4e2d-91b5-50dc9b0567cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdPrediction=pd.DataFrame(columns=['_id','_predict_severity'])\n",
    "\n",
    "for  row_dict in dfNewData.to_dict(orient=\"records\"):\n",
    "      incident_id=row_dict['id']\n",
    "      print(f\"{incident_id} - {row_dict['severity']}\") \n",
    "      for key_removed in unUsedColtoPredict:\n",
    "       row_dict.pop(key_removed)\n",
    "      # print(row_dict)  \n",
    "\n",
    "      input_dict = {name: tf.convert_to_tensor([value]) for name, value in row_dict.items()}\n",
    "      predictionResult = model.predict(input_dict)\n",
    "\n",
    "      prob = tf.nn.sigmoid(predictionResult[0])\n",
    "      prob_pct=(100 * prob)   \n",
    "      _class= 1 if prob[0]>=0.5 else 0  \n",
    "      print(f\"{prob_pct[0]} % at {_class} as 0(Normal)/1(Critcal)\") # np.argmax(prob, axis=0\n",
    "      \n",
    "      \n",
    "      pdPrediction =pd.concat([pdPrediction,pd.DataFrame.from_dict([{'_id':incident_id, '_predict_severity':_class}])] )\n",
    "      # print(input_dict)  \n",
    "   \n",
    "      print(\"======================================================================================\")\n",
    "\n",
    "dfPredictData=pd.merge(dfNewData,pdPrediction,how='inner',left_on='id',right_on='_id')\n",
    "dfPredictData=dfPredictData.drop(columns=['_id'])\n",
    "dfPredictData=dfPredictData[['id','_predict_severity','severity']]\n",
    "dfPredictData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead027ef-253b-410b-8b4b-beee59285895",
   "metadata": {},
   "source": [
    "# Classification Rerport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4486552-395b-45db-9ae1-44b676ca7ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8eb7cb-6811-486c-80f5-8ccc0090affa",
   "metadata": {},
   "outputs": [],
   "source": [
    "className=list(set().union(list(dfPredictData['severity'].unique()),list(dfPredictData['_predict_severity'].unique())))\n",
    "actualClass=[  f'actual-{x}' for x in  className]\n",
    "predictedlClass=[  f'predcited-{x}' for x in className]\n",
    "\n",
    "y_true=list(dfPredictData['severity'])\n",
    "y_pred=list(dfPredictData['_predict_severity'])\n",
    "cnf_matrix = confusion_matrix(y_true,y_pred)\n",
    "cnf_matrix\n",
    "\n",
    "# #index=actual , column=prediction\n",
    "cm_df = pd.DataFrame(cnf_matrix,\n",
    "                     index = actualClass, \n",
    "                     columns = predictedlClass)\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f909f102-3288-4433-ad58-84811cf84484",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true, y_pred, labels=className))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8da4a4a-32ae-4d62-ad8b-cf686e01f8ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
