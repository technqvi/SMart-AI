{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd54814-e227-4302-9a81-3d6ddcf0e9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from datetime import date, timedelta, datetime # Date Functions\n",
    "import time\n",
    "import os\n",
    "\n",
    "import google.cloud.aiplatform as aip\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "print(tf.__version__)\n",
    "print(aip.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9877dcac-05b5-45d7-a3ae-b4b7ebcb08b1",
   "metadata": {},
   "source": [
    "# Get explanations locally in Vertex AI Workbench user-managed notebooks\n",
    "* https://cloud.google.com/vertex-ai/docs/predictions/overview\n",
    "* https://cloud.google.com/vertex-ai/docs/explainable-ai/configuring-explanations-feature-based\n",
    "* https://cloud.google.com/vertex-ai/docs/explainable-ai/getting-explanations#local-explanations\n",
    "* https://cloud.google.com/vertex-ai/docs/tabular-data/classification-regression/get-online-predictions#aiplatform_explain_tabular_sample-python_vertex_ai_sdk\n",
    "* https://cloud.google.com/vertex-ai/docs/tabular-data/classification-regression/get-batch-predictions\n",
    "* https://cloud.google.com/vertex-ai/docs/explainable-ai/tensorflow\n",
    "\n",
    "# Use SDK  VertextAi Sample Code\n",
    "* https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/explainable_ai/sdk_custom_tabular_regression_online_explain_get_metadata.ipynb\n",
    "* https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/explainable_ai/sdk_custom_tabular_regression_online_explain.ipynb\n",
    "* https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/explainable_ai/sdk_custom_tabular_regression_batch_explain.ipynb\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cb7286-7f33-4140-b5ca-129b69dd822b",
   "metadata": {},
   "source": [
    "# Varaible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c943ea3-e29e-42f0-881d-657e9f36bf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#label_multi_severity\n",
    "project_id=\"pongthorn\"\n",
    "region='asia-southeast1'\n",
    "\n",
    "model_dir='gs://demo2-tf-incident-pongthorn/demo_model_tf' # demo\n",
    "# model_with_meta_dir='gs://demo2-tf-incident-pongthorn/demo_model_meta_tf'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac585a9f-71ed-4406-bef1-d7d8ac065804",
   "metadata": {},
   "source": [
    "# Load model from GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a3e401-2b57-4f52-80c7-e705154114be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_with_meta_dir='model_with_meta'\n",
    "local_model= tf.keras.models.load_model(model_dir)\n",
    "print(local_model.tensorflow_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86af40e-2142-4c2f-af6d-13bae8cd463e",
   "metadata": {},
   "source": [
    "# Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd916787-bacc-4537-b2b6-1c6d62932de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample= {\"sla\": [\"24x7 6Hrs Resolution Time\"], \"product_type\": [\"Storage\"], \"brand\": [\"NetApp\"], \n",
    "         \"service_type\": [\"Incident\"], \"incident_type\": [\"General Incident\"], \n",
    "         \"open_to_close_hour\": [1268.9333333333334], \"response_to_resolved_hour\": [1268.8]}\n",
    "\n",
    "print(sample)\n",
    "              \n",
    "print(\"===============================================================================================================\")    \n",
    "print(\"convert pain data to serdor as input to predict\")    \n",
    "input_dict = {name: tf.convert_to_tensor([value]) for name, value in sample.items()}\n",
    "print(input_dict)\n",
    "\n",
    "predictionList = local_model.predict(input_dict)\n",
    "print(predictionList)\n",
    "\n",
    "prob = tf.nn.softmax(predictionList[0])\n",
    "print(f\"{(100 * prob)} % at {np.argmax(prob, axis=0)} as Severity\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60cd841-c4f7-43fb-a0eb-c7018e32988f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36991efc-88e3-4c00-8c4f-b3dcd6acccac",
   "metadata": {},
   "source": [
    "# Get prepared the serving function signature input/output for explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5fb999-670a-43fa-b2a9-43510d621469",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_name = local_model.input_names\n",
    "print(\"Model input name:\", input_name)\n",
    "output_name = local_model.output_names\n",
    "print(\"Model output name:\", output_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffeb1db-0b33-40c8-86a6-9cc5a8d12d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = tf.saved_model.load(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ea0022-acc3-44dd-aa96-1c503f236f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "listServingInput= list(\n",
    "    loaded.signatures[\"serving_default\"].structured_input_signature[1].keys())\n",
    "print(listServingInput)\n",
    "serving_input = listServingInput[0]\n",
    "print(serving_input)\n",
    "\n",
    "print(\"Serving function input:\", serving_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533ef415-e716-4271-9382-89be25fdd393",
   "metadata": {},
   "outputs": [],
   "source": [
    "listServingOutput=list(loaded.signatures[\"serving_default\"].structured_outputs.keys())\n",
    "print(listServingOutput)\n",
    "serving_output =listServingOutput[0]\n",
    "print(\"Serving function output:\", serving_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50602507-3d25-4791-95dd-4885e4f2eadb",
   "metadata": {},
   "source": [
    "# Explanation Specification\n",
    "To get explanations when doing a prediction, you must enable the explanation capability and set corresponding settings when you upload your custom model to an Vertex Model resource. These settings are referred to as the explanation metadata, which consists of:\n",
    "\n",
    "* parameters: This is the specification for the explainability algorithm to use for explanations on your model. You can choose between:\n",
    "  * Shapley - Note, not recommended for image data -- can be very long running\n",
    "  * XRAI\n",
    "  * Integrated Gradients\n",
    "* metadata: This is the specification for how the algoithm is applied on your custom model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb322a53-98ee-4c8a-a87e-c4c7961e3eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "XAI = \"shapley\"  # [ shapley, ig, xrai ]\n",
    "path_count=35 # 70% of 50 [1-50]\n",
    "if XAI == \"shapley\":\n",
    "    PARAMETERS = {\"sampled_shapley_attribution\": {\"path_count\": path_count}}\n",
    "elif XAI == \"ig\":\n",
    "    PARAMETERS = {\"integrated_gradients_attribution\": {\"step_count\": path_count}}\n",
    "elif XAI == \"xrai\":\n",
    "    PARAMETERS = {\"xrai_attribution\": {\"step_count\": path_count}}\n",
    "\n",
    "parameters = aip.explain.ExplanationParameters(PARAMETERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d22cdd-a379-41be-9aec-8244397f5702",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud.aiplatform.explain.metadata.tf.v2 import saved_model_metadata_builder\n",
    "builder = saved_model_metadata_builder.SavedModelMetadataBuilder(model_dir)\n",
    "metadata = builder.get_metadata_protobuf()\n",
    "print(metadata)\n",
    "\n",
    "# import explainable_ai_sdk\n",
    "# from explainable_ai_sdk.metadata.tf.v2 import SavedModelMetadataBuilder\n",
    "\n",
    "# metadata_and_model_builder = SavedModelMetadataBuilder(model_dir)\n",
    "# metadata_and_model_builder.save_model_with_metadata(model_with_meta_dir)\n",
    "\n",
    "# https://cloud.google.com/vertex-ai/docs/explainable-ai/getting-explanations#local-explanations\n",
    "# error\n",
    "# # Load the model and adjust the configuration for Explainable AI parameters\n",
    "# # https://cloud.google.com/vertex-ai/docs/reference/rest/v1/ExplanationSpec#sampledshapleyattribution\n",
    "# num_paths = 25\n",
    "# model_artifact_with_metadata = explainable_ai_sdk.load_model_from_local_path(\n",
    "#     model_with_meta_dir,explainable_ai_sdk.SampledShapleyConfig(num_paths))\n",
    "\n",
    "# instances = [sample ]\n",
    "# explanations = model_artifact_with_metadata.explain(instances)\n",
    "# explanations[0].visualize_attributions()\n",
    "\n",
    "#AttributeError: module 'explainable_ai_sdk' has no attribute 'SampledShapleyConfig'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dfe4d3-0750-474e-b9e3-6ca67ab378ec",
   "metadata": {},
   "source": [
    "# Upload model to model registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58bea48-7deb-4f0f-a9d1-26d006a10881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://cloud.google.com/ai-platform-unified/docs/predictions/pre-built-containers\n",
    "# #https://cloud.google.com/vertex-ai/docs/samples/aiplatform-upload-model-sample\n",
    "image_uri=\"asia-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-12:latest\"\n",
    "model = aip.Model.upload(\n",
    "    display_name=\"model-incident-tf-explainable\",\n",
    "    artifact_uri=model_dir,\n",
    "    serving_container_image_uri=image_uri,\n",
    "    explanation_parameters=parameters,\n",
    "    explanation_metadata=metadata,\n",
    "    location=region,\n",
    "    sync=False,\n",
    ")\n",
    "\n",
    "model.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614f4e95-861a-4554-9ef2-9e447d591522",
   "metadata": {},
   "source": [
    "# Deploy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ede48c-15b5-47b4-82b5-de57e63df592",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEPLOYED_NAME = \"endpoint-incident-tf-explainable\"\n",
    "TRAFFIC_SPLIT = {\"0\": 100}\n",
    "MIN_NODES = 1\n",
    "MAX_NODES = 1\n",
    "\n",
    "MACHINE_TYPE = \"n1-standard\"\n",
    "VCP = \"2\"\n",
    "DEPLOY_COMPUTE = MACHINE_TYPE + \"-\" + VCP\n",
    "\n",
    "endpoint = model.deploy(\n",
    "    deployed_model_display_name=DEPLOYED_NAME,\n",
    "    traffic_split=TRAFFIC_SPLIT,\n",
    "    machine_type=DEPLOY_COMPUTE,\n",
    "    accelerator_count=0,\n",
    "    min_replica_count=MIN_NODES,\n",
    "    max_replica_count=MAX_NODES,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a88a5a-9115-4473-9483-62f34cc1be59",
   "metadata": {},
   "source": [
    "# Load model from endpoint to make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc847538-0755-47ec-979c-d45788ddda21",
   "metadata": {},
   "outputs": [],
   "source": [
    "instances=[\n",
    " {\"sla\": [\"24x7 6Hrs Resolution Time\"], \"product_type\": [\"Storage\"], \"brand\": [\"NetApp\"], \"service_type\": [\"Incident\"], \"incident_type\": [\"General Incident\"], \"open_to_close_hour\": [1268.9333333333334], \"response_to_resolved_hour\": [1268.8]},\n",
    " {\"sla\": [\"24x7 4Hrs Resolution Time\"], \"product_type\": [\"Software\"], \"brand\": [\"Veeam\"], \"service_type\": [\"Incident\"], \"incident_type\": [\"Software\"], \"open_to_close_hour\": [16.766666666666666], \"response_to_resolved_hour\": [16.666666666666668]},\n",
    "# {\"sla\": [\"24x7 4Hrs Resolution Time\"], \"product_type\": [\"Server\"], \"brand\": [\"HPE\"], \"service_type\": [\"Incident\"], \"incident_type\": [\"General Incident\"], \"open_to_close_hour\": [1.9], \"response_to_resolved_hour\": [1.8166666666666667]} \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a72c85-eb1a-41ff-afb1-4ab2d79ae738",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(project=project_id, location=region)\n",
    "endpoint_id=\"1843916184152440832\"\n",
    "endpoint = aiplatform.Endpoint(endpoint_name=f\"projects/{project_id}/locations/{region}/endpoints/{endpoint_id}\")\n",
    "endpoint.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f435143a-b6e9-4595-8f01-49ac0983e674",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = endpoint.predict(instances=instances)\n",
    "for prediction_ in response.predictions:\n",
    "        print(prediction_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f8c2f4-8999-4837-b504-da94af47907a",
   "metadata": {},
   "source": [
    "# Get explanations\n",
    "* https://cloud.google.com/vertex-ai/docs/tabular-data/classification-regression/get-online-predictions#interpret_explanation_results\n",
    "* https://cloud.google.com/vertex-ai/docs/tabular-data/classification-explanations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a330932d-78a0-4151-b677-2a7d9b511721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = endpoint.explain(instances)\n",
    "# response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e7aa27-80a1-4983-a688-b51ee102cb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_model( instanceList):\n",
    "\n",
    "    response = endpoint.explain(instances=instanceList, parameters={})\n",
    "\n",
    "    for explanation in response.explanations:\n",
    "        print(\"Explanation\")\n",
    "        # Feature attributions.\n",
    "        attributions = explanation.attributions\n",
    "        for attribution in attributions:\n",
    "            print(\"Attribution\")\n",
    "            print(\" baseline_output_value:\", attribution.baseline_output_value)\n",
    "            print(\" instance_output_value:\", attribution.instance_output_value)\n",
    "            print(\" approximation_error:\", attribution.approximation_error)\n",
    "            print(\" feature list:\")\n",
    "            sum_feat=0;\n",
    "            for name in input_name:\n",
    "              feat_value= attribution.feature_attributions[name]\n",
    "              sum_feat=sum_feat+feat_value[0]\n",
    "              print(f\"  {name} :{feat_value}\")\n",
    "            print(f\"  The sum of all of the feature importance values(instance-baseline) = {sum_feat}\")\n",
    "            \n",
    "            # print(\" output_display_name:\", attribution.output_display_name)\n",
    "            # print(\"  output_name:\", attribution.output_name)\n",
    "            output_index = attribution.output_index\n",
    "            for output_index in output_index:\n",
    "                print(\" output_index:\", output_index)\n",
    "            print(\"================================================================\")\n",
    "    \n",
    "\n",
    "    for prediction in response.predictions:\n",
    "        print(prediction)\n",
    "explain_model(instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851fae0c-b3b7-4b77-8e4e-f13f2d50015b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = endpoint.explain(instances=instances, parameters={})\n",
    "# for explanation in response.explanations:\n",
    "#  print(explanation.attributions)\n",
    "#  print(\"==========================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1794b3-f667-4063-97dd-5b77cd437f7b",
   "metadata": {},
   "source": [
    "# Examine feature attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14ed58e-a89f-4ebd-90c3-e98597fe8da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def sanity_check_explanations(\n",
    "    explanation, prediction, mean_tgt_value=None, variance_tgt_value=None\n",
    "):\n",
    "    passed_test = 0\n",
    "    total_test = 1\n",
    "    # `attributions` is a dict where keys are the feature names\n",
    "    # and values are the feature attributions for each feature\n",
    "    baseline_score = explanation.attributions[0].baseline_output_value\n",
    "    print(\"baseline:\", baseline_score)\n",
    "\n",
    "    # Sanity check 1\n",
    "    # The prediction at the input is equal to that at the baseline.\n",
    "    #  Please use a different baseline. Some suggestions are: random input, training\n",
    "    #  set mean.\n",
    "    if abs(prediction - baseline_score) <= 0.05:\n",
    "        print(\"Warning: example score and baseline score are too close.\")\n",
    "        print(\"You might not get attributions.\")\n",
    "    else:\n",
    "        passed_test += 1\n",
    "        print(\"Sanity Check 1: Passed\")\n",
    "\n",
    "    print(passed_test, \" out of \", total_test, \" sanity checks passed.\")\n",
    "\n",
    "\n",
    "i = 0\n",
    "for explanation in response.explanations:\n",
    "    try:\n",
    "        prediction = np.max(response.predictions[i][\"scores\"])\n",
    "    except TypeError:\n",
    "        prediction = np.max(response.predictions[i])\n",
    "    sanity_check_explanations(explanation, prediction)\n",
    "    i += 1\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08276282-2b28-4dea-958b-d0f75ef1469a",
   "metadata": {},
   "source": [
    "# Clean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f15b8f-582a-45d2-b4d8-33d227c19b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint.undeploy_all()\n",
    "delete_bucket = False\n",
    "\n",
    "endpoint.delete()\n",
    "# model.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5587682-2265-4eff-985f-ca1f7852ddf4",
   "metadata": {},
   "source": [
    "# Copy Model From Local To GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaabd3ac-47ad-43ae-b6e5-fc16fecec238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #https://codelabs.developers.google.com/codelabs/fraud-detection-ai-explanations?hl=en#6\n",
    "# # press_y3=input(f\"Press y=True to save model to Google Cloud storage : \") \n",
    "# # if press_y3.lower()=='y':\n",
    "# MODEL_BUCKET = 'gs://tf1-incident-smart-ml-yip'\n",
    "\n",
    "# # # # !gsutil mb -l $REGION $MODEL_BUCKET\n",
    "# # !gsutil -m cp -r ./$model_dir/* $MODEL_BUCKET/demo_model\n",
    "# !gsutil -m cp -r ./$model_dir/* $MODEL_BUCKET/model\n",
    "# #!gsutil -m cp -r ./$explain_meta_model_dir/* $MODEL_BUCKET/demo_model_explain_meta\n",
    "# # else:\n",
    "# #  quite()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6465851a-f078-41a2-991c-80a71d3e695d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0f6c5d-3ea4-4fae-ba78-b8decf134a92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff433f46-0e98-48ec-8b32-25b840541253",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-12.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-12:m109"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
