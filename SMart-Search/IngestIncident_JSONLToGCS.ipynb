{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c39b3f6-bba0-4a86-a7e9-06936925e4e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import psycopg2.extras as extras\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "from google.cloud import bigquery\n",
    "from dotenv import dotenv_values\n",
    "from dotenv import dotenv_values\n",
    "import re\n",
    "#pip uninstall psycopg\n",
    "#pip install psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006faf12-708d-41d8-a92e-e675cd0fd1a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "project_id='pongthorn'\n",
    "env_path='../.env'\n",
    "config = dotenv_values(dotenv_path=env_path)\n",
    "# config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf86216-a68a-4a1d-bdc9-df0bb5f3a961",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_date_query='2023-07-01'\n",
    "end_date_query='2023-11-30' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c550a3-31d9-4ab2-96b5-86788b3ed1b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dt_imported=datetime.now()\n",
    "str_imported=dt_imported.strftime('%Y-%m-%d %H:%M:%S')\n",
    "print(f\"Imported DateTime: {str_imported}\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02058f8d-cc89-4eea-8fd4-1c7995a0a6cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_postgres_conn():\n",
    " try:\n",
    "  conn = psycopg2.connect(\n",
    "        database=config['DATABASES_NAME'], user=config['DATABASES_USER'],\n",
    "      password=config['DATABASES_PASSWORD'], host=config['DATABASES_HOST']\n",
    "     )\n",
    "  return conn\n",
    "\n",
    " except Exception as error:\n",
    "  print(error)      \n",
    "  raise error\n",
    "def list_data(sql,params,connection):\n",
    " df=None   \n",
    " with connection.cursor() as cursor:\n",
    "    \n",
    "    if params is None:\n",
    "       cursor.execute(sql)\n",
    "    else:\n",
    "       cursor.execute(sql,params)\n",
    "    \n",
    "    columns = [col[0] for col in cursor.description]\n",
    "    dataList = [dict(zip(columns, row)) for row in cursor.fetchall()]\n",
    "    df = pd.DataFrame(data=dataList) \n",
    " return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c895bd-11bd-4e29-8d2b-3f2cec660c3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#incident.id,  order by id\n",
    "\n",
    "sql_incident=f\"\"\"\n",
    "\n",
    "select\n",
    "incident.id as id,incident.incident_no as incident_no\n",
    ",status.incident_status_name as status,severity.severity_name as  severity\n",
    ",incident.incident_subject as subject,incident.incident_description as description\n",
    ",TO_CHAR(incident.incident_datetime  AT TIME ZONE 'Asia/Bangkok','YYYY-MM-DD HH24:MI') as open_datetime\n",
    ",TO_CHAR(incident.incident_close_datetime  AT TIME ZONE 'Asia/Bangkok','YYYY-MM-DD HH24:MI') as close_datetime\n",
    ",xtype.incident_type_name as incident_type,service.service_type_name service_type\n",
    ",inventory.serial_number\n",
    "-- ,service_level.sla_name as sla\n",
    ",product_type.productype_name as product_type,brand.brand_name as brand,model.model_name as model\n",
    "\n",
    "\n",
    "from app_incident as incident\n",
    "inner join app_incident_type as  xtype on incident.incident_type_id = xtype.id\n",
    "inner join  app_incident_status as status on incident.incident_status_id = status.id\n",
    "inner join  app_incident_severity as severity on  incident.incident_severity_id = severity.id\n",
    "inner join  app_service_type as service on incident.service_type_id= service.id\n",
    "inner join app_inventory as inventory on incident.inventory_id = inventory.id\n",
    "inner join app_brand as brand on inventory.brand_id = brand.id\n",
    "inner join app_model as model on inventory.model_id = model.id\n",
    "inner join app_product_type as product_type on inventory.product_type_id = product_type.id\n",
    "inner join app_sla as service_level on inventory.customer_sla_id = service_level.id\n",
    "\n",
    "-- inner join app_project as project on inventory.project_id = project.id\n",
    "-- inner join app_company as company on project.company_id = company.id\n",
    "\n",
    "where incident_datetime>='{start_date_query}'\n",
    "and incident.incident_status_id=4\n",
    "and inventory.is_dummy=False\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "#and  incident.incident_datetime<=%(end_date_param)s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac67eab-20f6-4676-886b-d8184d4150ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# sql_detail=\"\"\"\n",
    "\n",
    "# select  detail.id, detail.incident_master_id as incident_id ,\n",
    "# workaround_resolution as resolution,\n",
    "# TO_CHAR(task_start,'YYYY-MM-DD HH24:MI:SS') as task_start,\n",
    "# TO_CHAR(task_end,'YYYY-MM-DD HH24:MI:SS') as task_end,\n",
    "# team.service_team_name\n",
    "# from app_incident_detail detail\n",
    "# inner join  app_serviceteam team on detail.service_team_id=team.id\n",
    "# inner  join  app_employee engineer on detail.employee_id=engineer.id\n",
    "#  where detail.incident_master_id = ?????????????\n",
    "\n",
    "#  \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac777d07-3149-4d68-bad7-037204f26140",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_ILLEGAL_CHARACTERS_RE = re.compile(r\"[\\000-\\010]|[\\013-\\014]|[\\016-\\037]\")\n",
    "# \\r\\n\\r\n",
    "# https://www.geeksforgeeks.org/python-removing-newline-character-from-string/\n",
    "def replace_ILLEGAL_CHARACTERS(text):\n",
    "   text_fixed = _ILLEGAL_CHARACTERS_RE.sub(\"\", text)\n",
    "   text_fixed=  text_fixed.replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "   return  text_fixed  \n",
    "\n",
    "print(\"Create all issues dataframe\")\n",
    "\n",
    "# dict_params={\"company_id_param\":company_id_query,\"start_date_param\":start_date_query,\"end_date_param\":end_date_query}\n",
    "# dict_params={\"company_id_param\":company_id_query,\"start_date_param\":start_date_query}\n",
    "\n",
    "df_all=list_data(sql_incident,None,get_postgres_conn())\n",
    "# df_all['imported_at']=dt_imported\n",
    "# df_all['imported_at']=df_all['imported_at'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "df_all['subject']=df_all['subject'].apply(replace_ILLEGAL_CHARACTERS)   \n",
    "df_all['description']=df_all['description'].apply(replace_ILLEGAL_CHARACTERS) \n",
    "\n",
    "                     \n",
    "# dateNone_cols=['close_datetime']\n",
    "# for index,row in df_all.iterrows():\n",
    "#   for dateNone in dateNone_cols:\n",
    "#     if  row[dateNone] is None:\n",
    "#         print(row['incident_no']+ \" is updated on None in \"+dateNone)\n",
    "#         df_all.loc[index, dateNone] =row['updated_at']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe82144-c9ec-4814-b7cc-b827a51a6c1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(df_all.info())\n",
    "df_all.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fba7f0-557a-4e46-b262-e833dbd49d25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# icident / file\n",
    "# for index, serie in df_all.iterrows(): \n",
    "#     id=serie[\"id\"]\n",
    "#     serie = serie.drop('id')\n",
    "#     # print(serie )\n",
    "#     # print(\"==================================================================\")\n",
    "#     with open(f'id_incident\\\\{id}-incident.ndjson', 'w',encoding='utf8') as f:\n",
    "#         json_object = json.dumps(serie.to_dict(),ensure_ascii=False)\n",
    "#         f.write(json_object + '\\n')\n",
    "\n",
    "\n",
    "#  1 files contaim all incidents\n",
    "with open(f'incident.ndjson', 'w',encoding='utf8') as f:\n",
    "    for index, serie in df_all.iterrows(): \n",
    "        id=serie[\"id\"]\n",
    "        serie = serie.drop('id')\n",
    "        json_object = json.dumps(serie.to_dict(),ensure_ascii=False)\n",
    "        f.write(json_object + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af45e55c-2939-4a15-89d1-c021e54893b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#df_all.to_excel(\"Incident.xlsx\",index=False)\n",
    "\n",
    "    \n",
    "    # incident_update_at= incident['imported_at']\n",
    "#     df_detail = list_data(sql_detail,{\"incident_id_param\": id},get_postgres_conn()) \n",
    "#     if df_detail.empty==False:\n",
    "    \n",
    "#       for index,row in df_detail.iterrows():\n",
    "#         if  row['task_end'] is None:\n",
    "#            print(f\"DetailId-{row['id']} of IncidentID-{row['incident_id']}  is updated on None in task_end\") \n",
    "#            df_detail.loc[index, 'task_end'] =  incident_update_at #row['updated_at']\n",
    "           \n",
    "#       df_detail=df_detail.drop(columns=['incident_id','id'])  \n",
    "#       json_detail = json.loads(df_detail.to_json(orient = 'records'))\n",
    "#       # print(json_detail)\n",
    "#       incident['incident_detail']=json_detail\n",
    "        \n",
    "    # else:\n",
    "    #  print(f'no detail in incident {id}')\n",
    "    #  #incident['incident_detail']=None\n",
    "    \n",
    "# no_incident=len(json_incident)\n",
    "# print(f\"No incident: {no_incident}\")\n",
    "# if len(json_incident)>0:\n",
    "#     print(json_incident[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134ffe12-fcd2-4e00-a7c4-7fd6d8d5a832",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af8d43a-61d2-4a8e-94f3-0f96447a2a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# job_config = bigquery.LoadJobConfig(\n",
    "#       schema = [              \n",
    "#     bigquery.SchemaField(\"company\", \"STRING\", mode=\"REQUIRED\"),\n",
    "#     bigquery.SchemaField(\"incident_no\", \"STRING\", mode=\"REQUIRED\"),\n",
    "#     bigquery.SchemaField(\"productype_name\", \"STRING\", mode=\"REQUIRED\"),\n",
    "#     bigquery.SchemaField(\"brand_name\", \"STRING\", mode=\"REQUIRED\"),\n",
    "#     bigquery.SchemaField(\"model_name\", \"STRING\", mode=\"REQUIRED\"),\n",
    "#     bigquery.SchemaField(\"serial_number\", \"STRING\", mode=\"REQUIRED\"), \n",
    "#     bigquery.SchemaField(\"datacenter_name\", \"STRING\", mode=\"REQUIRED\"), \n",
    "#     bigquery.SchemaField(\"branch_name\", \"STRING\", mode=\"REQUIRED\"),       \n",
    "#     bigquery.SchemaField(\"severity_id\", \"INTEGER\", mode=\"REQUIRED\"),\n",
    "#     bigquery.SchemaField(\"severity_name\", \"STRING\", mode=\"REQUIRED\"),\n",
    "#     bigquery.SchemaField(\"status_id\", \"INTEGER\", mode=\"REQUIRED\"),\n",
    "#     bigquery.SchemaField(\"status_name\", \"STRING\", mode=\"REQUIRED\"),\n",
    "#     bigquery.SchemaField(\"service_type_id\", \"INTEGER\", mode=\"REQUIRED\"),\n",
    "#     bigquery.SchemaField(\"service_type_name\", \"STRING\", mode=\"REQUIRED\"),\n",
    "#     bigquery.SchemaField(\"incident_type_id\", \"INTEGER\", mode=\"REQUIRED\"),\n",
    "#     bigquery.SchemaField(\"incident_type_name\", \"STRING\", mode=\"REQUIRED\"),\n",
    "#     bigquery.SchemaField(\"failure_type\", \"STRING\", mode=\"NULLABLE\"),          \n",
    "#     bigquery.SchemaField(\"open_datetime\", \"DATETIME\", mode=\"REQUIRED\"),\n",
    "#     bigquery.SchemaField(\"close_datetime\", \"DATETIME\", mode=\"REQUIRED\"),\n",
    "#     bigquery.SchemaField(\"response_datetime\", \"DATETIME\", mode=\"REQUIRED\"),\n",
    "#     bigquery.SchemaField(\"resolved_datetime\", \"DATETIME\", mode=\"REQUIRED\"),\n",
    "#     bigquery.SchemaField(\"updated_at\", \"DATETIME\", mode=\"REQUIRED\"),\n",
    "#     bigquery.SchemaField(\"install_date\", \"DATETIME\", mode=\"NULLABLE\"),\n",
    "#     bigquery.SchemaField(\"eos_date\", \"DATETIME\", mode=\"NULLABLE\"),\n",
    "#     bigquery.SchemaField(\"customer_warranty_start\", \"DATETIME\", mode=\"REQUIRED\"),\n",
    "#     bigquery.SchemaField(\"customer_warranty_end\", \"DATETIME\", mode=\"REQUIRED\"),\n",
    "#     bigquery.SchemaField(\"imported_at\", \"DATETIME\", mode=\"REQUIRED\"),      \n",
    "#     bigquery.SchemaField(\n",
    "#     \"incident_detail\",\n",
    "#     \"RECORD\",\n",
    "#     mode=\"REPEATED\",\n",
    "#     fields=[\n",
    "#         bigquery.SchemaField(\"task_start\", \"DATETIME\", mode=\"REQUIRED\"),\n",
    "#         bigquery.SchemaField(\"task_end\", \"DATETIME\", mode=\"REQUIRED\"),\n",
    "#         bigquery.SchemaField(\"service_team_name\", \"STRING\", mode=\"REQUIRED\"),\n",
    "#         bigquery.SchemaField(\"engineer_name\", \"STRING\", mode=\"REQUIRED\"),\n",
    "#         bigquery.SchemaField(\"updated_at\", \"DATETIME\", mode=\"REQUIRED\"),\n",
    "#     ],),    \n",
    "#     ]\n",
    "   \n",
    "# )\n",
    "# # for meta in job_config.schema:\n",
    "# #  print(meta)\n",
    "\n",
    "# job_config.source_format = bigquery.SourceFormat.NEWLINE_DELIMITED_JSON\n",
    "# #job_config.schema_update_options = [bigquery.SchemaUpdateOption.ALLOW_FIELD_ADDITION]\n",
    "# job_config.write_disposition = bigquery.WriteDisposition.WRITE_APPEND  \n",
    "# #job_config.write_disposition = bigquery.WriteDisposition.WRITE_TRUNCATE\n",
    "\n",
    "\n",
    "# job = client.load_table_from_json(json_incident,table_id, job_config = job_config)\n",
    "# if job.errors is not None:\n",
    "#     print(job.error_result)\n",
    "#     print(job.errors)\n",
    "# else:\n",
    "#     print(f\"import to bigquery successfully  {no_incident} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b17ca7a-92a8-4bc0-9174-6039c67b654f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edfee9a-f93e-4d71-bb68-84f279478e31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9996e057-c8cb-4b9b-a994-4d4c0265b143",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeaf1148-0623-4ccc-8e42-4b91d283078c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64c3f68-8ab8-447b-83ff-4ca648fbcb6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2944355e-8b23-4fbf-8f0d-cab8a0e7fdd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
