{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cce56c57-71a1-4db8-9873-696413f6baa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "from datetime import date,datetime,timedelta\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "from dotenv import dotenv_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fc89a06-fe9b-4ba5-9dc3-3cdb9f0b9ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get prediction as of 2023-07-03\n"
     ]
    }
   ],
   "source": [
    "isLoadingAll=False\n",
    "\n",
    "# we synch at 02:30(Bangkok) it is  7:30 (UTC is still Yesterday)\n",
    "predict_datetime = date.today() - timedelta(days = 1) \n",
    "#predict_datetime = date.today()\n",
    "print(f\"Get prediction as of {predict_datetime}\")\n",
    "\n",
    "\n",
    "env_path=r'D:\\PythonDev\\MyQuantFinProject\\SMart-AI\\.env'\n",
    "config = dotenv_values(dotenv_path=env_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57b5a2bf-1928-4e76-904d-0f586c7ef999",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'xxxxx.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15404\\2752400272.py\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtable_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"{projectId}.{dataset_id}.new_result_prediction_incident\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mcredentials\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mservice_account\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCredentials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_service_account_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'xxxxx.json'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mclient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbigquery\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mClient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcredentials\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mcredentials\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mproject\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprojectId\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# client = bigquery.Client(project=projectId)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\google_base\\lib\\site-packages\\google\\oauth2\\service_account.py\u001b[0m in \u001b[0;36mfrom_service_account_file\u001b[1;34m(cls, filename, **kwargs)\u001b[0m\n\u001b[0;32m    236\u001b[0m                 \u001b[0mcredentials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m         \"\"\"\n\u001b[1;32m--> 238\u001b[1;33m         info, signer = _service_account_info.from_filename(\n\u001b[0m\u001b[0;32m    239\u001b[0m             \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequire\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"client_email\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"token_uri\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m         )\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\google_base\\lib\\site-packages\\google\\auth\\_service_account_info.py\u001b[0m in \u001b[0;36mfrom_filename\u001b[1;34m(filename, require)\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[0minfo\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0ma\u001b[0m \u001b[0msigner\u001b[0m \u001b[0minstance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \"\"\"\n\u001b[1;32m---> 72\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfrom_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequire\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequire\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'xxxxx.json'"
     ]
    }
   ],
   "source": [
    "projectId='xxxx'\n",
    "dataset_id='yyyy'\n",
    "table_id = f\"{projectId}.{dataset_id}.new_result_prediction_incident\"\n",
    "\n",
    "credentials = service_account.Credentials.from_service_account_file(r'xxxxx.json')\n",
    "client = bigquery.Client(credentials= credentials,project=projectId)\n",
    "# client = bigquery.Client(project=projectId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fbb78d62-5704-46cc-9c35-f9fc3c0af632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    select id,predict_severity,prediction_datetime from smart-data-ml.SMartML.new_result_prediction_incident \n",
      "     where Date(prediction_datetime)='2023-04-03' \n"
     ]
    }
   ],
   "source": [
    "\n",
    "def load_data_bq(sql:str):\n",
    "\n",
    " query_result=client.query(sql)\n",
    " df_all=query_result.to_dataframe()\n",
    " return df_all\n",
    "\n",
    "if isLoadingAll:\n",
    "    sql=f\"\"\" select id,predict_severity,prediction_datetime from {table_id} \"\"\"\n",
    "else:\n",
    "    sql=f\"\"\"\n",
    "    select id,predict_severity,prediction_datetime from {table_id} \n",
    "     where Date(prediction_datetime)='{predict_datetime}' \"\"\"\n",
    "    \n",
    "print(sql)\n",
    "\n",
    "df=load_data_bq(sql)\n",
    "if len(df)>0:\n",
    "    df.columns=['incident_id','severity_label','prediction_at']\n",
    "else:\n",
    "    quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "48503275-c2de-49fe-a44d-340a17d7ea14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map severity Name to LabelCode: {0: 'Cosmatic', 1: 'Minor', 2: 'Major', 3: 'Critical'}\n"
     ]
    }
   ],
   "source": [
    "# load json file\n",
    "map_severity_to_class={'Cosmetic':0,'Minor': 1, \"Major\": 2, \"Critical\": 3}\n",
    "revert_class_to_severity = {v: k for k, v in map_severity_to_class.items()}\n",
    "\n",
    "print(f\"Map severity Name to LabelCode: {str(revert_class_to_severity)}\")\n",
    "\n",
    "df['severity_name']=df['severity_label'].map(revert_class_to_severity)\n",
    "\n",
    "update_at=datetime.now()\n",
    "df['imported_at']=update_at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "37273d71-bb0f-4dc6-887d-11ac95cfff61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3 entries, 0 to 2\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   incident_id     3 non-null      Int64         \n",
      " 1   severity_label  3 non-null      Int64         \n",
      " 2   prediction_at   3 non-null      datetime64[ns]\n",
      " 3   severity_name   3 non-null      object        \n",
      " 4   imported_at     3 non-null      datetime64[ns]\n",
      "dtypes: Int64(2), datetime64[ns](2), object(1)\n",
      "memory usage: 254.0+ bytes\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>incident_id</th>\n",
       "      <th>severity_label</th>\n",
       "      <th>prediction_at</th>\n",
       "      <th>severity_name</th>\n",
       "      <th>imported_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2575</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-04-03 19:00:29.655106</td>\n",
       "      <td>Minor</td>\n",
       "      <td>2023-04-04 19:13:31.863911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2576</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-04-03 19:00:29.655106</td>\n",
       "      <td>Minor</td>\n",
       "      <td>2023-04-04 19:13:31.863911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2577</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-04-03 19:00:29.655106</td>\n",
       "      <td>Minor</td>\n",
       "      <td>2023-04-04 19:13:31.863911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   incident_id  severity_label              prediction_at severity_name  \\\n",
       "0         2575               1 2023-04-03 19:00:29.655106         Minor   \n",
       "1         2576               1 2023-04-03 19:00:29.655106         Minor   \n",
       "2         2577               1 2023-04-03 19:00:29.655106         Minor   \n",
       "\n",
       "                 imported_at  \n",
       "0 2023-04-04 19:13:31.863911  \n",
       "1 2023-04-04 19:13:31.863911  \n",
       "2 2023-04-04 19:13:31.863911  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.info())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "284c8970-ea42-4bbc-897a-3cf601c7b645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144 items have been imported to database successfully.\n",
      "importing data succeeded\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import psycopg2.extras as extras\n",
    "\n",
    "def get_postgres_conn():\n",
    " try:\n",
    "  conn = psycopg2.connect(\n",
    "        database=config['DATABASES_NAME'], user=config['DATABASES_USER'],\n",
    "      password=config['DATABASES_PASSWORD'], host=config['DATABASES_HOST']\n",
    "     )\n",
    "  return conn\n",
    "\n",
    " except Exception as error:\n",
    "  print(error)      \n",
    "  raise error\n",
    "\n",
    "def add_data_values(df, table,conn):\n",
    "\n",
    "    tuples = [tuple(x) for x in df.to_numpy()]\n",
    "    # Comma-separated dataframe columns\n",
    "    cols = ','.join(list(df.columns))\n",
    "    # SQL quert to execute\n",
    "    query  = \"INSERT INTO %s(%s) VALUES %%s\" % (table, cols)\n",
    "    #print(query)\n",
    "    #return query,tuples\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        extras.execute_values(cursor, query, tuples)\n",
    "        conn.commit()\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(\"Error: %s\" % error)\n",
    "        conn.rollback()\n",
    "        cursor.close()\n",
    "        raise error\n",
    "        return 0\n",
    "    \n",
    "    return 1\n",
    "    cursor.close()\n",
    "    \n",
    "result=add_data_values(df,'app_prediction_ml_severity_incident',get_postgres_conn())\n",
    "\n",
    "if  result==1:\n",
    "    print(f\"{len(df.index)} items have been imported to database successfully.\")\n",
    "    print(\"importing data succeeded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef32954-4ef2-4ea1-a702-3f9f8c569168",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
