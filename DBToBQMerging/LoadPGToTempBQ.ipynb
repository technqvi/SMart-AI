{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imported Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "import psycopg2.extras as extras\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime,timezone\n",
    "from dateutil import tz\n",
    "\n",
    "import os\n",
    "import sys \n",
    "\n",
    "from configupdater import ConfigUpdater\n",
    "# pip install ConfigUpdater\n",
    "\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from google.cloud.exceptions import NotFound\n",
    "from google.api_core.exceptions import BadRequest\n",
    "from google.oauth2 import service_account\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View name to load to BQ :pmr_pm_item\n"
     ]
    }
   ],
   "source": [
    "is_py=False\n",
    "view_name = \"pmr_pm_item\"\n",
    "isFirstLoad=False\n",
    "if is_py:\n",
    "    press_Y=''\n",
    "    ok=False\n",
    "\n",
    "    if len(sys.argv) > 1:\n",
    "        view_name=sys.argv[1]\n",
    "    else:\n",
    "        print(\"Enter the following input: \")\n",
    "        view_name = input(\"View Table Name : \")\n",
    "print(f\"View name to load to BQ :{view_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imported date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UTC: 2023-12-29 17:50:01\n"
     ]
    }
   ],
   "source": [
    "dt_imported=datetime.now(timezone.utc) # utc\n",
    "dt_imported=datetime.strptime(dt_imported.strftime(\"%Y-%m-%d %H:%M:%S\"),\"%Y-%m-%d %H:%M:%S\")\n",
    "print(f\"UTC: {dt_imported}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "log = \"models_logging_change\"\n",
    "if view_name == \"pmr_pm_plan\":\n",
    "    content_id = 36\n",
    "    view_name_id = \"pm_id\"\n",
    "\n",
    "elif view_name == \"pmr_pm_item\":\n",
    "    content_id = 37\n",
    "    view_name_id = \"pm_item_id\"\n",
    "\n",
    "elif view_name == \"pmr_project\":\n",
    "    content_id = 7\n",
    "    view_name_id = \"project_id\"\n",
    "\n",
    "elif view_name == \"pmr_inventory\":\n",
    "    content_id = 14\n",
    "    view_name_id = \"inventory_id\"\n",
    "\n",
    "else:\n",
    "    raise Exception(\"No specified content type id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set data and cofig path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "projectId='smart-data-ml'  # smart-data-ml  or kku-intern-dataai\n",
    "dataset_id='SMartData_Temp'  # 'SMartData_Temp'  'PMReport_Temp'\n",
    "main_dataset_id='SMartDataAnalytics'  # ='SMartDataAnalytics'  'PMReport_Main'\n",
    "credential_file=r\"C:\\Windows\\smart-data-ml-91b6f6204773.json\"  \n",
    "# C:\\Windows\\smart-data-ml-91b6f6204773.json\n",
    "# C:\\Windows\\kku-intern-dataai-a5449aee8483.json\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smart-data-ml.SMartData_Temp.temp_pm_item\n",
      "smart-data-ml.SMartDataAnalytics.pm_item\n"
     ]
    }
   ],
   "source": [
    "credentials = service_account.Credentials.from_service_account_file(credential_file)\n",
    "\n",
    "table_name=view_name.replace(\"pmr_\",\"temp_\") #can change in (\"name\") to temp table\n",
    "table_id = f\"{projectId}.{dataset_id}.{table_name}\"\n",
    "print(table_id)\n",
    "\n",
    "\n",
    "main_table_name=view_name.replace(\"pmr_\",\"\")\n",
    "main_table_id = f\"{projectId}.{main_dataset_id}.{main_table_name}\"\n",
    "print(main_table_id)\n",
    "\n",
    "# https://cloud.google.com/bigquery/docs/reference/rest/v2/Job\n",
    "to_bq_mode=\"WRITE_EMPTY\"\n",
    "\n",
    "\n",
    "client = bigquery.Client(credentials= credentials,project=projectId)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Configuration File and Initialize BQ Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "updater = ConfigUpdater()\n",
    "updater.read(\".cfg\")\n",
    "\n",
    "env_path='.env'\n",
    "config = dotenv_values(dotenv_path=env_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UTC:2023-12-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "last_imported=datetime.strptime(updater[\"metadata\"][view_name].value,\"%Y-%m-%d %H:%M:%S\")\n",
    "print(f\"UTC:{last_imported}\")\n",
    "\n",
    "# local_zone = tz.tzlocal()\n",
    "# last_imported = last_imported.astimezone(local_zone)\n",
    "# print(f\"Local Asia/Bangkok:{last_imported}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Postgres &BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_postgres_conn():\n",
    " try:\n",
    "  conn = psycopg2.connect(\n",
    "        database=config['DATABASES_NAME'], user=config['DATABASES_USER'],\n",
    "      password=config['DATABASES_PASSWORD'], host=config['DATABASES_HOST']\n",
    "     )\n",
    "  return conn\n",
    "\n",
    " except Exception as error:\n",
    "  print(error)      \n",
    "  raise error\n",
    "def list_data(sql,params,connection):\n",
    " df=None   \n",
    " with connection.cursor() as cursor:\n",
    "    \n",
    "    if params is None:\n",
    "       cursor.execute(sql)\n",
    "    else:\n",
    "       cursor.execute(sql,params)\n",
    "    \n",
    "    columns = [col[0] for col in cursor.description]\n",
    "    dataList = [dict(zip(columns, row)) for row in cursor.fetchall()]\n",
    "    df = pd.DataFrame(data=dataList) \n",
    " return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_bq_table():\n",
    " try:\n",
    "    table=client.get_table(table_id)  # Make an API request.\n",
    "    print(\"Table {} already exists.\".format(table_id))\n",
    "    print(table.schema)\n",
    "    return True\n",
    " except NotFound:\n",
    "    raise Exception(\"Table {} is not found.\".format(table_id))\n",
    "    \n",
    "def collectBQError(x_job):\n",
    " if x_job.errors is not None:\n",
    "    for error in x_job.errors:  \n",
    "      msg=f\"{error['reason']} - {error['message']}\"\n",
    "      listError.append([datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),dtStr_imported,source_name,msg])\n",
    "    if   len(listError)>0:\n",
    "     logErrorMessage(listError,False)  \n",
    "\n",
    "    \n",
    "def insertDataFrameToBQ(df_trasns):\n",
    "    try:\n",
    "        job_config = bigquery.LoadJobConfig(write_disposition=to_bq_mode,)\n",
    "        job = client.load_table_from_dataframe(df_trasns, table_id, job_config=job_config)\n",
    "        try:\n",
    "         job.result()  # Wait for the job to complete.\n",
    "        except ClientError as e:\n",
    "         print(job.errors)\n",
    "\n",
    "        print(\"Total \", len(df_trasns), f\"Imported data to {table_id} on bigquery successfully\")\n",
    "\n",
    "    except BadRequest as e:\n",
    "        print(\"Bigquery Error\\n\")\n",
    "        print(e) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check whether it is the first loading?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If the main table is empty , so the action of each row  must be 'added' on temp table\n",
      "This is the first loaing , so there is No DATA in smart-data-ml.SMartDataAnalytics.pm_item, we load all rows from pmr_pm_item to import into smart-data-ml.SMartData_Temp.temp_pm_item action will be 'added' \n"
     ]
    }
   ],
   "source": [
    "print(\"If the main table is empty , so the action of each row  must be 'added' on temp table\")\n",
    "rows_iter   = client.list_rows(main_table_id, max_results=1) \n",
    "no_main=len(list(rows_iter))\n",
    "if no_main==0:\n",
    " isFirstLoad=True\n",
    " print(f\"This is the first loaing , so there is No DATA in {main_table_id}, we load all rows from {view_name} to import into {table_id} action will be 'added' \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For The next Load\n",
    "* get data from model log based on condition last_imported and table\n",
    "* Get all actions from log table by selecting unique object_id and setting by doing something as logic\n",
    "* Create  id and action dataframe form filtered rows from log table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def list_model_log(x_last_imported,x_content_id):\n",
    "    sql_log = f\"\"\"\n",
    "    SELECT object_id, action,TO_CHAR(date_created,'YYYY-MM-DD HH24:MI:SS') as date_created FROM {log}\n",
    "    WHERE date_created  AT time zone 'utc' >= '{x_last_imported}' AND content_type_id = {x_content_id} ORDER BY object_id, date_created\n",
    "    \"\"\"\n",
    "    print(sql_log)\n",
    "\n",
    "\n",
    "    # Asia/Bangkok \n",
    "    lf = list_data(sql_log, None, get_postgres_conn())\n",
    "    print(f\"Retrieve all rows after {last_imported}\")\n",
    "    print(lf.info())\n",
    "    return lf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def select_actual_action(lf):\n",
    "    listIDs=lf[\"object_id\"].unique().tolist()\n",
    "    listUpdateData=[]\n",
    "    for id in listIDs:\n",
    "        lfTemp=lf.query(\"object_id==@id\")\n",
    "        # print(lfTemp)\n",
    "        # print(\"----------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "        first_row = lfTemp.iloc[0]\n",
    "        last_row = lfTemp.iloc[-1]\n",
    "        # print(first_row)\n",
    "        # print(last_row)\n",
    "\n",
    "        if len(lfTemp)==1:\n",
    "            listUpdateData.append([id,first_row[\"action\"]])\n",
    "        else:\n",
    "            if first_row[\"action\"] == \"added\" and last_row[\"action\"] == \"deleted\":\n",
    "                continue\n",
    "            elif first_row[\"action\"] == \"added\" and last_row[\"action\"] != \"deleted\":\n",
    "                listUpdateData.append([id,\"added\"])\n",
    "            else : listUpdateData.append([id,last_row[\"action\"]])\n",
    "\n",
    "    print(\"Convert listUpdate to dataframe\")\n",
    "    dfUpdateData = pd.DataFrame(listUpdateData, columns= ['id', 'action'])\n",
    "    dfUpdateData['id'] = dfUpdateData['id'].astype('int64')\n",
    "    dfUpdateData=dfUpdateData.sort_values(by=\"id\")\n",
    "    dfUpdateData=dfUpdateData.reset_index(drop=True)\n",
    "\n",
    "    return dfUpdateData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if isFirstLoad==False:\n",
    "    dfModelLog=list_model_log(last_imported,content_id)\n",
    "    if dfModelLog.empty==True:\n",
    "        print(\"No row to be imported.\")\n",
    "        exit()\n",
    "    else:\n",
    "       dfModelLog=select_actual_action( dfModelLog)\n",
    "       listModelLogObjectIDs=dfModelLog['id'].tolist()\n",
    "       print(dfModelLog.info())\n",
    "       print(dfModelLog)       \n",
    "       print(listModelLogObjectIDs) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load view and transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select *  from pmr_pm_item  where  updated_at AT time zone 'utc' >= '2023-12-01 00:00:00'\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6204 entries, 0 to 6203\n",
      "Data columns (total 10 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   pm_item_id         6204 non-null   int64 \n",
      " 1   pm_id              6204 non-null   int64 \n",
      " 2   is_pm              6204 non-null   bool  \n",
      " 3   pm_engineer        297 non-null    object\n",
      " 4   actual_date        298 non-null    object\n",
      " 5   document_engineer  295 non-null    object\n",
      " 6   document_date      296 non-null    object\n",
      " 7   inventory_id       6204 non-null   int64 \n",
      " 8   is_complete        6204 non-null   bool  \n",
      " 9   action             6204 non-null   object\n",
      "dtypes: bool(2), int64(3), object(5)\n",
      "memory usage: 400.0+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pm_item_id</th>\n",
       "      <th>pm_id</th>\n",
       "      <th>is_pm</th>\n",
       "      <th>pm_engineer</th>\n",
       "      <th>actual_date</th>\n",
       "      <th>document_engineer</th>\n",
       "      <th>document_date</th>\n",
       "      <th>inventory_id</th>\n",
       "      <th>is_complete</th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>103662</td>\n",
       "      <td>5034</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>14216</td>\n",
       "      <td>False</td>\n",
       "      <td>added</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>103663</td>\n",
       "      <td>5034</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>14217</td>\n",
       "      <td>False</td>\n",
       "      <td>added</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103664</td>\n",
       "      <td>5034</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>14218</td>\n",
       "      <td>False</td>\n",
       "      <td>added</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103665</td>\n",
       "      <td>5034</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>14219</td>\n",
       "      <td>False</td>\n",
       "      <td>added</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>103666</td>\n",
       "      <td>5034</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>14222</td>\n",
       "      <td>False</td>\n",
       "      <td>added</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6199</th>\n",
       "      <td>103755</td>\n",
       "      <td>5050</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>19109</td>\n",
       "      <td>False</td>\n",
       "      <td>added</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6200</th>\n",
       "      <td>103756</td>\n",
       "      <td>5050</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>19110</td>\n",
       "      <td>False</td>\n",
       "      <td>added</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6201</th>\n",
       "      <td>103757</td>\n",
       "      <td>5051</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>19108</td>\n",
       "      <td>False</td>\n",
       "      <td>added</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6202</th>\n",
       "      <td>103758</td>\n",
       "      <td>5051</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>19109</td>\n",
       "      <td>False</td>\n",
       "      <td>added</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6203</th>\n",
       "      <td>103759</td>\n",
       "      <td>5051</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>19110</td>\n",
       "      <td>False</td>\n",
       "      <td>added</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6204 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pm_item_id  pm_id  is_pm pm_engineer actual_date document_engineer  \\\n",
       "0         103662   5034  False        None        None              None   \n",
       "1         103663   5034  False        None        None              None   \n",
       "2         103664   5034  False        None        None              None   \n",
       "3         103665   5034  False        None        None              None   \n",
       "4         103666   5034   True        None        None              None   \n",
       "...          ...    ...    ...         ...         ...               ...   \n",
       "6199      103755   5050   True        None        None              None   \n",
       "6200      103756   5050   True        None        None              None   \n",
       "6201      103757   5051   True        None        None              None   \n",
       "6202      103758   5051   True        None        None              None   \n",
       "6203      103759   5051   True        None        None              None   \n",
       "\n",
       "     document_date  inventory_id  is_complete action  \n",
       "0             None         14216        False  added  \n",
       "1             None         14217        False  added  \n",
       "2             None         14218        False  added  \n",
       "3             None         14219        False  added  \n",
       "4             None         14222        False  added  \n",
       "...            ...           ...          ...    ...  \n",
       "6199          None         19109        False  added  \n",
       "6200          None         19110        False  added  \n",
       "6201          None         19108        False  added  \n",
       "6202          None         19109        False  added  \n",
       "6203          None         19110        False  added  \n",
       "\n",
       "[6204 rows x 10 columns]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if isFirstLoad==False:\n",
    "    if len(listModelLogObjectIDs)>1:\n",
    "     sql_view=f\"select *  from {view_name}  where {view_name_id} in {tuple(listModelLogObjectIDs)}\"\n",
    "    else:\n",
    "     sql_view=f\"select *  from {view_name}  where {view_name_id} ={listModelLogObjectIDs[0]}\"\n",
    "else:\n",
    "     sql_view=f\"select *  from {view_name}  where  updated_at AT time zone 'utc' >= '{last_imported}'\"\n",
    "        \n",
    "\n",
    "print(sql_view)\n",
    "df=list_data(sql_view,None,get_postgres_conn())\n",
    "\n",
    "\n",
    "if df.empty==True:\n",
    "    print(\"No row to be imported.\")\n",
    "    exit()\n",
    "\n",
    "df=df.drop(columns='updated_at')\n",
    "\n",
    "\n",
    "if isFirstLoad:\n",
    "    df['action']='added'\n",
    "    \n",
    "print(df.info())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Transaformation\n",
    "* IF The first load then add actio='Added'\n",
    "* IF The nextload then Merge LogDF and ViewDF and add deleted row \n",
    "  * Get Deleted Items  to Create deleted dataframe by using listDeleted\n",
    "  * If there is one deletd row then  we will merge it to master dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_acutal_action_to_df_at_next(df,dfUpdateData):\n",
    "    merged_df = pd.merge(df, dfUpdateData, left_on=view_name_id, right_on='id', how='inner')\n",
    "    merged_df = merged_df.drop(columns=['id'])\n",
    "\n",
    "    listSelected = df[view_name_id].tolist()\n",
    "    print(listSelected)\n",
    "\n",
    "    set1 = set(listModelLogObjectIDs)\n",
    "    set2 = set(listSelected)\n",
    "    listDeleted = list(set1.symmetric_difference(set2))\n",
    "\n",
    "    print(listDeleted)\n",
    "\n",
    "    if len(listDeleted)>0:\n",
    "        print(\"There are some deleted rows\")\n",
    "        dfDeleted=pd.DataFrame(data=listDeleted,columns=[view_name_id])\n",
    "        dfDeleted['action']='deleted'\n",
    "        print(dfDeleted)\n",
    "        merged_df=pd.concat([merged_df,dfDeleted],axis=0)\n",
    "\n",
    "    else:\n",
    "        print(\"No row deleted\")\n",
    "\n",
    "    return merged_df    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check duplicate ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6204 entries, 0 to 6203\n",
      "Data columns (total 10 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   pm_item_id         6204 non-null   int64 \n",
      " 1   pm_id              6204 non-null   int64 \n",
      " 2   is_pm              6204 non-null   bool  \n",
      " 3   pm_engineer        297 non-null    object\n",
      " 4   actual_date        298 non-null    object\n",
      " 5   document_engineer  295 non-null    object\n",
      " 6   document_date      296 non-null    object\n",
      " 7   inventory_id       6204 non-null   int64 \n",
      " 8   is_complete        6204 non-null   bool  \n",
      " 9   action             6204 non-null   object\n",
      "dtypes: bool(2), int64(3), object(5)\n",
      "memory usage: 400.0+ KB\n",
      "None\n",
      "      pm_item_id  pm_id  is_pm pm_engineer actual_date document_engineer  \\\n",
      "0         103662   5034  False        None        None              None   \n",
      "1         103663   5034  False        None        None              None   \n",
      "2         103664   5034  False        None        None              None   \n",
      "3         103665   5034  False        None        None              None   \n",
      "4         103666   5034   True        None        None              None   \n",
      "...          ...    ...    ...         ...         ...               ...   \n",
      "6199      103755   5050   True        None        None              None   \n",
      "6200      103756   5050   True        None        None              None   \n",
      "6201      103757   5051   True        None        None              None   \n",
      "6202      103758   5051   True        None        None              None   \n",
      "6203      103759   5051   True        None        None              None   \n",
      "\n",
      "     document_date  inventory_id  is_complete action  \n",
      "0             None         14216        False  added  \n",
      "1             None         14217        False  added  \n",
      "2             None         14218        False  added  \n",
      "3             None         14219        False  added  \n",
      "4             None         14222        False  added  \n",
      "...            ...           ...          ...    ...  \n",
      "6199          None         19109        False  added  \n",
      "6200          None         19110        False  added  \n",
      "6201          None         19108        False  added  \n",
      "6202          None         19109        False  added  \n",
      "6203          None         19110        False  added  \n",
      "\n",
      "[6204 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "if isFirstLoad==False:\n",
    " df=add_acutal_action_to_df_at_next(df,dfModelLog)\n",
    " \n",
    "\n",
    "# merged_df['imported_at']=dt_imported\n",
    "df=df.reset_index(drop=True  )\n",
    "print(df.info())\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no duplicate pm_item_id ID\n"
     ]
    }
   ],
   "source": [
    "hasDplicateIDs = df[view_name_id].duplicated().any()\n",
    "if  hasDplicateIDs:\n",
    " raise Exception(\"There are some duplicate id on dfUpdateData\")\n",
    "else:\n",
    " print(f\"There is no duplicate {view_name_id} ID\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insert data to BQ data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table smart-data-ml.SMartData_Temp.temp_pm_item already exists.\n",
      "[SchemaField('pm_item_id', 'INTEGER', 'NULLABLE', None, None, (), None), SchemaField('pm_id', 'INTEGER', 'NULLABLE', None, None, (), None), SchemaField('is_pm', 'BOOLEAN', 'NULLABLE', None, None, (), None), SchemaField('pm_engineer', 'STRING', 'NULLABLE', None, None, (), None), SchemaField('actual_date', 'DATE', 'NULLABLE', None, None, (), None), SchemaField('document_engineer', 'STRING', 'NULLABLE', None, None, (), None), SchemaField('document_date', 'DATE', 'NULLABLE', None, None, (), None), SchemaField('inventory_id', 'INTEGER', 'NULLABLE', None, None, (), None), SchemaField('is_complete', 'BOOLEAN', 'NULLABLE', None, None, (), None), SchemaField('action', 'STRING', 'NULLABLE', None, None, (), None)]\n",
      "Total  6204 Imported data to smart-data-ml.SMartData_Temp.temp_pm_item on bigquery successfully\n"
     ]
    }
   ],
   "source": [
    "if get_bq_table():\n",
    "    try:\n",
    "        insertDataFrameToBQ(df)\n",
    "    except Exception as ex:\n",
    "        raise ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ConfigUpdater [\n",
       "    <Section: 'metadata' [\n",
       "        <Option: pmr_pm_plan = '2023-12-29 17:09:53'>\n",
       "        <Option: pmr_pm_item = '2023-12-29 17:50:01'>\n",
       "        <Option: pmr_project = '2023-12-01 00:00:00'>\n",
       "        <Option: pmr_inventory = '2023-12-01 00:00:00'>\n",
       "    ]>\n",
       "]>"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updater[\"metadata\"][view_name].value=dt_imported.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "updater.update_file() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-29 17:50:36.836521+00:00\n"
     ]
    }
   ],
   "source": [
    "print(datetime.now(timezone.utc) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
