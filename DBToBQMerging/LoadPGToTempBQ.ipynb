{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imported Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "import psycopg2.extras as extras\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime,timezone\n",
    "from dateutil import tz\n",
    "\n",
    "import os\n",
    "import sys \n",
    "\n",
    "from configupdater import ConfigUpdater\n",
    "# pip install ConfigUpdater\n",
    "\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from google.cloud.exceptions import NotFound\n",
    "from google.api_core.exceptions import BadRequest\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "# [metadata]\n",
    "# pmr_pm_plan = 2019-01-01 00:00:00\n",
    "# pmr_pm_item = 2019-01-01 00:00:00\n",
    "# pmr_project = 2019-01-01 00:00:00\n",
    "# pmr_inventory  = 2019-01-01 00:00:00\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View name to load to BQ :pmr_pm_item\n"
     ]
    }
   ],
   "source": [
    "is_py=False\n",
    "view_name = \"pmr_pm_item\"\n",
    "isFirstLoad=False\n",
    "if is_py:\n",
    "    press_Y=''\n",
    "    ok=False\n",
    "\n",
    "    if len(sys.argv) > 1:\n",
    "        view_name=sys.argv[1]\n",
    "    else:\n",
    "        print(\"Enter the following input: \")\n",
    "        view_name = input(\"View Table Name : \")\n",
    "print(f\"View name to load to BQ :{view_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imported date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UTC: 2023-12-30 06:21:12\n"
     ]
    }
   ],
   "source": [
    "dt_imported=datetime.now(timezone.utc) # utc\n",
    "dt_imported=datetime.strptime(dt_imported.strftime(\"%Y-%m-%d %H:%M:%S\"),\"%Y-%m-%d %H:%M:%S\")\n",
    "print(f\"UTC: {dt_imported}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "log = \"models_logging_change\"\n",
    "if view_name == \"pmr_pm_plan\":\n",
    "    content_id = 36\n",
    "    view_name_id = \"pm_id\"\n",
    "\n",
    "elif view_name == \"pmr_pm_item\":\n",
    "    content_id = 37\n",
    "    view_name_id = \"pm_item_id\"\n",
    "\n",
    "elif view_name == \"pmr_project\":\n",
    "    content_id = 7\n",
    "    view_name_id = \"project_id\"\n",
    "\n",
    "elif view_name == \"pmr_inventory\":\n",
    "    content_id = 14\n",
    "    view_name_id = \"inventory_id\"\n",
    "\n",
    "else:\n",
    "    raise Exception(\"No specified content type id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set data and cofig path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "updater = ConfigUpdater()\n",
    "updater.read(\".cfg\")\n",
    "\n",
    "env_path='.env'\n",
    "config = dotenv_values(dotenv_path=env_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "projectId=config['PROJECT_ID']  # smart-data-ml  or kku-intern-dataai or ponthorn\n",
    "credential_file=config['PROJECT_CREDENTIAL_FILE']\n",
    "# C:\\Windows\\smart-data-ml-91b6f6204773.json\n",
    "# C:\\Windows\\kku-intern-dataai-a5449aee8483.json\n",
    "# C:\\Windows\\pongthorn-5decdc5124f5.json\n",
    "\n",
    "\n",
    "dataset_id='SMartData_Temp'  # 'SMartData_Temp'  'PMReport_Temp'\n",
    "main_dataset_id='SMartDataAnalytics'  # ='SMartDataAnalytics'  'PMReport_Main'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pongthorn.SMartData_Temp.temp_pm_item\n",
      "pongthorn.SMartDataAnalytics.pm_item\n"
     ]
    }
   ],
   "source": [
    "credentials = service_account.Credentials.from_service_account_file(credential_file)\n",
    "\n",
    "table_name=view_name.replace(\"pmr_\",\"temp_\") #can change in (\"name\") to temp table\n",
    "table_id = f\"{projectId}.{dataset_id}.{table_name}\"\n",
    "print(table_id)\n",
    "\n",
    "\n",
    "main_table_name=view_name.replace(\"pmr_\",\"\")\n",
    "main_table_id = f\"{projectId}.{main_dataset_id}.{main_table_name}\"\n",
    "print(main_table_id)\n",
    "\n",
    "# https://cloud.google.com/bigquery/docs/reference/rest/v2/Job\n",
    "to_bq_mode=\"WRITE_EMPTY\"\n",
    "\n",
    "\n",
    "client = bigquery.Client(credentials= credentials,project=projectId)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Configuration File and Initialize BQ Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UTC:2023-12-30 06:15:43\n"
     ]
    }
   ],
   "source": [
    "last_imported=datetime.strptime(updater[\"metadata\"][view_name].value,\"%Y-%m-%d %H:%M:%S\")\n",
    "print(f\"UTC:{last_imported}\")\n",
    "\n",
    "# local_zone = tz.tzlocal()\n",
    "# last_imported = last_imported.astimezone(local_zone)\n",
    "# print(f\"Local Asia/Bangkok:{last_imported}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Postgres &BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_postgres_conn():\n",
    " try:\n",
    "  conn = psycopg2.connect(\n",
    "        database=config['DATABASES_NAME'], user=config['DATABASES_USER'],\n",
    "      password=config['DATABASES_PASSWORD'], host=config['DATABASES_HOST']\n",
    "     )\n",
    "  return conn\n",
    "\n",
    " except Exception as error:\n",
    "  print(error)      \n",
    "  raise error\n",
    "def list_data(sql,params,connection):\n",
    " df=None   \n",
    " with connection.cursor() as cursor:\n",
    "    \n",
    "    if params is None:\n",
    "       cursor.execute(sql)\n",
    "    else:\n",
    "       cursor.execute(sql,params)\n",
    "    \n",
    "    columns = [col[0] for col in cursor.description]\n",
    "    dataList = [dict(zip(columns, row)) for row in cursor.fetchall()]\n",
    "    df = pd.DataFrame(data=dataList) \n",
    " return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_bq_table():\n",
    " try:\n",
    "    table=client.get_table(table_id)  # Make an API request.\n",
    "    print(\"Table {} already exists.\".format(table_id))\n",
    "    print(table.schema)\n",
    "    return True\n",
    " except NotFound:\n",
    "    raise Exception(\"Table {} is not found.\".format(table_id))\n",
    "    \n",
    "def collectBQError(x_job):\n",
    " if x_job.errors is not None:\n",
    "    for error in x_job.errors:  \n",
    "      msg=f\"{error['reason']} - {error['message']}\"\n",
    "      listError.append([datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),dtStr_imported,source_name,msg])\n",
    "    if   len(listError)>0:\n",
    "     logErrorMessage(listError,False)  \n",
    "\n",
    "    \n",
    "def insertDataFrameToBQ(df_trasns):\n",
    "    try:\n",
    "        job_config = bigquery.LoadJobConfig(write_disposition=to_bq_mode,)\n",
    "        job = client.load_table_from_dataframe(df_trasns, table_id, job_config=job_config)\n",
    "        try:\n",
    "         job.result()  # Wait for the job to complete.\n",
    "        except ClientError as e:\n",
    "         print(job.errors)\n",
    "\n",
    "        print(\"Total \", len(df_trasns), f\"Imported data to {table_id} on bigquery successfully\")\n",
    "\n",
    "    except BadRequest as e:\n",
    "        print(\"Bigquery Error\\n\")\n",
    "        print(e) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check whether it is the first loading?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If the main table is empty , so the action of each row  must be 'added' on temp table\n"
     ]
    }
   ],
   "source": [
    "print(\"If the main table is empty , so the action of each row  must be 'added' on temp table\")\n",
    "rows_iter   = client.list_rows(main_table_id, max_results=1) \n",
    "no_main=len(list(rows_iter))\n",
    "if no_main==0:\n",
    " isFirstLoad=True\n",
    " print(f\"This is the first loaing , so there is No DATA in {main_table_id}, we load all rows from {view_name} to import into {table_id} action will be 'added' \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For The next Load\n",
    "* get data from model log based on condition last_imported and table\n",
    "* Get all actions from log table by selecting unique object_id and setting by doing something as logic\n",
    "* Create  id and action dataframe form filtered rows from log table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def list_model_log(x_last_imported,x_content_id):\n",
    "    sql_log = f\"\"\"\n",
    "    SELECT object_id, action,TO_CHAR(date_created,'YYYY-MM-DD HH24:MI:SS') as date_created FROM {log}\n",
    "    WHERE date_created  AT time zone 'utc' >= '{x_last_imported}' AND content_type_id = {x_content_id} \n",
    "    ORDER BY object_id, date_created\n",
    "    \"\"\"\n",
    "    print(sql_log)\n",
    "\n",
    "\n",
    "    # Asia/Bangkok \n",
    "    lf = list_data(sql_log, None, get_postgres_conn())\n",
    "    print(f\"Retrieve all rows after {last_imported}\")\n",
    "    print(lf.info())\n",
    "    return lf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def select_actual_action(lf):\n",
    "    listIDs=lf[\"object_id\"].unique().tolist()\n",
    "    listUpdateData=[]\n",
    "    for id in listIDs:\n",
    "        lfTemp=lf.query(\"object_id==@id\")\n",
    "        print(lfTemp)\n",
    "        print(\"----------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "        first_row = lfTemp.iloc[0]\n",
    "        last_row = lfTemp.iloc[-1]\n",
    "        # print(first_row)\n",
    "        # print(last_row)\n",
    "\n",
    "        if len(lfTemp)==1:\n",
    "            listUpdateData.append([id,first_row[\"action\"]])\n",
    "        else:\n",
    "            if first_row[\"action\"] == \"added\" and last_row[\"action\"] == \"deleted\":\n",
    "                continue\n",
    "            elif first_row[\"action\"] == \"added\" and last_row[\"action\"] != \"deleted\":\n",
    "                listUpdateData.append([id,\"added\"])\n",
    "            else : listUpdateData.append([id,last_row[\"action\"]])\n",
    "\n",
    "    print(\"Convert listUpdate to dataframe\")\n",
    "    dfUpdateData = pd.DataFrame(listUpdateData, columns= ['id', 'action'])\n",
    "    dfUpdateData['id'] = dfUpdateData['id'].astype('int64')\n",
    "    dfUpdateData=dfUpdateData.sort_values(by=\"id\")\n",
    "    dfUpdateData=dfUpdateData.reset_index(drop=True)\n",
    "\n",
    "    return dfUpdateData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    SELECT object_id, action,TO_CHAR(date_created,'YYYY-MM-DD HH24:MI:SS') as date_created FROM models_logging_change\n",
      "    WHERE date_created  AT time zone 'utc' >= '2023-12-30 06:15:43' AND content_type_id = 37 \n",
      "    ORDER BY object_id, date_created\n",
      "    \n",
      "Retrieve all rows after 2023-12-30 06:15:43\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6 entries, 0 to 5\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   object_id     6 non-null      object\n",
      " 1   action        6 non-null      object\n",
      " 2   date_created  6 non-null      object\n",
      "dtypes: object(3)\n",
      "memory usage: 272.0+ bytes\n",
      "None\n",
      "Get row imported from model log to set action\n",
      "  object_id   action         date_created\n",
      "0    105979  changed  2023-12-30 13:19:31\n",
      "----------------------------------------------------------------\n",
      "  object_id   action         date_created\n",
      "1    105980  changed  2023-12-30 13:19:31\n",
      "----------------------------------------------------------------\n",
      "  object_id   action         date_created\n",
      "2    105981  changed  2023-12-30 13:18:57\n",
      "----------------------------------------------------------------\n",
      "  object_id action         date_created\n",
      "3    106008  added  2023-12-30 13:20:38\n",
      "----------------------------------------------------------------\n",
      "  object_id action         date_created\n",
      "4    106009  added  2023-12-30 13:20:38\n",
      "----------------------------------------------------------------\n",
      "  object_id action         date_created\n",
      "5    106010  added  2023-12-30 13:20:38\n",
      "----------------------------------------------------------------\n",
      "Convert listUpdate to dataframe\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6 entries, 0 to 5\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      6 non-null      int64 \n",
      " 1   action  6 non-null      object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 224.0+ bytes\n",
      "None\n",
      "       id   action\n",
      "0  105979  changed\n",
      "1  105980  changed\n",
      "2  105981  changed\n",
      "3  106008    added\n",
      "4  106009    added\n",
      "5  106010    added\n",
      "[105979, 105980, 105981, 106008, 106009, 106010]\n"
     ]
    }
   ],
   "source": [
    "if isFirstLoad==False:\n",
    "    listModelLogObjectIDs=[]\n",
    "    dfModelLog=list_model_log(last_imported,content_id)\n",
    "    if dfModelLog.empty==True:\n",
    "        print(\"No row to be imported.\")\n",
    "        exit()\n",
    "    else:\n",
    "       print(\"Get row imported from model log to set action\") \n",
    "       dfModelLog=select_actual_action( dfModelLog)\n",
    "       listModelLogObjectIDs=dfModelLog['id'].tolist()\n",
    "       print(dfModelLog.info())\n",
    "       print(dfModelLog)       \n",
    "       print(listModelLogObjectIDs) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load view and transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select *  from pmr_pm_item  where pm_item_id in (105979, 105980, 105981, 106008, 106009, 106010)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6 entries, 0 to 5\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   pm_item_id         6 non-null      int64 \n",
      " 1   pm_id              6 non-null      int64 \n",
      " 2   is_pm              6 non-null      bool  \n",
      " 3   pm_engineer        2 non-null      object\n",
      " 4   actual_date        2 non-null      object\n",
      " 5   document_engineer  0 non-null      object\n",
      " 6   document_date      0 non-null      object\n",
      " 7   inventory_id       6 non-null      int64 \n",
      " 8   is_complete        6 non-null      bool  \n",
      "dtypes: bool(2), int64(3), object(4)\n",
      "memory usage: 476.0+ bytes\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pm_item_id</th>\n",
       "      <th>pm_id</th>\n",
       "      <th>is_pm</th>\n",
       "      <th>pm_engineer</th>\n",
       "      <th>actual_date</th>\n",
       "      <th>document_engineer</th>\n",
       "      <th>document_date</th>\n",
       "      <th>inventory_id</th>\n",
       "      <th>is_complete</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105979</td>\n",
       "      <td>5248</td>\n",
       "      <td>True</td>\n",
       "      <td>Akaradej Ketruskul</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>11563</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105980</td>\n",
       "      <td>5248</td>\n",
       "      <td>True</td>\n",
       "      <td>Akaradej Ketruskul</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>11562</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>105981</td>\n",
       "      <td>5248</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>12279</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106008</td>\n",
       "      <td>5256</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>11562</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>106009</td>\n",
       "      <td>5256</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>11563</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>106010</td>\n",
       "      <td>5256</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>12279</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pm_item_id  pm_id  is_pm         pm_engineer actual_date document_engineer  \\\n",
       "0      105979   5248   True  Akaradej Ketruskul  2024-01-01              None   \n",
       "1      105980   5248   True  Akaradej Ketruskul  2024-01-01              None   \n",
       "2      105981   5248  False                None        None              None   \n",
       "3      106008   5256   True                None        None              None   \n",
       "4      106009   5256   True                None        None              None   \n",
       "5      106010   5256   True                None        None              None   \n",
       "\n",
       "  document_date  inventory_id  is_complete  \n",
       "0          None         11563        False  \n",
       "1          None         11562        False  \n",
       "2          None         12279        False  \n",
       "3          None         11562        False  \n",
       "4          None         11563        False  \n",
       "5          None         12279        False  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def retrive_next_data_from_view(x_view,x_id,x_listModelLogObjectIDs):\n",
    "    if len(x_listModelLogObjectIDs)>1:\n",
    "     sql_view=f\"select *  from {x_view}  where {x_id} in {tuple(x_listModelLogObjectIDs)}\"\n",
    "    else:\n",
    "     sql_view=f\"select *  from {x_view}  where {x_id} ={x_listModelLogObjectIDs[0]}\"\n",
    "    \n",
    "    print(sql_view)\n",
    "    df=list_data(sql_view,None,get_postgres_conn())\n",
    "\n",
    "    if df.empty==True:\n",
    "     return None\n",
    "    df=df.drop(columns='updated_at')\n",
    "    return df \n",
    "\n",
    "\n",
    "def retrive_first_data_from_view(x_view,x_last_imported):\n",
    "     sql_view=f\"select *  from {x_view}  where  updated_at AT time zone 'utc' >= '{x_last_imported}'\"\n",
    "     print(sql_view)\n",
    "     df=list_data(sql_view,None,get_postgres_conn())\n",
    "     if df.empty==True:\n",
    "            return None\n",
    "     df=df.drop(columns='updated_at')\n",
    "     df['action']='added'\n",
    "     return df   \n",
    "     \n",
    "\n",
    "\n",
    "if isFirstLoad:\n",
    " df=retrive_first_data_from_view(view_name,last_imported)\n",
    "else:\n",
    " df=retrive_next_data_from_view(view_name,view_name_id,listModelLogObjectIDs)   \n",
    "    \n",
    "if df is None:\n",
    "    print(\"No row to be imported.\")\n",
    "    exit()\n",
    "    \n",
    "print(df.info())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Transaformation\n",
    "* IF The first load then add actio='Added'\n",
    "* IF The nextload then Merge LogDF and ViewDF and add deleted row \n",
    "  * Get Deleted Items  to Create deleted dataframe by using listDeleted\n",
    "  * If there is one deletd row then  we will merge it to master dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[105979, 105980, 105981, 106008, 106009, 106010]\n",
      "[]\n",
      "No row deleted\n"
     ]
    }
   ],
   "source": [
    "def add_acutal_action_to_df_at_next(df,dfUpdateData):\n",
    "    merged_df = pd.merge(df, dfUpdateData, left_on=view_name_id, right_on='id', how='inner')\n",
    "    merged_df = merged_df.drop(columns=['id'])\n",
    "\n",
    "    listSelected = df[view_name_id].tolist()\n",
    "    print(listSelected)\n",
    "\n",
    "    set1 = set(listModelLogObjectIDs)\n",
    "    set2 = set(listSelected)\n",
    "    listDeleted = list(set1.symmetric_difference(set2))\n",
    "\n",
    "    print(listDeleted)\n",
    "\n",
    "    if len(listDeleted)>0:\n",
    "        print(\"There are some deleted rows\")\n",
    "        dfDeleted=pd.DataFrame(data=listDeleted,columns=[view_name_id])\n",
    "        dfDeleted['action']='deleted'\n",
    "        print(dfDeleted)\n",
    "        merged_df=pd.concat([merged_df,dfDeleted],axis=0)\n",
    "\n",
    "    else:\n",
    "        print(\"No row deleted\")\n",
    "\n",
    "    return merged_df    \n",
    "\n",
    "if isFirstLoad==False:\n",
    " df=add_acutal_action_to_df_at_next(df,dfModelLog)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check duplicate ID & reset index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no duplicate pm_item_id ID\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6 entries, 0 to 5\n",
      "Data columns (total 10 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   pm_item_id         6 non-null      int64 \n",
      " 1   pm_id              6 non-null      int64 \n",
      " 2   is_pm              6 non-null      bool  \n",
      " 3   pm_engineer        2 non-null      object\n",
      " 4   actual_date        2 non-null      object\n",
      " 5   document_engineer  0 non-null      object\n",
      " 6   document_date      0 non-null      object\n",
      " 7   inventory_id       6 non-null      int64 \n",
      " 8   is_complete        6 non-null      bool  \n",
      " 9   action             6 non-null      object\n",
      "dtypes: bool(2), int64(3), object(5)\n",
      "memory usage: 524.0+ bytes\n",
      "None\n",
      "   pm_item_id  pm_id  is_pm         pm_engineer actual_date document_engineer  \\\n",
      "0      105979   5248   True  Akaradej Ketruskul  2024-01-01              None   \n",
      "1      105980   5248   True  Akaradej Ketruskul  2024-01-01              None   \n",
      "2      105981   5248  False                None        None              None   \n",
      "3      106008   5256   True                None        None              None   \n",
      "4      106009   5256   True                None        None              None   \n",
      "5      106010   5256   True                None        None              None   \n",
      "\n",
      "  document_date  inventory_id  is_complete   action  \n",
      "0          None         11563        False  changed  \n",
      "1          None         11562        False  changed  \n",
      "2          None         12279        False  changed  \n",
      "3          None         11562        False    added  \n",
      "4          None         11563        False    added  \n",
      "5          None         12279        False    added  \n"
     ]
    }
   ],
   "source": [
    "hasDplicateIDs = df[view_name_id].duplicated().any()\n",
    "if  hasDplicateIDs:\n",
    " raise Exception(\"There are some duplicate id on dfUpdateData\")\n",
    "else:\n",
    " print(f\"There is no duplicate {view_name_id} ID\")  \n",
    "\n",
    "\n",
    "# merged_df['imported_at']=dt_imported\n",
    "df=df.reset_index(drop=True  )\n",
    "print(df.info())\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insert data to BQ data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table pongthorn.SMartData_Temp.temp_pm_plan already exists.\n",
      "[SchemaField('pm_id', 'INTEGER', 'NULLABLE', None, None, (), None), SchemaField('project_id', 'INTEGER', 'NULLABLE', None, None, (), None), SchemaField('planned_date', 'DATE', 'NULLABLE', None, None, (), None), SchemaField('ended_pm_date', 'DATE', 'NULLABLE', None, None, (), None), SchemaField('pm_period', 'STRING', 'NULLABLE', None, None, (), None), SchemaField('team_lead', 'STRING', 'NULLABLE', None, None, (), None), SchemaField('action', 'STRING', 'NULLABLE', None, None, (), None)]\n",
      "Total  4613 Imported data to pongthorn.SMartData_Temp.temp_pm_plan on bigquery successfully\n"
     ]
    }
   ],
   "source": [
    "if get_bq_table():\n",
    "    try:\n",
    "        insertDataFrameToBQ(df)\n",
    "    except Exception as ex:\n",
    "        raise ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ConfigUpdater [\n",
       "    <Section: 'metadata' [\n",
       "        <Option: pmr_pm_plan = '2023-12-30 04:28:45'>\n",
       "        <Option: pmr_pm_item = '2019-01-01 00:00:00'>\n",
       "        <Option: pmr_project = '2019-01-01 00:00:00'>\n",
       "        <Option: pmr_inventory = '2019-01-01 00:00:00'>\n",
       "    ]>\n",
       "]>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updater[\"metadata\"][view_name].value=dt_imported.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "updater.update_file() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-30 04:29:29.908823+00:00\n"
     ]
    }
   ],
   "source": [
    "print(datetime.now(timezone.utc) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
