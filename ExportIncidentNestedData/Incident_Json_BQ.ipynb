{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c39b3f6-bba0-4a86-a7e9-06936925e4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import psycopg2.extras as extras\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "from google.cloud import bigquery\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "env_path='.env'\n",
    "config = dotenv_values(dotenv_path=env_path)\n",
    "#pip uninstall psycopg\n",
    "#pip install psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d5cedd-582e-4571-9d69-24b32613a3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#company_id_query=(2,16,17,18,19) # AIS,BBL,INET- (HPE Product)\n",
    "company_id_query=(2,) # ais \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006faf12-708d-41d8-a92e-e675cd0fd1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_id = \"pongthorn.SMartAppData.incident_info\"\n",
    "client = bigquery.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf86216-a68a-4a1d-bdc9-df0bb5f3a961",
   "metadata": {},
   "outputs": [],
   "source": [
    "#start_date_query='2000-01-01' \n",
    "start_date_query='2022-01-01'  # last exported data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c550a3-31d9-4ab2-96b5-86788b3ed1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_imported=datetime.now()\n",
    "str_imported=dt_imported.strftime('%Y-%m-%d %H:%M:%S')\n",
    "print(f\"Imported DateTime: {str_imported}\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f260bb-88f8-4f97-97d2-b7a5f3142a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_lastImport=f\"SELECT max(imported_at) as last_imported from `pongthorn.SMartAppData.incident_info` where open_datetime>='{start_date_query}' \"\n",
    "job_lastImported=client.query(sql_lastImport)\n",
    "str_lastImported=None\n",
    "for row in job_lastImported:    \n",
    "    if row.last_imported is not None: \n",
    "        str_lastImported=row.last_imported.strftime('%Y-%m-%d %H:%M:%S')\n",
    "print(f\"Last Imported DateTime: {str_lastImported}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93799284-9bb4-456a-8f47-93d48c0ef14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if str_lastImported is not None:\n",
    "  start_date_query=str_lastImported\n",
    "\n",
    "print(f\"Start Import on update_at of last imported date : {start_date_query}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02058f8d-cc89-4eea-8fd4-1c7995a0a6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_postgres_conn():\n",
    " try:\n",
    "  conn = psycopg2.connect(\n",
    "        database=config['DATABASES_NAME'], user=config['DATABASES_USER'],\n",
    "      password=config['DATABASES_PASSWORD'], host=config['DATABASES_HOST']\n",
    "     )\n",
    "  return conn\n",
    "\n",
    " except Exception as error:\n",
    "  print(error)      \n",
    "  raise error\n",
    "def list_data(sql,params,connection):\n",
    " df=None   \n",
    " with connection.cursor() as cursor:\n",
    "    \n",
    "    if params is None:\n",
    "       cursor.execute(sql)\n",
    "    else:\n",
    "       cursor.execute(sql,params)\n",
    "    \n",
    "    columns = [col[0] for col in cursor.description]\n",
    "    dataList = [dict(zip(columns, row)) for row in cursor.fetchall()]\n",
    "    df = pd.DataFrame(data=dataList) \n",
    " return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c895bd-11bd-4e29-8d2b-3f2cec660c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#incident.id,  order by id\n",
    "\n",
    "sql_incident=\"\"\"\n",
    "select  \n",
    "incident.id ,\n",
    "company.company_name as company,incident.incident_no as incident_no, \n",
    "\n",
    "product_type.productype_name,brand.brand_name,model.model_name,\n",
    "inventory.serial_number,datacenter.datacenter_name,branch.branch_name,\n",
    "\n",
    "incident.incident_severity_id as severity_id,severity.severity_name ,\n",
    "incident.incident_status_id as status_id,\n",
    "status.incident_status_name as status_name,\n",
    "\n",
    "incident.service_type_id,service.service_type_name,\n",
    "incident.incident_type_id,xtype.incident_type_name,\n",
    "failure_type,\n",
    "\n",
    "TO_CHAR(incident.incident_datetime,'YYYY-MM-DD HH24:MI:SS') as open_datetime,\n",
    "TO_CHAR(incident.incident_close_datetime,'YYYY-MM-DD HH24:MI:SS') as close_datetime,\n",
    "\n",
    "TO_CHAR(incident.incident_problem_start,'YYYY-MM-DD HH24:MI:SS') as response_datetime,\n",
    "TO_CHAR(incident.incident_problem_end,'YYYY-MM-DD HH24:MI:SS') as resolved_datetime,\n",
    "TO_CHAR(incident.updated_at,'YYYY-MM-DD HH24:MI:SS') as updated_at ,\n",
    "\n",
    "\n",
    "TO_CHAR(inventory.install_date,'YYYY-MM-DD HH24:MI:SS') as install_date,\n",
    "TO_CHAR(inventory.eos_date,'YYYY-MM-DD HH24:MI:SS') as eos_date,\n",
    "TO_CHAR(inventory.customer_warranty_start,'YYYY-MM-DD HH24:MI:SS') as customer_warranty_start,\n",
    "TO_CHAR(inventory.customer_warranty_end,'YYYY-MM-DD HH24:MI:SS') as customer_warranty_end\n",
    "\n",
    "\n",
    "from app_incident as incident\n",
    "inner join  app_incident_status as status on incident.incident_status_id = status.id\n",
    "inner join  app_incident_severity as severity on  incident.incident_severity_id = severity.id\n",
    "inner join  app_service_type as service on incident.service_type_id= service.id\n",
    "inner join  app_incident_type as  xtype on incident.incident_type_id = xtype.id\n",
    "\n",
    "\n",
    "inner join app_inventory as inventory on incident.inventory_id = inventory.id\n",
    "inner join app_brand as brand on inventory.brand_id = brand.id\n",
    "inner join app_model as model on inventory.model_id = model.id\n",
    "inner join app_product_type as product_type on inventory.product_type_id = product_type.id\n",
    "inner join app_datacenter as datacenter on inventory.datacenter_id = datacenter.id\n",
    "inner join app_branch as branch on inventory.branch_id = branch.id\n",
    "\n",
    "inner join app_project as project on inventory.project_id = project.id\n",
    "inner join app_company as company on project.company_id = company.id\n",
    "\n",
    "where  incident.updated_at > %(start_date_param)s  \n",
    "\n",
    "and company.id in %(company_id_param)s\n",
    "and incident.incident_status_id=4\n",
    "\n",
    "order by  incident.updated_at desc\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#and  incident.incident_datetime<=%(end_date_param)s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac67eab-20f6-4676-886b-d8184d4150ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sql_detail=\"\"\"\n",
    "select  detail.id, detail.incident_master_id as incident_id ,\n",
    "TO_CHAR(task_start,'YYYY-MM-DD HH24:MI:SS') as task_start,\n",
    "TO_CHAR(task_end,'YYYY-MM-DD HH24:MI:SS') as task_end,\n",
    "team.service_team_name,\n",
    "engineer.employee_name as engineer_name,\n",
    "TO_CHAR(detail.updated_at,'YYYY-MM-DD HH24:MI:SS') as updated_at \n",
    "\n",
    "from app_incident_detail detail\n",
    "inner join  app_serviceteam team on detail.service_team_id=team.id\n",
    "inner  join  app_employee engineer on detail.employee_id=engineer.id\n",
    " where detail.incident_master_id = %(incident_id_param)s \n",
    " \"\"\"\n",
    "\n",
    "#,detail.\"reference_product_caseNo\" as case_id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac777d07-3149-4d68-bad7-037204f26140",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Create all issues dataframe\")\n",
    "\n",
    "# dict_params={\"company_id_param\":company_id_query,\"start_date_param\":start_date_query,\"end_date_param\":end_date_query}\n",
    "dict_params={\"company_id_param\":company_id_query,\"start_date_param\":start_date_query}\n",
    "\n",
    "df_all=list_data(sql_incident,dict_params,get_postgres_conn())\n",
    "df_all['imported_at']=dt_imported\n",
    "df_all['imported_at']=df_all['imported_at'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "dateNone_cols=['close_datetime','resolved_datetime']\n",
    "for index,row in df_all.iterrows():\n",
    "  for dateNone in dateNone_cols:\n",
    "    if  row[dateNone] is None:\n",
    "        print(row['incident_no']+ \" is updated on None in \"+dateNone)\n",
    "        df_all.loc[index, dateNone] =row['updated_at']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e18e2e2-696b-42dd-8196-7fb277940ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_all=df_all.head(10)\n",
    "print(df_all.info())\n",
    "df_all.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af45e55c-2939-4a15-89d1-c021e54893b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_incident = json.loads(df_all.to_json(orient = 'records'))\n",
    "for incident in json_incident:\n",
    "    \n",
    "    id = incident['id']\n",
    "    incident.pop('id')\n",
    "    \n",
    "    incident_update_at= incident['imported_at']\n",
    "    \n",
    "    df_detail = list_data(sql_detail,{\"incident_id_param\": id},get_postgres_conn())\n",
    "    \n",
    "    if df_detail.empty==False:\n",
    "    \n",
    "      for index,row in df_detail.iterrows():\n",
    "        if  row['task_end'] is None:\n",
    "           print(f\"DetailId-{row['id']} of IncidentID-{row['incident_id']}  is updated on None in task_end\") \n",
    "           df_detail.loc[index, 'task_end'] =  incident_update_at #row['updated_at']\n",
    "           \n",
    "      df_detail=df_detail.drop(columns=['incident_id','id'])  \n",
    "      json_detail = json.loads(df_detail.to_json(orient = 'records'))\n",
    "      # print(json_detail)\n",
    "      incident['incident_detail']=json_detail\n",
    "        \n",
    "    else:\n",
    "     print(f'no detail in incident {id}')\n",
    "     #incident['incident_detail']=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134ffe12-fcd2-4e00-a7c4-7fd6d8d5a832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"incident.json\", \"w\") as outfile:\n",
    "#     json.dump(json_incident, outfile)\n",
    "\n",
    "no_incident=len(json_incident)\n",
    "print(f\"No incident: {no_incident}\")\n",
    "if len(json_incident)>0:\n",
    "    print(json_incident[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af8d43a-61d2-4a8e-94f3-0f96447a2a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "      schema = [              \n",
    "    bigquery.SchemaField(\"company\", \"STRING\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"incident_no\", \"STRING\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"productype_name\", \"STRING\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"brand_name\", \"STRING\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"model_name\", \"STRING\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"serial_number\", \"STRING\", mode=\"REQUIRED\"), \n",
    "    bigquery.SchemaField(\"datacenter_name\", \"STRING\", mode=\"REQUIRED\"), \n",
    "    bigquery.SchemaField(\"branch_name\", \"STRING\", mode=\"REQUIRED\"),       \n",
    "    bigquery.SchemaField(\"severity_id\", \"INTEGER\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"severity_name\", \"STRING\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"status_id\", \"INTEGER\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"status_name\", \"STRING\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"service_type_id\", \"INTEGER\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"service_type_name\", \"STRING\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"incident_type_id\", \"INTEGER\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"incident_type_name\", \"STRING\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"failure_type\", \"STRING\", mode=\"NULLABLE\"),          \n",
    "    bigquery.SchemaField(\"open_datetime\", \"DATETIME\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"close_datetime\", \"DATETIME\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"response_datetime\", \"DATETIME\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"resolved_datetime\", \"DATETIME\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"updated_at\", \"DATETIME\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"install_date\", \"DATETIME\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"eos_date\", \"DATETIME\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"customer_warranty_start\", \"DATETIME\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"customer_warranty_end\", \"DATETIME\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"imported_at\", \"DATETIME\", mode=\"REQUIRED\"),      \n",
    "    bigquery.SchemaField(\n",
    "    \"incident_detail\",\n",
    "    \"RECORD\",\n",
    "    mode=\"REPEATED\",\n",
    "    fields=[\n",
    "        bigquery.SchemaField(\"task_start\", \"DATETIME\", mode=\"REQUIRED\"),\n",
    "        bigquery.SchemaField(\"task_end\", \"DATETIME\", mode=\"REQUIRED\"),\n",
    "        bigquery.SchemaField(\"service_team_name\", \"STRING\", mode=\"REQUIRED\"),\n",
    "        bigquery.SchemaField(\"engineer_name\", \"STRING\", mode=\"REQUIRED\"),\n",
    "        bigquery.SchemaField(\"updated_at\", \"DATETIME\", mode=\"REQUIRED\"),\n",
    "    ],),    \n",
    "    ]\n",
    "   \n",
    ")\n",
    "# for meta in job_config.schema:\n",
    "#  print(meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b17ca7a-92a8-4bc0-9174-6039c67b654f",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_config.source_format = bigquery.SourceFormat.NEWLINE_DELIMITED_JSON\n",
    "#job_config.schema_update_options = [bigquery.SchemaUpdateOption.ALLOW_FIELD_ADDITION]\n",
    "job_config.write_disposition = bigquery.WriteDisposition.WRITE_APPEND  \n",
    "#job_config.write_disposition = bigquery.WriteDisposition.WRITE_TRUNCATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edfee9a-f93e-4d71-bb68-84f279478e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "job = client.load_table_from_json(json_incident,table_id, job_config = job_config)\n",
    "if job.errors is not None:\n",
    "    print(job.error_result)\n",
    "    print(job.errors)\n",
    "else:\n",
    "    print(f\"import to bigquery successfully  {no_incident} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9996e057-c8cb-4b9b-a994-4d4c0265b143",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeaf1148-0623-4ccc-8e42-4b91d283078c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64c3f68-8ab8-447b-83ff-4ca648fbcb6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2944355e-8b23-4fbf-8f0d-cab8a0e7fdd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
