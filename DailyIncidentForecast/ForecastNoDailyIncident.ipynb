{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cb56bd-3c45-4f45-a2fb-c33f5198d50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime,date,timedelta,timezone\n",
    "import pytz\n",
    "import json\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "\n",
    "from google.cloud import storage\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud.exceptions import NotFound\n",
    "from google.api_core.exceptions import BadRequest\n",
    "\n",
    "\n",
    "print('Tensorflow Version: ' + tensorflow.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103dd64a-6c76-4653-a504-5ba44bb56dcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8de071b2-41b2-40db-ab1d-7743faa0199f",
   "metadata": {},
   "source": [
    "# Constant & Parameter Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff9d96d8-0f3e-4d1b-8a9f-22d78e226b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incident_60To5_E150S15B32-M0122-0723\n"
     ]
    }
   ],
   "source": [
    "#today='2023-07-08' # last record of training data to predict the first movement\n",
    "today=''\n",
    "\n",
    "input_sequence_length =60\n",
    "output_sequence_length =5\n",
    "\n",
    "projectId='pongthorn'\n",
    "\n",
    "local_model_path=\"model\\Incident_60To5_E150S15B32\"\n",
    "\n",
    "model_file='Incident_60To5_E150S15B32-M0122-0723.h5'\n",
    "scaler_file='scaler_Incident_60To5_E150S15B32-M0122-0723.gz'\n",
    "scalerPred_file='scaler_pred_Incident_60To5_E150S15B32-M0122-0723.gz'\n",
    "\n",
    "\n",
    "model_id=model_file.split(\".\")[0]\n",
    "print(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e81398-c118-43c5-8a1e-68cfbd0d5ea2",
   "metadata": {},
   "source": [
    "# BigQuery Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54cabd15-5e81-4075-a4a7-9aba2ebff632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pongthorn.SMartDW.prediction_daily_incident\n",
      "pongthorn.SMartDW.daily_incident\n"
     ]
    }
   ],
   "source": [
    "dataset_id=\"SMartDW\"\n",
    "table_data_id = f\"{projectId}.{dataset_id}.daily_incident\"\n",
    "table_id = f\"{projectId}.{dataset_id}.prediction_daily_incident\"\n",
    "\n",
    "print(table_id)\n",
    "print(table_data_id)\n",
    "\n",
    "client = bigquery.Client(project=projectId )\n",
    "\n",
    "def load_data_bq(sql:str):\n",
    " query_result=client.query(sql)\n",
    " df=query_result.to_dataframe()\n",
    " return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061a7f48-7759-48bf-8806-089595651be4",
   "metadata": {},
   "source": [
    "# Load Model  Configuration MetaData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c90459-6931-49f7-9908-aaf7e99699bc",
   "metadata": {},
   "source": [
    "# Load model and scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2765c501-77a0-45bd-8cec-1f404d31ad00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model\\Incident_60To5_E150S15B32/Incident_60To5_E150S15B32-M0122-0723.h5\n",
      "model\\Incident_60To5_E150S15B32/scaler_Incident_60To5_E150S15B32-M0122-0723.gz\n",
      "model\\Incident_60To5_E150S15B32/scaler_pred_Incident_60To5_E150S15B32-M0122-0723.gz\n",
      "Model and Scaler Object Summary\n",
      "Scaler Max-Min\n",
      "=====================================================================================================\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_3 (LSTM)               (None, 60)                14880     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 60)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 5)                 305       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,185\n",
      "Trainable params: 15,185\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "max=[16.] and min=[0.] and scale=[0.0625]\n",
      "max=[16.] and min=[0.] and scale=[0.0625]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\envs\\google_base\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator MinMaxScaler from version 1.2.1 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "objectPaht=local_model_path\n",
    "model_path=f\"{objectPaht}/{model_file}\"\n",
    "scale_input_path=f\"{objectPaht}/{scaler_file}\"\n",
    "scale_output_path=f\"{objectPaht}/{scalerPred_file}\"\n",
    "\n",
    "print(model_path)\n",
    "print(scale_input_path)\n",
    "print(scale_output_path)\n",
    "\n",
    "try:\n",
    "    print(\"Model and Scaler Object Summary\")\n",
    "    x_model = load_model(model_path)\n",
    "except Exception as ex:\n",
    "    print(str(ex))\n",
    "    raise Exception(str(ex)) \n",
    "\n",
    "try:\n",
    "    print(\"Scaler Max-Min\")\n",
    "    x_scaler = joblib.load(scale_input_path)\n",
    "    x_scalerPred=joblib.load(scale_output_path)\n",
    "\n",
    "except Exception as ex:\n",
    "    print(str(ex))\n",
    "    raise Exception(str(ex))\n",
    "\n",
    "print(\"=====================================================================================================\")\n",
    "\n",
    "print(x_model.summary())\n",
    "#(max - min) / (X.max(axis=0) - X.min(axis=0))\n",
    "print(f\"max={x_scaler.data_max_} and min={x_scaler.data_min_} and scale={x_scaler.scale_}\")\n",
    "print(f\"max={x_scalerPred.data_max_} and min={x_scalerPred.data_min_} and scale={x_scalerPred.scale_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb99063-ed8b-44a9-9bd4-6d708f755cbf",
   "metadata": {},
   "source": [
    "# Declare and Initialize TS Model Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a33b887-b266-4ff9-b2ca-a334364eb410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-10 01:46:56\n"
     ]
    }
   ],
   "source": [
    "date_col='date'\n",
    "prediction_col=\"count_incident\"\n",
    "feature_cols=[prediction_col]\n",
    "\n",
    "nLastData=int(input_sequence_length)\n",
    "# nLastData=int(input_sequence_length*1.5)\n",
    "\n",
    "dt_imported=datetime.now()\n",
    "# dt_imported=datetime.now(timezone.utc)\n",
    "dtStr_imported=dt_imported.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(dtStr_imported)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74ce645-c4c1-4b34-a56e-fd510aa1e66f",
   "metadata": {},
   "source": [
    "# Query Fin Data from BQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2efe5184-5874-4464-9b82-14a38c804285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check Last Record as starting point to retrive  sequence count_incident over the past 60 day\n"
     ]
    }
   ],
   "source": [
    "print(f\"Check Last Record as starting point to retrive  sequence {prediction_col} over the past {input_sequence_length} day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b682d76-f7b1-45b2-92c1-78a5c0e7af38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " select max(date) as LastDate  from `pongthorn.SMartDW.daily_incident` \n",
      "    LastDate\n",
      "0 2023-07-08\n",
      "Take incident the last 60 days to Forecast  over the next 5  days at 2023-07-08\n"
     ]
    }
   ],
   "source": [
    "lastDate=None\n",
    "if today=='':\n",
    "    sqlLastDate=f\"\"\" select max({date_col}) as LastDate  from `{table_data_id}` \"\"\"\n",
    "\n",
    "else:\n",
    "    sqlLastDate=f\"\"\" \n",
    "    select {date_col} as LastDate  from `{table_data_id}` where {date_col}='{today}' order by datetime_imported desc limit 1\n",
    "    \"\"\"\n",
    "print(sqlLastDate)\n",
    "\n",
    "results = client.query(sqlLastDate)\n",
    "dfLastDate=results.to_dataframe()\n",
    "print(dfLastDate)\n",
    "if dfLastDate.empty:\n",
    "    print( f\"Not found {prediction_col}  at {today}\")\n",
    "    exit()\n",
    "    # return f\"Not found {prediction_col} at {today}  \"\n",
    "else:\n",
    "    lastDate=dfLastDate.iloc[0,0]\n",
    "    today=lastDate.strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "print(f\"Take incident the last {input_sequence_length} days to Forecast  over the next {output_sequence_length}  days at {today}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4835aad-60d9-4c16-b69e-7da926e9ab79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check whether count_incident as 2023-07-08 was predicted the future for the next 5 days\n",
      "select prediction_date,pred_timestamp from `pongthorn.SMartDW.prediction_daily_incident` \n",
      "where prediction_date='2023-07-08' order by pred_timestamp \n",
      "\n",
      "2023-07-08 has been predicted count_incident\n",
      "  prediction_date            pred_timestamp\n",
      "0      2023-07-08 2023-07-10 01:28:34+00:00\n"
     ]
    }
   ],
   "source": [
    "print(f\"Check whether {prediction_col} as {today} was predicted the future for the next {output_sequence_length} days\")\n",
    "\n",
    "sqlLastPred=f\"\"\"select prediction_date,pred_timestamp from `{table_id}` \n",
    "where prediction_date='{today}' order by pred_timestamp \n",
    "\"\"\"\n",
    "print(sqlLastPred)\n",
    "dfLastPred=load_data_bq(sqlLastPred)\n",
    "if dfLastPred.empty==False:\n",
    "   dfLastPred=dfLastPred.drop_duplicates(subset=['prediction_date'],keep='last') \n",
    "   print(f\"{today} has been predicted {prediction_col}\")\n",
    "   print(dfLastPred)\n",
    "   exit()\n",
    "   # return f\"Prediction price movement of {asset_name}-{prediction_col} at {today} has been predicted\"\n",
    "else:\n",
    "       print(f\"{today} has not been predicted {prediction_col} yet.\") \n",
    "       print(f\"The system is about to predict {prediction_col} shortly.\") \n",
    "       print(\"=======================================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "729b0f1f-020a-4c61-a80a-0403c6ecd9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get data from 2023-05-09 - 2023-07-08 as input to forecast\n",
      "\n",
      "SELECT  *  FROM `pongthorn.SMartDW.daily_incident`  \n",
      "Where  date between  DATE_SUB(date '2023-07-08', INTERVAL 60 DAY) \n",
      "and '2023-07-08'  order by date,datetime_imported\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 61 entries, 2023-05-09 to 2023-07-08\n",
      "Data columns (total 2 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   count_incident     61 non-null     float64       \n",
      " 1   datetime_imported  61 non-null     datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(1)\n",
      "memory usage: 1.4 KB\n",
      "None\n",
      "            count_incident          datetime_imported\n",
      "date                                                 \n",
      "2023-05-09             5.0 2023-07-09 15:04:27.770878\n",
      "2023-05-10            10.0 2023-07-09 15:04:27.770878\n",
      "2023-05-11             7.0 2023-07-09 15:04:27.770878\n",
      "2023-05-12             1.0 2023-07-09 15:04:27.770878\n",
      "2023-05-13             2.0 2023-07-09 15:04:27.770878\n",
      "            count_incident          datetime_imported\n",
      "date                                                 \n",
      "2023-07-04            13.0 2023-07-09 15:04:27.770878\n",
      "2023-07-05             5.0 2023-07-09 15:04:27.770878\n",
      "2023-07-06             5.0 2023-07-09 15:04:27.770878\n",
      "2023-07-07             1.0 2023-07-09 15:04:27.770878\n",
      "2023-07-08             0.0 2023-07-09 15:06:22.244948\n"
     ]
    }
   ],
   "source": [
    "dayAgo=datetime.strptime(today,'%Y-%m-%d') +timedelta(days=-nLastData)\n",
    "print(f\"Get data from {dayAgo.strftime('%Y-%m-%d')} - {today} as input to forecast\")\n",
    "\n",
    "sql=f\"\"\"\n",
    "SELECT  *  FROM `{table_data_id}`  \n",
    "Where  {date_col} between  DATE_SUB({date_col} '{today}', INTERVAL {nLastData} DAY) \n",
    "and '{today}'  order by {date_col},datetime_imported\n",
    "\"\"\"\n",
    "print(sql)\n",
    "query_result=client.query(sql)\n",
    "df=query_result.to_dataframe()\n",
    "\n",
    "df=df.drop_duplicates(subset=[date_col],keep='last')\n",
    "df[date_col]=pd.to_datetime(df[date_col],format='%Y-%m-%d')\n",
    "df.set_index(date_col,inplace=True)\n",
    "\n",
    "print(df.info())\n",
    "print(df.head())\n",
    "print(df.tail())\n",
    "\n",
    "if df.empty==True or len(df)<input_sequence_length:\n",
    "    print(f\"There is no enough data to make prediction during {dayAgo.strftime('%Y-%m-%d')} - {today}\")\n",
    "    exit()\n",
    "    # return f\"There is no enough data to make prediction during {dayAgo.strftime('%Y-%m-%d')} - {today}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327a7a76-24a7-4f8f-82c7-836c6a3778dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.dates as mdates\n",
    "# import seaborn as sns\n",
    "\n",
    "# plt.subplots(1, 1, figsize = (20, 10),sharex=True)\n",
    "\n",
    "# ax1 = plt.subplot(2, 1, 1)\n",
    "# plt.plot(df[[prediction_col]])\n",
    "# plt.ylabel(prediction_col)\n",
    "\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e546448a-234c-49d2-9a97-346a7e62ee25",
   "metadata": {},
   "source": [
    "# Get only Feature( 1 Indicator) to Predict itself in the next N days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d29f68-fa93-42fc-903a-20ac2cc556ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Get Feature to Predict : {prediction_col} \")\n",
    "dfForPred=df[feature_cols]\n",
    "#dfForPred=dfForPred.iloc[-(input_sequence_length+1):-1,:]\n",
    "dfForPred=dfForPred.iloc[-input_sequence_length:,:]\n",
    "print(dfForPred.info())\n",
    "print(dfForPred.shape)\n",
    "\n",
    "print(dfForPred.head(10))\n",
    "print(dfForPred.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9306df85-1fb9-4e9e-9987-e42d6e2c84f5",
   "metadata": {},
   "source": [
    "# Make Pediction as Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0866a254-f643-4772-a239-9ff5621f89d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "xUnscaled=dfForPred.values #print(xUnscaled.shape)\n",
    "xScaled=x_scaler.transform(xUnscaled)\n",
    "print(xScaled.shape)\n",
    "# print(xScaled[-5:])\n",
    "\n",
    "\n",
    "xScaledToPredict= xScaled.reshape(1,input_sequence_length,len(feature_cols))\n",
    "print(xScaledToPredict.shape)\n",
    "\n",
    "yPredScaled = x_model.predict(xScaledToPredict)\n",
    "print(yPredScaled.shape, yPredScaled)\n",
    "\n",
    "yPred = x_scalerPred.inverse_transform(yPredScaled).reshape(-1, 1)\n",
    "print(yPred.shape, yPred)\n",
    "\n",
    "\n",
    "print(\"============================Summary============================\")\n",
    "print(xUnscaled.shape)\n",
    "print(yPred.shape)\n",
    "\n",
    "print(\"============================Input============================\")\n",
    "print(xUnscaled)\n",
    "print(\"============================Output============================\")\n",
    "print(yPred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a97710-b915-4d94-baec-9ffedca2ef73",
   "metadata": {},
   "source": [
    "# Build Prediction Result Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b893eae3-3adf-4eb6-815a-df7905520da6",
   "metadata": {},
   "source": [
    "## Feature Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9fb7d106-f6c2-47dd-99db-f764b8697e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create indexes from Dataframe dfForPred\n",
      "(60, 2)\n",
      "            count_incident     type\n",
      "date                               \n",
      "2023-05-10            10.0  feature\n",
      "2023-05-11             7.0  feature\n",
      "2023-05-12             1.0  feature\n",
      "2023-05-13             2.0  feature\n",
      "2023-05-14             0.0  feature\n",
      "            count_incident     type\n",
      "date                               \n",
      "2023-07-04            13.0  feature\n",
      "2023-07-05             5.0  feature\n",
      "2023-07-06             5.0  feature\n",
      "2023-07-07             1.0  feature\n",
      "2023-07-08             0.0  feature\n"
     ]
    }
   ],
   "source": [
    "print(\"Create indexes from Dataframe dfForPred\")\n",
    "dfFeature=pd.DataFrame(data= xUnscaled,columns=feature_cols,index=dfForPred.index)\n",
    "dfFeature['type']='feature'\n",
    "print(dfFeature.shape)\n",
    "print(dfFeature.head())\n",
    "print(dfFeature.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b51723-9516-4297-b40e-61cd1d6375e1",
   "metadata": {},
   "source": [
    "## Forecast/Preidction Value Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ddda02a2-0d00-4c64-80f3-2bf42a548aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create indexes by specifying output_sequence_length stating from get last record of DFFeature+1\n",
      "DatetimeIndex(['2023-07-09', '2023-07-10', '2023-07-11', '2023-07-12',\n",
      "               '2023-07-13'],\n",
      "              dtype='datetime64[ns]', freq='D')\n"
     ]
    }
   ],
   "source": [
    "print(\"Create indexes by specifying output_sequence_length stating from get last record of DFFeature+1\")\n",
    "lastRowOfFeature=dfFeature.index.max()\n",
    "firstRowofPrediction=lastRowOfFeature+timedelta(days=1)\n",
    "datePred=pd.date_range(start=firstRowofPrediction,freq='d',periods=output_sequence_length)\n",
    "print(datePred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e9c1f307-5e3e-4ea5-9e3f-fe614518819c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 2)\n",
      "            count_incident        type\n",
      "date                                  \n",
      "2023-07-09             1.0  prediction\n",
      "2023-07-10             6.0  prediction\n",
      "2023-07-11             6.0  prediction\n",
      "2023-07-12             6.0  prediction\n",
      "2023-07-13             5.0  prediction\n"
     ]
    }
   ],
   "source": [
    "dfPrediction=pd.DataFrame(data= yPred,columns=[prediction_col],index=datePred)\n",
    "dfPrediction['type']='prediction'\n",
    "dfPrediction[prediction_col]=dfPrediction[prediction_col].round(0)\n",
    "dfPrediction.index.name=date_col\n",
    "print(dfPrediction.shape)\n",
    "print(dfPrediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4f69c4-1d12-45eb-9c1e-4f46a8aff165",
   "metadata": {},
   "source": [
    "# Merge Feature and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "45cb9752-2bb6-4529-b134-2502e5d4d4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            count_incident        type\n",
      "date                                  \n",
      "2023-05-10            10.0     feature\n",
      "2023-05-11             7.0     feature\n",
      "2023-05-12             1.0     feature\n",
      "2023-05-13             2.0     feature\n",
      "2023-05-14             0.0     feature\n",
      "...                    ...         ...\n",
      "2023-07-09             1.0  prediction\n",
      "2023-07-10             6.0  prediction\n",
      "2023-07-11             6.0  prediction\n",
      "2023-07-12             6.0  prediction\n",
      "2023-07-13             5.0  prediction\n",
      "\n",
      "[65 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "dfFeaToPred=pd.concat([dfFeature,dfPrediction])\n",
    "print(dfFeaToPred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0e321c-4fa0-4d78-8678-99b9b925a2ec",
   "metadata": {},
   "source": [
    "# Get Prepraed To ingest data into BQ , we have to create dataframe and convert to Json-Rowns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bbf27cb7-663b-4b63-866e-547b3a4e45e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1 entries, 0 to 0\n",
      "Data columns (total 3 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   prediction_date  1 non-null      object\n",
      " 1   pred_timestamp   1 non-null      object\n",
      " 2   model_id         1 non-null      object\n",
      "dtypes: object(3)\n",
      "memory usage: 152.0+ bytes\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction_date</th>\n",
       "      <th>pred_timestamp</th>\n",
       "      <th>model_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-07-08</td>\n",
       "      <td>2023-07-10 01:28:34</td>\n",
       "      <td>Incident_60To5_E150S15B32-M0122-0723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  prediction_date       pred_timestamp                              model_id\n",
       "0      2023-07-08  2023-07-10 01:28:34  Incident_60To5_E150S15B32-M0122-0723"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputDF=pd.DataFrame(data=[ [today,dtStr_imported,model_id] ],columns=[\"prediction_date\",\"pred_timestamp\",\"model_id\"])\n",
    "print(outputDF.info())\n",
    "outputDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c89e2d97-1f3d-41bf-9b50-e22e94ef8457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          date  count_incident        type\n",
      "0   2023-05-10            10.0     feature\n",
      "1   2023-05-11             7.0     feature\n",
      "2   2023-05-12             1.0     feature\n",
      "3   2023-05-13             2.0     feature\n",
      "4   2023-05-14             0.0     feature\n",
      "..         ...             ...         ...\n",
      "60  2023-07-09             1.0  prediction\n",
      "61  2023-07-10             6.0  prediction\n",
      "62  2023-07-11             6.0  prediction\n",
      "63  2023-07-12             6.0  prediction\n",
      "64  2023-07-13             5.0  prediction\n",
      "\n",
      "[65 rows x 3 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'prediction_date': '2023-07-08',\n",
       "  'pred_timestamp': '2023-07-10 01:28:34',\n",
       "  'model_id': 'Incident_60To5_E150S15B32-M0122-0723',\n",
       "  'prediction_result': [{'date': '2023-05-10',\n",
       "    'count_incident': 10.0,\n",
       "    'type': 'feature'},\n",
       "   {'date': '2023-05-11', 'count_incident': 7.0, 'type': 'feature'},\n",
       "   {'date': '2023-05-12', 'count_incident': 1.0, 'type': 'feature'},\n",
       "   {'date': '2023-05-13', 'count_incident': 2.0, 'type': 'feature'},\n",
       "   {'date': '2023-05-14', 'count_incident': 0.0, 'type': 'feature'},\n",
       "   {'date': '2023-05-15', 'count_incident': 7.0, 'type': 'feature'},\n",
       "   {'date': '2023-05-16', 'count_incident': 7.0, 'type': 'feature'},\n",
       "   {'date': '2023-05-17', 'count_incident': 2.0, 'type': 'feature'},\n",
       "   {'date': '2023-05-18', 'count_incident': 11.0, 'type': 'feature'},\n",
       "   {'date': '2023-05-19', 'count_incident': 7.0, 'type': 'feature'},\n",
       "   {'date': '2023-05-20', 'count_incident': 1.0, 'type': 'feature'},\n",
       "   {'date': '2023-05-21', 'count_incident': 3.0, 'type': 'feature'},\n",
       "   {'date': '2023-05-22', 'count_incident': 5.0, 'type': 'feature'},\n",
       "   {'date': '2023-05-23', 'count_incident': 15.0, 'type': 'feature'},\n",
       "   {'date': '2023-05-24', 'count_incident': 7.0, 'type': 'feature'},\n",
       "   {'date': '2023-05-25', 'count_incident': 9.0, 'type': 'feature'},\n",
       "   {'date': '2023-05-26', 'count_incident': 6.0, 'type': 'feature'},\n",
       "   {'date': '2023-05-27', 'count_incident': 2.0, 'type': 'feature'},\n",
       "   {'date': '2023-05-28', 'count_incident': 1.0, 'type': 'feature'},\n",
       "   {'date': '2023-05-29', 'count_incident': 4.0, 'type': 'feature'},\n",
       "   {'date': '2023-05-30', 'count_incident': 5.0, 'type': 'feature'},\n",
       "   {'date': '2023-05-31', 'count_incident': 5.0, 'type': 'feature'},\n",
       "   {'date': '2023-06-01', 'count_incident': 6.0, 'type': 'feature'},\n",
       "   {'date': '2023-06-02', 'count_incident': 4.0, 'type': 'feature'},\n",
       "   {'date': '2023-06-03', 'count_incident': 4.0, 'type': 'feature'},\n",
       "   {'date': '2023-06-04', 'count_incident': 1.0, 'type': 'feature'},\n",
       "   {'date': '2023-06-05', 'count_incident': 2.0, 'type': 'feature'},\n",
       "   {'date': '2023-06-06', 'count_incident': 9.0, 'type': 'feature'},\n",
       "   {'date': '2023-06-07', 'count_incident': 9.0, 'type': 'feature'},\n",
       "   {'date': '2023-06-08', 'count_incident': 5.0, 'type': 'feature'},\n",
       "   {'date': '2023-06-09', 'count_incident': 9.0, 'type': 'feature'},\n",
       "   {'date': '2023-06-10', 'count_incident': 5.0, 'type': 'feature'},\n",
       "   {'date': '2023-06-11', 'count_incident': 1.0, 'type': 'feature'},\n",
       "   {'date': '2023-06-12', 'count_incident': 10.0, 'type': 'feature'},\n",
       "   {'date': '2023-06-13', 'count_incident': 3.0, 'type': 'feature'},\n",
       "   {'date': '2023-06-14', 'count_incident': 7.0, 'type': 'feature'},\n",
       "   {'date': '2023-06-15', 'count_incident': 3.0, 'type': 'feature'},\n",
       "   {'date': '2023-06-16', 'count_incident': 7.0, 'type': 'feature'},\n",
       "   {'date': '2023-06-17', 'count_incident': 3.0, 'type': 'feature'},\n",
       "   {'date': '2023-06-18', 'count_incident': 2.0, 'type': 'feature'},\n",
       "   {'date': '2023-06-19', 'count_incident': 10.0, 'type': 'feature'},\n",
       "   {'date': '2023-06-20', 'count_incident': 7.0, 'type': 'feature'},\n",
       "   {'date': '2023-06-21', 'count_incident': 9.0, 'type': 'feature'},\n",
       "   {'date': '2023-06-22', 'count_incident': 10.0, 'type': 'feature'},\n",
       "   {'date': '2023-06-23', 'count_incident': 3.0, 'type': 'feature'},\n",
       "   {'date': '2023-06-24', 'count_incident': 2.0, 'type': 'feature'},\n",
       "   {'date': '2023-06-25', 'count_incident': 4.0, 'type': 'feature'},\n",
       "   {'date': '2023-06-26', 'count_incident': 11.0, 'type': 'feature'},\n",
       "   {'date': '2023-06-27', 'count_incident': 4.0, 'type': 'feature'},\n",
       "   {'date': '2023-06-28', 'count_incident': 12.0, 'type': 'feature'},\n",
       "   {'date': '2023-06-29', 'count_incident': 2.0, 'type': 'feature'},\n",
       "   {'date': '2023-06-30', 'count_incident': 5.0, 'type': 'feature'},\n",
       "   {'date': '2023-07-01', 'count_incident': 3.0, 'type': 'feature'},\n",
       "   {'date': '2023-07-02', 'count_incident': 1.0, 'type': 'feature'},\n",
       "   {'date': '2023-07-03', 'count_incident': 8.0, 'type': 'feature'},\n",
       "   {'date': '2023-07-04', 'count_incident': 13.0, 'type': 'feature'},\n",
       "   {'date': '2023-07-05', 'count_incident': 5.0, 'type': 'feature'},\n",
       "   {'date': '2023-07-06', 'count_incident': 5.0, 'type': 'feature'},\n",
       "   {'date': '2023-07-07', 'count_incident': 1.0, 'type': 'feature'},\n",
       "   {'date': '2023-07-08', 'count_incident': 0.0, 'type': 'feature'},\n",
       "   {'date': '2023-07-09', 'count_incident': 1.0, 'type': 'prediction'},\n",
       "   {'date': '2023-07-10', 'count_incident': 6.0, 'type': 'prediction'},\n",
       "   {'date': '2023-07-11', 'count_incident': 6.0, 'type': 'prediction'},\n",
       "   {'date': '2023-07-12', 'count_incident': 6.0, 'type': 'prediction'},\n",
       "   {'date': '2023-07-13', 'count_incident': 5.0, 'type': 'prediction'}]}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsonOutput = json.loads(outputDF.to_json(orient = 'records'))\n",
    "for item in jsonOutput:\n",
    "    \n",
    "    dataFeaToPred=dfFeaToPred.reset_index()[[date_col,prediction_col,'type']]\n",
    "    dataFeaToPred[date_col]=dataFeaToPred[date_col].dt.strftime('%Y-%m-%d')\n",
    "    print(dataFeaToPred)\n",
    "    jsonFeaToPred= json.loads(dataFeaToPred.to_json(orient = 'records'))\n",
    "    item[\"prediction_result\"]=jsonFeaToPred\n",
    "    \n",
    " \n",
    "with open(\"incident_prediction.json\", \"w\") as outfile:\n",
    "    json.dump(jsonOutput, outfile)\n",
    "jsonOutput"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d061e560-fba8-478e-8eb3-70e2922ec302",
   "metadata": {},
   "source": [
    "# Ingest Data to BigQuery "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fea798dd-a57e-44d5-bd0e-cde7f84a4158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table pongthorn.SMartDW.prediction_daily_incident already exists.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    table=client.get_table(table_id)\n",
    "    print(\"Table {} already exists.\".format(table_id))\n",
    "except Exception as ex :\n",
    "    print(str(ex))\n",
    "#if error  please create table and other configuration as  bq_prediction.txt    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "be18d813-67a2-4e7e-9ca3-29f3661cbe82",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_config = bigquery.LoadJobConfig(\n",
    "schema=table.schema\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bf9c75db-619f-4cf1-be6f-c63d498cc957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import to bigquery successfully  1 records\n"
     ]
    }
   ],
   "source": [
    "job_config.source_format = bigquery.SourceFormat.NEWLINE_DELIMITED_JSON\n",
    "job_config.write_disposition = bigquery.WriteDisposition.WRITE_APPEND  \n",
    "#job_config.write_disposition = bigquery.WriteDisposition.WRITE_TRUNCATE\n",
    "job = client.load_table_from_json(jsonOutput,table_id, job_config = job_config)\n",
    "if job.errors is not None:\n",
    "    print(job.error_result)\n",
    "    print(job.errors)\n",
    "else:\n",
    "    print(f\"Import to bigquery successfully  {len(jsonOutput)} records\")\n",
    "    \n",
    "#job_config.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef245de-ad6a-4315-8505-2c1fdba16af5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467828a9-b291-4816-b1a2-26e63855b046",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6116348e-3b7a-4216-9283-191c97652b7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
