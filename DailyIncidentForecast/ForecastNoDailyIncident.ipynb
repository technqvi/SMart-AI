{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cb56bd-3c45-4f45-a2fb-c33f5198d50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime,date,timedelta,timezone\n",
    "import pytz\n",
    "import json\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "\n",
    "from google.cloud import storage\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud.exceptions import NotFound\n",
    "from google.api_core.exceptions import BadRequest\n",
    "\n",
    "\n",
    "print('Tensorflow Version: ' + tensorflow.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103dd64a-6c76-4653-a504-5ba44bb56dcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8de071b2-41b2-40db-ab1d-7743faa0199f",
   "metadata": {},
   "source": [
    "# Constant & Parameter Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9d96d8-0f3e-4d1b-8a9f-22d78e226b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#today='2023-07-08' # last record of training data to predict the first movement\n",
    "today=''\n",
    "\n",
    "input_sequence_length =60\n",
    "output_sequence_length =5\n",
    "\n",
    "projectId='pongthorn'\n",
    "\n",
    "local_model_path=\"model\\Incident_60To5_E150S15B32\"\n",
    "\n",
    "model_file='Incident_60To5_E150S15B32-M0122-0723.h5'\n",
    "scaler_file='scaler_Incident_60To5_E150S15B32-M0122-0723.gz'\n",
    "scalerPred_file='scaler_pred_Incident_60To5_E150S15B32-M0122-0723.gz'\n",
    "\n",
    "\n",
    "model_id=model_file.split(\".\")[0]\n",
    "print(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e81398-c118-43c5-8a1e-68cfbd0d5ea2",
   "metadata": {},
   "source": [
    "# BigQuery Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cabd15-5e81-4075-a4a7-9aba2ebff632",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id=\"SMartDW\"\n",
    "table_data_id = f\"{projectId}.{dataset_id}.daily_incident\"\n",
    "table_id = f\"{projectId}.{dataset_id}.prediction_daily_incident\"\n",
    "\n",
    "print(table_id)\n",
    "print(table_data_id)\n",
    "\n",
    "client = bigquery.Client(project=projectId )\n",
    "\n",
    "def load_data_bq(sql:str):\n",
    " query_result=client.query(sql)\n",
    " df=query_result.to_dataframe()\n",
    " return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061a7f48-7759-48bf-8806-089595651be4",
   "metadata": {},
   "source": [
    "# Load Model  Configuration MetaData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c90459-6931-49f7-9908-aaf7e99699bc",
   "metadata": {},
   "source": [
    "# Load model and scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2765c501-77a0-45bd-8cec-1f404d31ad00",
   "metadata": {},
   "outputs": [],
   "source": [
    "objectPaht=local_model_path\n",
    "model_path=f\"{objectPaht}/{model_file}\"\n",
    "scale_input_path=f\"{objectPaht}/{scaler_file}\"\n",
    "scale_output_path=f\"{objectPaht}/{scalerPred_file}\"\n",
    "\n",
    "print(model_path)\n",
    "print(scale_input_path)\n",
    "print(scale_output_path)\n",
    "\n",
    "try:\n",
    "    print(\"Model and Scaler Object Summary\")\n",
    "    x_model = load_model(model_path)\n",
    "except Exception as ex:\n",
    "    print(str(ex))\n",
    "    raise Exception(str(ex)) \n",
    "\n",
    "try:\n",
    "    print(\"Scaler Max-Min\")\n",
    "    x_scaler = joblib.load(scale_input_path)\n",
    "    x_scalerPred=joblib.load(scale_output_path)\n",
    "\n",
    "except Exception as ex:\n",
    "    print(str(ex))\n",
    "    raise Exception(str(ex))\n",
    "\n",
    "print(\"=====================================================================================================\")\n",
    "\n",
    "print(x_model.summary())\n",
    "#(max - min) / (X.max(axis=0) - X.min(axis=0))\n",
    "print(f\"max={x_scaler.data_max_} and min={x_scaler.data_min_} and scale={x_scaler.scale_}\")\n",
    "print(f\"max={x_scalerPred.data_max_} and min={x_scalerPred.data_min_} and scale={x_scalerPred.scale_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb99063-ed8b-44a9-9bd4-6d708f755cbf",
   "metadata": {},
   "source": [
    "# Declare and Initialize TS Model Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a33b887-b266-4ff9-b2ca-a334364eb410",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_col='date'\n",
    "prediction_col=\"count_incident\"\n",
    "feature_cols=[prediction_col]\n",
    "\n",
    "nLastData=int(input_sequence_length)\n",
    "# nLastData=int(input_sequence_length*1.5)\n",
    "\n",
    "dt_imported=datetime.now()\n",
    "# dt_imported=datetime.now(timezone.utc)\n",
    "dtStr_imported=dt_imported.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(dtStr_imported)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74ce645-c4c1-4b34-a56e-fd510aa1e66f",
   "metadata": {},
   "source": [
    "# Query Fin Data from BQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efe5184-5874-4464-9b82-14a38c804285",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Check Last Record as starting point to retrive  sequence {prediction_col} over the past {input_sequence_length} day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b682d76-f7b1-45b2-92c1-78a5c0e7af38",
   "metadata": {},
   "outputs": [],
   "source": [
    "lastDate=None\n",
    "if today=='':\n",
    "    sqlLastDate=f\"\"\" select max({date_col}) as LastDate  from `{table_data_id}` \"\"\"\n",
    "\n",
    "else:\n",
    "    sqlLastDate=f\"\"\" \n",
    "    select {date_col} as LastDate  from `{table_data_id}` where {date_col}='{today}' order by datetime_imported desc limit 1\n",
    "    \"\"\"\n",
    "print(sqlLastDate)\n",
    "\n",
    "results = client.query(sqlLastDate)\n",
    "dfLastDate=results.to_dataframe()\n",
    "print(dfLastDate)\n",
    "if dfLastDate.empty:\n",
    "    print( f\"Not found {prediction_col}  at {today}\")\n",
    "    exit()\n",
    "    # return f\"Not found {prediction_col} at {today}  \"\n",
    "else:\n",
    "    lastDate=dfLastDate.iloc[0,0]\n",
    "    today=lastDate.strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "print(f\"Take incident the last {input_sequence_length} days to Forecast  over the next {output_sequence_length}  days at {today}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4835aad-60d9-4c16-b69e-7da926e9ab79",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Check whether {prediction_col} as {today} was predicted the future for the next {output_sequence_length} days\")\n",
    "\n",
    "sqlLastPred=f\"\"\"select prediction_date,pred_timestamp from `{table_id}` \n",
    "where prediction_date='{today}' order by pred_timestamp \n",
    "\"\"\"\n",
    "print(sqlLastPred)\n",
    "dfLastPred=load_data_bq(sqlLastPred)\n",
    "if dfLastPred.empty==False:\n",
    "   dfLastPred=dfLastPred.drop_duplicates(subset=['prediction_date'],keep='last') \n",
    "   print(f\"{today} has been predicted {prediction_col}\")\n",
    "   print(dfLastPred)\n",
    "   exit()\n",
    "   # return f\"Prediction price movement of {asset_name}-{prediction_col} at {today} has been predicted\"\n",
    "else:\n",
    "       print(f\"{today} has not been predicted {prediction_col} yet.\") \n",
    "       print(f\"The system is about to predict {prediction_col} shortly.\") \n",
    "       print(\"=======================================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729b0f1f-020a-4c61-a80a-0403c6ecd9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dayAgo=datetime.strptime(today,'%Y-%m-%d') +timedelta(days=-nLastData)\n",
    "print(f\"Get data from {dayAgo.strftime('%Y-%m-%d')} - {today} as input to forecast\")\n",
    "\n",
    "sql=f\"\"\"\n",
    "SELECT  *  FROM `{table_data_id}`  \n",
    "Where  {date_col} between  DATE_SUB({date_col} '{today}', INTERVAL {nLastData} DAY) \n",
    "and '{today}'  order by {date_col},datetime_imported\n",
    "\"\"\"\n",
    "print(sql)\n",
    "query_result=client.query(sql)\n",
    "df=query_result.to_dataframe()\n",
    "\n",
    "df=df.drop_duplicates(subset=[date_col],keep='last')\n",
    "df[date_col]=pd.to_datetime(df[date_col],format='%Y-%m-%d')\n",
    "df.set_index(date_col,inplace=True)\n",
    "\n",
    "print(df.info())\n",
    "print(df.head())\n",
    "print(df.tail())\n",
    "\n",
    "if df.empty==True or len(df)<input_sequence_length:\n",
    "    print(f\"There is no enough data to make prediction during {dayAgo.strftime('%Y-%m-%d')} - {today}\")\n",
    "    exit()\n",
    "    # return f\"There is no enough data to make prediction during {dayAgo.strftime('%Y-%m-%d')} - {today}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327a7a76-24a7-4f8f-82c7-836c6a3778dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.dates as mdates\n",
    "# import seaborn as sns\n",
    "\n",
    "# plt.subplots(1, 1, figsize = (20, 10),sharex=True)\n",
    "\n",
    "# ax1 = plt.subplot(2, 1, 1)\n",
    "# plt.plot(df[[prediction_col]])\n",
    "# plt.ylabel(prediction_col)\n",
    "\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e546448a-234c-49d2-9a97-346a7e62ee25",
   "metadata": {},
   "source": [
    "# Get only Feature( 1 Indicator) to Predict itself in the next N days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d29f68-fa93-42fc-903a-20ac2cc556ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Get Feature to Predict : {prediction_col} \")\n",
    "dfForPred=df[feature_cols]\n",
    "#dfForPred=dfForPred.iloc[-(input_sequence_length+1):-1,:]\n",
    "dfForPred=dfForPred.iloc[-input_sequence_length:,:]\n",
    "print(dfForPred.info())\n",
    "print(dfForPred.shape)\n",
    "\n",
    "print(dfForPred.head(10))\n",
    "print(dfForPred.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9306df85-1fb9-4e9e-9987-e42d6e2c84f5",
   "metadata": {},
   "source": [
    "# Make Pediction as Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0866a254-f643-4772-a239-9ff5621f89d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "xUnscaled=dfForPred.values #print(xUnscaled.shape)\n",
    "xScaled=x_scaler.transform(xUnscaled)\n",
    "print(xScaled.shape)\n",
    "# print(xScaled[-5:])\n",
    "\n",
    "\n",
    "xScaledToPredict= xScaled.reshape(1,input_sequence_length,len(feature_cols))\n",
    "print(xScaledToPredict.shape)\n",
    "\n",
    "yPredScaled = x_model.predict(xScaledToPredict)\n",
    "print(yPredScaled.shape, yPredScaled)\n",
    "\n",
    "yPred = x_scalerPred.inverse_transform(yPredScaled).reshape(-1, 1)\n",
    "print(yPred.shape, yPred)\n",
    "\n",
    "\n",
    "print(\"============================Summary============================\")\n",
    "print(xUnscaled.shape)\n",
    "print(yPred.shape)\n",
    "\n",
    "print(\"============================Input============================\")\n",
    "print(xUnscaled)\n",
    "print(\"============================Output============================\")\n",
    "print(yPred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a97710-b915-4d94-baec-9ffedca2ef73",
   "metadata": {},
   "source": [
    "# Build Prediction Result Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b893eae3-3adf-4eb6-815a-df7905520da6",
   "metadata": {},
   "source": [
    "## Feature Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb7d106-f6c2-47dd-99db-f764b8697e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Create indexes from Dataframe dfForPred\")\n",
    "dfFeature=pd.DataFrame(data= xUnscaled,columns=feature_cols,index=dfForPred.index)\n",
    "dfFeature['type']='feature'\n",
    "print(dfFeature.shape)\n",
    "print(dfFeature.head())\n",
    "print(dfFeature.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b51723-9516-4297-b40e-61cd1d6375e1",
   "metadata": {},
   "source": [
    "## Forecast/Preidction Value Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddda02a2-0d00-4c64-80f3-2bf42a548aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Create indexes by specifying output_sequence_length stating from get last record of DFFeature+1\")\n",
    "lastRowOfFeature=dfFeature.index.max()\n",
    "firstRowofPrediction=lastRowOfFeature+timedelta(days=1)\n",
    "datePred=pd.date_range(start=firstRowofPrediction,freq='d',periods=output_sequence_length)\n",
    "print(datePred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c1f307-5e3e-4ea5-9e3f-fe614518819c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPrediction=pd.DataFrame(data= yPred,columns=[prediction_col],index=datePred)\n",
    "dfPrediction['type']='prediction'\n",
    "dfPrediction[prediction_col]=dfPrediction[prediction_col].round(0)\n",
    "dfPrediction.index.name=date_col\n",
    "print(dfPrediction.shape)\n",
    "print(dfPrediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4f69c4-1d12-45eb-9c1e-4f46a8aff165",
   "metadata": {},
   "source": [
    "# Merge Feature and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cb9752-2bb6-4529-b134-2502e5d4d4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFeaToPred=pd.concat([dfFeature,dfPrediction])\n",
    "print(dfFeaToPred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0e321c-4fa0-4d78-8678-99b9b925a2ec",
   "metadata": {},
   "source": [
    "# Get Prepraed To ingest data into BQ , we have to create dataframe and convert to Json-Rowns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf27cb7-663b-4b63-866e-547b3a4e45e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputDF=pd.DataFrame(data=[ [today,dtStr_imported,model_id] ],columns=[\"prediction_date\",\"pred_timestamp\",\"model_id\"])\n",
    "print(outputDF.info())\n",
    "outputDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89e2d97-1f3d-41bf-9b50-e22e94ef8457",
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonOutput = json.loads(outputDF.to_json(orient = 'records'))\n",
    "for item in jsonOutput:\n",
    "    \n",
    "    dataFeaToPred=dfFeaToPred.reset_index()[[date_col,prediction_col,'type']]\n",
    "    dataFeaToPred[date_col]=dataFeaToPred[date_col].dt.strftime('%Y-%m-%d')\n",
    "    print(dataFeaToPred)\n",
    "    jsonFeaToPred= json.loads(dataFeaToPred.to_json(orient = 'records'))\n",
    "    item[\"prediction_result\"]=jsonFeaToPred\n",
    "    \n",
    " \n",
    "with open(\"incident_prediction.json\", \"w\") as outfile:\n",
    "    json.dump(jsonOutput, outfile)\n",
    "jsonOutput"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d061e560-fba8-478e-8eb3-70e2922ec302",
   "metadata": {},
   "source": [
    "# Ingest Data to BigQuery "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea798dd-a57e-44d5-bd0e-cde7f84a4158",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    table=client.get_table(table_id)\n",
    "    print(\"Table {} already exists.\".format(table_id))\n",
    "except Exception as ex :\n",
    "    print(str(ex))\n",
    "#if error  please create table and other configuration as  bq_prediction.txt    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be18d813-67a2-4e7e-9ca3-29f3661cbe82",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_config = bigquery.LoadJobConfig(\n",
    "schema=table.schema\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9c75db-619f-4cf1-be6f-c63d498cc957",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_config.source_format = bigquery.SourceFormat.NEWLINE_DELIMITED_JSON\n",
    "job_config.write_disposition = bigquery.WriteDisposition.WRITE_APPEND  \n",
    "#job_config.write_disposition = bigquery.WriteDisposition.WRITE_TRUNCATE\n",
    "job = client.load_table_from_json(jsonOutput,table_id, job_config = job_config)\n",
    "if job.errors is not None:\n",
    "    print(job.error_result)\n",
    "    print(job.errors)\n",
    "else:\n",
    "    print(f\"Import to bigquery successfully  {len(jsonOutput)} records\")\n",
    "    \n",
    "#job_config.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef245de-ad6a-4315-8505-2c1fdba16af5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467828a9-b291-4816-b1a2-26e63855b046",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6116348e-3b7a-4216-9283-191c97652b7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
