{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "164a4014-3aad-47de-9c62-911d3d5a82ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime,date,timedelta,timezone\n",
    "import calendar\n",
    "import json\n",
    "\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud.exceptions import NotFound\n",
    "from google.api_core.exceptions import BadRequest\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "70179656-b3c0-4034-b606-9e856e4b62c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "collectionDate='2023-07-09 00:10' # comment\n",
    "# uncomment and indent\n",
    "# import functions_framework\n",
    "# @functions_framework.http\n",
    "# def collect_prediction_result(request):   # run on clound function\n",
    "\n",
    "# def collect_prediction_result(collectionDate): # migrate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b906bf-b946-449a-a3a7-94c204799c86",
   "metadata": {},
   "source": [
    "# Init parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ec00a87e-4070-4933-9ee4-09b2f986649d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date to collect data on 2023-07-09 Sunday(Idx:6) at 2023-07-09 00:10:00\n",
      "week_day=6\n"
     ]
    }
   ],
   "source": [
    "model_id=\"Incident_60To5_E150S15B32-M0122-0723\"\n",
    "\n",
    "mode=1\n",
    "\n",
    "if mode==1: # Migrate to backfill data and Test \n",
    "    logDate=collectionDate\n",
    "    log_date=datetime.strptime(logDate,'%Y-%m-%d %H:%M')\n",
    "    log_timestamp=datetime.strptime(logDate,'%Y-%m-%d %H:%M')\n",
    "else: # On weekly basis\n",
    "    log_timestamp=datetime.now(timezone.utc)\n",
    "    log_date=datetime.strptime(log_timestamp.strftime('%Y-%m-%d'),'%Y-%m-%d')\n",
    "\n",
    "week_day=log_date.weekday()\n",
    "day_name=calendar.day_name[log_date.weekday()]\n",
    "\n",
    "print(f\"Date to collect data on {log_date.strftime('%Y-%m-%d')} {day_name}(Idx:{week_day}) at {log_timestamp}\")\n",
    "\n",
    "if  week_day!=6:\n",
    "    raise Exception(\"Monday is allowed  as Collection Date for forcasting result.\")   \n",
    "\n",
    "print(f\"week_day={week_day}\")\n",
    "\n",
    "genTableSchema=False\n",
    "metric_name='mae'\n",
    "\n",
    "\n",
    "date_col='date'\n",
    "genTableSchema=True\n",
    "metric_name='mae'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a40750-7bfa-4761-a618-bf8135c0616b",
   "metadata": {},
   "source": [
    "# BigQuery Setting & Configuration Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6630349a-f4ae-4673-8d01-c7a3f842ea17",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smart-data-ml.SMartDW.prediction_daily_incident\n",
      "smart-data-ml.SMartDW.daily_incident\n",
      "smart-data-ml.SMartDW.model_perfromance_daily_incident\n"
     ]
    }
   ],
   "source": [
    "\n",
    "projectId='smart-data-ml'\n",
    "dataset_id='SMartDW'\n",
    "\n",
    "table_data_id=f\"{projectId}.{dataset_id}.daily_incident\"\n",
    "table_id = f\"{projectId}.{dataset_id}.prediction_daily_incident\"\n",
    "table_perf_id= f\"{projectId}.{dataset_id}.model_perfromance_daily_incident\"\n",
    "\n",
    "print(table_id)\n",
    "print(table_data_id)\n",
    "print(table_perf_id)\n",
    "\n",
    "# client = bigquery.Client(project=projectId )\n",
    "credentials = service_account.Credentials.from_service_account_file(r'C:\\Windows\\smart-data-ml-91b6f6204773.json')\n",
    "client = bigquery.Client(credentials=credentials, project=projectId)\n",
    "\n",
    "def load_data_bq(sql:str):\n",
    "    query_result=client.query(sql)\n",
    "    df=query_result.to_dataframe()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7552d58-047a-4738-804b-490f34468b08",
   "metadata": {},
   "source": [
    "# Create Start to End Date By Getting Last Date of Week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "af8ef5bf-e1f7-4633-a265-9d57e403cc97",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection data the last  7 days :From Monday 03-07-2023 To Sunday 09-07-2023\n",
      "Convert start and end data 2023-07-03 - 2023-07-09 to string\n"
     ]
    }
   ],
   "source": [
    "# get  prev prediction  from  get end prediction to beginneg or predicton of week \n",
    "endX=log_date\n",
    "days_in_weeks=7\n",
    "startX=endX+timedelta(days=-(days_in_weeks-1))#\n",
    "print(f\"Collection data the last  {(endX-startX).days+1} days :From {startX.strftime('%A %d-%m-%Y')} To {endX.strftime('%A %d-%m-%Y')}\")\n",
    "\n",
    "endX=endX.strftime('%Y-%m-%d')\n",
    "startX=startX.strftime('%Y-%m-%d')\n",
    "\n",
    "print(f\"Convert start and end data {startX} - {endX} to string\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cafb7e6-e876-4327-9747-8d1181c39881",
   "metadata": {},
   "source": [
    "# Check where the given date collected data or not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "421f8e88-996d-41ad-8388-fae8bef117dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "select collection_timestamp from `smart-data-ml.SMartDW.model_perfromance_daily_incident`\n",
      "where date(collection_timestamp)='2023-07-09' and model_id='Incident_60To5_E150S15B32-M0122-0723'\n",
      "\n",
      "We are ready to Collect data on 2023-07-09 00:10:00\n"
     ]
    }
   ],
   "source": [
    "sqlCheck=f\"\"\"\n",
    "select collection_timestamp from `{table_perf_id}`\n",
    "where date(collection_timestamp)='{log_date.strftime('%Y-%m-%d')}' and model_id='{model_id}'\n",
    "\"\"\"\n",
    "\n",
    "print(sqlCheck)\n",
    "dfCheckDate=load_data_bq(sqlCheck)\n",
    "if  dfCheckDate.empty==False:\n",
    "    print(f\"Collection data on {log_date} for {model_id} found, no any action\")\n",
    "    # uncomment\n",
    "    #return f\"Collection data on {log_date} for {model_id} found, no any action\"\n",
    "else:\n",
    "    print(f\"We are ready to Collect data on {log_date}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8201bb-91d8-4e3e-80da-20e7d61b25ba",
   "metadata": {},
   "source": [
    "# Retrive forecasting result data to Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "001948b5-8ef8-46d7-af6e-53b2ef82ce0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================Get data from 2023-07-03====to===2023-07-09================\n",
      "1.How far in advance does model want to  make prediction\n",
      "\n",
      "    select t.pred_timestamp,t.prediction_date,t_pred.date,t_pred.count_incident\n",
      "    from  `smart-data-ml.SMartDW.prediction_daily_incident` t cross join unnest(t.prediction_result) t_pred\n",
      "    where (t.prediction_date>='2023-07-03' and  t.prediction_date<='2023-07-09')\n",
      "    and t.model_id='Incident_60To5_E150S15B32-M0122-0723' and t_pred.type='prediction'\n",
      "    order by  t.pred_timestamp,t.prediction_date,t_pred.date\n",
      "    \n",
      "output_sequence_length=10\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 10 entries, 2023-07-09 to 2023-07-14\n",
      "Data columns (total 3 columns):\n",
      " #   Column           Non-Null Count  Dtype              \n",
      "---  ------           --------------  -----              \n",
      " 0   pred_timestamp   10 non-null     datetime64[ns, UTC]\n",
      " 1   prediction_date  10 non-null     dbdate             \n",
      " 2   count_incident   10 non-null     float64            \n",
      "dtypes: datetime64[ns, UTC](1), dbdate(1), float64(1)\n",
      "memory usage: 320.0 bytes\n",
      "None\n",
      "                      pred_timestamp prediction_date  count_incident\n",
      "date                                                                \n",
      "2023-07-09 2023-07-10 02:06:47+00:00      2023-07-08             1.0\n",
      "2023-07-10 2023-07-10 02:06:47+00:00      2023-07-08             6.0\n",
      "2023-07-11 2023-07-10 02:06:47+00:00      2023-07-08             6.0\n",
      "2023-07-12 2023-07-10 02:06:47+00:00      2023-07-08             6.0\n",
      "2023-07-13 2023-07-10 02:06:47+00:00      2023-07-08             5.0\n",
      "2023-07-10 2023-07-10 06:15:11+00:00      2023-07-09             6.0\n",
      "2023-07-11 2023-07-10 06:15:11+00:00      2023-07-09             6.0\n",
      "2023-07-12 2023-07-10 06:15:11+00:00      2023-07-09             5.0\n",
      "2023-07-13 2023-07-10 06:15:11+00:00      2023-07-09             6.0\n",
      "2023-07-14 2023-07-10 06:15:11+00:00      2023-07-09             5.0\n",
      "================================================================================================\n",
      "2.Get Real Data  to compare to prediction from 2023-07-09 to 2023-07-14\n",
      "\n",
      "    select date,count_incident, datetime_imported, from `smart-data-ml.SMartDW.daily_incident` \n",
      "    where (date>='2023-07-09' and date<='2023-07-14')\n",
      "    order by datetime_imported,date\n",
      "    \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 6 entries, 2023-07-09 to 2023-07-14\n",
      "Data columns (total 2 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   count_incident     6 non-null      float64       \n",
      " 1   datetime_imported  6 non-null      datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(1)\n",
      "memory usage: 144.0 bytes\n",
      "None\n",
      "            count_incident          datetime_imported\n",
      "date                                                 \n",
      "2023-07-09             1.0 2023-07-10 06:00:06.870104\n",
      "2023-07-10             6.0 2023-07-11 06:00:08.221592\n",
      "2023-07-11             3.0 2023-07-12 06:00:08.260716\n",
      "2023-07-12             2.0 2023-07-13 06:00:08.258459\n",
      "2023-07-13             3.0 2023-07-14 06:00:07.033469\n",
      "2023-07-14             2.0 2023-07-15 06:00:08.582651\n",
      "================================================================================================\n",
      "=======================================================================\n"
     ]
    }
   ],
   "source": [
    "def get_forecasting_result_data(request):\n",
    "\n",
    "    if   request is not None:  \n",
    "        start_date=request[\"start_date\"]\n",
    "        end_date=request[\"end_date\"]\n",
    "        model_id=request[\"model_id\"]\n",
    "    else:\n",
    "        raise Exception(\"No request parameters such as start_date,end_date\")\n",
    "\n",
    "    \n",
    "    print(\"1.How far in advance does model want to  make prediction\")\n",
    "    sqlOutput=f\"\"\"\n",
    "    select t.pred_timestamp,t.prediction_date,t_pred.date,t_pred.count_incident\n",
    "    from  `{table_id}` t cross join unnest(t.prediction_result) t_pred\n",
    "    where (t.prediction_date>='{start_date}' and  t.prediction_date<='{end_date}')\n",
    "    and t.model_id='{model_id}' and t_pred.type='prediction'\n",
    "    order by  t.pred_timestamp,t.prediction_date,t_pred.date\n",
    "    \"\"\"\n",
    "    print(sqlOutput)\n",
    "    dfOutput=load_data_bq(sqlOutput)\n",
    "    dfOutput[date_col]=pd.to_datetime(dfOutput[date_col],format='%Y-%m-%d')\n",
    "    dfOutput.set_index(date_col,inplace=True)\n",
    "\n",
    "    output_sequence_length=len(dfOutput)\n",
    "    print(f\"output_sequence_length={output_sequence_length}\")\n",
    "    \n",
    "\n",
    "    print(dfOutput.info())\n",
    "    print(dfOutput)\n",
    "    print(\"================================================================================================\")\n",
    "\n",
    "    \n",
    "    #get actual data since the fist day of input and the last day of output(if covered)\n",
    "    startFinData=dfOutput.index.min().strftime('%Y-%m-%d')\n",
    "    endFindData=dfOutput.index.max().strftime('%Y-%m-%d')\n",
    "    print(f\"2.Get Real Data  to compare to prediction from {startFinData} to {endFindData}\")\n",
    "\n",
    "    sqlData=f\"\"\"\n",
    "    select {date_col},count_incident, datetime_imported, from `{table_data_id}` \n",
    "    where ({date_col}>='{startFinData}' and {date_col}<='{endFindData}')\n",
    "    order by datetime_imported,{date_col}\n",
    "    \"\"\"\n",
    "    \n",
    "    print(sqlData)\n",
    "\n",
    "    dfRealData=load_data_bq(sqlData)\n",
    "    dfRealData=dfRealData.drop_duplicates(subset=[date_col],keep='last',)\n",
    "    dfRealData[date_col]=pd.to_datetime(dfRealData[date_col],format='%Y-%m-%d')\n",
    "    dfRealData.set_index(date_col,inplace=True)\n",
    "    \n",
    "    print(dfRealData.info())\n",
    "    print(dfRealData)\n",
    "    print(\"================================================================================================\")\n",
    "\n",
    "    return {'actual_no_incident':dfRealData,'predicted_no_incident':dfOutput }\n",
    "\n",
    "\n",
    "print(f\"================Get data from {startX}====to==={endX}================\")\n",
    "request={'start_date':startX,'end_date':endX,'model_id':model_id}\n",
    "data=get_forecasting_result_data(request)\n",
    "print(f\"=======================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5051678-ffb7-4d67-be3a-da1ef00d08cb",
   "metadata": {},
   "source": [
    "# Create Predictive and Actual Value dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9785fb22-818b-499f-9fb1-85fb8063d517",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List all trading day in the week\n",
      "<DateArray>\n",
      "[datetime.date(2023, 7, 8), datetime.date(2023, 7, 9)]\n",
      "Length: 2, dtype: dbdate\n"
     ]
    }
   ],
   "source": [
    "print(\"List all trading day in the week\")\n",
    "myTradingDataList=data['predicted_no_incident']['prediction_date'].unique()\n",
    "print(myTradingDataList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "221d88e1-2cba-47ab-952d-990c5b833a62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================dfX :Actual Price========================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 6 entries, 2023-07-09 to 2023-07-14\n",
      "Data columns (total 1 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   actual_value  6 non-null      float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 96.0 bytes\n",
      "None\n",
      "            actual_value\n",
      "date                    \n",
      "2023-07-09           1.0\n",
      "2023-07-10           6.0\n",
      "2023-07-11           3.0\n",
      "2023-07-12           2.0\n",
      "2023-07-13           3.0\n",
      "2023-07-14           2.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"========================dfX :Actual Price========================\")\n",
    "dfX=data['actual_no_incident'][['count_incident']]\n",
    "dfX.columns=[f'actual_value']\n",
    "print(dfX.info())\n",
    "print(dfX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "06df24fb-f7e5-4fdc-81d0-e5ff2b537cd9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================dfPred:Predicted Price at 2023-07-08=========================\n",
      "=====================dfCompare:Join Actual price to Predicted Price=================\n",
      "        date  pred_value  actual_value prediction_date\n",
      "0 2023-07-09         1.0           1.0      2023-07-08\n",
      "1 2023-07-10         6.0           6.0      2023-07-08\n",
      "2 2023-07-11         6.0           3.0      2023-07-08\n",
      "3 2023-07-12         6.0           2.0      2023-07-08\n",
      "4 2023-07-13         5.0           3.0      2023-07-08\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Data columns (total 4 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   date             5 non-null      datetime64[ns]\n",
      " 1   pred_value       5 non-null      float64       \n",
      " 2   actual_value     5 non-null      float64       \n",
      " 3   prediction_date  5 non-null      object        \n",
      "dtypes: datetime64[ns](1), float64(2), object(1)\n",
      "memory usage: 288.0+ bytes\n",
      "None\n",
      "=========================Appended Data Joined=========================\n",
      "=========================dfPred:Predicted Price at 2023-07-09=========================\n",
      "=====================dfCompare:Join Actual price to Predicted Price=================\n",
      "        date  pred_value  actual_value prediction_date\n",
      "0 2023-07-10         6.0           6.0      2023-07-09\n",
      "1 2023-07-11         6.0           3.0      2023-07-09\n",
      "2 2023-07-12         5.0           2.0      2023-07-09\n",
      "3 2023-07-13         6.0           3.0      2023-07-09\n",
      "4 2023-07-14         5.0           2.0      2023-07-09\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Data columns (total 4 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   date             5 non-null      datetime64[ns]\n",
      " 1   pred_value       5 non-null      float64       \n",
      " 2   actual_value     5 non-null      float64       \n",
      " 3   prediction_date  5 non-null      object        \n",
      "dtypes: datetime64[ns](1), float64(2), object(1)\n",
      "memory usage: 288.0+ bytes\n",
      "None\n",
      "=========================Appended Data Joined=========================\n"
     ]
    }
   ],
   "source": [
    "dfAllForecastResult=pd.DataFrame(columns=['date','pred_value','actual_value','prediction_date'])\n",
    "# actually , we can jon without spilting data by prediction_dtate\n",
    "for date in  myTradingDataList: # trading day on giver week\n",
    "    print(f\"=========================dfPred:Predicted Price at {date}=========================\")\n",
    "    dfPred=data['predicted_no_incident'].query(\"prediction_date==@date\")[['count_incident']]\n",
    "    dfPred.columns=[f'pred_value']\n",
    "    # print(dfPred.info())\n",
    "\n",
    "    print(\"=====================dfCompare:Join Actual price to Predicted Price=================\")\n",
    "    dfCompare=pd.merge(left=dfPred,right=dfX,how='inner',right_index=True,left_index=True)\n",
    "    dfCompare.reset_index(inplace=True)   \n",
    "    dfCompare['prediction_date']=date.strftime('%Y-%m-%d')      \n",
    "    print(dfCompare) \n",
    "    print(dfCompare.info())\n",
    "\n",
    "    if len(dfCompare)>0 : # it will be join if there is at least one record to show actual vs pred\n",
    "        dfAllForecastResult= pd.concat([dfAllForecastResult,dfCompare],ignore_index=True)\n",
    "        print(f\"=========================Appended Data Joined=========================\")\n",
    "    else:\n",
    "        print(\"No Appendind Data due to no at least one record to show actual vs pred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8fb89caf-45e7-4339-be0b-12012bb96884",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================dfAllForecastResult: All Predicton Result========================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 4 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   date             10 non-null     object \n",
      " 1   pred_value       10 non-null     float64\n",
      " 2   actual_value     10 non-null     float64\n",
      " 3   prediction_date  10 non-null     object \n",
      "dtypes: float64(2), object(2)\n",
      "memory usage: 448.0+ bytes\n",
      "None\n",
      "         date  pred_value  actual_value prediction_date\n",
      "0  2023-07-09         1.0           1.0      2023-07-08\n",
      "1  2023-07-10         6.0           6.0      2023-07-08\n",
      "2  2023-07-11         6.0           3.0      2023-07-08\n",
      "3  2023-07-12         6.0           2.0      2023-07-08\n",
      "4  2023-07-13         5.0           3.0      2023-07-08\n",
      "5  2023-07-10         6.0           6.0      2023-07-09\n",
      "6  2023-07-11         6.0           3.0      2023-07-09\n",
      "7  2023-07-12         5.0           2.0      2023-07-09\n",
      "8  2023-07-13         6.0           3.0      2023-07-09\n",
      "9  2023-07-14         5.0           2.0      2023-07-09\n"
     ]
    }
   ],
   "source": [
    "print(\"========================dfAllForecastResult: All Predicton Result========================\")\n",
    "dfAllForecastResult[date_col]=dfAllForecastResult[date_col].dt.strftime('%Y-%m-%d')\n",
    "print(dfAllForecastResult.info())\n",
    "print(dfAllForecastResult)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56adbf50-b5f9-4788-a1d1-e15effc86e3f",
   "metadata": {},
   "source": [
    "# Calculate Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200bb009-2934-403c-99be-f18c8231a1cc",
   "metadata": {},
   "source": [
    "## Get sum distance between pred and actul value from prev rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7f072e08-3757-4ce5-9564-7b6c9a09ab0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prev Sum=0 and Count=0\n"
     ]
    }
   ],
   "source": [
    "sqlMetric=f\"\"\"\n",
    "with pred_actual_by_model as  \n",
    "(\n",
    "SELECT  detail.actual_value,detail.pred_value\n",
    "from `{table_perf_id}`  t\n",
    " cross join unnest(t.pred_actual_data) as detail\n",
    " where t.model_id='{model_id}' and t.collection_timestamp<'{log_timestamp}'\n",
    ")\n",
    "select COALESCE( sum(abs(x.actual_value-x.pred_value)),0) as pred_diff_actual,count(*) as no_row  from pred_actual_by_model  x\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "if genTableSchema==False:\n",
    "    print(sqlMetric)\n",
    "\n",
    "    dfMetric=load_data_bq(sqlMetric)\n",
    "    prevSum=dfMetric.iloc[0,0]\n",
    "    prevCount=dfMetric.iloc[0,1]\n",
    "\n",
    "else:  # it is used if there are something changed in table schema\n",
    "# for generating table schema\n",
    "    prevSum=0\n",
    "    prevCount=0\n",
    "\n",
    "print(f\"Prev Sum={prevSum} and Count={prevCount}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c5e088-d020-45c8-a9a8-4e9407906acd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Cal sum distance between pred and actul value from last rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7d7ffc03-db16-4c83-b897-e454134c6761",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recent Sum=21.0 and Count=10\n",
      "mae = 2.1\n"
     ]
    }
   ],
   "source": [
    "dfAllForecastResult['pred_diff_actual']=dfAllForecastResult.apply(lambda x : abs(x['pred_value']-x['actual_value']),axis=1)\n",
    "recentSum=dfAllForecastResult['pred_diff_actual'].sum()\n",
    "recentCount=len(dfAllForecastResult)\n",
    "\n",
    "dfAllForecastResult=dfAllForecastResult.drop(columns=['pred_diff_actual'])\n",
    "print(f\"Recent Sum={recentSum} and Count={recentCount}\")\n",
    "\n",
    "#https://en.wikipedia.org/wiki/Mean_absolute_error\n",
    "metric_value= round((prevSum+recentSum)/(prevCount+recentCount),2)\n",
    "print(f\"{metric_name} = {metric_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec25219-a1f1-4c3a-a018-0de174dfc669",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Create Collection Performance Info Dataframe and Store \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b9c8d3d7-abfe-4c48-b918-e37d65aea31e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1 entries, 0 to 0\n",
      "Data columns (total 5 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   collection_date       1 non-null      object \n",
      " 1   model_id              1 non-null      object \n",
      " 2   metric_name           1 non-null      object \n",
      " 3   metric_value          1 non-null      float64\n",
      " 4   collection_timestamp  1 non-null      object \n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 168.0+ bytes\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>collection_date</th>\n",
       "      <th>model_id</th>\n",
       "      <th>metric_name</th>\n",
       "      <th>metric_value</th>\n",
       "      <th>collection_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-07-09</td>\n",
       "      <td>Incident_60To5_E150S15B32-M0122-0723</td>\n",
       "      <td>mae</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2023-07-09 00:10:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  collection_date                              model_id metric_name  \\\n",
       "0      2023-07-09  Incident_60To5_E150S15B32-M0122-0723         mae   \n",
       "\n",
       "   metric_value collection_timestamp  \n",
       "0           2.1  2023-07-09 00:10:00  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masterDF=pd.DataFrame(data=[ [log_date,model_id,metric_name,metric_value,log_timestamp] ],\n",
    "                columns=[\"collection_date\",\"model_id\",\"metric_name\",\"metric_value\",\"collection_timestamp\"])\n",
    "\n",
    "masterDF[\"collection_date\"]=masterDF[\"collection_date\"].dt.strftime('%Y-%m-%d') # for json format\n",
    "masterDF[\"collection_timestamp\"]=masterDF[\"collection_timestamp\"].dt.strftime('%Y-%m-%d %H:%M:%S') # for json format\n",
    "print(masterDF.info())\n",
    "masterDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5ffae7-8549-4e7c-b919-b90ce1f920e0",
   "metadata": {},
   "source": [
    "# Create Dataframe to  Json Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c6c87e63-04de-4c19-a831-26fc21241612",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "master_perf = json.loads(masterDF.to_json(orient = 'records')) # 1 main dataframe has 1 records\n",
    "for  master in master_perf:\n",
    "    detail= json.loads(dfAllForecastResult.to_json(orient = 'records'))\n",
    "    master[\"pred_actual_data\"]=detail\n",
    "\n",
    "    \n",
    "with open(\"no_incident_forecast_performance.json\", \"w\") as outfile:\n",
    "    json.dump( master_perf, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5083681a-8987-4bea-93b2-d6d52aac936c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8bb797d-d12d-48d7-9787-384823c9ddf3",
   "metadata": {},
   "source": [
    "# Ingest Data to BigQuery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc85496-fac5-406a-a281-822cae395bf9",
   "metadata": {},
   "source": [
    "## Try to ingest data to get correct schema and copy the schema to create table including partion/cluster manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7a8fddac-312e-400e-8b55-6391b73559b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table smart-data-ml.SMartDW.prediction_daily_incident already exists.\n",
      "Import to bigquery successfully  1 records\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    table=client.get_table(table_perf_id)\n",
    "    print(\"Table {} already exists.\".format(table_id))\n",
    "    \n",
    "    job_config = bigquery.LoadJobConfig()\n",
    "    job_config.source_format = bigquery.SourceFormat.NEWLINE_DELIMITED_JSON\n",
    "    # Try to ingest data to get correct schema and copy the schema to create table including partiion/cluster manually\n",
    "    job_config.write_disposition = bigquery.WriteDisposition.WRITE_APPEND \n",
    "    job = client.load_table_from_json(master_perf,table_perf_id, job_config = job_config)\n",
    "    if job.errors is not None:\n",
    "        print(job.error_result)\n",
    "        print(job.errors)\n",
    "        # uncomment\n",
    "        # return \"Error to load data to BigQuery\"\n",
    "    else:\n",
    "        print(f\"Import to bigquery successfully  {len(master_perf)} records\")\n",
    "        # print(table.schema)\n",
    "except Exception as ex :\n",
    "    print(str(ex))\n",
    "    \n",
    "\n",
    "    \n",
    "#job_config.schema\n",
    "# truncate table`pongthorn.FinAssetForecast.model_forecast_performance` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f54298d5-6437-40ac-bbc7-ea2ff03eae6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment\n",
    "#return 'completely'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b6fa76-afff-421f-ba7a-9fb587776730",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b6e5c796-ff17-4fd3-8b33-21dfccce4321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2023-07-09 00:30', '2023-07-16 00:30', '2023-07-23 00:30', '2023-07-30 00:30', '2023-08-06 00:30', '2023-08-13 00:30', '2023-08-20 00:30', '2023-08-27 00:30', '2023-09-03 00:30']\n"
     ]
    }
   ],
   "source": [
    "start_backfill='2023-07-09 00:30' # comment\n",
    "end_backfill='2023-09-03 00:30'\n",
    "period_index=pd.date_range(start=start_backfill,end=end_backfill, freq=\"W-SUN\")\n",
    "listLogDate=[ d.strftime('%Y-%m-%d %H:%M')   for  d in  period_index   ]\n",
    "print(listLogDate)\n",
    "# uncomment\n",
    "# Main \n",
    "# print(\"Collect prediction result to monitor performance model\")\n",
    "\n",
    "# multiple items\n",
    "# listLogDate=[\n",
    "#     '2023-06-03 00:00','2023-06-10 00:00','2023-06-17 00:00','2023-06-24 00:00',\n",
    "#     '2023-07-01 00:00','2023-07-08 00:00','2023-07-15 00:00','2023-07-22 00:00','2023-07-29 00:00',\n",
    "#     '2023-08-05 00:00','2023-08-12 00:00','2023-08-19 00:00','2023-08-26 00:00','2023-09-02 00:00',\n",
    "#     ] \n",
    "# listLogDate=[\n",
    "#      '2023-08-05 00:00','2023-08-12 00:00','2023-08-19 00:00','2023-08-26 00:00','2023-09-02 00:00'\n",
    "# ]\n",
    "# for  d in listLogDate:\n",
    "#   print(f\"*******************************Collect prediction result as of {d}*****************************************\")\n",
    "#   print(collect_prediction_result(d))\n",
    "#   print(\"************************************************************************************************\")\n",
    "\n",
    "# sigle item\n",
    "# collectionDate='2023-08-26 00:00' # comment    \n",
    "# print(collect_prediction_result(collectionDate))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ee397d-ca12-4600-a26e-cb9dc4deb32c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
